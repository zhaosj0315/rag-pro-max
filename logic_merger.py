#!/usr/bin/env python3
"""
é€»è¾‘åˆå¹¶æ¸…ç†å™¨ - Phase 3
åˆå¹¶é‡å¤çš„å‡½æ•°å’Œç›¸ä¼¼çš„é€»è¾‘
"""

import os
import ast
import re
import json
from pathlib import Path
from typing import List, Dict, Set

class LogicMerger:
    """é€»è¾‘åˆå¹¶æ¸…ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.analysis_file = self.project_root / "code_cleanup_analysis.json"
        self.backup_dir = self.project_root / ".cleanup_backup_phase3"
        self.merged_functions = []
        
        # åŠ è½½åˆ†æç»“æœ
        with open(self.analysis_file, 'r', encoding='utf-8') as f:
            self.analysis_data = json.load(f)
    
    def merge_logic(self):
        """æ‰§è¡Œé€»è¾‘åˆå¹¶"""
        print("ğŸ”„ å¼€å§‹é€»è¾‘åˆå¹¶æ¸…ç†...")
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        self.backup_dir.mkdir(exist_ok=True)
        
        # 1. åˆ†æé‡å¤å‡½æ•°çš„å…·ä½“æƒ…å†µ
        self._analyze_duplicate_functions()
        
        # 2. åˆå¹¶ç®€å•çš„é‡å¤å‡½æ•°
        self._merge_simple_duplicates()
        
        # 3. ç”Ÿæˆåˆå¹¶æŠ¥å‘Š
        self._generate_merge_report()
        
        print("âœ… é€»è¾‘åˆå¹¶å®Œæˆï¼")
    
    def _analyze_duplicate_functions(self):
        """åˆ†æé‡å¤å‡½æ•°çš„å…·ä½“æƒ…å†µ"""
        print("ğŸ” åˆ†æé‡å¤å‡½æ•°...")
        
        # æŒ‰å‡½æ•°ååˆ†ç»„
        function_groups = {}
        for item in self.analysis_data['duplicate_functions']:
            func_name = item['function']
            if func_name not in function_groups:
                function_groups[func_name] = []
            function_groups[func_name].append(item)
        
        # åˆ†ææ¯ç»„å‡½æ•°
        for func_name, items in function_groups.items():
            print(f"ğŸ“‹ å‡½æ•° '{func_name}' åœ¨ {len(items)} ä¸ªä½ç½®é‡å¤")
            
            # ç‰¹æ®Šå¤„ç†å¸¸è§çš„é‡å¤å‡½æ•°
            if func_name == '__init__':
                self._analyze_init_functions(items)
            elif func_name == 'update_status':
                self._analyze_update_status_functions(items)
            elif func_name.endswith('_fragment'):
                self._analyze_fragment_functions(items)
    
    def _analyze_init_functions(self, items):
        """åˆ†æ__init__å‡½æ•°çš„é‡å¤æƒ…å†µ"""
        print("ğŸ” åˆ†æ__init__å‡½æ•°é‡å¤...")
        
        # __init__å‡½æ•°é€šå¸¸æ˜¯æ­£å¸¸çš„ï¼Œæ¯ä¸ªç±»éƒ½æœ‰è‡ªå·±çš„åˆå§‹åŒ–
        # è¿™é‡Œä¸»è¦æ£€æŸ¥æ˜¯å¦æœ‰çœŸæ­£çš„é‡å¤é€»è¾‘
        for item in items:
            files = item['files']
            if len(files) >= 2:
                # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€ä¸ªæ–‡ä»¶ä¸­é‡å¤å®šä¹‰
                if files[0] == files[1]:
                    print(f"âš ï¸ å‘ç°åŒæ–‡ä»¶å†…é‡å¤__init__: {files[0]}")
    
    def _analyze_update_status_functions(self, items):
        """åˆ†æupdate_statuså‡½æ•°çš„é‡å¤æƒ…å†µ"""
        print("ğŸ” åˆ†æupdate_statuså‡½æ•°é‡å¤...")
        
        # update_statuså‡½æ•°å¯èƒ½ç¡®å®æœ‰é‡å¤é€»è¾‘ï¼Œéœ€è¦åˆå¹¶
        for item in items:
            files = item['files']
            if len(files) >= 2:
                print(f"ğŸ“ å¯èƒ½éœ€è¦åˆå¹¶çš„update_status: {files}")
                self._check_function_similarity(files, 'update_status')
    
    def _analyze_fragment_functions(self, items):
        """åˆ†æfragmentå‡½æ•°çš„é‡å¤æƒ…å†µ"""
        print("ğŸ” åˆ†æfragmentå‡½æ•°é‡å¤...")
        
        # fragmentå‡½æ•°å¯èƒ½æœ‰ç›¸ä¼¼çš„UIé€»è¾‘
        for item in items:
            files = item['files']
            if len(files) >= 2:
                print(f"ğŸ“ å¯èƒ½éœ€è¦åˆå¹¶çš„fragment: {files}")
    
    def _check_function_similarity(self, files: List[str], func_name: str):
        """æ£€æŸ¥å‡½æ•°çš„ç›¸ä¼¼æ€§"""
        try:
            function_contents = []
            
            for file_path in files:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æå–å‡½æ•°å†…å®¹
                escaped_name = re.escape(func_name)
                pattern = rf'def\s+{escaped_name}\s*\([^)]*\):.*?(?=\n\s*def|\n\s*class|\Z)'
                matches = re.findall(pattern, content, re.DOTALL)
                if matches:
                    function_contents.append((file_path, matches[0]))
            
            # æ¯”è¾ƒå‡½æ•°å†…å®¹çš„ç›¸ä¼¼æ€§
            if len(function_contents) >= 2:
                content1 = function_contents[0][1]
                content2 = function_contents[1][1]
                
                # ç®€å•çš„ç›¸ä¼¼æ€§æ£€æŸ¥ï¼ˆå»é™¤ç©ºç™½åæ¯”è¾ƒï¼‰
                clean_content1 = re.sub(r'\s+', ' ', content1).strip()
                clean_content2 = re.sub(r'\s+', ' ', content2).strip()
                
                if clean_content1 == clean_content2:
                    print(f"ğŸ¯ å‘ç°å®Œå…¨ç›¸åŒçš„å‡½æ•°: {func_name}")
                    return True
                elif len(clean_content1) > 0 and len(clean_content2) > 0:
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    similarity = self._calculate_similarity(clean_content1, clean_content2)
                    if similarity > 0.8:
                        print(f"ğŸ¯ å‘ç°é«˜åº¦ç›¸ä¼¼çš„å‡½æ•°: {func_name} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                        return True
        
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥å‡½æ•°ç›¸ä¼¼æ€§å¤±è´¥: {e}")
        
        return False
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        # ç®€å•çš„åŸºäºå­—ç¬¦çš„ç›¸ä¼¼åº¦è®¡ç®—
        if not text1 or not text2:
            return 0.0
        
        # ä½¿ç”¨æœ€é•¿å…¬å…±å­åºåˆ—
        def lcs_length(s1, s2):
            m, n = len(s1), len(s2)
            dp = [[0] * (n + 1) for _ in range(m + 1)]
            
            for i in range(1, m + 1):
                for j in range(1, n + 1):
                    if s1[i-1] == s2[j-1]:
                        dp[i][j] = dp[i-1][j-1] + 1
                    else:
                        dp[i][j] = max(dp[i-1][j], dp[i][j-1])
            
            return dp[m][n]
        
        lcs_len = lcs_length(text1, text2)
        max_len = max(len(text1), len(text2))
        
        return lcs_len / max_len if max_len > 0 else 0.0
    
    def _merge_simple_duplicates(self):
        """åˆå¹¶ç®€å•çš„é‡å¤å‡½æ•°"""
        print("ğŸ”„ åˆå¹¶ç®€å•çš„é‡å¤å‡½æ•°...")
        
        # è¿™é‡Œå®ç°ä¿å®ˆçš„åˆå¹¶ç­–ç•¥
        # åªåˆå¹¶æ˜æ˜¾ç›¸åŒçš„å‡½æ•°ï¼Œé¿å…ç ´ååŠŸèƒ½
        
        # ç¤ºä¾‹ï¼šåˆå¹¶å®Œå…¨ç›¸åŒçš„å·¥å…·å‡½æ•°
        self._merge_identical_utility_functions()
    
    def _merge_identical_utility_functions(self):
        """åˆå¹¶å®Œå…¨ç›¸åŒçš„å·¥å…·å‡½æ•°"""
        print("ğŸ”§ åˆå¹¶å®Œå…¨ç›¸åŒçš„å·¥å…·å‡½æ•°...")
        
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„åˆå¹¶é€»è¾‘
        # ä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œå…ˆç”ŸæˆæŠ¥å‘Šï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨ç¡®è®¤
        pass
    
    def _backup_file(self, file_path: str):
        """å¤‡ä»½æ–‡ä»¶"""
        source_path = Path(file_path)
        if not source_path.exists():
            return
        
        # åˆ›å»ºå¤‡ä»½è·¯å¾„
        relative_path = source_path.relative_to(self.project_root)
        backup_path = self.backup_dir / relative_path
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        
        # å¤åˆ¶æ–‡ä»¶
        import shutil
        shutil.copy2(source_path, backup_path)
    
    def _generate_merge_report(self):
        """ç”Ÿæˆåˆå¹¶æŠ¥å‘Š"""
        report_content = f"""# é€»è¾‘åˆå¹¶æŠ¥å‘Š - Phase 3

## ğŸ“Š åˆ†ææ¦‚è§ˆ

- **é‡å¤å‡½æ•°æ€»æ•°**: {len(self.analysis_data['duplicate_functions'])}
- **å·²åˆå¹¶å‡½æ•°**: {len(self.merged_functions)}

## ğŸ” é‡å¤å‡½æ•°åˆ†æ

### å¸¸è§é‡å¤å‡½æ•°

"""
        
        # æŒ‰å‡½æ•°åç»Ÿè®¡
        function_counts = {}
        for item in self.analysis_data['duplicate_functions']:
            func_name = item['function']
            function_counts[func_name] = function_counts.get(func_name, 0) + 1
        
        # æ˜¾ç¤ºæœ€å¸¸è§çš„é‡å¤å‡½æ•°
        sorted_functions = sorted(function_counts.items(), key=lambda x: x[1], reverse=True)
        for func_name, count in sorted_functions[:10]:
            report_content += f"- `{func_name}()`: {count} æ¬¡é‡å¤\n"
        
        report_content += f"""

## ğŸ¯ å»ºè®®æ‰‹åŠ¨å¤„ç†çš„é‡å¤å‡½æ•°

### __init__ å‡½æ•°
- å¤§å¤šæ•°__init__å‡½æ•°æ˜¯æ­£å¸¸çš„ç±»åˆå§‹åŒ–ï¼Œæ— éœ€åˆå¹¶
- åªæœ‰åŒä¸€æ–‡ä»¶å†…çš„é‡å¤å®šä¹‰éœ€è¦å¤„ç†

### update_status å‡½æ•°
- å¯èƒ½å­˜åœ¨çœŸæ­£çš„é‡å¤é€»è¾‘
- å»ºè®®æ£€æŸ¥æ˜¯å¦å¯ä»¥æå–ä¸ºå…¬å…±å‡½æ•°

### fragment å‡½æ•°
- UIç»„ä»¶çš„fragmentå‡½æ•°å¯èƒ½æœ‰ç›¸ä¼¼é€»è¾‘
- å»ºè®®æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ›å»ºé€šç”¨çš„UIç»„ä»¶

## ğŸ› ï¸ ä¸‹ä¸€æ­¥å»ºè®®

1. **æ‰‹åŠ¨æ£€æŸ¥**: é€ä¸ªæ£€æŸ¥é‡å¤å‡½æ•°çš„å®é™…å†…å®¹
2. **æå–å…¬å…±é€»è¾‘**: å°†ç›¸åŒçš„é€»è¾‘æå–ä¸ºå…¬å…±å‡½æ•°
3. **åˆ›å»ºå·¥å…·ç±»**: å°†é‡å¤çš„å·¥å…·å‡½æ•°æ•´åˆåˆ°å·¥å…·ç±»ä¸­
4. **ç»Ÿä¸€æ¥å£**: ä¸ºç›¸ä¼¼åŠŸèƒ½åˆ›å»ºç»Ÿä¸€çš„æ¥å£

## âš ï¸ æ³¨æ„äº‹é¡¹

- ä¸è¦ç›²ç›®åˆå¹¶æ‰€æœ‰é‡å¤å‡½æ•°
- ç¡®ä¿åˆå¹¶åçš„é€»è¾‘ç¬¦åˆå„è‡ªçš„ä½¿ç”¨åœºæ™¯
- ä¿æŒæ¥å£çš„å‘åå…¼å®¹æ€§
- å……åˆ†æµ‹è¯•åˆå¹¶åçš„åŠŸèƒ½
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.project_root / "CLEANUP_PHASE3_REPORT.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“„ åˆå¹¶æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    merger = LogicMerger()
    merger.merge_logic()
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. æŸ¥çœ‹ CLEANUP_PHASE3_REPORT.md äº†è§£é‡å¤å‡½æ•°åˆ†æ")
    print("2. æ‰‹åŠ¨æ£€æŸ¥å’Œåˆå¹¶çœŸæ­£é‡å¤çš„é€»è¾‘")
    print("3. åˆ›å»ºå…¬å…±å·¥å…·å‡½æ•°å‡å°‘é‡å¤")
    print("4. ç»§ç»­Phase 4: ç»“æ„ä¼˜åŒ–")

if __name__ == "__main__":
    main()
