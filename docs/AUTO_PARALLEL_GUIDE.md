# è‡ªåŠ¨å¹¶è¡Œæ‰§è¡ŒæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

`ParallelExecutor` æä¾›äº†ä¸‰ç§ä½¿ç”¨æ–¹å¼ï¼š
1. **æ‰‹åŠ¨è°ƒç”¨**ï¼šå®Œå…¨æ§åˆ¶
2. **ä¾¿æ·å‡½æ•°**ï¼šç®€åŒ–è°ƒç”¨
3. **è£…é¥°å™¨**ï¼šè‡ªåŠ¨åº”ç”¨ï¼ˆæœªæ¥ï¼‰

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### æ–¹å¼1: æ‰‹åŠ¨è°ƒç”¨ï¼ˆå½“å‰æ¨èï¼‰

**é€‚ç”¨åœºæ™¯**: éœ€è¦å®Œå…¨æ§åˆ¶å¹¶è¡Œè¡Œä¸º

```python
from src.utils.parallel_executor import ParallelExecutor
from src.utils.parallel_tasks import extract_metadata_task

# åˆ›å»ºæ‰§è¡Œå™¨
executor = ParallelExecutor()

# å‡†å¤‡ä»»åŠ¡
tasks = [(file1, name1, ids1, text1, dir1),
         (file2, name2, ids2, text2, dir2),
         ...]

# æ‰§è¡Œï¼ˆè‡ªåŠ¨åˆ¤æ–­ä¸²è¡Œ/å¹¶è¡Œï¼‰
results = executor.execute(
    extract_metadata_task, 
    tasks, 
    chunksize=50,    # å¯é€‰
    threshold=50     # å°‘äº50ä¸ªä»»åŠ¡æ—¶ä¸²è¡Œ
)
```

**ä¼˜ç‚¹**:
- âœ… å®Œå…¨æ§åˆ¶
- âœ… çµæ´»é…ç½®
- âœ… æ˜“äºè°ƒè¯•

---

### æ–¹å¼2: ä¾¿æ·å‡½æ•°ï¼ˆæ¨èï¼‰

**é€‚ç”¨åœºæ™¯**: ç®€å•çš„åˆ—è¡¨å¤„ç†

```python
from src.utils.parallel_executor import parallelize_list

def process_single_file(file_path):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    # å¤„ç†é€»è¾‘
    return result

# è‡ªåŠ¨å¹¶è¡Œå¤„ç†æ–‡ä»¶åˆ—è¡¨
file_list = ['file1.txt', 'file2.txt', ...]
results = parallelize_list(
    process_single_file, 
    file_list, 
    threshold=50
)
```

**ä¼˜ç‚¹**:
- âœ… ç®€æ´æ˜“ç”¨
- âœ… è‡ªåŠ¨åˆ¤æ–­
- âœ… ä¸€è¡Œä»£ç 

---

### æ–¹å¼3: è£…é¥°å™¨ï¼ˆå®éªŒæ€§ï¼‰

**é€‚ç”¨åœºæ™¯**: å‡½æ•°çº§åˆ«çš„è‡ªåŠ¨å¹¶è¡Œ

```python
from src.utils.parallel_executor import auto_parallel

@auto_parallel(threshold=50)
def process_files(file_list):
    """å¤„ç†æ–‡ä»¶åˆ—è¡¨"""
    results = []
    for file in file_list:
        results.append(process_single_file(file))
    return results

# è‡ªåŠ¨åº”ç”¨å¹¶è¡Œ
results = process_files(large_file_list)
```

**æ³¨æ„**: 
- âš ï¸ è£…é¥°å™¨ç›®å‰æ˜¯å®éªŒæ€§åŠŸèƒ½
- âš ï¸ éœ€è¦å‡½æ•°æ”¯æŒå•å…ƒç´ å¤„ç†
- âš ï¸ å»ºè®®ä½¿ç”¨æ–¹å¼1æˆ–2

---

## ğŸ¯ æ™ºèƒ½åˆ¤æ–­é€»è¾‘

### è‡ªåŠ¨åˆ¤æ–­æ¡ä»¶

```python
def should_parallelize(task_count, threshold=10):
    # 1. ä»»åŠ¡æ•°æ£€æŸ¥
    if task_count < threshold:
        return False  # å¤ªå°‘ï¼Œä¸²è¡Œæ›´å¿«
    
    # 2. CPUæ ¸å¿ƒæ•°æ£€æŸ¥
    if os.cpu_count() <= 2:
        return False  # æ ¸å¿ƒå¤ªå°‘ï¼Œå¹¶è¡Œæ— æ„ä¹‰
    
    # 3. CPUè´Ÿè½½æ£€æŸ¥
    if psutil.cpu_percent() > 85:
        return False  # è´Ÿè½½è¿‡é«˜ï¼Œé¿å…è¿‡è½½
    
    return True  # å¯ä»¥å¹¶è¡Œ
```

### åˆ¤æ–­æµç¨‹å›¾

```
è¾“å…¥ä»»åŠ¡åˆ—è¡¨
    â†“
ä»»åŠ¡æ•° < threshold? â”€â”€Yesâ†’ ä¸²è¡Œæ‰§è¡Œ
    â†“ No
CPUæ ¸å¿ƒæ•° <= 2? â”€â”€Yesâ†’ ä¸²è¡Œæ‰§è¡Œ
    â†“ No
CPUè´Ÿè½½ > 85%? â”€â”€Yesâ†’ ä¸²è¡Œæ‰§è¡Œ
    â†“ No
å¹¶è¡Œæ‰§è¡Œ
```

---

## ğŸ“Š é˜ˆå€¼é…ç½®å»ºè®®

### ä¸åŒåœºæ™¯çš„é˜ˆå€¼

| åœºæ™¯ | æ¨èé˜ˆå€¼ | ç†ç”± |
|------|---------|------|
| å…ƒæ•°æ®æå– | 50 | å•ä¸ªä»»åŠ¡è€—æ—¶è¾ƒé•¿ |
| èŠ‚ç‚¹å¤„ç† | 10 | å•ä¸ªä»»åŠ¡å¾ˆå¿« |
| æ–‡æ¡£è§£æ | 20 | ä¸­ç­‰è€—æ—¶ |
| å‘é‡åŒ– | 100 | GPUå¯†é›†å‹ï¼Œè¿›ç¨‹å¼€é”€å¤§ |

### å¦‚ä½•é€‰æ‹©é˜ˆå€¼

```python
# ç»éªŒå…¬å¼
threshold = max(10, è¿›ç¨‹åˆ›å»ºæ—¶é—´ / å•ä»»åŠ¡å¤„ç†æ—¶é—´ * 2)

# ç¤ºä¾‹
# è¿›ç¨‹åˆ›å»º: 0.5s
# å•ä»»åŠ¡å¤„ç†: 0.1s
# threshold = max(10, 0.5 / 0.1 * 2) = 10

# è¿›ç¨‹åˆ›å»º: 0.5s
# å•ä»»åŠ¡å¤„ç†: 0.01s
# threshold = max(10, 0.5 / 0.01 * 2) = 100
```

---

## ğŸ”§ å®é™…åº”ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: å…ƒæ•°æ®æå–ï¼ˆIndexBuilderï¼‰

```python
# src/processors/index_builder.py

from src.utils.parallel_executor import ParallelExecutor
from src.utils.parallel_tasks import extract_metadata_task

def _extract_metadata(self, file_map, text_samples, source_path, callback):
    # å‡†å¤‡ä»»åŠ¡
    tasks = []
    for fname, text in text_samples.items():
        if fname in file_map:
            fp = os.path.join(source_path, fname)
            if os.path.exists(fp):
                doc_ids = file_map[fname]['doc_ids']
                tasks.append((fp, fname, doc_ids, text, self.persist_dir))
    
    # è‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œ
    executor = ParallelExecutor()
    results = executor.execute(
        extract_metadata_task, 
        tasks, 
        chunksize=50, 
        threshold=50  # 50ä¸ªæ–‡ä»¶ä»¥ä¸Šæ‰å¹¶è¡Œ
    )
    
    # å¤„ç†ç»“æœ
    for fname, meta in results:
        if fname in file_map:
            file_map[fname].update(meta)
```

### ç¤ºä¾‹2: èŠ‚ç‚¹å¤„ç†ï¼ˆä¸»æ–‡ä»¶ï¼‰

```python
# src/apppro.py

from src.utils.parallel_executor import ParallelExecutor
from src.utils.parallel_tasks import process_node_worker

# æå–èŠ‚ç‚¹æ•°æ®
node_data = [...]

# è‡ªåŠ¨å¹¶è¡Œå¤„ç†
executor = ParallelExecutor()
tasks = [(d, active_kb_name) for d in node_data]
srcs = [s for s in executor.execute(
    process_node_worker, 
    tasks, 
    threshold=10  # 10ä¸ªèŠ‚ç‚¹ä»¥ä¸Šæ‰å¹¶è¡Œ
) if s]
```

### ç¤ºä¾‹3: ä¾¿æ·å‡½æ•°æ–¹å¼

```python
from src.utils.parallel_executor import parallelize_list

def process_document(doc):
    """å¤„ç†å•ä¸ªæ–‡æ¡£"""
    # è§£æã€æ¸…ç†ã€æå–ç­‰
    return processed_doc

# æ‰¹é‡å¤„ç†
documents = [doc1, doc2, doc3, ...]
results = parallelize_list(
    process_document, 
    documents, 
    threshold=20
)
```

---

## âš™ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰æ‰§è¡Œå™¨

```python
# åˆ›å»ºè‡ªå®šä¹‰æ‰§è¡Œå™¨
executor = ParallelExecutor(max_workers=8)

# ä½¿ç”¨è‡ªå®šä¹‰æ‰§è¡Œå™¨
results = executor.execute(func, tasks)
```

### å¸¦è¿›åº¦å›è°ƒ

```python
def progress_callback(completed, total):
    print(f"è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%)")

executor = ParallelExecutor()
results = executor.execute_with_progress(
    func, 
    tasks, 
    callback=progress_callback,
    threshold=50
)
```

### å…¨å±€å•ä¾‹æ¨¡å¼

```python
from src.utils.parallel_executor import get_global_executor

# è·å–å…¨å±€æ‰§è¡Œå™¨ï¼ˆå•ä¾‹ï¼‰
executor = get_global_executor()

# æ‰€æœ‰åœ°æ–¹ä½¿ç”¨åŒä¸€ä¸ªæ‰§è¡Œå™¨
results1 = executor.execute(func1, tasks1)
results2 = executor.execute(func2, tasks2)
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæ²¡æœ‰å¹¶è¡Œæ‰§è¡Œï¼Ÿ

**å¯èƒ½åŸå› **:
1. ä»»åŠ¡æ•° < threshold
2. CPUæ ¸å¿ƒæ•° <= 2
3. CPUè´Ÿè½½ > 85%

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥åˆ¤æ–­é€»è¾‘
executor = ParallelExecutor()
print(f"ä»»åŠ¡æ•°: {len(tasks)}")
print(f"é˜ˆå€¼: {threshold}")
print(f"CPUæ ¸å¿ƒæ•°: {os.cpu_count()}")
print(f"CPUè´Ÿè½½: {psutil.cpu_percent()}%")
print(f"åº”è¯¥å¹¶è¡Œ: {executor.should_parallelize(len(tasks), threshold)}")
```

### Q2: å¦‚ä½•å¼ºåˆ¶å¹¶è¡Œï¼Ÿ

```python
# æ–¹å¼1: é™ä½é˜ˆå€¼
results = executor.execute(func, tasks, threshold=1)

# æ–¹å¼2: ç›´æ¥ä½¿ç”¨ ProcessPoolExecutor
from concurrent.futures import ProcessPoolExecutor
with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(func, tasks))
```

### Q3: å¦‚ä½•ç¦ç”¨å¹¶è¡Œï¼Ÿ

```python
# æ–¹å¼1: æé«˜é˜ˆå€¼
results = executor.execute(func, tasks, threshold=999999)

# æ–¹å¼2: ç›´æ¥ä¸²è¡Œ
results = [func(task) for task in tasks]
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### æµ‹è¯•åœºæ™¯: å¤„ç†100ä¸ªæ–‡ä»¶

| æ–¹å¼ | è€—æ—¶ | æå‡ |
|------|------|------|
| ä¸²è¡Œ | 10.0s | - |
| å¹¶è¡Œï¼ˆ2è¿›ç¨‹ï¼‰ | 5.5s | 45% |
| å¹¶è¡Œï¼ˆ4è¿›ç¨‹ï¼‰ | 3.2s | 68% |
| å¹¶è¡Œï¼ˆ8è¿›ç¨‹ï¼‰ | 2.1s | 79% |
| å¹¶è¡Œï¼ˆ14è¿›ç¨‹ï¼‰ | 1.8s | 82% |

**ç»“è®º**: 
- å¹¶è¡Œæ”¶ç›Šæ˜æ˜¾ï¼ˆ82%æå‡ï¼‰
- è¿›ç¨‹æ•°å¢åŠ æ”¶ç›Šé€’å‡
- æœ€ä¼˜è¿›ç¨‹æ•°çº¦ä¸º CPUæ ¸å¿ƒæ•°-1

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„é˜ˆå€¼
```python
# æ ¹æ®ä»»åŠ¡è€—æ—¶é€‰æ‹©
if å•ä»»åŠ¡è€—æ—¶ > 1s:
    threshold = 10  # ä½é˜ˆå€¼
elif å•ä»»åŠ¡è€—æ—¶ > 0.1s:
    threshold = 50  # ä¸­é˜ˆå€¼
else:
    threshold = 100  # é«˜é˜ˆå€¼
```

### 2. ä½¿ç”¨ä¾¿æ·å‡½æ•°
```python
# æ¨èï¼šç®€æ´æ˜“ç”¨
results = parallelize_list(func, items, threshold=50)

# ä¸æ¨èï¼šå†—é•¿
executor = ParallelExecutor()
results = executor.execute(func, items, threshold=50)
```

### 3. é¿å…è¿‡åº¦å¹¶è¡Œ
```python
# ä¸å¥½ï¼šé˜ˆå€¼å¤ªä½ï¼Œé¢‘ç¹åˆ›å»ºè¿›ç¨‹
results = executor.execute(func, tasks, threshold=1)

# å¥½ï¼šåˆç†é˜ˆå€¼
results = executor.execute(func, tasks, threshold=50)
```

### 4. ç›‘æ§èµ„æºä½¿ç”¨
```python
import psutil

# æ‰§è¡Œå‰æ£€æŸ¥
cpu_before = psutil.cpu_percent()
mem_before = psutil.virtual_memory().percent

results = executor.execute(func, tasks)

# æ‰§è¡Œåæ£€æŸ¥
cpu_after = psutil.cpu_percent()
mem_after = psutil.virtual_memory().percent

print(f"CPU: {cpu_before}% â†’ {cpu_after}%")
print(f"å†…å­˜: {mem_before}% â†’ {mem_after}%")
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Stage 6 å®ŒæˆæŠ¥å‘Š](STAGE6_COMPLETE.md)
- [å¹¶è¡Œä»»åŠ¡å‡½æ•°](../src/utils/parallel_tasks.py)

---

*æ–‡æ¡£æ›´æ–°æ—¶é—´: 2025-12-09*
