# 🔍 关键词搜索逻辑修复说明

## 🚫 **修复前的问题**

### **错误逻辑**:
- 每次搜索遍历**所有10个网站**
- 每个网站都爬取**完整的设定页数**
- 深度2，每层20页 = 每个网站40页 × 10个网站 = **400页**
- 用户设置"总页数20"，实际爬取200-400页

### **用户困惑**:
- 设置深度2×2，期望总共6页
- 实际爬取几百页，耗时很长
- 不符合"关键词搜索"的预期

## ✅ **修复后的逻辑**

### **智能网站选择**:
- 不再遍历所有网站
- **智能选择2-3个最相关的网站**
- 根据行业和关键词匹配度选择

### **页数智能分配**:
- 用户设置"总页数20" = 真正的总页数20
- 智能分配到选中的网站：20页 ÷ 3个网站 = 每个网站约7页
- 深度2 = 第一层爬取，第二层扩展

### **搜索流程优化**:
```
用户输入: 关键词"Python编程" + 总页数20 + 深度2
↓
系统选择: 菜鸟教程、Python文档、阿里云 (3个最相关网站)
↓
页数分配: 每个网站分配 20÷3 ≈ 7页
↓
实际爬取: 3个网站 × 7页 = 21页 (接近用户预期)
```

## 📊 **修复对比**

| 项目 | 修复前 | 修复后 |
|------|--------|--------|
| **网站数量** | 10个全部 | 2-3个智选 |
| **页数逻辑** | 每个网站N页 | 总共N页分配 |
| **实际页数** | 设置20→爬取200+ | 设置20→爬取~20 |
| **搜索精度** | 广撒网 | 精准匹配 |
| **爬取时间** | 很长 | 合理 |

## 🎯 **新的参数说明**

### **界面更新**:
- ✅ "每层页数" → "总页数"
- ✅ "每个网站X页" → "所有网站总共X页"
- ✅ 添加智能分配说明

### **用户体验**:
- 🎯 **更精准**: 只在最相关的网站搜索
- ⚡ **更快速**: 页数可控，时间可预期
- 🎨 **更智能**: 根据关键词自动选择网站

## 🚀 **智能选择算法**

### **网站选择策略**:
1. **技术开发**: 菜鸟教程、Python文档、阿里云
2. **金融财经**: 东方财富、雪球、央行
3. **教育培训**: 中国大学MOOC、学堂在线、网易公开课
4. **其他行业**: 选择该行业前3个权威网站

### **页数分配策略**:
```python
# 智能分配算法
selected_sites = top_3_relevant_sites  # 选择最相关的3个网站
pages_per_site = max(1, total_pages // len(selected_sites))  # 平均分配
```

## 💡 **使用建议**

### **最佳实践**:
- **总页数**: 建议10-50页，既能获得足够内容又不会太慢
- **递归深度**: 建议2-3层，平衡内容丰富度和爬取时间
- **关键词**: 使用具体的专业术语，提高匹配精度

### **预期效果**:
- 设置20页 → 实际爬取18-22页 ✅
- 设置深度2 → 真正按2层递归 ✅
- 搜索"Python" → 只在编程相关网站搜索 ✅

## 🔧 **技术实现**

### **核心代码变更**:
```python
# 修复前
for site in all_sites:  # 遍历所有10个网站
    crawl(site, max_pages)  # 每个网站爬取完整页数

# 修复后  
selected_sites = smart_select(keyword, top_3)  # 智能选择3个网站
pages_per_site = total_pages // len(selected_sites)  # 分配页数
for site in selected_sites:
    crawl(site, pages_per_site)  # 每个网站爬取分配的页数
```

---
**修复时间**: 2025-12-15 16:10  
**影响版本**: v2.3.1+  
**修复状态**: ✅ 完成
