#!/usr/bin/env python3
"""
å®æ—¶çˆ¬è™«ç›‘æ§
æ˜¾ç¤ºå½“å‰æ­£åœ¨çˆ¬å–çš„URLå’Œè¿›åº¦
"""

import os
import time
import json
from pathlib import Path
from datetime import datetime

def monitor_crawl_progress():
    """ç›‘æ§çˆ¬å–è¿›åº¦"""
    print("ğŸ” RAG Pro Max çˆ¬è™«ç›‘æ§")
    print("=" * 50)
    
    # ç›‘æ§ä¸´æ—¶æ–‡ä»¶å¤¹
    temp_dir = Path("temp_uploads")
    
    while True:
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„çˆ¬å–ä¼šè¯
            crawl_dirs = []
            if temp_dir.exists():
                for item in temp_dir.iterdir():
                    if item.is_dir() and item.name.startswith("Search_"):
                        crawl_dirs.append(item)
            
            if not crawl_dirs:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ” ç­‰å¾…çˆ¬å–ä»»åŠ¡...")
                time.sleep(2)
                continue
            
            # è·å–æœ€æ–°çš„çˆ¬å–ç›®å½•
            latest_dir = max(crawl_dirs, key=lambda x: x.stat().st_mtime)
            
            # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
            files = list(latest_dir.glob("*.txt"))
            file_count = len(files)
            
            # è·å–æœ€æ–°æ–‡ä»¶
            if files:
                latest_file = max(files, key=lambda x: x.stat().st_mtime)
                latest_time = datetime.fromtimestamp(latest_file.stat().st_mtime)
                
                # å°è¯•è¯»å–æ–‡ä»¶å†…å®¹è·å–URLä¿¡æ¯
                try:
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # æå–URLï¼ˆå‡è®¾æ–‡ä»¶å¼€å¤´æœ‰URLä¿¡æ¯ï¼‰
                    lines = content.split('\n')
                    url_info = "æœªçŸ¥URL"
                    for line in lines[:5]:  # æ£€æŸ¥å‰5è¡Œ
                        if 'http' in line:
                            url_info = line.strip()
                            break
                    
                    print(f"\r[{datetime.now().strftime('%H:%M:%S')}] ğŸ“ {latest_dir.name} | ğŸ“„ {file_count} ä¸ªæ–‡ä»¶ | ğŸ”— æœ€æ–°: {url_info[:80]}...", end="")
                    
                except Exception:
                    print(f"\r[{datetime.now().strftime('%H:%M:%S')}] ğŸ“ {latest_dir.name} | ğŸ“„ {file_count} ä¸ªæ–‡ä»¶ | â° {latest_time.strftime('%H:%M:%S')}", end="")
            else:
                print(f"\r[{datetime.now().strftime('%H:%M:%S')}] ğŸ“ {latest_dir.name} | ğŸ“„ 0 ä¸ªæ–‡ä»¶ | ğŸ” å‡†å¤‡ä¸­...", end="")
            
            time.sleep(1)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")
            break
        except Exception as e:
            print(f"\nâŒ ç›‘æ§é”™è¯¯: {e}")
            time.sleep(2)

def show_crawl_stats():
    """æ˜¾ç¤ºçˆ¬å–ç»Ÿè®¡"""
    print("\nğŸ“Š çˆ¬å–ç»Ÿè®¡ä¿¡æ¯")
    print("-" * 30)
    
    # æ£€æŸ¥çˆ¬å–ç»Ÿè®¡æ–‡ä»¶
    stats_file = Path("app_logs/crawl_stats.json")
    if stats_file.exists():
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)
            
            if stats:
                latest_session = stats[-1]
                print(f"ğŸ“… æœ€æ–°ä¼šè¯: {latest_session.get('session_id', 'N/A')}")
                print(f"ğŸ• å¼€å§‹æ—¶é—´: {latest_session.get('start_time', 'N/A')}")
                print(f"ğŸ“„ æ€»URLæ•°: {latest_session.get('total_urls', 0)}")
                print(f"âœ… æˆåŠŸ: {latest_session.get('successful_urls', 0)}")
                print(f"âŒ å¤±è´¥: {latest_session.get('failed_urls', 0)}")
                print(f"ğŸ“Š æˆåŠŸç‡: {latest_session.get('total_urls', 0) and (latest_session.get('successful_urls', 0) / latest_session.get('total_urls', 1) * 100):.1f}%")
            else:
                print("ğŸ“„ æš‚æ— ç»Ÿè®¡æ•°æ®")
                
        except Exception as e:
            print(f"âŒ è¯»å–ç»Ÿè®¡å¤±è´¥: {e}")
    else:
        print("ğŸ“„ ç»Ÿè®¡æ–‡ä»¶ä¸å­˜åœ¨")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "stats":
        show_crawl_stats()
    else:
        try:
            monitor_crawl_progress()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")

if __name__ == "__main__":
    main()
