"""
å¢å¼ºçš„æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿
"""

import time
import psutil
import torch
import streamlit as st
from datetime import datetime, timedelta
from typing import Dict, List, Any

class PerformanceDashboard:
    """å®æ—¶æ€§èƒ½ä»ªè¡¨æ¿"""
    
    def __init__(self):
        self.metrics_history = []
        self.max_history = 100
        
    def collect_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        # CPUæŒ‡æ ‡
        cpu_percent = psutil.cpu_percent(interval=0.1)
        cpu_per_core = psutil.cpu_percent(percpu=True)
        
        # å†…å­˜æŒ‡æ ‡
        memory = psutil.virtual_memory()
        
        # GPUæŒ‡æ ‡
        gpu_metrics = {"available": False}
        if torch.backends.mps.is_available():
            try:
                gpu_metrics = {
                    "available": True,
                    "allocated_mb": torch.mps.driver_allocated_memory() / (1024**2),
                    "cached_mb": torch.mps.driver_allocated_memory() / (1024**2)
                }
            except:
                pass
        
        # ç£ç›˜æŒ‡æ ‡
        disk = psutil.disk_usage('/')
        
        metrics = {
            "timestamp": datetime.now(),
            "cpu_percent": cpu_percent,
            "cpu_per_core": cpu_per_core,
            "memory_percent": memory.percent,
            "memory_used_gb": memory.used / (1024**3),
            "memory_total_gb": memory.total / (1024**3),
            "disk_percent": disk.percent,
            "gpu": gpu_metrics
        }
        
        # ä¿å­˜å†å²
        self.metrics_history.append(metrics)
        if len(self.metrics_history) > self.max_history:
            self.metrics_history.pop(0)
        
        return metrics
    
    def display_realtime_metrics(self):
        """æ˜¾ç¤ºå®æ—¶æŒ‡æ ‡"""
        metrics = self.collect_metrics()
        
        st.subheader("ğŸ”¥ å®æ—¶æ€§èƒ½ç›‘æ§")
        
        # ä¸»è¦æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            cpu_color = "red" if metrics["cpu_percent"] > 80 else "orange" if metrics["cpu_percent"] > 60 else "green"
            st.metric("CPUä½¿ç”¨ç‡", f"{metrics['cpu_percent']:.1f}%", 
                     delta_color=cpu_color)
        
        with col2:
            mem_color = "red" if metrics["memory_percent"] > 85 else "orange" if metrics["memory_percent"] > 70 else "green"
            st.metric("å†…å­˜ä½¿ç”¨", f"{metrics['memory_percent']:.1f}%",
                     f"{metrics['memory_used_gb']:.1f}GB")
        
        with col3:
            if metrics["gpu"]["available"]:
                st.metric("GPUå†…å­˜", f"{metrics['gpu']['allocated_mb']:.0f}MB")
            else:
                st.metric("GPU", "ä¸å¯ç”¨")
        
        with col4:
            disk_color = "red" if metrics["disk_percent"] > 90 else "orange" if metrics["disk_percent"] > 80 else "green"
            st.metric("ç£ç›˜ä½¿ç”¨", f"{metrics['disk_percent']:.1f}%")
        
        # CPUæ ¸å¿ƒè¯¦æƒ…
        if st.checkbox("æ˜¾ç¤ºCPUæ ¸å¿ƒè¯¦æƒ…"):
            st.write("**CPUæ ¸å¿ƒä½¿ç”¨ç‡:**")
            cores_per_row = 4
            for i in range(0, len(metrics["cpu_per_core"]), cores_per_row):
                cols = st.columns(cores_per_row)
                for j, col in enumerate(cols):
                    if i + j < len(metrics["cpu_per_core"]):
                        core_usage = metrics["cpu_per_core"][i + j]
                        col.metric(f"æ ¸å¿ƒ {i+j}", f"{core_usage:.1f}%")
    
    def display_performance_trends(self):
        """æ˜¾ç¤ºæ€§èƒ½è¶‹åŠ¿"""
        if len(self.metrics_history) < 2:
            st.info("æ”¶é›†æ•°æ®ä¸­ï¼Œè¯·ç¨å€™...")
            return
        
        st.subheader("ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿")
        
        # å‡†å¤‡æ•°æ®
        timestamps = [m["timestamp"] for m in self.metrics_history[-20:]]
        cpu_data = [m["cpu_percent"] for m in self.metrics_history[-20:]]
        memory_data = [m["memory_percent"] for m in self.metrics_history[-20:]]
        
        # ç®€å•çš„æ–‡æœ¬å›¾è¡¨
        st.write("**æœ€è¿‘20æ¬¡é‡‡æ ·:**")
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("CPUä½¿ç”¨ç‡è¶‹åŠ¿:")
            for i, (ts, cpu) in enumerate(zip(timestamps[-5:], cpu_data[-5:])):
                bar_length = int(cpu / 5)  # ç¼©æ”¾åˆ°20å­—ç¬¦
                bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
                st.text(f"{ts.strftime('%H:%M:%S')} {bar} {cpu:.1f}%")
        
        with col2:
            st.write("å†…å­˜ä½¿ç”¨ç‡è¶‹åŠ¿:")
            for i, (ts, mem) in enumerate(zip(timestamps[-5:], memory_data[-5:])):
                bar_length = int(mem / 5)
                bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
                st.text(f"{ts.strftime('%H:%M:%S')} {bar} {mem:.1f}%")
    
    def display_benchmark_results(self):
        """æ˜¾ç¤ºåŸºå‡†æµ‹è¯•ç»“æœ"""
        st.subheader("ğŸƒ æ€§èƒ½åŸºå‡†")
        
        if st.button("è¿è¡ŒåŸºå‡†æµ‹è¯•"):
            with st.spinner("è¿è¡ŒåŸºå‡†æµ‹è¯•..."):
                results = self.run_benchmark()
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("CPUè®¡ç®—", f"{results['cpu_score']:.0f} ops/s")
                with col2:
                    st.metric("å†…å­˜å¸¦å®½", f"{results['memory_score']:.0f} MB/s")
                with col3:
                    if results['gpu_score'] > 0:
                        st.metric("GPUè®¡ç®—", f"{results['gpu_score']:.0f} ops/s")
                    else:
                        st.metric("GPU", "ä¸å¯ç”¨")
    
    def run_benchmark(self) -> Dict[str, float]:
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        results = {"cpu_score": 0, "memory_score": 0, "gpu_score": 0}
        
        # CPUåŸºå‡†æµ‹è¯•
        start_time = time.time()
        total = sum(i * i for i in range(100000))
        cpu_time = time.time() - start_time
        results["cpu_score"] = 100000 / cpu_time if cpu_time > 0 else 0
        
        # å†…å­˜åŸºå‡†æµ‹è¯•
        start_time = time.time()
        data = [i for i in range(1000000)]
        memory_time = time.time() - start_time
        results["memory_score"] = len(data) * 4 / (1024 * 1024) / memory_time if memory_time > 0 else 0
        
        # GPUåŸºå‡†æµ‹è¯•
        if torch.backends.mps.is_available():
            try:
                start_time = time.time()
                x = torch.randn(1000, 1000, device='mps')
                y = torch.mm(x, x)
                torch.mps.synchronize()
                gpu_time = time.time() - start_time
                results["gpu_score"] = 1000000 / gpu_time if gpu_time > 0 else 0
            except:
                pass
        
        return results

# å…¨å±€æ€§èƒ½ä»ªè¡¨æ¿
performance_dashboard = PerformanceDashboard()
