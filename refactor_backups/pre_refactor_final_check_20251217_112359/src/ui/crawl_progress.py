"""
çˆ¬è™«è¿›åº¦å¯è§†åŒ–ç»„ä»¶
"""

import streamlit as st
import time
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
from typing import Dict, List

class CrawlProgressMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.stats = {
            'total_urls': 0,
            'crawled_urls': 0,
            'failed_urls': 0,
            'duplicate_content': 0,
            'robots_blocked': 0,
            'bytes_downloaded': 0,
            'current_depth': 0,
            'max_depth': 0
        }
        self.timeline = []
        
    def update_stats(self, **kwargs):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        for key, value in kwargs.items():
            if key in self.stats:
                self.stats[key] = value
        
        # è®°å½•æ—¶é—´çº¿
        self.timeline.append({
            'timestamp': time.time(),
            'crawled': self.stats['crawled_urls'],
            'failed': self.stats['failed_urls']
        })
    
    def render_progress_dashboard(self):
        """æ¸²æŸ“è¿›åº¦ä»ªè¡¨æ¿"""
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        elapsed_time = time.time() - self.start_time
        success_rate = (self.stats['crawled_urls'] / max(self.stats['total_urls'], 1)) * 100
        crawl_speed = self.stats['crawled_urls'] / max(elapsed_time / 60, 0.1)  # é¡µé¢/åˆ†é’Ÿ
        
        # é¡¶éƒ¨æŒ‡æ ‡å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "æˆåŠŸçˆ¬å–", 
                f"{self.stats['crawled_urls']}", 
                f"+{self.stats['crawled_urls'] - self.stats.get('prev_crawled', 0)}"
            )
        
        with col2:
            st.metric(
                "æˆåŠŸç‡", 
                f"{success_rate:.1f}%",
                f"{success_rate - 90:.1f}%" if success_rate < 90 else "ä¼˜ç§€"
            )
        
        with col3:
            st.metric(
                "çˆ¬å–é€Ÿåº¦", 
                f"{crawl_speed:.1f} é¡µ/åˆ†é’Ÿ",
                "ğŸš€" if crawl_speed > 10 else "ğŸ“ˆ"
            )
        
        with col4:
            st.metric(
                "æ•°æ®é‡", 
                f"{self.stats['bytes_downloaded'] / 1024 / 1024:.1f} MB",
                f"æ·±åº¦ {self.stats['current_depth']}/{self.stats['max_depth']}"
            )
        
        # è¿›åº¦æ¡
        if self.stats['total_urls'] > 0:
            progress = self.stats['crawled_urls'] / self.stats['total_urls']
            st.progress(progress)
            st.caption(f"æ€»è¿›åº¦: {self.stats['crawled_urls']}/{self.stats['total_urls']} ({progress*100:.1f}%)")
        
        # å®æ—¶å›¾è¡¨
        if len(self.timeline) > 1:
            self.render_realtime_chart()
        
        # è¯¦ç»†ç»Ÿè®¡
        self.render_detailed_stats()
    
    def render_realtime_chart(self):
        """æ¸²æŸ“å®æ—¶å›¾è¡¨"""
        df = pd.DataFrame(self.timeline)
        df['time_elapsed'] = (df['timestamp'] - self.start_time) / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('çˆ¬å–è¿›åº¦', 'æˆåŠŸ/å¤±è´¥è¶‹åŠ¿'),
            vertical_spacing=0.1
        )
        
        # çˆ¬å–è¿›åº¦çº¿
        fig.add_trace(
            go.Scatter(
                x=df['time_elapsed'], 
                y=df['crawled'],
                mode='lines+markers',
                name='æˆåŠŸçˆ¬å–',
                line=dict(color='green', width=2)
            ),
            row=1, col=1
        )
        
        # å¤±è´¥è¶‹åŠ¿
        fig.add_trace(
            go.Scatter(
                x=df['time_elapsed'], 
                y=df['failed'],
                mode='lines+markers',
                name='å¤±è´¥',
                line=dict(color='red', width=2)
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            height=400,
            showlegend=True,
            title_text="å®æ—¶çˆ¬å–ç›‘æ§"
        )
        
        fig.update_xaxes(title_text="æ—¶é—´ (åˆ†é’Ÿ)")
        fig.update_yaxes(title_text="é¡µé¢æ•°é‡")
        
        st.plotly_chart(fig, use_container_width=True)
    
    def render_detailed_stats(self):
        """æ¸²æŸ“è¯¦ç»†ç»Ÿè®¡"""
        with st.expander("ğŸ“Š è¯¦ç»†ç»Ÿè®¡", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("çˆ¬å–ç»Ÿè®¡")
                st.write(f"â€¢ æ€»URLæ•°: {self.stats['total_urls']}")
                st.write(f"â€¢ æˆåŠŸçˆ¬å–: {self.stats['crawled_urls']}")
                st.write(f"â€¢ å¤±è´¥æ•°é‡: {self.stats['failed_urls']}")
                st.write(f"â€¢ é‡å¤å†…å®¹: {self.stats['duplicate_content']}")
                st.write(f"â€¢ robots.txté˜»æ­¢: {self.stats['robots_blocked']}")
            
            with col2:
                st.subheader("æ€§èƒ½æŒ‡æ ‡")
                elapsed = time.time() - self.start_time
                st.write(f"â€¢ è¿è¡Œæ—¶é—´: {elapsed/60:.1f} åˆ†é’Ÿ")
                st.write(f"â€¢ å¹³å‡é€Ÿåº¦: {self.stats['crawled_urls']/(elapsed/60):.1f} é¡µ/åˆ†é’Ÿ")
                st.write(f"â€¢ æ•°æ®ä¸‹è½½: {self.stats['bytes_downloaded']/1024/1024:.2f} MB")
                st.write(f"â€¢ å½“å‰æ·±åº¦: {self.stats['current_depth']}/{self.stats['max_depth']}")

class AsyncCrawlUI:
    """å¼‚æ­¥çˆ¬è™«UIåŒ…è£…å™¨"""
    
    def __init__(self):
        self.monitor = CrawlProgressMonitor()
        self.status_container = None
        self.progress_container = None
    
    def setup_ui(self):
        """è®¾ç½®UIå®¹å™¨"""
        st.subheader("ğŸš€ å¼‚æ­¥å¹¶å‘çˆ¬è™«")
        
        # é…ç½®åŒºåŸŸ
        col1, col2, col3 = st.columns(3)
        with col1:
            max_concurrent = st.slider("å¹¶å‘æ•°", 5, 50, 15)
        with col2:
            enable_dedup = st.checkbox("å†…å®¹å»é‡", True)
        with col3:
            check_robots = st.checkbox("robots.txtæ£€æŸ¥", True)
        
        # è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
        self.progress_container = st.container()
        self.status_container = st.empty()
        
        return {
            'max_concurrent': max_concurrent,
            'enable_dedup': enable_dedup,
            'check_robots': check_robots
        }
    
    def update_progress(self, message: str, stats: Dict = None):
        """æ›´æ–°è¿›åº¦æ˜¾ç¤º"""
        self.status_container.info(f"ğŸ”„ {message}")
        
        if stats:
            self.monitor.update_stats(**stats)
            
            with self.progress_container:
                self.monitor.render_progress_dashboard()
    
    def show_completion(self, results: Dict):
        """æ˜¾ç¤ºå®Œæˆç»“æœ"""
        self.status_container.success(f"âœ… çˆ¬å–å®Œæˆï¼")
        
        # æœ€ç»ˆç»Ÿè®¡
        st.balloons()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»é¡µé¢", results.get('total_pages', 0))
        with col2:
            st.metric("æˆåŠŸç‡", f"{results.get('success_rate', 0):.1f}%")
        with col3:
            st.metric("æ€»ç”¨æ—¶", f"{results.get('total_time', 0):.1f}åˆ†é’Ÿ")

# ä½¿ç”¨ç¤ºä¾‹
def demo_progress_monitor():
    """æ¼”ç¤ºè¿›åº¦ç›‘æ§"""
    monitor = CrawlProgressMonitor()
    
    # æ¨¡æ‹Ÿçˆ¬å–è¿‡ç¨‹
    for i in range(10):
        time.sleep(0.5)
        monitor.update_stats(
            total_urls=100,
            crawled_urls=i*10,
            failed_urls=i*2,
            bytes_downloaded=i*1024*1024,
            current_depth=min(i//3 + 1, 5),
            max_depth=5
        )
        monitor.render_progress_dashboard()
        time.sleep(1)

if __name__ == "__main__":
    demo_progress_monitor()
