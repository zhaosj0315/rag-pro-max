"""
æœç´¢UIç»„ä»¶
"""

import streamlit as st
from datetime import datetime, date
from src.utils.search_engine import search_engine

def render_search_interface():
    """æ¸²æŸ“æœç´¢ç•Œé¢"""
    st.markdown("### ğŸ” æ™ºèƒ½æœç´¢")
    
    # æœç´¢è¾“å…¥æ¡†
    col1, col2 = st.columns([4, 1])
    
    with col1:
        search_query = st.text_input(
            "æœç´¢å†…å®¹", 
            placeholder="è¾“å…¥å…³é”®è¯æœç´¢æ–‡æ¡£å†…å®¹...",
            label_visibility="collapsed"
        )
    
    with col2:
        search_clicked = st.button("ğŸ” æœç´¢", use_container_width=True, type="primary")
    
    # æœç´¢å»ºè®®
    if search_query and len(search_query) > 1:
        suggestions = search_engine.get_search_suggestions(search_query)
        if suggestions:
            st.markdown("ğŸ’¡ **æœç´¢å»ºè®®:**")
            for suggestion in suggestions:
                if st.button(f"ğŸ“ {suggestion}", key=f"suggest_{suggestion}"):
                    st.session_state.search_query = suggestion
                    st.rerun()
    
    # é«˜çº§è¿‡æ»¤å™¨
    with st.expander("ğŸ›ï¸ é«˜çº§è¿‡æ»¤", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            # æ–‡ä»¶ç±»å‹è¿‡æ»¤
            file_types = st.multiselect(
                "ğŸ“„ æ–‡ä»¶ç±»å‹",
                ["PDF", "DOCX", "TXT", "MD", "XLSX", "PPTX"],
                help="é€‰æ‹©è¦æœç´¢çš„æ–‡ä»¶ç±»å‹"
            )
            
            # æ—¥æœŸèŒƒå›´
            date_range = st.date_input(
                "ğŸ“… æ—¥æœŸèŒƒå›´",
                value=(),
                help="é€‰æ‹©æ–‡æ¡£çš„æ—¥æœŸèŒƒå›´"
            )
        
        with col2:
            # æ ‡ç­¾è¿‡æ»¤
            available_tags = search_engine.get_all_tags()
            selected_tags = st.multiselect(
                "ğŸ·ï¸ æ ‡ç­¾",
                available_tags,
                help="æŒ‰æ ‡ç­¾è¿‡æ»¤æ–‡æ¡£"
            )
            
            # æ’åºæ–¹å¼
            sort_by = st.selectbox(
                "ğŸ“Š æ’åºæ–¹å¼",
                ["relevance", "date", "size", "name"],
                format_func=lambda x: {
                    "relevance": "ğŸ¯ ç›¸å…³æ€§",
                    "date": "ğŸ“… æ—¥æœŸ",
                    "size": "ğŸ“ å¤§å°", 
                    "name": "ğŸ“ åç§°"
                }[x]
            )
    
    # æ‰§è¡Œæœç´¢
    if search_clicked or search_query:
        # æ¨¡æ‹Ÿæ–‡æ¡£æ•°æ®
        mock_documents = [
            {
                'id': '1',
                'filename': 'AIæŠ€æœ¯æŠ¥å‘Š.pdf',
                'title': 'äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•æŠ¥å‘Š',
                'content': 'äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæ·±åº¦å­¦ä¹ ã€æœºå™¨å­¦ä¹ ç­‰æŠ€æœ¯å¹¿æ³›åº”ç”¨...',
                'file_type': 'PDF',
                'size': 2048000,
                'date': '2024-12-10',
                'tags': ['AI', 'æŠ€æœ¯', 'æŠ¥å‘Š']
            },
            {
                'id': '2', 
                'filename': 'é¡¹ç›®æ–‡æ¡£.docx',
                'title': 'é¡¹ç›®å¼€å‘æ–‡æ¡£',
                'content': 'æœ¬é¡¹ç›®é‡‡ç”¨Pythonå¼€å‘ï¼Œä½¿ç”¨Streamlitæ¡†æ¶æ„å»ºç”¨æˆ·ç•Œé¢ï¼Œé›†æˆäº†å¤šç§AIæ¨¡å‹...',
                'file_type': 'DOCX',
                'size': 1024000,
                'date': '2024-12-12',
                'tags': ['é¡¹ç›®', 'å¼€å‘', 'Python']
            },
            {
                'id': '3',
                'filename': 'ä¼šè®®çºªè¦.txt', 
                'title': 'æŠ€æœ¯è®¨è®ºä¼šè®®çºªè¦',
                'content': 'ä¼šè®®è®¨è®ºäº†AIæŠ€æœ¯çš„åº”ç”¨åœºæ™¯ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸ...',
                'file_type': 'TXT',
                'size': 512000,
                'date': '2024-12-08',
                'tags': ['ä¼šè®®', 'è®¨è®º', 'AI']
            }
        ]
        
        # åº”ç”¨æœç´¢å’Œè¿‡æ»¤
        results = mock_documents
        
        if search_query:
            results = search_engine.full_text_search(search_query, results)
        
        if file_types:
            results = search_engine.filter_by_file_type(results, file_types)
        
        if selected_tags:
            results = search_engine.filter_by_tags(results, selected_tags)
        
        if date_range and len(date_range) == 2:
            start_date, end_date = date_range
            results = search_engine.filter_by_date_range(
                results, 
                start_date.strftime('%Y-%m-%d'),
                end_date.strftime('%Y-%m-%d')
            )
        
        results = search_engine.sort_results(results, sort_by)
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        st.markdown(f"### ğŸ“‹ æœç´¢ç»“æœ ({len(results)} ä¸ª)")
        
        if results:
            for i, doc in enumerate(results):
                with st.container():
                    col1, col2, col3 = st.columns([3, 1, 1])
                    
                    with col1:
                        st.markdown(f"**ğŸ“„ {doc['filename']}**")
                        if 'matches' in doc and doc['matches']:
                            for match in doc['matches'][:1]:  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªåŒ¹é…
                                st.markdown(f"ğŸ’¬ {match['snippet']}")
                        else:
                            # æ˜¾ç¤ºå†…å®¹æ‘˜è¦
                            content_preview = doc['content'][:100] + "..." if len(doc['content']) > 100 else doc['content']
                            st.markdown(f"ğŸ’¬ {content_preview}")
                    
                    with col2:
                        st.markdown(f"ğŸ“… {doc['date']}")
                        st.markdown(f"ğŸ“ {doc['size']/1024:.0f}KB")
                    
                    with col3:
                        if 'search_score' in doc:
                            st.markdown(f"ğŸ¯ ç›¸å…³æ€§: {doc['search_score']}")
                        
                        # æ ‡ç­¾æ˜¾ç¤º
                        if doc.get('tags'):
                            tags_str = " ".join([f"`{tag}`" for tag in doc['tags'][:3]])
                            st.markdown(f"ğŸ·ï¸ {tags_str}")
                    
                    st.divider()
        else:
            st.info("ğŸ” æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯")

def render_tag_management():
    """æ¸²æŸ“æ ‡ç­¾ç®¡ç†ç•Œé¢"""
    st.markdown("### ğŸ·ï¸ æ ‡ç­¾ç®¡ç†")
    
    # æ·»åŠ æ–°æ ‡ç­¾
    col1, col2 = st.columns([3, 1])
    
    with col1:
        new_tag = st.text_input("æ–°æ ‡ç­¾", placeholder="è¾“å…¥æ ‡ç­¾åç§°...", label_visibility="collapsed")
    
    with col2:
        if st.button("â• æ·»åŠ ", use_container_width=True):
            if new_tag.strip():
                search_engine.add_tag_to_document("", new_tag.strip())
                st.success(f"âœ… å·²æ·»åŠ æ ‡ç­¾: {new_tag}")
                st.rerun()
    
    # æ˜¾ç¤ºç°æœ‰æ ‡ç­¾
    all_tags = search_engine.get_all_tags()
    if all_tags:
        st.markdown("#### ğŸ“‹ ç°æœ‰æ ‡ç­¾")
        
        # åˆ†åˆ—æ˜¾ç¤ºæ ‡ç­¾
        cols = st.columns(3)
        for i, tag in enumerate(all_tags):
            with cols[i % 3]:
                st.markdown(f"ğŸ·ï¸ `{tag}`")
    else:
        st.info("ğŸ“ è¿˜æ²¡æœ‰æ ‡ç­¾ï¼Œè¯·æ·»åŠ ä¸€äº›æ ‡ç­¾æ¥ç»„ç»‡æ–‡æ¡£")

def render_search_analytics():
    """æ¸²æŸ“æœç´¢åˆ†æç•Œé¢"""
    st.markdown("### ğŸ“Š æœç´¢åˆ†æ")
    
    # æœç´¢å†å²
    search_history = search_engine.search_history
    if search_history:
        st.markdown("#### ğŸ•’ æœ€è¿‘æœç´¢")
        for i, query in enumerate(reversed(search_history[-5:])):
            col1, col2 = st.columns([4, 1])
            with col1:
                st.markdown(f"ğŸ” {query}")
            with col2:
                if st.button("ğŸ”„", key=f"repeat_{i}", help="é‡å¤æœç´¢"):
                    st.session_state.search_query = query
                    st.rerun()
    else:
        st.info("ğŸ“ è¿˜æ²¡æœ‰æœç´¢è®°å½•")
    
    # æœç´¢ç»Ÿè®¡
    st.markdown("#### ğŸ“ˆ æœç´¢ç»Ÿè®¡")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ” æ€»æœç´¢æ¬¡æ•°", len(search_history))
    
    with col2:
        unique_queries = len(set(search_history)) if search_history else 0
        st.metric("ğŸ’¡ ä¸åŒæŸ¥è¯¢", unique_queries)
    
    with col3:
        avg_query_length = sum(len(q) for q in search_history) / len(search_history) if search_history else 0
        st.metric("ğŸ“ å¹³å‡æŸ¥è¯¢é•¿åº¦", f"{avg_query_length:.1f}å­—ç¬¦")
