#!/bin/bash

echo "ğŸ“¦ RAG Pro Max ä¼˜åŒ–å®Œå…¨ç¦»çº¿åŒ…æ„å»º"
echo "=================================="

# æ¸…ç†æ—§åŒ…
rm -rf rag-pro-max-optimized-offline
rm -f rag-pro-max-optimized-offline.tar.gz

# åˆ›å»ºç›®å½•
mkdir -p rag-pro-max-optimized-offline/{offline_packages,hf_models,ollama_models,ollama_bin}

echo "ğŸ“‹ å¤åˆ¶åº”ç”¨ä»£ç ..."
cp -r src/ rag-pro-max-optimized-offline/
cp requirements.txt rag-pro-max-optimized-offline/
cp -r config/ rag-pro-max-optimized-offline/ 2>/dev/null || true

echo "ğŸ“¦ ä¸‹è½½Pythonä¾èµ–..."
pip download -r requirements.txt -d rag-pro-max-optimized-offline/offline_packages/ --platform linux_x86_64 --only-binary=:all: --python-version 3.10

echo "ğŸ¤– ä¸‹è½½OllamaäºŒè¿›åˆ¶..."
curl -L https://github.com/ollama/ollama/releases/latest/download/ollama-linux-amd64 -o rag-pro-max-optimized-offline/ollama_bin/ollama
chmod +x rag-pro-max-optimized-offline/ollama_bin/ollama

echo "ğŸ§  å¤åˆ¶HuggingFaceæ¨¡å‹..."
python3 -c "
from sentence_transformers import SentenceTransformer
import shutil
import os
model = SentenceTransformer('BAAI/bge-small-zh-v1.5')
cache_dir = os.path.expanduser('~/.cache/huggingface/hub')
target_dir = 'rag-pro-max-optimized-offline/hf_models'
if os.path.exists(cache_dir):
    shutil.copytree(cache_dir, target_dir, dirs_exist_ok=True)
print('âœ… HFæ¨¡å‹å¤åˆ¶å®Œæˆ')
"

echo "ğŸ¯ å‡†å¤‡å¹²å‡€çš„Ollamaç¯å¢ƒ..."
# åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå¹²å‡€çš„æ¨¡å‹ä¸‹è½½
TEMP_OLLAMA_DIR="/tmp/ollama_clean_$(date +%s)"
mkdir -p "$TEMP_OLLAMA_DIR"

echo "ğŸ“¥ åœ¨å¹²å‡€ç¯å¢ƒä¸­ä¸‹è½½gemma2:2b..."
# ä½¿ç”¨ä¸´æ—¶ç›®å½•ä¸‹è½½æ¨¡å‹
export OLLAMA_MODELS="$TEMP_OLLAMA_DIR"

# å¯åŠ¨ä¸´æ—¶OllamaæœåŠ¡
ollama serve &
OLLAMA_PID=$!
sleep 10

# ä¸‹è½½æŒ‡å®šæ¨¡å‹
ollama pull gemma2:2b

# åœæ­¢æœåŠ¡
kill $OLLAMA_PID 2>/dev/null || true
sleep 5

echo "ğŸ“‹ å¤åˆ¶å¹²å‡€çš„æ¨¡å‹æ–‡ä»¶..."
cp -r "$TEMP_OLLAMA_DIR"/* rag-pro-max-optimized-offline/ollama_models/

echo "ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
rm -rf "$TEMP_OLLAMA_DIR"

echo "ğŸ“ åˆ›å»ºå®‰è£…è„šæœ¬..."
cat > rag-pro-max-optimized-offline/install_optimized.sh << 'EOF'
#!/bin/bash
echo "ğŸš€ RAG Pro Max ä¼˜åŒ–ç¦»çº¿å®‰è£…"

# å®‰è£…Pythonä¾èµ–
echo "ğŸ“¦ å®‰è£…Pythonä¾èµ–..."
pip install --no-index --find-links offline_packages/ -r requirements.txt

# å®‰è£…Ollama
echo "ğŸ¤– å®‰è£…Ollama..."
sudo cp ollama_bin/ollama /usr/local/bin/
sudo chmod +x /usr/local/bin/ollama

# å¤åˆ¶HFæ¨¡å‹
echo "ğŸ§  å¤åˆ¶HuggingFaceæ¨¡å‹..."
mkdir -p ~/.cache/huggingface/
cp -r hf_models/* ~/.cache/huggingface/ 2>/dev/null || true

# å¤åˆ¶Ollamaæ¨¡å‹
echo "ğŸ¯ å¤åˆ¶Ollamaæ¨¡å‹..."
mkdir -p ~/.ollama/
cp -r ollama_models ~/.ollama/models 2>/dev/null || true

echo "âœ… ä¼˜åŒ–å®‰è£…å®Œæˆï¼"
echo "ğŸš€ å¯åŠ¨: streamlit run src/apppro.py"
EOF

chmod +x rag-pro-max-optimized-offline/install_optimized.sh

echo "ğŸ—œï¸ æ‰“åŒ…..."
tar -czf rag-pro-max-optimized-offline.tar.gz rag-pro-max-optimized-offline/

echo "âœ… ä¼˜åŒ–ç¦»çº¿åŒ…æ„å»ºå®Œæˆ"
echo "ğŸ“¦ æ–‡ä»¶: rag-pro-max-optimized-offline.tar.gz"
ls -lh rag-pro-max-optimized-offline.tar.gz

# æ˜¾ç¤ºå„éƒ¨åˆ†å¤§å°
echo ""
echo "ğŸ“Š å„éƒ¨åˆ†å¤§å°:"
du -sh rag-pro-max-optimized-offline/*/

echo ""
echo "ğŸ¯ ä¼˜åŒ–ç‰ˆæœ¬ç‰¹ç‚¹:"
echo "  - åªåŒ…å«gemma2:2bæ¨¡å‹ (~1.6GB)"
echo "  - æ‰€æœ‰Pythonä¾èµ–å®Œæ•´"
echo "  - HuggingFaceæ¨¡å‹å®Œæ•´"
echo "  - é¢„è®¡æ€»å¤§å°: ~3-5GB"
