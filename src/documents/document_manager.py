"""
æ–‡æ¡£ç®¡ç†å™¨æ¨¡å—
è´Ÿè´£æ–‡æ¡£åˆ—è¡¨æ˜¾ç¤ºã€æœç´¢ã€ç­›é€‰å’Œç®¡ç†
"""

import os
import json
import time
import streamlit as st
from llama_index.core import StorageContext, load_index_from_storage

from src.app_logging import LogManager
from src.config import ManifestManager
from src.metadata_manager import MetadataManager

logger = LogManager()


class DocumentManager:
    """æ–‡æ¡£ç®¡ç†å™¨"""
    
    def __init__(self, db_path):
        self.db_path = db_path
        self.manifest = ManifestManager.load(db_path)
    
    def get_kb_statistics(self):
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        files = self.manifest.get('files', [])
        file_cnt = len(files)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_sz = 0
        total_chunks = 0
        file_types = {}
        oldest_date = None
        newest_date = None
        
        for f in files:
            try:
                if 'KB' in f['size']:
                    total_sz += float(f['size'].replace(' KB', ''))
                elif 'MB' in f['size']:
                    total_sz += float(f['size'].replace(' MB', '')) * 1024
            except:
                pass
            
            total_chunks += len(f.get('doc_ids', []))
            ftype = f.get('type', 'Unknown')
            file_types[ftype] = file_types.get(ftype, 0) + 1
            
            file_date = f.get('added_at', '')
            if file_date:
                if oldest_date is None or file_date < oldest_date:
                    oldest_date = file_date
                if newest_date is None or file_date > newest_date:
                    newest_date = file_date
        
        return {
            'file_cnt': file_cnt,
            'total_sz': total_sz,
            'total_chunks': total_chunks,
            'file_types': file_types,
            'oldest_date': oldest_date,
            'newest_date': newest_date
        }
    
    def render_statistics_overview(self, kb_name, stats):
        """æ¸²æŸ“ç»Ÿè®¡æ¦‚è§ˆ"""
        file_cnt = stats['file_cnt']
        total_sz = stats['total_sz']
        total_chunks = stats['total_chunks']
        
        # è¯»å–çŸ¥è¯†åº“æ¨¡å‹ä¿¡æ¯
        kb_info_file = os.path.join(self.db_path, ".kb_info.json")
        if os.path.exists(kb_info_file):
            try:
                with open(kb_info_file, 'r') as f:
                    kb_info = json.load(f)
                    kb_model = kb_info.get('embedding_model', 'Unknown')
            except:
                kb_model = self.manifest.get('embed_model', 'Unknown')
        else:
            kb_model = self.manifest.get('embed_model', 'Unknown')
        
        # å•è¡Œç´§å‡‘æ ‡é¢˜ + ç»Ÿè®¡
        col1, col2, col3, col4, col5, col6 = st.columns([2, 1, 1, 1, 1, 0.6])
        col1.markdown(f"### ğŸ’¬ {kb_name}")
        col2.metric("ğŸ“„ æ–‡ä»¶", file_cnt)
        col3.metric("ğŸ’¾ å¤§å°", f"{total_sz/1024:.1f}MB" if total_sz > 1024 else f"{int(total_sz)}KB")
        col4.metric("ğŸ“¦ ç‰‡æ®µ", total_chunks)
        col5.metric("ğŸ§¬ æ¨¡å‹", kb_model.split('/')[-1] if '/' in kb_model else kb_model)
        
        return col6
    
    def render_detailed_statistics(self, stats):
        """æ¸²æŸ“è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        file_cnt = stats['file_cnt']
        total_sz = stats['total_sz']
        total_chunks = stats['total_chunks']
        file_types = stats['file_types']
        oldest_date = stats['oldest_date']
        newest_date = stats['newest_date']
        
        # è®¡ç®—å­˜å‚¨å¤§å°
        db_size = 0
        if os.path.exists(self.db_path):
            for root, dirs, files in os.walk(self.db_path):
                db_size += sum(os.path.getsize(os.path.join(root, f)) for f in files)
        db_size_mb = db_size / (1024 * 1024)
        
        # è®¡ç®—æˆåŠŸç‡å’Œå‹ç¼©æ¯”
        files_with_chunks = len([f for f in self.manifest['files'] if len(f.get('doc_ids', [])) > 0])
        success_rate = (files_with_chunks / file_cnt * 100) if file_cnt > 0 else 0
        
        total_sz_bytes = total_sz * 1024
        compression_ratio = (total_sz_bytes / db_size) if db_size > 0 else 0
        storage_efficiency = f"{compression_ratio:.1f}x" if compression_ratio > 1 else "1.0x" if compression_ratio > 0 else "N/A"
        
        # æ—¶é—´èŒƒå›´
        last_upd = self.manifest.get('last_updated', 'N/A')[:10]
        time_range = f"{oldest_date[:10]} ~ {newest_date[:10]}" if oldest_date and newest_date else last_upd
        
        # ç»Ÿè®¡æ‘˜è¦
        st.markdown(f"**ğŸ“Š ç»Ÿè®¡** Â· {file_cnt} æ–‡ä»¶ Â· {total_chunks} ç‰‡æ®µ Â· ğŸ“ åŸå§‹ {f'{total_sz/1024:.1f}MB' if total_sz > 1024 else f'{int(total_sz)}KB'} Â· ğŸ’¾ å‘é‡åº“ {db_size_mb:.1f}MB ({storage_efficiency}) Â· ğŸ“… {time_range}")
        
        # æ ¸å¿ƒæŒ‡æ ‡
        metric_col1, metric_col2, metric_col3, metric_col4, metric_col5, metric_col6 = st.columns(6)
        avg_chunks = total_chunks / file_cnt if file_cnt > 0 else 0
        avg_size = (total_sz / file_cnt) if file_cnt > 0 else 0
        
        metric_col1.metric("ğŸ“ˆ å¹³å‡ç‰‡æ®µ", f"{avg_chunks:.1f}")
        metric_col2.metric("ğŸ“Š å¹³å‡å¤§å°", f"{avg_size/1024:.1f}KB" if avg_size > 1024 else f"{int(avg_size)}KB")
        
        # å¥åº·åº¦
        health_icon = "ğŸŸ¢" if success_rate >= 90 else "ğŸŸ¡" if success_rate >= 70 else "ğŸ”´"
        metric_col3.metric("ğŸ’š å¥åº·åº¦", f"{health_icon} {success_rate:.0f}%")
        
        # è´¨é‡åˆ†æ
        low_quality = len([f for f in self.manifest['files'] if len(f.get('doc_ids', [])) < 2])
        large_files = len([f for f in self.manifest['files'] if 'MB' in f['size']])
        empty_docs = len([f for f in self.manifest['files'] if len(f.get('doc_ids', [])) == 0])
        
        quality_status = "âœ… ä¼˜ç§€" if low_quality == 0 and large_files == 0 and empty_docs == 0 else f"âš ï¸ {empty_docs}ç©º {low_quality}ä½è´¨"
        metric_col4.metric("ğŸ” è´¨é‡", quality_status)
        
        type_count = len(file_types)
        metric_col5.metric("ğŸ“‚ ç±»å‹", f"{type_count} ç§")
        
        kb_model = self.manifest.get('embed_model', 'Unknown')
        metric_col6.metric("ğŸ”¤ æ¨¡å‹", kb_model.split('/')[-1][:12] if '/' in kb_model else kb_model[:12])
        
        return {
            'success_rate': success_rate,
            'low_quality': low_quality,
            'empty_docs': empty_docs
        }
    
    def render_distribution_analysis(self, stats):
        """æ¸²æŸ“åˆ†å¸ƒåˆ†æ"""
        file_types = stats['file_types']
        file_cnt = stats['file_cnt']
        
        # å››åˆ—å¸ƒå±€ï¼šç±»å‹åˆ†å¸ƒ + å¤§å°åˆ†å¸ƒ + ç‰‡æ®µåˆ†å¸ƒ + æ•°æ®æ´å¯Ÿ
        type_col, size_col, chunk_col, insight_col = st.columns([2, 2, 2, 2])
        
        with type_col:
            st.markdown("**ğŸ“‚ ç±»å‹åˆ†å¸ƒ**")
            sorted_types = sorted(file_types.items(), key=lambda x: x[1], reverse=True)
            for i, (ftype, count) in enumerate(sorted_types[:5]):
                pct = (count / file_cnt * 100) if file_cnt > 0 else 0
                bar = "â–ˆ" * int(pct / 5) + "â–‘" * (20 - int(pct / 5))
                st.caption(f"{ftype}: {count} ({pct:.0f}%) {bar[:10]}")
            if len(sorted_types) > 5:
                other_count = sum(c for _, c in sorted_types[5:])
                other_pct = (other_count / file_cnt * 100) if file_cnt > 0 else 0
                st.caption(f"å…¶ä»–: {other_count} ({other_pct:.0f}%)")
        
        with size_col:
            st.markdown("**ğŸ“Š å¤§å°åˆ†å¸ƒ**")
            size_ranges = {"<100KB": 0, "100KB-1MB": 0, "1MB-10MB": 0, ">10MB": 0}
            for f in self.manifest['files']:
                size_bytes = f.get('size_bytes', 0)
                if size_bytes < 100 * 1024:
                    size_ranges["<100KB"] += 1
                elif size_bytes < 1024 * 1024:
                    size_ranges["100KB-1MB"] += 1
                elif size_bytes < 10 * 1024 * 1024:
                    size_ranges["1MB-10MB"] += 1
                else:
                    size_ranges[">10MB"] += 1
            
            for range_name, count in size_ranges.items():
                if count > 0:
                    pct = (count / file_cnt * 100) if file_cnt > 0 else 0
                    st.caption(f"{range_name}: {count} ({pct:.0f}%)")
        
        with chunk_col:
            st.markdown("**ğŸ“¦ ç‰‡æ®µåˆ†å¸ƒ**")
            chunk_ranges = {"0ç‰‡æ®µ": 0, "1-5ç‰‡æ®µ": 0, "6-20ç‰‡æ®µ": 0, ">20ç‰‡æ®µ": 0}
            for f in self.manifest['files']:
                chunk_count = len(f.get('doc_ids', []))
                if chunk_count == 0:
                    chunk_ranges["0ç‰‡æ®µ"] += 1
                elif chunk_count <= 5:
                    chunk_ranges["1-5ç‰‡æ®µ"] += 1
                elif chunk_count <= 20:
                    chunk_ranges["6-20ç‰‡æ®µ"] += 1
                else:
                    chunk_ranges[">20ç‰‡æ®µ"] += 1
            
            for range_name, count in chunk_ranges.items():
                if count > 0:
                    pct = (count / file_cnt * 100) if file_cnt > 0 else 0
                    icon = "âš ï¸" if range_name == "0ç‰‡æ®µ" else "âœ…" if range_name == ">20ç‰‡æ®µ" else ""
                    st.caption(f"{icon}{range_name}: {count} ({pct:.0f}%)")
        
        with insight_col:
            st.markdown("**ğŸ’¡ æ•°æ®æ´å¯Ÿ**")
            if self.manifest['files']:
                # çƒ­é—¨æ–‡ä»¶
                hot_files = [(f['name'], f.get('hit_count', 0)) for f in self.manifest['files'] if f.get('hit_count', 0) > 0]
                if hot_files:
                    hot_files.sort(key=lambda x: x[1], reverse=True)
                    top_file = hot_files[0]
                    st.caption(f"ğŸ”¥ æœ€çƒ­: {top_file[0][:12]}... ({top_file[1]}æ¬¡)")
                
                # æœ€å¤šç‰‡æ®µ
                chunks_list = [(f['name'], len(f.get('doc_ids', []))) for f in self.manifest['files']]
                most_chunks = max(chunks_list, key=lambda x: x[1]) if chunks_list else None
                if most_chunks and most_chunks[1] > 0:
                    st.caption(f"ğŸ”¢ æœ€å¤šç‰‡æ®µ: {most_chunks[0][:12]}... ({most_chunks[1]})")
                
                # ä¸»è¦ç±»å‹
                if file_types:
                    main_type = max(file_types.items(), key=lambda x: x[1])
                    st.caption(f"ğŸ“‚ ä¸»è¦ç±»å‹: {main_type[0]} ({main_type[1]}ä¸ª)")
    
    def filter_and_sort_files(self, search_term, filter_type, filter_category, filter_heat, filter_quality, sort_by):
        """ç­›é€‰å’Œæ’åºæ–‡ä»¶"""
        filtered_files = self.manifest['files']
        
        # æœç´¢
        if search_term:
            filtered_files = [f for f in filtered_files if search_term.lower() in f['name'].lower()]
        
        # ç±»å‹ç­›é€‰
        if filter_type != "å…¨éƒ¨":
            filtered_files = [f for f in filtered_files if f.get('type') == filter_type]
        
        # åˆ†ç±»ç­›é€‰
        if filter_category != "å…¨éƒ¨":
            filtered_files = [f for f in filtered_files if f.get('category') == filter_category]
        
        # çƒ­åº¦ç­›é€‰
        if filter_heat == "é«˜é¢‘":
            filtered_files = [f for f in filtered_files if f.get('hit_count', 0) > 10]
        elif filter_heat == "ä¸­é¢‘":
            filtered_files = [f for f in filtered_files if 3 < f.get('hit_count', 0) <= 10]
        elif filter_heat == "ä½é¢‘":
            filtered_files = [f for f in filtered_files if 0 < f.get('hit_count', 0) <= 3]
        elif filter_heat == "æœªç”¨":
            filtered_files = [f for f in filtered_files if f.get('hit_count', 0) == 0]
        
        # è´¨é‡ç­›é€‰
        if filter_quality == "ä¼˜ç§€":
            filtered_files = [f for f in filtered_files if len(f.get('doc_ids', [])) >= 10]
        elif filter_quality == "æ­£å¸¸":
            filtered_files = [f for f in filtered_files if 2 <= len(f.get('doc_ids', [])) < 10]
        elif filter_quality == "ä½è´¨":
            filtered_files = [f for f in filtered_files if 0 < len(f.get('doc_ids', [])) < 2]
        elif filter_quality == "ç©º":
            filtered_files = [f for f in filtered_files if len(f.get('doc_ids', [])) == 0]
        
        # æ’åº
        if sort_by == "æ—¶é—´â†“":
            filtered_files = sorted(filtered_files, key=lambda x: x.get('added_at', ''), reverse=True)
        elif sort_by == "æ—¶é—´â†‘":
            filtered_files = sorted(filtered_files, key=lambda x: x.get('added_at', ''))
        elif sort_by == "å¤§å°â†“":
            filtered_files = sorted(filtered_files, key=lambda x: x.get('size_bytes', 0), reverse=True)
        elif sort_by == "å¤§å°â†‘":
            filtered_files = sorted(filtered_files, key=lambda x: x.get('size_bytes', 0))
        elif sort_by == "åç§°":
            filtered_files = sorted(filtered_files, key=lambda x: x['name'].lower())
        elif sort_by == "çƒ­åº¦â†“":
            filtered_files = sorted(filtered_files, key=lambda x: x.get('hit_count', 0), reverse=True)
        elif sort_by == "ç‰‡æ®µâ†“":
            filtered_files = sorted(filtered_files, key=lambda x: len(x.get('doc_ids', [])), reverse=True)
        
        return filtered_files
    
    def render_file_list(self, filtered_files, start_idx, end_idx, page_size):
        """æ¸²æŸ“æ–‡ä»¶åˆ—è¡¨"""
        # è¡¨å¤´
        cols = st.columns([0.5, 2.5, 1, 0.8, 1, 0.8, 1.2, 0.8])
        
        # å…¨é€‰å¤é€‰æ¡†
        current_page_files = [f['name'] for f in filtered_files[start_idx:end_idx] 
                             if not f.get('summary') and f.get('doc_ids')]
        
        if current_page_files:
            if 'selected_for_summary' not in st.session_state:
                st.session_state.selected_for_summary = set()
            
            all_selected = all(fname in st.session_state.selected_for_summary for fname in current_page_files)
            
            def toggle_select_all(files=current_page_files):
                if st.session_state.get(f"select_all_page_{st.session_state.file_page}"):
                    st.session_state.selected_for_summary.update(files)
                else:
                    st.session_state.selected_for_summary.difference_update(files)
            
            cols[0].checkbox(
                "å…¨é€‰",
                value=all_selected,
                key=f"select_all_page_{st.session_state.file_page}",
                label_visibility="collapsed",
                on_change=toggle_select_all
            )
        else:
            cols[0].markdown("**âœ¨**")
        
        cols[1].markdown("**æ–‡ä»¶å**")
        cols[2].markdown("**ç±»å‹**")
        cols[3].markdown("**ç‰‡æ®µ**")
        cols[4].markdown("**å¤§å°**")
        cols[5].markdown("**è´¨é‡**")
        cols[6].markdown("**æ—¶é—´**")
        cols[7].markdown("**æ“ä½œ**")
        st.divider()
        
        # æ¸²æŸ“æ–‡ä»¶è¡Œ
        for i in range(start_idx, end_idx):
            f = filtered_files[i]
            orig_idx = self.manifest['files'].index(f)
            
            self._render_file_row(f, orig_idx, i)
    
    def _render_file_row(self, f, orig_idx, display_idx):
        """æ¸²æŸ“å•ä¸ªæ–‡ä»¶è¡Œ"""
        cols = st.columns([0.5, 2.5, 1, 0.8, 1, 0.8, 1.2, 0.8])
        
        # æ‘˜è¦å¤é€‰æ¡†
        if not f.get('summary') and f.get('doc_ids'):
            if 'selected_for_summary' not in st.session_state:
                st.session_state.selected_for_summary = set()
            
            is_checked = f['name'] in st.session_state.selected_for_summary
            checked = cols[0].checkbox("é€‰æ‹©", value=is_checked, 
                                     key=f"sum_{f['name']}_{st.session_state.file_page}", 
                                     label_visibility="collapsed")
            
            if checked:
                st.session_state.selected_for_summary.add(f['name'])
            else:
                st.session_state.selected_for_summary.discard(f['name'])
        else:
            cols[0].write("")
        
        # æ–‡ä»¶ä¿¡æ¯
        cols[1].caption(f'{f["icon"]} {f["name"]}')
        cols[2].caption(f['type'])
        
        chunk_count = len(f.get('doc_ids', []))
        cols[3].caption(str(chunk_count))
        cols[4].caption(f['size'])
        
        # è´¨é‡æŒ‡ç¤ºå™¨
        if chunk_count == 0:
            quality_icon = "âŒ"
        elif chunk_count < 2:
            quality_icon = "âš ï¸"
        elif chunk_count < 10:
            quality_icon = "âœ…"
        else:
            quality_icon = "ğŸ‰"
        cols[5].caption(quality_icon)
        
        cols[6].caption(f['added_at'])
        
        # åˆ é™¤æŒ‰é’®
        if cols[7].button("ğŸ—‘ï¸", key=f"del_{orig_idx}_{display_idx}"):
            self._delete_file(f)
        
        # æ–‡ä»¶æ‘˜è¦å±•å¼€
        if f.get('summary'):
            with st.expander(f"ğŸ“– {f['summary'][:50]}...", expanded=False):
                st.markdown(f.get('summary'))
        
        # æ–‡ä»¶è¯¦æƒ…å±•å¼€
        with st.expander(f"ğŸ“Š è¯¦æƒ… - {f['name']}", expanded=False):
            self._render_file_details(f)
    
    def _render_file_details(self, f):
        """æ¸²æŸ“æ–‡ä»¶è¯¦æƒ…"""
        chunk_count = len(f.get('doc_ids', []))
        
        # åŸºç¡€ä¿¡æ¯
        detail_cols = st.columns(4)
        detail_cols[0].metric("ğŸ“¦ ç‰‡æ®µ", chunk_count)
        detail_cols[1].metric("ğŸ’¾ å¤§å°", f['size'])
        detail_cols[2].metric("ğŸ“… æ—¶é—´", f['added_at'][:10])
        detail_cols[3].metric("ğŸ·ï¸ ç±»å‹", f['type'])
        
        # è´¨é‡è¯„ä¼°
        if chunk_count == 0:
            quality_info = "âŒ è§£æå¤±è´¥"
        elif chunk_count < 2:
            quality_info = "âš ï¸ ä½è´¨ï¼ˆå†…å®¹è¿‡å°‘ï¼‰"
        elif chunk_count < 10:
            quality_info = "âœ… æ­£å¸¸"
        else:
            quality_info = "ğŸ‰ ä¼˜ç§€ï¼ˆå†…å®¹ä¸°å¯Œï¼‰"
        
        estimated_chars = chunk_count * 500
        st.caption(f"**è´¨é‡**: {quality_info} Â· **å­—ç¬¦**: ~{estimated_chars:,} Â· **å‘é‡**: {chunk_count}")
        
        # å…ƒæ•°æ®ä¿¡æ¯
        if f.get('hit_count', 0) > 0 or f.get('keywords') or f.get('category'):
            st.divider()
            self._render_file_metadata(f)
        
        # æ–‡æ¡£ID
        if f.get('doc_ids'):
            if len(f['doc_ids']) <= 3:
                st.caption(f"**ç‰‡æ®µID**: `{', '.join(f['doc_ids'])}`")
            else:
                st.caption(f"**ç‰‡æ®µID**: `{f['doc_ids'][0]}` ... (å…±{len(f['doc_ids'])}ä¸ª)")
                with st.expander("æŸ¥çœ‹å…¨éƒ¨ID", expanded=False):
                    st.code('\n'.join(f['doc_ids']), language=None)
        else:
            st.warning("âš ï¸ æœªç”Ÿæˆç‰‡æ®µ Â· å¯èƒ½åŸå› ï¼šæ–‡ä»¶ä¸ºç©º/æ ¼å¼ä¸æ”¯æŒ/å·²æŸå/åŠ å¯†")
    
    def _render_file_metadata(self, f):
        """æ¸²æŸ“æ–‡ä»¶å…ƒæ•°æ®"""
        meta_cols = st.columns(4)
        
        # æ£€ç´¢ç»Ÿè®¡
        hit_count = f.get('hit_count', 0)
        avg_score = f.get('avg_score', 0.0)
        heat = "ğŸ”¥" if hit_count > 10 else "ğŸ“Š" if hit_count > 3 else "ğŸ“¦" if hit_count > 0 else "â„ï¸"
        
        meta_cols[0].metric("ğŸ”¥ å‘½ä¸­", f"{hit_count} æ¬¡")
        meta_cols[1].metric("â­ å¾—åˆ†", f"{avg_score:.2f}")
        meta_cols[2].metric("ğŸŒ¡ï¸ çƒ­åº¦", heat)
        
        # æœ€åè®¿é—®
        last_accessed = f.get('last_accessed')
        if last_accessed:
            meta_cols[3].metric("ğŸ• è®¿é—®", last_accessed[:10])
        else:
            meta_cols[3].metric("ğŸ• è®¿é—®", "ä»æœª")
        
        # åˆ†ç±»å’Œè¯­è¨€
        category = f.get('category', 'å…¶ä»–')
        language = f.get('language', 'unknown')
        lang_map = {"zh": "ğŸ‡¨ğŸ‡³", "en": "ğŸ‡¬ğŸ‡§", "zh-en": "ğŸŒ", "unknown": "â“"}
        lang_icon = lang_map.get(language, "â“")
        
        st.caption(f"**ğŸ“‚ åˆ†ç±»**: {category} Â· **ğŸŒ è¯­è¨€**: {lang_icon} {language}")
        
        # å…³é”®è¯
        keywords = f.get('keywords', [])
        if keywords:
            st.caption(f"**ğŸ·ï¸ å…³é”®è¯**: {' Â· '.join(keywords[:5])}")
    
    def _delete_file(self, f):
        """åˆ é™¤æ–‡ä»¶"""
        with st.status(f"æ­£åœ¨åˆ é™¤ {f['name']}...", expanded=True) as status:
            try:
                ctx = StorageContext.from_defaults(persist_dir=self.db_path)
                idx = load_index_from_storage(ctx)
                for did in f.get('doc_ids', []):
                    idx.delete_ref_doc(did, delete_from_docstore=True)
                idx.storage_context.persist(persist_dir=self.db_path)
                
                # ä» manifest ä¸­ç§»é™¤
                self.manifest['files'] = [file for file in self.manifest['files'] if file['name'] != f['name']]
                with open(ManifestManager.get_path(self.db_path), 'w', encoding='utf-8') as mf:
                    json.dump(self.manifest, mf, indent=4, ensure_ascii=False)
                
                status.update(label="âœ… å·²åˆ é™¤", state="complete")
                st.session_state.chat_engine = None
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(str(e))
