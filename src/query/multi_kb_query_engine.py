"""
å¤šçŸ¥è¯†åº“è”åˆæŸ¥è¯¢å¼•æ“
æ”¯æŒä»å¤šä¸ªçŸ¥è¯†åº“ä¸­å¹¶è¡Œæ£€ç´¢å¹¶æ•´åˆç­”æ¡ˆ
"""

import os
import json
from typing import List
from concurrent.futures import ThreadPoolExecutor, as_completed
from llama_index.core import StorageContext, load_index_from_storage

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
from src.logger import logger


class MultiKBQueryEngine:
    """å¤šçŸ¥è¯†åº“è”åˆæŸ¥è¯¢å¼•æ“"""
    
    def __init__(self, output_base: str):
        self.output_base = output_base
    
    def query(self, question: str, kb_names: List[str], embed_provider: str, 
              embed_model: str, embed_key: str, embed_url: str) -> str:
        """
        ä»å¤šä¸ªçŸ¥è¯†åº“ä¸­æŸ¥è¯¢å¹¶æ•´åˆç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            kb_names: çŸ¥è¯†åº“åç§°åˆ—è¡¨
            embed_provider: åµŒå…¥æ¨¡å‹æä¾›å•†
            embed_model: åµŒå…¥æ¨¡å‹åç§°
            embed_key: APIå¯†é’¥
            embed_url: APIåœ°å€
            
        Returns:
            æ•´åˆåçš„ç­”æ¡ˆ
        """
        if not kb_names:
            logger.warning("âŒ å¤šçŸ¥è¯†åº“æŸ¥è¯¢: æœªé€‰æ‹©ä»»ä½•çŸ¥è¯†åº“")
            return "âŒ æœªé€‰æ‹©ä»»ä½•çŸ¥è¯†åº“"
        
        logger.info(f"ğŸ” å¼€å§‹å¤šçŸ¥è¯†åº“è”åˆæŸ¥è¯¢: {len(kb_names)} ä¸ªçŸ¥è¯†åº“")
        logger.info(f"ğŸ“‹ çŸ¥è¯†åº“åˆ—è¡¨: {', '.join(kb_names)}")
        logger.info(f"â“ æŸ¥è¯¢é—®é¢˜: {question[:100]}{'...' if len(question) > 100 else ''}")
        
        # å¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰çŸ¥è¯†åº“
        results = []
        with ThreadPoolExecutor(max_workers=min(len(kb_names), 4)) as executor:
            logger.info(f"âš¡ å¯åŠ¨å¹¶è¡ŒæŸ¥è¯¢ï¼Œæœ€å¤§å¹¶å‘æ•°: {min(len(kb_names), 4)}")
            
            future_to_kb = {
                executor.submit(self._query_single_kb, question, kb_name, 
                              embed_provider, embed_model, embed_key, embed_url): kb_name
                for kb_name in kb_names
            }
            
            completed_count = 0
            for future in as_completed(future_to_kb):
                kb_name = future_to_kb[future]
                completed_count += 1
                try:
                    result = future.result()
                    if result and result.strip():
                        logger.success(f"âœ… [{completed_count}/{len(kb_names)}] {kb_name}: æŸ¥è¯¢æˆåŠŸ")
                        results.append({
                            'kb_name': kb_name,
                            'content': result
                        })
                    else:
                        logger.warning(f"âš ï¸ [{completed_count}/{len(kb_names)}] {kb_name}: è¿”å›ç©ºç»“æœ")
                except Exception as e:
                    logger.error(f"âŒ [{completed_count}/{len(kb_names)}] {kb_name}: æŸ¥è¯¢å¤±è´¥ - {str(e)}")
                    results.append({
                        'kb_name': kb_name,
                        'content': f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
                    })
        
        # æ•´åˆç­”æ¡ˆ
        logger.info("ğŸ”„ å¼€å§‹æ•´åˆæŸ¥è¯¢ç»“æœ...")
        integrated_result = self._integrate_results(question, results)
        logger.success("âœ… å¤šçŸ¥è¯†åº“è”åˆæŸ¥è¯¢å®Œæˆ")
        return integrated_result
    
    def _query_single_kb(self, question: str, kb_name: str, embed_provider: str,
                        embed_model: str, embed_key: str, embed_url: str) -> str:
        """æŸ¥è¯¢å•ä¸ªçŸ¥è¯†åº“"""
        try:
            logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢çŸ¥è¯†åº“: {kb_name}")
            
            db_path = os.path.join(self.output_base, kb_name)
            if not os.path.exists(db_path):
                logger.error(f"âŒ çŸ¥è¯†åº“è·¯å¾„ä¸å­˜åœ¨: {db_path}")
                return f"çŸ¥è¯†åº“ {kb_name} ä¸å­˜åœ¨"
            
            # åŠ è½½çŸ¥è¯†åº“
            logger.info(f"ğŸ“‚ åŠ è½½çŸ¥è¯†åº“ç´¢å¼•: {kb_name}")
            storage_context = StorageContext.from_defaults(persist_dir=db_path)
            index = load_index_from_storage(storage_context)
            
            # åˆ›å»ºæŸ¥è¯¢å¼•æ“ - ä¼˜åŒ–å‚æ•°æé«˜ç­”æ¡ˆè´¨é‡
            logger.info(f"âš™ï¸ åˆ›å»ºæŸ¥è¯¢å¼•æ“: {kb_name}")
            query_engine = index.as_query_engine(
                similarity_top_k=5,
                response_mode="tree_summarize"
            )
            
            # æ‰§è¡ŒæŸ¥è¯¢
            logger.info(f"ğŸš€ æ‰§è¡ŒæŸ¥è¯¢: {kb_name}")
            response = query_engine.query(question)
            result = str(response)
            
            logger.info(f"ğŸ“ æŸ¥è¯¢ç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢çŸ¥è¯†åº“ {kb_name} å¼‚å¸¸: {str(e)}")
            return f"æŸ¥è¯¢çŸ¥è¯†åº“ {kb_name} æ—¶å‡ºé”™: {str(e)}"
    
    def _integrate_results(self, question: str, results: List[dict]) -> str:
        """æ•´åˆå¤šä¸ªçŸ¥è¯†åº“çš„æŸ¥è¯¢ç»“æœ"""
        if not results:
            logger.warning("âŒ æ‰€æœ‰çŸ¥è¯†åº“æŸ¥è¯¢å‡å¤±è´¥")
            return "âŒ æ‰€æœ‰çŸ¥è¯†åº“æŸ¥è¯¢å‡å¤±è´¥"
        
        # è¿‡æ»¤æœ‰æ•ˆç»“æœ - æ’é™¤è¿‡äºç®€çŸ­æˆ–æ— å…³çš„å›ç­”
        valid_results = []
        for r in results:
            content = r['content'].strip()
            # è¿‡æ»¤æ‰æ˜æ˜¾çš„é”™è¯¯ã€è¿‡çŸ­æˆ–æ— å…³å›ç­”
            if (not content.startswith('æŸ¥è¯¢') and 
                len(content) > 10 and 
                not content.lower() in ['å¥½çš„', 'æ”¶åˆ°', 'æµ‹è¯•æˆåŠŸ', 'æ²¡æœ‰ç›¸å…³ä¿¡æ¯']):
                valid_results.append(r)
        
        logger.info(f"ğŸ“Š ç»“æœç»Ÿè®¡: æ€»è®¡ {len(results)} ä¸ªï¼Œæœ‰æ•ˆ {len(valid_results)} ä¸ª")
        
        if not valid_results:
            # æ‰€æœ‰æŸ¥è¯¢éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„æŸ¥è¯¢ç»“æœ")
            error_summary = "\n".join([f"â€¢ {r['kb_name']}: {r['content']}" for r in results])
            return f"âŒ æŸ¥è¯¢å¤±è´¥:\n{error_summary}"
        
        # æ„å»ºæ•´åˆç­”æ¡ˆ
        logger.info("ğŸ”§ æ„å»ºæ•´åˆç­”æ¡ˆ...")
        answer_parts = []
        answer_parts.append(f"ğŸ” **åŸºäº {len(valid_results)} ä¸ªçŸ¥è¯†åº“çš„è”åˆæŸ¥è¯¢ç»“æœ:**\n")
        
        for i, result in enumerate(valid_results, 1):
            kb_name = result['kb_name']
            content = result['content'].strip()
            
            # ç®€åŒ–çŸ¥è¯†åº“åç§°æ˜¾ç¤º
            display_name = kb_name.replace('_20251223_', ' ').replace('_', ' ')
            logger.info(f"ğŸ“š æ•´åˆæ¥æº {i}: {display_name} ({len(content)} å­—ç¬¦)")
            
            answer_parts.append(f"**ğŸ“š æ¥æº {i}: {display_name}**")
            answer_parts.append(content)
            answer_parts.append("")  # ç©ºè¡Œåˆ†éš”
        
        # å¦‚æœæœ‰å¤±è´¥çš„æŸ¥è¯¢ï¼Œåœ¨æœ«å°¾æåŠ
        failed_results = [r for r in results if r['content'].startswith('æŸ¥è¯¢')]
        if failed_results:
            logger.warning(f"âš ï¸ {len(failed_results)} ä¸ªçŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥")
            answer_parts.append("âš ï¸ **éƒ¨åˆ†çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥:**")
            for r in failed_results:
                answer_parts.append(f"â€¢ {r['kb_name']}: {r['content']}")
        
        final_answer = "\n".join(answer_parts)
        logger.success(f"âœ… ç­”æ¡ˆæ•´åˆå®Œæˆï¼Œæ€»é•¿åº¦: {len(final_answer)} å­—ç¬¦")
        return final_answer
