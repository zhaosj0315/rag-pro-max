"""
æŸ¥è¯¢å¤„ç†å™¨
æå–è‡ª apppro.py çš„æŸ¥è¯¢å¤„ç†é€»è¾‘
"""

import os
import time
import streamlit as st
from llama_index.core import Settings, load_index_from_storage, StorageContext

from src.app_logging import LogManager
from src.utils.memory import cleanup_memory
from src.utils.model_manager import load_embedding_model, load_llm_model
from src.chat import HistoryManager


class QueryHandler:
    """æŸ¥è¯¢å¤„ç†å™¨"""
    
    def __init__(self):
        self.logger = LogManager()
    
    def load_knowledge_base(self, kb_name: str, output_base: str, embed_provider: str, 
                           embed_model: str, embed_key: str, embed_url: str) -> bool:
        """
        åŠ è½½çŸ¥è¯†åº“
        
        Args:
            kb_name: çŸ¥è¯†åº“åç§°
            output_base: è¾“å‡ºåŸºç¡€è·¯å¾„
            embed_provider: åµŒå…¥æ¨¡å‹æä¾›å•†
            embed_model: åµŒå…¥æ¨¡å‹åç§°
            embed_key: APIå¯†é’¥
            embed_url: APIåœ°å€
            
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        db_path = os.path.join(output_base, kb_name)
        if not os.path.exists(db_path):
            return False
        
        try:
            self.logger.log("INFO", f"å¼€å§‹åŠ è½½çŸ¥è¯†åº“: {kb_name}", stage="çŸ¥è¯†åº“åŠ è½½")
            
            # æ£€æµ‹çŸ¥è¯†åº“çš„å‘é‡ç»´åº¦
            kb_dim = self._get_kb_embedding_dim(db_path)
            if kb_dim:
                # æ ¹æ®ç»´åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
                model_map = {
                    512: "sentence-transformers/all-MiniLM-L6-v2",
                    768: "BAAI/bge-base-zh-v1.5", 
                    1024: "BAAI/bge-m3"
                }
                
                if kb_dim in model_map:
                    required_model = model_map[kb_dim]
                    if embed_model != required_model:
                        self.logger.warning(f"âš ï¸ çŸ¥è¯†åº“ç»´åº¦: {kb_dim}Dï¼Œè‡ªåŠ¨åˆ‡æ¢æ¨¡å‹: {required_model}")
                        embed_model = required_model
                        # é‡æ–°åŠ è½½ embedding æ¨¡å‹
                        embed = load_embedding_model(embed_provider, embed_model, embed_key, embed_url)
                        if embed:
                            Settings.embed_model = embed
            
            # åŠ è½½å‘é‡ç´¢å¼•
            storage_context = StorageContext.from_defaults(persist_dir=db_path)
            index = load_index_from_storage(storage_context)
            
            # åˆ›å»ºæŸ¥è¯¢å¼•æ“
            chat_engine = index.as_chat_engine(
                chat_mode="context",
                memory=None,
                system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼Œå¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚",
                verbose=False
            )
            
            st.session_state.chat_engine = chat_engine
            self.logger.success(f"âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸ: {kb_name}")
            
            # æ¸…ç†å†…å­˜
            cleanup_memory()
            self.logger.info("ğŸ§¹ å·²æ¸…ç† MPS æ˜¾å­˜ç¼“å­˜")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def process_question(self, question: str, llm_provider: str, llm_model: str, 
                        llm_key: str, llm_url: str, temperature: float = 0.7):
        """
        å¤„ç†ç”¨æˆ·é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            llm_provider: LLMæä¾›å•†
            llm_model: LLMæ¨¡å‹
            llm_key: APIå¯†é’¥
            llm_url: APIåœ°å€
            temperature: æ¸©åº¦å‚æ•°
            
        Yields:
            dict: å¤„ç†ç»“æœ
        """
        try:
            # è®¾ç½®LLM
            llm = load_llm_model(llm_provider, llm_model, llm_key, llm_url, temperature)
            if llm:
                Settings.llm = llm
            
            # å¼€å§‹æŸ¥è¯¢
            self.logger.log("INFO", f"ç”¨æˆ·æé—®: {question}", stage="æŸ¥è¯¢å¯¹è¯")
            self.logger.log("INFO", "å¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£", stage="æŸ¥è¯¢å¯¹è¯")
            
            start_time = time.time()
            
            # æµå¼å“åº”
            response = st.session_state.chat_engine.stream_chat(question)
            
            full_text = ""
            for token in response.response_gen:
                full_text += token
                yield {
                    'type': 'token',
                    'content': token
                }
            
            # å®Œæˆå¤„ç†
            elapsed = time.time() - start_time
            
            # è·å–æºæ–‡æ¡£
            sources = []
            if hasattr(response, 'source_nodes'):
                for node in response.source_nodes:
                    if hasattr(node, 'metadata') and 'file_name' in node.metadata:
                        sources.append({
                            'file_name': node.metadata['file_name'],
                            'content': node.text[:200] + "..." if len(node.text) > 200 else node.text
                        })
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'elapsed_time': elapsed,
                'source_count': len(sources)
            }
            
            self.logger.success("âœ… æŸ¥è¯¢å¯¹è¯å›ç­”ç”Ÿæˆå®Œæˆ")
            self.logger.log("INFO", f"å®Œæˆ: æŸ¥è¯¢å®Œæˆ (è€—æ—¶ {elapsed:.2f}s)", stage="æŸ¥è¯¢å¯¹è¯")
            
            yield {
                'type': 'complete',
                'content': full_text,
                'sources': sources,
                'stats': stats
            }
            
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            yield {
                'type': 'error',
                'content': str(e)
            }
    
    def _get_kb_embedding_dim(self, db_path: str) -> int:
        """è·å–çŸ¥è¯†åº“åµŒå…¥ç»´åº¦"""
        try:
            # ç®€åŒ–å®ç°ï¼šä»çŸ¥è¯†åº“ä¿¡æ¯æ–‡ä»¶è¯»å–
            kb_info_file = os.path.join(db_path, "kb_info.json")
            if os.path.exists(kb_info_file):
                import json
                with open(kb_info_file, 'r', encoding='utf-8') as f:
                    info = json.load(f)
                    return info.get('embedding_dim', 1024)
            return 1024  # é»˜è®¤ç»´åº¦
        except:
            return 1024
