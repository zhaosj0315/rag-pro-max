"""
é…ç½®ç•Œé¢ç®¡ç†å™¨ - è´Ÿè´£é…ç½®ç›¸å…³çš„UIé€»è¾‘
"""

import streamlit as st


class ConfigInterface:
    """é…ç½®ç•Œé¢ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é…ç½®ç•Œé¢"""
        pass
    
    def render_config_tab(self):
        """æ¸²æŸ“é…ç½®æ ‡ç­¾é¡µ"""
        st.markdown("### âš™ï¸ æ¨¡å‹é…ç½®")
        
        # è·å–é»˜è®¤é…ç½®
        from src.config import ConfigLoader
        defaults = ConfigLoader.load()
        
        # åŸºç¡€é…ç½®
        config_values = self.render_basic_config(defaults)
        
        # é«˜çº§é…ç½®
        self.render_advanced_config()
        
        return config_values
    
    def render_basic_config(self, defaults: dict):
        """æ¸²æŸ“åŸºç¡€é…ç½® - ä½¿ç”¨ç»Ÿä¸€ç»„ä»¶"""
        from src.ui.unified_config_components import render_basic_config
        return render_basic_config(defaults, "config_interface")
    
    def render_advanced_config(self):
        """æ¸²æŸ“é«˜çº§é…ç½® - ä½¿ç”¨ç»Ÿä¸€ç»„ä»¶"""
        from src.ui.unified_config_components import unified_config_renderer
        config_data = unified_config_renderer.load_config("advanced")
        return unified_config_renderer.render_advanced_config(config_data, "config_interface")
    
    def render_model_config(self):
        """æ¸²æŸ“æ¨¡å‹é…ç½®"""
        st.markdown("#### ğŸ¤– LLM é…ç½®")
        
        # LLM æä¾›å•†é€‰æ‹©
        llm_provider = st.selectbox(
            "LLM æä¾›å•†",
            ["Ollama", "OpenAI", "å…¶ä»–"],
            key="config_llm_provider"
        )
        
        config_values = {"llm_provider": llm_provider}
        
        if llm_provider == "Ollama":
            config_values.update(self.render_ollama_config())
        elif llm_provider == "OpenAI":
            config_values.update(self.render_openai_config())
        
        st.markdown("#### ğŸ§  åµŒå…¥æ¨¡å‹é…ç½®")
        embed_config = self.render_embedding_config()
        config_values.update(embed_config)
        
        return config_values
    
    def render_ollama_config(self):
        """æ¸²æŸ“Ollamaé…ç½®"""
        col1, col2 = st.columns(2)
        
        with col1:
            llm_url = st.text_input(
                "APIåœ°å€",
                value="http://localhost:11434",
                key="config_ollama_url"
            )
        
        with col2:
            llm_model = st.text_input(
                "æ¨¡å‹åç§°",
                value="gpt-oss:20b",
                key="config_ollama_model"
            )
        
        return {
            "llm_url": llm_url,
            "llm_model": llm_model,
            "llm_key": ""
        }
    
    def render_openai_config(self):
        """æ¸²æŸ“OpenAIé…ç½®"""
        col1, col2 = st.columns(2)
        
        with col1:
            llm_url = st.text_input(
                "APIåœ°å€",
                value="https://api.openai.com/v1",
                key="config_openai_url"
            )
        
        with col2:
            llm_model = st.selectbox(
                "æ¨¡å‹",
                ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"],
                key="config_openai_model"
            )
        
        llm_key = st.text_input(
            "API Key",
            type="password",
            key="config_openai_key"
        )
        
        return {
            "llm_url": llm_url,
            "llm_model": llm_model,
            "llm_key": llm_key
        }
    
    def render_embedding_config(self):
        """æ¸²æŸ“åµŒå…¥æ¨¡å‹é…ç½®"""
        embed_provider = st.selectbox(
            "åµŒå…¥æ¨¡å‹æä¾›å•†",
            ["HuggingFace (æœ¬åœ°/æé€Ÿ)", "OpenAI-Compatible", "Ollama"],
            key="config_embed_provider"
        )
        
        config = {"embed_provider": embed_provider}
        
        if embed_provider.startswith("HuggingFace"):
            embed_model = st.selectbox(
                "HuggingFaceæ¨¡å‹",
                [
                    "sentence-transformers/all-MiniLM-L6-v2",
                    "BAAI/bge-large-zh-v1.5",
                    "sentence-transformers/all-MiniLM-L6-v2"
                ],
                key="config_hf_model"
            )
            config.update({
                "embed_model": embed_model,
                "embed_url": "",
                "embed_key": ""
            })
        
        elif embed_provider == "OpenAI-Compatible":
            col1, col2 = st.columns(2)
            with col1:
                embed_url = st.text_input("APIåœ°å€", key="config_embed_url")
            with col2:
                embed_key = st.text_input("API Key", type="password", key="config_embed_key")
            
            embed_model = st.text_input("æ¨¡å‹åç§°", key="config_embed_model")
            
            config.update({
                "embed_model": embed_model,
                "embed_url": embed_url,
                "embed_key": embed_key
            })
        
        elif embed_provider == "Ollama":
            col1, col2 = st.columns(2)
            with col1:
                embed_url = st.text_input(
                    "Ollamaåœ°å€",
                    value="http://localhost:11434",
                    key="config_ollama_embed_url"
                )
            with col2:
                embed_model = st.text_input(
                    "æ¨¡å‹åç§°",
                    value="nomic-embed-text",
                    key="config_ollama_embed_model"
                )
            
            config.update({
                "embed_model": embed_model,
                "embed_url": embed_url,
                "embed_key": ""
            })
        
        return config
    
    def render_rag_config(self):
        """æ¸²æŸ“RAGé…ç½®"""
        st.markdown("#### ğŸ” RAG å‚æ•°é…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            chunk_size = st.number_input(
                "æ–‡æ¡£åˆ†å—å¤§å°",
                min_value=100,
                max_value=2000,
                value=500,
                step=50,
                key="config_chunk_size"
            )
            
            top_k = st.number_input(
                "æ£€ç´¢æ–‡æ¡£æ•°é‡",
                min_value=1,
                max_value=20,
                value=5,
                key="config_top_k"
            )
        
        with col2:
            chunk_overlap = st.number_input(
                "åˆ†å—é‡å é•¿åº¦",
                min_value=0,
                max_value=200,
                value=50,
                step=10,
                key="config_chunk_overlap"
            )
            
            similarity_threshold = st.slider(
                "ç›¸ä¼¼åº¦é˜ˆå€¼",
                min_value=0.0,
                max_value=1.0,
                value=0.7,
                step=0.05,
                key="config_similarity_threshold"
            )
        
        return {
            "chunk_size": chunk_size,
            "chunk_overlap": chunk_overlap,
            "top_k": top_k,
            "similarity_threshold": similarity_threshold
        }
    
    def render_performance_config(self):
        """æ¸²æŸ“æ€§èƒ½é…ç½®"""
        st.markdown("#### âš¡ æ€§èƒ½é…ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            enable_gpu = st.checkbox(
                "å¯ç”¨GPUåŠ é€Ÿ",
                value=True,
                key="config_enable_gpu"
            )
            
            max_workers = st.number_input(
                "æœ€å¤§å·¥ä½œçº¿ç¨‹",
                min_value=1,
                max_value=16,
                value=4,
                key="config_max_workers"
            )
        
        with col2:
            enable_cache = st.checkbox(
                "å¯ç”¨ç¼“å­˜",
                value=True,
                key="config_enable_cache"
            )
            
            batch_size = st.number_input(
                "æ‰¹å¤„ç†å¤§å°",
                min_value=1,
                max_value=100,
                value=10,
                key="config_batch_size"
            )
        
        return {
            "enable_gpu": enable_gpu,
            "max_workers": max_workers,
            "enable_cache": enable_cache,
            "batch_size": batch_size
        }
    
    def save_config(self, config_values: dict):
        """ä¿å­˜é…ç½®"""
        try:
            from src.config import ConfigLoader
            ConfigLoader.save(config_values)
            st.success("âœ… é…ç½®å·²ä¿å­˜")
        except Exception as e:
            st.error(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
    
    def test_config(self, config_values: dict):
        """æµ‹è¯•é…ç½®"""
        st.markdown("#### ğŸ§ª é…ç½®æµ‹è¯•")
        
        if st.button("ğŸ” æµ‹è¯•LLMè¿æ¥", use_container_width=True):
            self.test_llm_connection(config_values)
        
        if st.button("ğŸ§  æµ‹è¯•åµŒå…¥æ¨¡å‹", use_container_width=True):
            self.test_embedding_model(config_values)
    
    def test_llm_connection(self, config_values: dict):
        """æµ‹è¯•LLMè¿æ¥"""
        try:
            llm_provider = config_values.get("llm_provider", "Ollama")
            
            with st.spinner("æµ‹è¯•LLMè¿æ¥..."):
                if llm_provider == "Ollama":
                    import ollama
                    models = ollama.list()
                    st.success(f"âœ… Ollamaè¿æ¥æˆåŠŸï¼Œå‘ç° {len(models.get('models', []))} ä¸ªæ¨¡å‹")
                
                elif llm_provider == "OpenAI":
                    # ç®€å•çš„APIæµ‹è¯•
                    st.success("âœ… OpenAIé…ç½®æ ¼å¼æ­£ç¡®")
                
        except Exception as e:
            st.error(f"âŒ LLMè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
    
    def test_embedding_model(self, config_values: dict):
        """æµ‹è¯•åµŒå…¥æ¨¡å‹"""
        try:
            embed_provider = config_values.get("embed_provider", "HuggingFace (æœ¬åœ°/æé€Ÿ)")
            embed_model = config_values.get("embed_model", "sentence-transformers/all-MiniLM-L6-v2")
            
            with st.spinner("æµ‹è¯•åµŒå…¥æ¨¡å‹..."):
                from src.utils.model_manager import load_embedding_model
                
                embed = load_embedding_model(
                    embed_provider,
                    embed_model,
                    config_values.get("embed_key", ""),
                    config_values.get("embed_url", "")
                )
                
                if embed:
                    # æµ‹è¯•åµŒå…¥
                    test_embedding = embed._get_text_embedding("æµ‹è¯•æ–‡æœ¬")
                    st.success(f"âœ… åµŒå…¥æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œç»´åº¦: {len(test_embedding)}")
                else:
                    st.error("âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥")
                
        except Exception as e:
            st.error(f"âŒ åµŒå…¥æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
    
    def render_quick_setup(self):
        """æ¸²æŸ“å¿«é€Ÿè®¾ç½®"""
        st.markdown("#### âš¡ å¿«é€Ÿè®¾ç½®")
        
        setup_type = st.selectbox(
            "é€‰æ‹©é…ç½®æ–¹æ¡ˆ",
            ["æœ¬åœ°éƒ¨ç½² (Ollama)", "äº‘ç«¯æœåŠ¡ (OpenAI)", "è‡ªå®šä¹‰é…ç½®"],
            key="quick_setup_type"
        )
        
        if st.button("ğŸš€ ä¸€é”®é…ç½®", type="primary", use_container_width=True):
            self.apply_quick_setup(setup_type)
    
    def apply_quick_setup(self, setup_type: str):
        """åº”ç”¨å¿«é€Ÿè®¾ç½®"""
        try:
            from src.config import ConfigLoader
            
            if setup_type == "æœ¬åœ°éƒ¨ç½² (Ollama)":
                config = {
                    "llm_provider": "Ollama",
                    "llm_url": "http://localhost:11434",
                    "llm_model": "gpt-oss:20b",
                    "llm_key": "",
                    "embed_provider": "HuggingFace (æœ¬åœ°/æé€Ÿ)",
                    "embed_model": "sentence-transformers/all-MiniLM-L6-v2"
                }
            
            elif setup_type == "äº‘ç«¯æœåŠ¡ (OpenAI)":
                config = {
                    "llm_provider": "OpenAI",
                    "llm_url": "https://api.openai.com/v1",
                    "llm_model": "gpt-3.5-turbo",
                    "embed_provider": "HuggingFace (æœ¬åœ°/æé€Ÿ)",
                    "embed_model": "sentence-transformers/all-MiniLM-L6-v2"
                }
            
            else:
                st.info("è¯·æ‰‹åŠ¨é…ç½®å„é¡¹å‚æ•°")
                return
            
            ConfigLoader.save(config)
            st.success(f"âœ… {setup_type} é…ç½®å·²åº”ç”¨ï¼")
            
        except Exception as e:
            st.error(f"âŒ å¿«é€Ÿé…ç½®å¤±è´¥: {str(e)}")
