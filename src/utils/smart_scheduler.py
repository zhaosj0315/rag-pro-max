"""
æ™ºèƒ½èµ„æºè°ƒåº¦å™¨
åŸºäºå†å²æ•°æ®å’Œå®æ—¶çŠ¶æ€ä¼˜åŒ–èµ„æºåˆ†é…
"""

import json
import os
import time
import psutil
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from enum import Enum
import logging

class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹æšä¸¾"""
    CPU_INTENSIVE = "cpu_intensive"
    GPU_INTENSIVE = "gpu_intensive" 
    IO_INTENSIVE = "io_intensive"
    GENERAL = "general"

class SmartScheduler:
    def __init__(self):
        self.history_file = "config/scheduler_history.json"
        self.config_file = "config/scheduler_config.json"
        self.max_history = 200
        self.learning_rate = 0.1
        
        # é»˜è®¤é…ç½®
        self.default_config = {
            'cpu_thresholds': {'low': 40, 'medium': 75, 'high': 92},
            'memory_thresholds': {'low': 40, 'medium': 75, 'high': 90},
            'worker_configs': {
                'low_load': {'cpu_workers': 10, 'io_workers': 5},
                'medium_load': {'cpu_workers': 6, 'io_workers': 3},
                'high_load': {'cpu_workers': 4, 'io_workers': 2}
            },
            'adaptive_enabled': True,
            'learning_enabled': True
        }
        
        self.load_config()
    
    def load_config(self):
        """åŠ è½½è°ƒåº¦é…ç½®"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r') as f:
                    self.config = json.load(f)
            except:
                self.config = self.default_config.copy()
        else:
            self.config = self.default_config.copy()
            self.save_config()
    
    def save_config(self):
        """ä¿å­˜è°ƒåº¦é…ç½®"""
        os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
        with open(self.config_file, 'w') as f:
            json.dump(self.config, f, indent=2)
    
    def get_system_load(self) -> Dict:
        """è·å–ç³»ç»Ÿè´Ÿè½½"""
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory_percent = psutil.virtual_memory().percent
        
        # åˆ†ç±»è´Ÿè½½ç­‰çº§
        cpu_level = self._classify_load(cpu_percent, self.config['cpu_thresholds'])
        memory_level = self._classify_load(memory_percent, self.config['memory_thresholds'])
        
        # ç»¼åˆè´Ÿè½½ç­‰çº§ï¼ˆå–è¾ƒé«˜è€…ï¼‰
        load_levels = ['low', 'medium', 'high']
        cpu_idx = load_levels.index(cpu_level) if cpu_level in load_levels else 1
        memory_idx = load_levels.index(memory_level) if memory_level in load_levels else 1
        overall_level = load_levels[max(cpu_idx, memory_idx)]
        
        return {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': cpu_percent,
            'memory_percent': memory_percent,
            'cpu_level': cpu_level,
            'memory_level': memory_level,
            'overall_level': overall_level
        }
    
    def _classify_load(self, value: float, thresholds: Dict) -> str:
        """åˆ†ç±»è´Ÿè½½ç­‰çº§"""
        if value < thresholds['low']:
            return 'low'
        elif value < thresholds['medium']:
            return 'medium'
        else:
            return 'high'
    
    def get_optimal_workers(self, task_type: str = 'general') -> Dict:
        """è·å–æœ€ä¼˜å·¥ä½œçº¿ç¨‹é…ç½®"""
        load = self.get_system_load()
        level = load['overall_level']
        
        # æ˜ å°„è´Ÿè½½ç­‰çº§åˆ°é…ç½®é”®
        level_mapping = {
            'low': 'low_load',
            'medium': 'medium_load', 
            'high': 'high_load'
        }
        
        config_key = level_mapping.get(level, 'medium_load')
        base_config = self.config['worker_configs'][config_key].copy()
        
        # å¦‚æœå¯ç”¨è‡ªé€‚åº”å­¦ä¹ 
        if self.config['adaptive_enabled']:
            base_config = self._apply_adaptive_adjustment(base_config, load, task_type)
        
        # è®°å½•å†³ç­–å†å²
        self._record_decision(load, base_config, task_type)
        
        return {
            'cpu_workers': base_config['cpu_workers'],
            'io_workers': base_config['io_workers'],
            'load_level': level,
            'reasoning': f"ç³»ç»Ÿè´Ÿè½½: {level}, CPU: {load['cpu_percent']:.1f}%, å†…å­˜: {load['memory_percent']:.1f}%"
        }
    
    def _apply_adaptive_adjustment(self, base_config: Dict, load: Dict, task_type: str) -> Dict:
        """åº”ç”¨è‡ªé€‚åº”è°ƒæ•´"""
        if not self.config['learning_enabled']:
            return base_config
        
        # åŸºäºå†å²æ€§èƒ½è°ƒæ•´
        history = self._load_history()
        if len(history) < 10:  # å†å²æ•°æ®ä¸è¶³
            return base_config
        
        # åˆ†æç›¸ä¼¼åœºæ™¯çš„å†å²è¡¨ç°
        similar_scenarios = [
            h for h in history[-50:] 
            if abs(h['load']['cpu_percent'] - load['cpu_percent']) < 10
            and abs(h['load']['memory_percent'] - load['memory_percent']) < 10
            and h.get('task_type') == task_type
        ]
        
        if len(similar_scenarios) < 3:
            return base_config
        
        # è®¡ç®—å¹³å‡æ€§èƒ½
        avg_performance = sum(s.get('performance_score', 0.5) for s in similar_scenarios) / len(similar_scenarios)
        
        # å¦‚æœå†å²æ€§èƒ½ä¸ä½³ï¼Œè°ƒæ•´é…ç½®
        if avg_performance < 0.6:
            base_config['cpu_workers'] = max(1, int(base_config['cpu_workers'] * 0.8))
            base_config['io_workers'] = max(1, int(base_config['io_workers'] * 0.8))
        elif avg_performance > 0.8:
            base_config['cpu_workers'] = min(12, int(base_config['cpu_workers'] * 1.2))
            base_config['io_workers'] = min(6, int(base_config['io_workers'] * 1.2))
        
        return base_config
    
    def _record_decision(self, load: Dict, config: Dict, task_type: str):
        """è®°å½•è°ƒåº¦å†³ç­–"""
        decision = {
            'timestamp': datetime.now().isoformat(),
            'load': load,
            'config': config,
            'task_type': task_type
        }
        
        history = self._load_history()
        history.append(decision)
        
        if len(history) > self.max_history:
            history = history[-self.max_history:]
        
        self._save_history(history)
    
    def record_performance(self, task_type: str, duration: float, success: bool, cpu_usage: float = None):
        """è®°å½•ä»»åŠ¡æ€§èƒ½"""
        self.history.append({
            'task_type': task_type,
            'duration': duration,
            'success': success,
            'cpu_usage': cpu_usage,
            'timestamp': time.time()
        })
        
        # é™åˆ¶å†å²è®°å½•æ•°é‡
        if len(self.history) > 1000:
            self.history = self.history[-1000:]
            
        # è‡ªåŠ¨ä¿å­˜
        if len(self.history) % 10 == 0:
            self.save_history()

    def shutdown(self):
        """å…³é—­è°ƒåº¦å™¨å¹¶é‡Šæ”¾èµ„æº"""
        try:
            self.save_config()
        except:
            pass
    
    def _load_history(self) -> List:
        """åŠ è½½å†å²è®°å½•"""
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r') as f:
                    return json.load(f)
            except:
                return []
        return []
    
    def _save_history(self, history: List):
        """ä¿å­˜å†å²è®°å½•"""
        os.makedirs(os.path.dirname(self.history_file), exist_ok=True)
        with open(self.history_file, 'w') as f:
            json.dump(history, f)
    
    def get_recommendations(self) -> Dict:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        load = self.get_system_load()
        history = self._load_history()
        
        recommendations = []
        
        # åŸºäºå½“å‰è´Ÿè½½çš„å»ºè®®
        if load['cpu_percent'] > 85:
            recommendations.append("âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®å‡å°‘å¹¶è¡Œä»»åŠ¡")
        elif load['cpu_percent'] < 20:
            recommendations.append("ğŸ’¡ CPUä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥å¢åŠ å¹¶è¡Œåº¦")
        
        if load['memory_percent'] > 90:
            recommendations.append("ğŸš¨ å†…å­˜ä½¿ç”¨ç‡å±é™©ï¼Œå»ºè®®ç«‹å³æ¸…ç†ç¼“å­˜")
        elif load['memory_percent'] > 80:
            recommendations.append("âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®å‡å°‘å†…å­˜å¯†é›†å‹ä»»åŠ¡")
        
        # åŸºäºå†å²æ•°æ®çš„å»ºè®®
        if len(history) > 20:
            recent_performance = [h.get('performance_score', 0.5) for h in history[-20:]]
            avg_performance = sum(recent_performance) / len(recent_performance)
            
            if avg_performance < 0.5:
                recommendations.append("ğŸ“‰ æœ€è¿‘æ€§èƒ½è¡¨ç°ä¸ä½³ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿé…ç½®")
            elif avg_performance > 0.8:
                recommendations.append("ğŸ“ˆ ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œå½“å‰é…ç½®è¾ƒä¸ºåˆé€‚")
        
        return {
            'current_load': load,
            'recommendations': recommendations,
            'optimal_config': self.get_optimal_workers()
        }

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
_scheduler = None

def get_smart_scheduler() -> SmartScheduler:
    """è·å–æ™ºèƒ½è°ƒåº¦å™¨å®ä¾‹"""
    global _scheduler
    if _scheduler is None:
        _scheduler = SmartScheduler()
    return _scheduler
