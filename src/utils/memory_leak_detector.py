"""
å†…å­˜æ³„æ¼æ£€æµ‹å’Œä¿®å¤å·¥å…·
è§£å†³é•¿æ—¶é—´è¿è¡Œå†…å­˜å¢é•¿é—®é¢˜
"""

import gc
import psutil
import threading
import time
import weakref
from datetime import datetime
import streamlit as st

class MemoryLeakDetector:
    def __init__(self):
        self.process = psutil.Process()
        self.baseline_memory = self.get_memory_usage()
        self.memory_history = []
        self.object_refs = weakref.WeakSet()
        self.monitoring = False
        self.monitor_thread = None
        
    def get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡(MB)"""
        return self.process.memory_info().rss / 1024 / 1024
    
    def start_monitoring(self, interval=30):
        """å¼€å§‹å†…å­˜ç›‘æ§"""
        if not self.monitoring:
            self.monitoring = True
            self.monitor_thread = threading.Thread(
                target=self._monitor_loop, 
                args=(interval,), 
                daemon=True
            )
            self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢å†…å­˜ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)
    
    def _monitor_loop(self, interval):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            current_memory = self.get_memory_usage()
            self.memory_history.append({
                'timestamp': datetime.now(),
                'memory_mb': current_memory,
                'growth': current_memory - self.baseline_memory
            })
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
            if len(self.memory_history) > 100:
                self.memory_history = self.memory_history[-50:]
            
            # æ£€æµ‹å†…å­˜æ³„æ¼
            if self.detect_leak():
                self.auto_cleanup()
            
            time.sleep(interval)
    
    def detect_leak(self, threshold_mb=500, growth_rate=1.5):
        """æ£€æµ‹å†…å­˜æ³„æ¼"""
        if len(self.memory_history) < 5:
            return False
        
        current = self.memory_history[-1]
        
        # æ£€æŸ¥ç»å¯¹å†…å­˜ä½¿ç”¨é‡
        if current['memory_mb'] > threshold_mb:
            return True
        
        # æ£€æŸ¥å†…å­˜å¢é•¿ç‡
        if len(self.memory_history) >= 10:
            recent_growth = current['memory_mb'] - self.memory_history[-10]['memory_mb']
            if recent_growth > growth_rate * 10:  # 10ä¸ªå‘¨æœŸå†…å¢é•¿è¶…è¿‡é˜ˆå€¼
                return True
        
        return False
    
    def auto_cleanup(self):
        """è‡ªåŠ¨å†…å­˜æ¸…ç†"""
        print(f"ğŸ§¹ æ£€æµ‹åˆ°å†…å­˜æ³„æ¼ï¼Œå¼€å§‹è‡ªåŠ¨æ¸…ç†...")
        
        # 1. æ¸…ç†Streamlitç¼“å­˜
        if hasattr(st, 'cache_data'):
            st.cache_data.clear()
        if hasattr(st, 'cache_resource'):
            st.cache_resource.clear()
        
        # 2. æ¸…ç†ä¼šè¯çŠ¶æ€ä¸­çš„å¤§å¯¹è±¡
        self._cleanup_session_state()
        
        # 3. æ¸…ç†GPUç¼“å­˜
        self._cleanup_gpu_cache()
        
        # 4. å¼ºåˆ¶åƒåœ¾å›æ”¶
        collected = gc.collect()
        
        # 5. æ›´æ–°åŸºçº¿
        new_memory = self.get_memory_usage()
        freed_mb = self.memory_history[-1]['memory_mb'] - new_memory
        
        print(f"âœ… å†…å­˜æ¸…ç†å®Œæˆ: é‡Šæ”¾ {freed_mb:.1f}MB, å›æ”¶ {collected} ä¸ªå¯¹è±¡")
        
        # è®°å½•æ¸…ç†äº‹ä»¶
        self.memory_history.append({
            'timestamp': datetime.now(),
            'memory_mb': new_memory,
            'growth': new_memory - self.baseline_memory,
            'cleanup': True,
            'freed_mb': freed_mb
        })
    
    def _cleanup_session_state(self):
        """æ¸…ç†ä¼šè¯çŠ¶æ€"""
        if not hasattr(st, 'session_state'):
            return
        
        # æ¸…ç†å¤§å‹å¯¹è±¡
        large_keys = []
        for key, value in st.session_state.items():
            try:
                # ä¼°ç®—å¯¹è±¡å¤§å°
                if hasattr(value, '__sizeof__'):
                    size = value.__sizeof__()
                    if size > 10 * 1024 * 1024:  # å¤§äº10MB
                        large_keys.append(key)
            except:
                pass
        
        # æ¸…ç†å†å²è®°å½•ï¼ˆä¿ç•™æœ€è¿‘50æ¡ï¼‰
        if 'messages' in st.session_state and len(st.session_state.messages) > 50:
            st.session_state.messages = st.session_state.messages[-50:]
        
        if 'suggestions_history' in st.session_state and len(st.session_state.suggestions_history) > 20:
            st.session_state.suggestions_history = st.session_state.suggestions_history[-20:]
    
    def _cleanup_gpu_cache(self):
        """æ¸…ç†GPUç¼“å­˜"""
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                torch.mps.empty_cache()
        except ImportError:
            pass
    
    def get_memory_report(self):
        """è·å–å†…å­˜æŠ¥å‘Š"""
        if not self.memory_history:
            return "æš‚æ— å†…å­˜ç›‘æ§æ•°æ®"
        
        current = self.memory_history[-1]
        max_memory = max(h['memory_mb'] for h in self.memory_history)
        min_memory = min(h['memory_mb'] for h in self.memory_history)
        
        report = f"""
ğŸ“Š å†…å­˜ä½¿ç”¨æŠ¥å‘Š:
- å½“å‰å†…å­˜: {current['memory_mb']:.1f} MB
- åŸºçº¿å†…å­˜: {self.baseline_memory:.1f} MB
- å†…å­˜å¢é•¿: {current['growth']:.1f} MB
- æœ€é«˜å†…å­˜: {max_memory:.1f} MB
- æœ€ä½å†…å­˜: {min_memory:.1f} MB
- ç›‘æ§å‘¨æœŸ: {len(self.memory_history)} æ¬¡
"""
        
        # ç»Ÿè®¡æ¸…ç†æ¬¡æ•°
        cleanup_count = sum(1 for h in self.memory_history if h.get('cleanup', False))
        if cleanup_count > 0:
            report += f"- è‡ªåŠ¨æ¸…ç†: {cleanup_count} æ¬¡\n"
        
        return report
    
    def register_object(self, obj):
        """æ³¨å†Œéœ€è¦ç›‘æ§çš„å¯¹è±¡"""
        self.object_refs.add(obj)
    
    def get_object_count(self):
        """è·å–ç›‘æ§å¯¹è±¡æ•°é‡"""
        return len(self.object_refs)

# å…¨å±€å†…å­˜æ³„æ¼æ£€æµ‹å™¨
memory_detector = MemoryLeakDetector()
