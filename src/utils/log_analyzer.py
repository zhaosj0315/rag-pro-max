"""
æ—¥å¿—åˆ†æå™¨ - è§£æå’Œç»Ÿè®¡å¤„ç†æ—¥å¿—
"""

import re
from collections import defaultdict

class LogAnalyzer:
    def __init__(self):
        self.ocr_stats = {
            'total_files': 0,
            'success_count': 0,
            'failed_count': 0,
            'total_pages': 0,
            'total_time': 0,
            'avg_speed': 0,
            'files': []
        }
        
        self.vector_stats = {
            'total_nodes': 0,
            'processed_batches': 0,
            'total_time': 0,
            'avg_speed': 0,
            'progress': 0
        }
        
        self.timeline = []
    
    def parse_log_text(self, log_text):
        """è§£ææ—¥å¿—æ–‡æœ¬"""
        lines = log_text.strip().split('\n')
        
        for line in lines:
            self._parse_ocr_line(line)
            self._parse_vector_line(line)
            self._parse_timeline_line(line)
    
    def _parse_ocr_line(self, line):
        """è§£æOCRç›¸å…³æ—¥å¿—"""
        # OCRå¤„ç†å¼€å§‹
        if "ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç†" in line:
            match = re.search(r'å¤„ç† (\d+) é¡µ', line)
            if match:
                pages = int(match.group(1))
                self.ocr_stats['total_files'] += 1
                self.ocr_stats['total_pages'] += pages
        
        # OCRå¤„ç†å®Œæˆ
        elif "OCRå¤„ç†å®Œæˆ:" in line:
            match = re.search(r'(\d+\.?\d*)ç§’, (\d+\.?\d*)é¡µ/ç§’', line)
            if match:
                time_cost = float(match.group(1))
                speed = float(match.group(2))
                self.ocr_stats['total_time'] += time_cost
                
                # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
                if "âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹" in line:
                    self.ocr_stats['failed_count'] += 1
                else:
                    self.ocr_stats['success_count'] += 1
    
    def _parse_vector_line(self, line):
        """è§£æå‘é‡åŒ–ç›¸å…³æ—¥å¿—"""
        # è§£æèŠ‚ç‚¹æ•°é‡
        if "è§£ææ–‡æ¡£ç‰‡æ®µ" in line:
            match = re.search(r'å…± (\d+) ä¸ª', line)
            if match:
                self.vector_stats['total_nodes'] = int(match.group(1))
        
        # è§£æå‘é‡åŒ–è¿›åº¦
        elif "Generating embeddings:" in line:
            match = re.search(r'(\d+)%.*?(\d+)/(\d+)', line)
            if match:
                progress = int(match.group(1))
                current = int(match.group(2))
                total = int(match.group(3))
                self.vector_stats['progress'] = progress
                self.vector_stats['processed_batches'] += 1
    
    def _parse_timeline_line(self, line):
        """è§£ææ—¶é—´çº¿"""
        # æå–æ—¶é—´æˆ³
        time_match = re.search(r'\[(\d{2}:\d{2}:\d{2})\]', line)
        if time_match:
            timestamp = time_match.group(1)
            
            # æå–æ­¥éª¤ä¿¡æ¯
            step_match = re.search(r'æ­¥éª¤ (\d+)/(\d+)', line)
            if step_match:
                current_step = int(step_match.group(1))
                total_steps = int(step_match.group(2))
                
                self.timeline.append({
                    'time': timestamp,
                    'step': current_step,
                    'total_steps': total_steps,
                    'description': line.split(']', 2)[-1].strip() if ']' in line else line
                })
    
    def generate_summary(self):
        """ç”Ÿæˆå¤„ç†æ‘˜è¦"""
        # è®¡ç®—OCRç»Ÿè®¡
        if self.ocr_stats['total_time'] > 0:
            self.ocr_stats['avg_speed'] = self.ocr_stats['total_pages'] / self.ocr_stats['total_time']
        
        success_rate = 0
        if self.ocr_stats['total_files'] > 0:
            success_rate = (self.ocr_stats['success_count'] / self.ocr_stats['total_files']) * 100
        
        summary = {
            'ocr_summary': {
                'ğŸ“„ æ€»æ–‡ä»¶æ•°': self.ocr_stats['total_files'],
                'ğŸ“‘ æ€»é¡µæ•°': self.ocr_stats['total_pages'],
                'âœ… æˆåŠŸæ–‡ä»¶': self.ocr_stats['success_count'],
                'âŒ å¤±è´¥æ–‡ä»¶': self.ocr_stats['failed_count'],
                'ğŸ“Š æˆåŠŸç‡': f"{success_rate:.1f}%",
                'â±ï¸ æ€»è€—æ—¶': f"{self.ocr_stats['total_time']:.1f}ç§’",
                'ğŸš€ å¹³å‡é€Ÿåº¦': f"{self.ocr_stats['avg_speed']:.1f}é¡µ/ç§’"
            },
            'vector_summary': {
                'ğŸ“ æ–‡æ¡£ç‰‡æ®µ': self.vector_stats['total_nodes'],
                'ğŸ“¦ å¤„ç†æ‰¹æ¬¡': self.vector_stats['processed_batches'],
                'ğŸ“ˆ å½“å‰è¿›åº¦': f"{self.vector_stats['progress']}%"
            },
            'timeline': self.timeline
        }
        
        return summary
    
    def print_summary(self):
        """æ‰“å°æ ¼å¼åŒ–æ‘˜è¦"""
        summary = self.generate_summary()
        
        print("=" * 60)
        print("ğŸ“Š å¤„ç†æ‘˜è¦æŠ¥å‘Š")
        print("=" * 60)
        
        print("\nğŸ” OCRå¤„ç†ç»Ÿè®¡:")
        for key, value in summary['ocr_summary'].items():
            print(f"   {key}: {value}")
        
        print("\nğŸ§  å‘é‡åŒ–ç»Ÿè®¡:")
        for key, value in summary['vector_summary'].items():
            print(f"   {key}: {value}")
        
        if summary['timeline']:
            print("\nâ° å¤„ç†æ—¶é—´çº¿:")
            for event in summary['timeline']:
                print(f"   [{event['time']}] æ­¥éª¤{event['step']}/{event['total_steps']}: {event['description']}")
        
        print("=" * 60)

def analyze_current_log():
    """åˆ†æå½“å‰æ—¥å¿—"""
    log_text = """
ğŸ” æ£€æµ‹åˆ°æ‰«æç‰ˆPDFï¼Œå¯ç”¨å¢å¼ºOCRå¤„ç†...
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 4 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 3.1ç§’, 1.3é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 122 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 307.3ç§’, 2.8é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 39 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 205.7ç§’, 2.8é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 1 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 2.0ç§’, 0.5é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 221 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 205.7ç§’, 2.8é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 6 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 3.1ç§’, 1.9é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 417 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 560.5ç§’, 2.9é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 225 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 330.2ç§’, 2.9é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
ğŸ“Š ä½¿ç”¨ä¼˜åŒ–OCRå¤„ç†å™¨å¤„ç† 90 é¡µ
âœ… OCRå¤„ç†å®Œæˆ: 43.3ç§’, 2.8é¡µ/ç§’
âš ï¸  OCRæœªæå–åˆ°æ–‡æœ¬å†…å®¹
â„¹ï¸ [06:39:40] ğŸ“‚ [æ­¥éª¤ 4/6] æ„å»ºæ–‡ä»¶æ¸…å•
â„¹ï¸ [06:39:40] ğŸ“‚ [æ­¥éª¤ 5/6] è§£ææ–‡æ¡£ç‰‡æ®µ (å…± 27940 ä¸ª)
â„¹ï¸ [06:39:53] ğŸ“‚ [æ­¥éª¤ 6/6] å‘é‡åŒ–å’Œç´¢å¼•æ„å»º
Generating embeddings: 100%|##########| 2048/2048 [01:32<00:00, 22.17it/s]
Generating embeddings: 44%|####3     | 900/2048 [00:41<00:51, 22.34it/s]
"""
    
    analyzer = LogAnalyzer()
    analyzer.parse_log_text(log_text)
    analyzer.print_summary()

if __name__ == "__main__":
    analyze_current_log()
