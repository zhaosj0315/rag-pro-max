"""
æ¨¡å‹å·¥å…·å‡½æ•°
æå–è‡ª apppro.py
"""

import os
import json
import requests
import streamlit as st


def check_ollama_status(url):
    """
    æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€
    
    Args:
        url: Ollama API URL
        
    Returns:
        bool: æœåŠ¡æ˜¯å¦å¯ç”¨
    """
    try:
        # æ¸…ç†ä»£ç†è®¾ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            from utils.model_manager import clean_proxy
            clean_proxy()
        except:
            pass
        
        clean = url.replace("/api/chat", "").replace("/v1", "").rstrip('/')
        # ä½¿ç”¨ Ollama çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹
        response = requests.get(f"{clean}/api/tags", timeout=2.0)
        return response.status_code == 200
    except:
        return False


def fetch_remote_models(base_url, api_key):
    """
    è·å–è¿œç¨‹æ¨¡å‹åˆ—è¡¨ (OpenAI å…¼å®¹æ¥å£)
    
    Args:
        base_url: API Base URL
        api_key: API Key
        
    Returns:
        tuple: (æ¨¡å‹åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
    """
    if not base_url:
        return None, "è¯·å¡«å†™ Base URL"
    
    # è‡ªåŠ¨è¯†åˆ« Ollama åœ°å€
    if "localhost:11434" in base_url or "127.0.0.1:11434" in base_url:
        return fetch_ollama_models(base_url)
    
    clean_url = base_url.rstrip('/')
    endpoints = [f"{clean_url}/models", f"{clean_url}/v1/models"]
    headers = {"Authorization": f"Bearer {api_key}" if api_key else "Bearer EMPTY"}
    
    for url in endpoints:
        try:
            resp = requests.get(url, headers=headers, timeout=5)
            if resp.status_code == 200:
                data = resp.json()
                if "data" in data and isinstance(data['data'], list):
                    return [item['id'] for item in data['data']], None
        except Exception as e:
            continue # å°è¯•ä¸‹ä¸€ä¸ª endpoint
    
    return None, "æœªæ‰¾åˆ°æ¨¡å‹åˆ—è¡¨æˆ–è·¯å¾„é”™è¯¯"


def fetch_ollama_models(url):
    """
    è·å– Ollama æ¨¡å‹åˆ—è¡¨
    
    Args:
        url: Ollama API URL
        
    Returns:
        tuple: (æ¨¡å‹åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
    """
    try:
        clean = url.replace("/api/chat", "").replace("/v1", "").rstrip('/')
        response = requests.get(f"{clean}/api/tags", timeout=3.0)
        if response.status_code == 200:
            data = response.json()
            models = []
            if "models" in data:
                for m in data["models"]:
                    models.append(m.get("name") or m.get("model", ""))
            return [m for m in models if m], None
    except Exception as e:
        return None, f"Ollama è¿æ¥å¤±è´¥: {e}"
    return None, "æœªæ‰¾åˆ° Ollama æ¨¡å‹"


def check_hf_model_exists(model_name):
    """
    æ£€æŸ¥ HuggingFace æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½åˆ°æœ¬åœ°
    
    Args:
        model_name: æ¨¡å‹åç§°
        
    Returns:
        bool: æ¨¡å‹æ˜¯å¦å­˜åœ¨
    """
    cache_dir = "./hf_cache"
    
    # æ–¹å¼1: ç›´æ¥ç›®å½•æ ¼å¼ (BAAI--bge-large-zh-v1.5)
    model_dir1 = os.path.join(cache_dir, model_name.replace('/', '--'))
    if os.path.exists(os.path.join(model_dir1, "config.json")):
        return True
    
    # æ–¹å¼2: HF Hub ç¼“å­˜æ ¼å¼ (models--BAAI--bge-small-zh-v1.5)
    model_dir2 = os.path.join(cache_dir, f"models--{model_name.replace('/', '--')}")
    if os.path.exists(model_dir2):
        return True
    
    return False


def get_kb_embedding_dim(db_path):
    """
    æ£€æµ‹çŸ¥è¯†åº“çš„å‘é‡ç»´åº¦ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Args:
        db_path: çŸ¥è¯†åº“è·¯å¾„
        
    Returns:
        int or None: å‘é‡ç»´åº¦
    """
    # 1. å°è¯•ä»ç¼“å­˜è·å–
    if 'kb_dimensions' not in st.session_state:
        st.session_state.kb_dimensions = {}
    
    # ä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´ä½œä¸ºç¼“å­˜é”®çš„ä¸€éƒ¨åˆ†
    kb_cache_key = f"{os.path.basename(db_path)}_dim"
    try:
        kb_info_file = os.path.join(db_path, ".kb_info.json")
        if os.path.exists(kb_info_file):
            mtime = os.path.getmtime(kb_info_file)
            kb_cache_key = f"{os.path.basename(db_path)}_dim_{mtime}"
            
            # æ¸…ç†æ—§ç¼“å­˜
            keys_to_remove = [
                k for k in st.session_state.kb_dimensions 
                if k.startswith(f"{os.path.basename(db_path)}_dim") and k != kb_cache_key
            ]
            for k in keys_to_remove:
                del st.session_state.kb_dimensions[k]
    except:
        pass

    if kb_cache_key in st.session_state.kb_dimensions:
        return st.session_state.kb_dimensions[kb_cache_key]

    print(f"ğŸ” å¼€å§‹æ£€æµ‹ç»´åº¦: {db_path}")
    
    try:
        # æ–¹æ³•0: ä¼˜å…ˆæ£€æŸ¥ä¿å­˜çš„ KB ä¿¡æ¯ (.kb_info.json)
        # è¿™æ˜¯æœ€å‡†ç¡®çš„æ¥æºï¼Œå› ä¸ºå®ƒæ˜¯åœ¨æ„å»ºæ—¶å†™å…¥çš„
        kb_info_file = os.path.join(db_path, ".kb_info.json")
        if os.path.exists(kb_info_file):
            try:
                with open(kb_info_file, 'r') as f:
                    kb_info = json.load(f)
                    
                    # ä¼˜å…ˆè·å–æ˜ç¡®è®°å½•çš„ç»´åº¦
                    if 'embedding_dim' in kb_info and isinstance(kb_info['embedding_dim'], int) and kb_info['embedding_dim'] > 0:
                        dim = kb_info['embedding_dim']
                        model = kb_info.get('embedding_model', 'unknown')
                        print(f"âœ… ä» KB ä¿¡æ¯è¯»å–ç»´åº¦: {dim}D (æ¨¡å‹: {model})")
                        st.session_state.kb_dimensions[kb_cache_key] = dim
                        return dim
                    
                    # å¦‚æœæ²¡æœ‰ç»´åº¦ä½†æœ‰æ¨¡å‹åç§°ï¼Œå°è¯•æ¨æ–­
                    if 'embedding_model' in kb_info:
                        model_name = kb_info['embedding_model']
                        inferred_dim = get_model_dimension(model_name)
                        print(f"âš ï¸ æœªæ‰¾åˆ°æ˜ç¡®ç»´åº¦ï¼Œæ ¹æ®æ¨¡å‹åæ¨æ–­: {model_name} -> {inferred_dim}D")
                        st.session_state.kb_dimensions[kb_cache_key] = inferred_dim
                        return inferred_dim
                        
            except Exception as e:
                print(f"âš ï¸ è¯»å– KB ä¿¡æ¯å¤±è´¥: {e}")
        
        # æ–¹æ³•1: ç›´æ¥ä» ChromaDB è¯»å–ç»´åº¦
        import chromadb
        try:
            client = chromadb.PersistentClient(path=db_path)
            collections = client.list_collections()
            print(f"ğŸ“¦ æ‰¾åˆ° {len(collections)} ä¸ªé›†åˆ")
            
            if collections:
                col = client.get_collection(collections[0].name)
                data = col.get(limit=1, include=['embeddings'])
                if data['embeddings'] and len(data['embeddings']) > 0:
                    dim = len(data['embeddings'][0])
                    print(f"âœ… ChromaDB æ£€æµ‹åˆ°ç»´åº¦: {dim}D")
                    st.session_state.kb_dimensions[kb_cache_key] = dim
                    return dim
        except Exception as e:
            print(f"âš ï¸ ChromaDB æ£€æµ‹å¤±è´¥: {e}")
        
        # æ–¹æ³•2: æ£€æŸ¥ vector_store.json
        vector_store_path = os.path.join(db_path, "vector_store.json")
        if os.path.exists(vector_store_path):
            print(f"ğŸ“„ æ£€æŸ¥ vector_store.json...")
            with open(vector_store_path, 'r') as f:
                data = json.load(f)
                if 'embedding_dict' in data and data['embedding_dict']:
                    first_embedding = next(iter(data['embedding_dict'].values()))
                    if isinstance(first_embedding, list):
                        dim = len(first_embedding)
                        print(f"âœ… JSON æ£€æµ‹åˆ°ç»´åº¦: {dim}D")
                        st.session_state.kb_dimensions[kb_cache_key] = dim
                        return dim
        else:
            print(f"âŒ vector_store.json ä¸å­˜åœ¨")
        
    except Exception as e:
        print(f"âŒ ç»´åº¦æ£€æµ‹å¼‚å¸¸: {e}")
    
    print(f"âŒ æ— æ³•æ£€æµ‹ç»´åº¦")
    return None


def auto_switch_model(kb_dim, current_model):
    """
    æ ¹æ®çŸ¥è¯†åº“ç»´åº¦è‡ªåŠ¨åˆ‡æ¢æ¨¡å‹
    
    Args:
        kb_dim: çŸ¥è¯†åº“ç»´åº¦
        current_model: å½“å‰æ¨¡å‹
        
    Returns:
        str: æ¨èçš„æ¨¡å‹åç§°
    """
    model_map = {
        512: "sentence-transformers/all-MiniLM-L6-v2",
        768: "BAAI/bge-large-zh-v1.5",
        1024: "BAAI/bge-large-zh-v1.5"
    }
    
    if kb_dim in model_map:
        return model_map[kb_dim]
    
    # é»˜è®¤è¿”å›å½“å‰æ¨¡å‹
    return current_model


def get_model_dimension(model_name):
    """
    è·å–æ¨¡å‹çš„å‘é‡ç»´åº¦
    
    Args:
        model_name: æ¨¡å‹åç§°
        
    Returns:
        int: å‘é‡ç»´åº¦
    """
    dimension_map = {
        "sentence-transformers/all-MiniLM-L6-v2": 512,
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-m3": 1024,
        "text-embedding-ada-002": 1536,
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072
    }
    
    return dimension_map.get(model_name, 768)  # é»˜è®¤768
