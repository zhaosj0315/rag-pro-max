"""
GPU OCRåŠ é€Ÿå™¨
ä½¿ç”¨PaddleOCR GPUç‰ˆæœ¬å’Œæ‰¹é‡æ¨ç†åŠ é€ŸOCRå¤„ç†
"""

import os
import time
import torch
import numpy as np
from typing import List, Tuple, Optional
from PIL import Image
import logging

# è®¾ç½®PaddleOCRæ—¥å¿—çº§åˆ«
logging.getLogger('ppocr').setLevel(logging.ERROR)

class GPUOCRAccelerator:
    """GPU OCRåŠ é€Ÿå™¨"""
    
    def __init__(self):
        self.ocr_engine = None
        self.device = self._detect_device()
        self.batch_size = self._get_optimal_batch_size()
        self.initialized = False
        
    def _detect_device(self) -> str:
        """æ£€æµ‹å¯ç”¨çš„GPUè®¾å¤‡"""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def _get_optimal_batch_size(self) -> int:
        """è·å–æœ€ä¼˜æ‰¹é‡å¤§å°"""
        if self.device == "cuda":
            # CUDAè®¾å¤‡æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´
            try:
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                if gpu_memory >= 8:
                    return 8
                elif gpu_memory >= 4:
                    return 4
                else:
                    return 2
            except:
                return 2
        elif self.device == "mps":
            # Apple Siliconè®¾å¤‡
            return 4
        else:
            # CPUè®¾å¤‡
            return 1
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–OCRå¼•æ“"""
        if self.initialized:
            return True
        
        try:
            # å°è¯•å¯¼å…¥PaddleOCR
            from paddleocr import PaddleOCR
            
            print(f"ğŸš€ åˆå§‹åŒ–GPU OCRåŠ é€Ÿå™¨...")
            print(f"   è®¾å¤‡: {self.device}")
            print(f"   æ‰¹é‡å¤§å°: {self.batch_size}")
            
            # åˆå§‹åŒ–PaddleOCR
            # è®¾å¤‡æ£€æµ‹å·²åœ¨åˆå§‹åŒ–ä¸­å¤„ç†
            
            # æ ¹æ®è®¾å¤‡ç±»å‹è®¾ç½®å‚æ•°
            if self.device == "cuda":
                self.ocr_engine = PaddleOCR(
                    use_angle_use_angle_cls=True,
                    lang='ch',
                    # GPUä¼˜åŒ–å‚æ•°
                    det_db_thresh=0.3,
                    det_db_box_thresh=0.6,
                    det_db_unclip_ratio=1.5,
                    det_limit_side_len=960,
                    det_limit_type='max'
                )
            else:
                # CPUæˆ–MPSè®¾å¤‡
                self.ocr_engine = PaddleOCR(
                    use_angle_use_angle_cls=True,
                    lang='ch',
                    det_db_thresh=0.3,
                    det_db_box_thresh=0.6,
                    det_db_unclip_ratio=1.5,
                    det_limit_side_len=960,
                    det_limit_type='max'
                )
            
            # é¢„çƒ­æ¨¡å‹
            self._warmup()
            
            self.initialized = True
            print(f"âœ… GPU OCRåŠ é€Ÿå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except ImportError:
            print("âš ï¸  PaddleOCRæœªå®‰è£…ï¼Œå›é€€åˆ°CPU OCR")
            return False
        except Exception as e:
            print(f"âŒ GPU OCRåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _warmup(self):
        """é¢„çƒ­æ¨¡å‹"""
        try:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_image = Image.new('RGB', (100, 50), color='white')
            self.ocr_engine.ocr(np.array(test_image))
            print("ğŸ”¥ æ¨¡å‹é¢„çƒ­å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
    
    def process_images_batch(self, images: List[Image.Image]) -> List[str]:
        """æ‰¹é‡å¤„ç†å›¾åƒ"""
        if not self.initialized:
            if not self.initialize():
                return self._fallback_ocr(images)
        
        results = []
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(images), self.batch_size):
            batch = images[i:i + self.batch_size]
            batch_results = self._process_batch(batch)
            results.extend(batch_results)
            
            # GPUå†…å­˜æ¸…ç†
            if self.device in ["cuda", "mps"]:
                self._cleanup_gpu_memory()
        
        return results
    
    def _process_batch(self, batch: List[Image.Image]) -> List[str]:
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        batch_texts = []
        
        try:
            start_time = time.time()
            
            for image in batch:
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_array = np.array(image)
                
                # OCRè¯†åˆ«
                try:
                    result = self.ocr_engine.ocr(img_array)
                except Exception as ocr_error:
                    print(f"âŒ GPU OCRå¤„ç†å¤±è´¥: {ocr_error}")
                    result = None
                
                # æå–æ–‡æœ¬
                text = self._extract_text_from_result(result)
                batch_texts.append(text)
            
            elapsed = time.time() - start_time
            speed = len(batch) / elapsed if elapsed > 0 else 0
            
            print(f"ğŸš€ GPUæ‰¹é‡OCR: {len(batch)}å¼ å›¾ç‰‡, {elapsed:.2f}ç§’, {speed:.1f}å¼ /ç§’")
            
        except Exception as e:
            print(f"âŒ GPU OCRæ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            # å›é€€åˆ°é€å¼ å¤„ç†
            batch_texts = self._fallback_ocr(batch)
        
        return batch_texts
    
    def _extract_text_from_result(self, result) -> str:
        """ä»OCRç»“æœä¸­æå–æ–‡æœ¬"""
        if not result or not result[0]:
            return ""
        
        texts = []
        for line in result[0]:
            if len(line) >= 2:
                text = line[1][0] if isinstance(line[1], (list, tuple)) else str(line[1])
                if text.strip():
                    texts.append(text.strip())
        
        return '\n'.join(texts)
    
    def _fallback_ocr(self, images: List[Image.Image]) -> List[str]:
        """å›é€€åˆ°CPU OCR"""
        try:
            import pytesseract
            
            print(f"ğŸ”„ å›é€€åˆ°CPU OCRå¤„ç† {len(images)} å¼ å›¾ç‰‡")
            results = []
            
            for image in images:
                try:
                    text = pytesseract.image_to_string(image, lang='chi_sim+eng')
                    results.append(text.strip())
                except Exception as e:
                    print(f"âš ï¸  CPU OCRå¤±è´¥: {e}")
                    results.append("")
            
            return results
            
        except ImportError:
            print("âŒ æœªå®‰è£…pytesseractï¼Œæ— æ³•è¿›è¡ŒOCR")
            return [""] * len(images)
    
    def _cleanup_gpu_memory(self):
        """æ¸…ç†GPUå†…å­˜"""
        try:
            if self.device == "cuda":
                torch.cuda.empty_cache()
            elif self.device == "mps":
                torch.mps.empty_cache()
        except Exception as e:
            print(f"âš ï¸  GPUå†…å­˜æ¸…ç†å¤±è´¥: {e}")
    
    def get_device_info(self) -> dict:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        info = {
            "device": self.device,
            "batch_size": self.batch_size,
            "initialized": self.initialized
        }
        
        if self.device == "cuda":
            try:
                info["gpu_name"] = torch.cuda.get_device_name(0)
                info["gpu_memory"] = f"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB"
                info["gpu_memory_used"] = f"{torch.cuda.memory_allocated(0) / 1024**3:.1f}GB"
            except:
                pass
        elif self.device == "mps":
            info["gpu_name"] = "Apple Silicon GPU"
            
        return info
    
    def benchmark(self, test_images: int = 10) -> dict:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        if not self.initialized:
            if not self.initialize():
                return {"error": "åˆå§‹åŒ–å¤±è´¥"}
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_imgs = []
        for i in range(test_images):
            img = Image.new('RGB', (800, 600), color='white')
            test_imgs.append(img)
        
        # æµ‹è¯•å¤„ç†æ—¶é—´
        start_time = time.time()
        results = self.process_images_batch(test_imgs)
        elapsed = time.time() - start_time
        
        return {
            "images_processed": len(results),
            "total_time": f"{elapsed:.2f}ç§’",
            "speed": f"{len(results) / elapsed:.1f}å¼ /ç§’",
            "device": self.device,
            "batch_size": self.batch_size
        }

# å…¨å±€å®ä¾‹
gpu_ocr_accelerator = GPUOCRAccelerator()
