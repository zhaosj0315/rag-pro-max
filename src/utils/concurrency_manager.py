"""
å¹¶å‘ä¼˜åŒ–ç®¡ç†å™¨ - Concurrency Optimization Manager
ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å¹¶å‘ä¼˜åŒ–åŠŸèƒ½
"""

from typing import List, Dict, Any, Callable
from .async_pipeline import AsyncPipeline, run_async_pipeline
from .dynamic_batch import DynamicBatchOptimizer
from .smart_scheduler import SmartScheduler, TaskType
import time


class ConcurrencyManager:
    """å¹¶å‘ä¼˜åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, embedding_dim: int = 1024):
        self.batch_optimizer = DynamicBatchOptimizer(embedding_dim=embedding_dim)
        self.scheduler = SmartScheduler()
        self.stats = {
            'total_docs': 0,
            'total_time': 0,
            'throughput': 0
        }
        self._is_shutdown = False
    
    def process_documents_optimized(self, documents: List[Any],
                                    parse_func: Callable,
                                    embed_func: Callable,
                                    store_func: Callable,
                                    use_pipeline: bool = True) -> Dict[str, Any]:
        """
        ä¼˜åŒ–çš„æ–‡æ¡£å¤„ç†
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            parse_func: è§£æå‡½æ•°
            embed_func: å‘é‡åŒ–å‡½æ•°
            store_func: å­˜å‚¨å‡½æ•°
            use_pipeline: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥ç®¡é“
        
        Returns:
            å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        """
        if self._is_shutdown:
            raise RuntimeError("ConcurrencyManagerå·²å…³é—­")
        
        start_time = time.time()
        doc_count = len(documents)
        
        # å‰ç«¯è¿›åº¦æ˜¾ç¤º
        try:
            import streamlit as st
            progress_container = st.container()
            with progress_container:
                st.info(f"ğŸ”„ **å¹¶å‘å¤„ç†**: æ­£åœ¨å¤„ç† {doc_count} ä¸ªæ–‡æ¡£...")
                progress_bar = st.progress(0, text="â³ å‡†å¤‡å¹¶å‘å¤„ç†...")
        except:
            progress_bar = None
        
        # è·å–æœ€ä¼˜é…ç½®
        config = self.batch_optimizer.get_optimal_config(doc_count)
        
        try:
            if use_pipeline and doc_count > 10:
                # ä½¿ç”¨å¼‚æ­¥ç®¡é“
                stats = run_async_pipeline(documents, parse_func, embed_func, store_func)
            else:
                # ä½¿ç”¨æ™ºèƒ½è°ƒåº¦å™¨
                stats = self._process_with_scheduler(documents, parse_func, embed_func, store_func)
        except Exception as e:
            raise RuntimeError(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
        
        total_time = time.time() - start_time
        
        return {
            'config': config,
            'stats': stats,
            'total_time': total_time,
            'throughput': doc_count / total_time if total_time > 0 else 0
        }
    
    def _process_with_scheduler(self, documents: List[Any],
                                parse_func: Callable,
                                embed_func: Callable,
                                store_func: Callable) -> Dict[str, Any]:
        """ä½¿ç”¨æ™ºèƒ½è°ƒåº¦å™¨å¤„ç†"""
        # è§£æé˜¶æ®µï¼ˆCPUå¯†é›†ï¼‰
        parsed = self.scheduler.map(TaskType.CPU_INTENSIVE, parse_func, documents)
        
        # å‘é‡åŒ–é˜¶æ®µï¼ˆGPUå¯†é›†ï¼‰
        embedded = self.scheduler.map(TaskType.GPU_INTENSIVE, embed_func, parsed)
        
        # å­˜å‚¨é˜¶æ®µï¼ˆIOå¯†é›†ï¼‰
        stored = self.scheduler.map(TaskType.IO_INTENSIVE, store_func, embedded)
        
        return {
            'parsed': len(parsed),
            'embedded': len(embedded),
            'stored': len(stored),
            'scheduler_stats': self.scheduler.get_stats()
        }
    
    def get_optimal_batch_size(self, doc_count: int) -> int:
        """è·å–æœ€ä¼˜batch size"""
        return self.batch_optimizer.calculate_batch_size(doc_count)
    
    def shutdown(self):
        """å…³é—­ç®¡ç†å™¨ï¼Œé‡Šæ”¾èµ„æº"""
        if not self._is_shutdown:
            self.scheduler.shutdown()
            self._is_shutdown = True
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.shutdown()
    
    def __del__(self):
        """ææ„æ—¶è‡ªåŠ¨æ¸…ç†"""
        if not self._is_shutdown:
            self.shutdown()


# å…¨å±€å®ä¾‹
_manager = None


def get_concurrency_manager(embedding_dim: int = 1024) -> ConcurrencyManager:
    """è·å–å…¨å±€å¹¶å‘ç®¡ç†å™¨"""
    global _manager
    if _manager is None or _manager._is_shutdown:
        _manager = ConcurrencyManager(embedding_dim=embedding_dim)
    return _manager


def cleanup_concurrency_manager():
    """æ¸…ç†å…¨å±€ç®¡ç†å™¨"""
    global _manager
    if _manager is not None:
        _manager.shutdown()
        _manager = None
