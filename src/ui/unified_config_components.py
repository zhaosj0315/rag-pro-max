#!/usr/bin/env python3
"""
ç»Ÿä¸€é…ç½®ç»„ä»¶
æ•´åˆæ‰€æœ‰é…ç½®ç›¸å…³çš„UIæ¸²æŸ“å‡½æ•°ï¼Œæ¶ˆé™¤é‡å¤ä»£ç 
"""

import streamlit as st
from typing import Dict, Any, Optional, List, Tuple
import json
import os

class UnifiedConfigRenderer:
    """ç»Ÿä¸€é…ç½®æ¸²æŸ“å™¨"""
    
    def __init__(self):
        self.config_cache = {}
    
    def render_basic_config(self, config_data: Dict[str, Any], key_prefix: str = "basic") -> Dict[str, Any]:
        """æ¸²æŸ“åŸºç¡€é…ç½®è¡¨å•"""
        updated_config = {}
        
        with st.expander("ğŸ”§ åŸºç¡€é…ç½®", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                # æ¨¡å‹é…ç½®
                st.markdown("##### ğŸ¤– æ¨¡å‹è®¾ç½®")
                updated_config['default_model'] = st.selectbox(
                    "é»˜è®¤æ¨¡å‹",
                    options=['gpt-3.5-turbo', 'gpt-4', 'qwen2.5:7b', 'llama3.1:8b'],
                    index=0 if 'default_model' not in config_data else 
                          ['gpt-3.5-turbo', 'gpt-4', 'qwen2.5:7b', 'llama3.1:8b'].index(config_data.get('default_model', 'gpt-3.5-turbo')),
                    key=f"{key_prefix}_model"
                )
                
                updated_config['temperature'] = st.slider(
                    "æ¸©åº¦",
                    min_value=0.0,
                    max_value=2.0,
                    value=config_data.get('temperature', 0.7),
                    step=0.1,
                    key=f"{key_prefix}_temp"
                )
            
            with col2:
                # æ£€ç´¢é…ç½®
                st.markdown("##### ğŸ” æ£€ç´¢è®¾ç½®")
                updated_config['top_k'] = st.number_input(
                    "æ£€ç´¢æ•°é‡",
                    min_value=1,
                    max_value=20,
                    value=config_data.get('top_k', 5),
                    key=f"{key_prefix}_topk"
                )
                
                updated_config['similarity_threshold'] = st.slider(
                    "ç›¸ä¼¼åº¦é˜ˆå€¼",
                    min_value=0.0,
                    max_value=1.0,
                    value=config_data.get('similarity_threshold', 0.7),
                    step=0.05,
                    key=f"{key_prefix}_sim"
                )
        
        return updated_config
    
    def render_embedding_config(self, config_data: Dict[str, Any], key_prefix: str = "embed") -> Dict[str, Any]:
        """æ¸²æŸ“åµŒå…¥æ¨¡å‹é…ç½®è¡¨å•"""
        updated_config = {}
        
        with st.expander("ğŸ§  åµŒå…¥æ¨¡å‹é…ç½®", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ“Š æ¨¡å‹é€‰æ‹©")
                updated_config['embedding_model'] = st.selectbox(
                    "åµŒå…¥æ¨¡å‹",
                    options=[
                        'sentence-transformers/all-MiniLM-L6-v2',
                        'sentence-transformers/all-mpnet-base-v2',
                        'text-embedding-ada-002',
                        'bge-large-zh-v1.5'
                    ],
                    index=0 if 'embedding_model' not in config_data else 0,
                    key=f"{key_prefix}_model"
                )
                
                updated_config['chunk_size'] = st.number_input(
                    "æ–‡æ¡£åˆ†å—å¤§å°",
                    min_value=100,
                    max_value=2000,
                    value=config_data.get('chunk_size', 512),
                    step=50,
                    key=f"{key_prefix}_chunk"
                )
            
            with col2:
                st.markdown("##### âš¡ æ€§èƒ½è®¾ç½®")
                updated_config['batch_size'] = st.number_input(
                    "æ‰¹å¤„ç†å¤§å°",
                    min_value=1,
                    max_value=100,
                    value=config_data.get('batch_size', 32),
                    key=f"{key_prefix}_batch"
                )
                
                updated_config['use_gpu'] = st.checkbox(
                    "å¯ç”¨GPUåŠ é€Ÿ",
                    value=config_data.get('use_gpu', True),
                    key=f"{key_prefix}_gpu"
                )
        
        return updated_config
    
    def render_advanced_config(self, config_data: Dict[str, Any], key_prefix: str = "advanced") -> Dict[str, Any]:
        """æ¸²æŸ“é«˜çº§é…ç½®è¡¨å•"""
        updated_config = {}
        
        with st.expander("âš™ï¸ é«˜çº§é…ç½®", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ”„ ç¼“å­˜è®¾ç½®")
                updated_config['enable_cache'] = st.checkbox(
                    "å¯ç”¨ç¼“å­˜",
                    value=config_data.get('enable_cache', True),
                    key=f"{key_prefix}_cache"
                )
                
                updated_config['cache_ttl'] = st.number_input(
                    "ç¼“å­˜è¿‡æœŸæ—¶é—´(ç§’)",
                    min_value=60,
                    max_value=86400,
                    value=config_data.get('cache_ttl', 3600),
                    key=f"{key_prefix}_ttl"
                )
            
            with col2:
                st.markdown("##### ğŸ“ æ—¥å¿—è®¾ç½®")
                updated_config['log_level'] = st.selectbox(
                    "æ—¥å¿—çº§åˆ«",
                    options=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                    index=['DEBUG', 'INFO', 'WARNING', 'ERROR'].index(config_data.get('log_level', 'INFO')),
                    key=f"{key_prefix}_log"
                )
                
                updated_config['max_log_files'] = st.number_input(
                    "æœ€å¤§æ—¥å¿—æ–‡ä»¶æ•°",
                    min_value=1,
                    max_value=100,
                    value=config_data.get('max_log_files', 10),
                    key=f"{key_prefix}_maxlog"
                )
        
        return updated_config
    
    def render_config_tab(self, tab_name: str, config_data: Dict[str, Any], 
                         sections: List[str] = None) -> Dict[str, Any]:
        """æ¸²æŸ“å®Œæ•´çš„é…ç½®æ ‡ç­¾é¡µ"""
        if sections is None:
            sections = ['basic', 'embedding', 'advanced']
        
        st.markdown(f"#### âš™ï¸ {tab_name}")
        
        all_config = {}
        
        # æ¸²æŸ“å„ä¸ªé…ç½®éƒ¨åˆ†
        if 'basic' in sections:
            basic_config = self.render_basic_config(config_data, f"{tab_name.lower()}_basic")
            all_config.update(basic_config)
        
        if 'embedding' in sections:
            embed_config = self.render_embedding_config(config_data, f"{tab_name.lower()}_embed")
            all_config.update(embed_config)
        
        if 'advanced' in sections:
            advanced_config = self.render_advanced_config(config_data, f"{tab_name.lower()}_advanced")
            all_config.update(advanced_config)
        
        # é…ç½®æ“ä½œæŒ‰é’®
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ’¾ ä¿å­˜é…ç½®", key=f"{tab_name.lower()}_save"):
                self._save_config(all_config, tab_name.lower())
                st.success("é…ç½®å·²ä¿å­˜ï¼")
        
        with col2:
            if st.button("ğŸ”„ é‡ç½®é…ç½®", key=f"{tab_name.lower()}_reset"):
                st.session_state.clear()
                st.rerun()
        
        with col3:
            if st.button("ğŸ“¥ å¯¼å…¥é…ç½®", key=f"{tab_name.lower()}_import"):
                uploaded_file = st.file_uploader("é€‰æ‹©é…ç½®æ–‡ä»¶", type=['json'])
                if uploaded_file:
                    imported_config = json.load(uploaded_file)
                    all_config.update(imported_config)
                    st.success("é…ç½®å·²å¯¼å…¥ï¼")
        
        return all_config
    
    def _save_config(self, config_data: Dict[str, Any], config_name: str):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        config_dir = "config"
        os.makedirs(config_dir, exist_ok=True)
        
        config_file = os.path.join(config_dir, f"{config_name}_config.json")
        
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            st.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    def load_config(self, config_name: str) -> Dict[str, Any]:
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        config_file = os.path.join("config", f"{config_name}_config.json")
        
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        
        # è¿”å›é»˜è®¤é…ç½®
        return {
            'default_model': 'gpt-3.5-turbo',
            'temperature': 0.7,
            'top_k': 5,
            'similarity_threshold': 0.7,
            'embedding_model': 'sentence-transformers/all-MiniLM-L6-v2',
            'chunk_size': 512,
            'batch_size': 32,
            'use_gpu': True,
            'enable_cache': True,
            'cache_ttl': 3600,
            'log_level': 'INFO',
            'max_log_files': 10
        }

# å…¨å±€å®ä¾‹
unified_config_renderer = UnifiedConfigRenderer()

# ä¾¿æ·å‡½æ•°
def render_basic_config(config_data: Dict[str, Any], key_prefix: str = "basic") -> Dict[str, Any]:
    """æ¸²æŸ“åŸºç¡€é…ç½® - ä¾¿æ·å‡½æ•°"""
    return unified_config_renderer.render_basic_config(config_data, key_prefix)

def render_embedding_config(config_data: Dict[str, Any], key_prefix: str = "embed") -> Dict[str, Any]:
    """æ¸²æŸ“åµŒå…¥é…ç½® - ä¾¿æ·å‡½æ•°"""
    return unified_config_renderer.render_embedding_config(config_data, key_prefix)

def render_config_tab(tab_name: str, config_data: Dict[str, Any], 
                     sections: List[str] = None) -> Dict[str, Any]:
    """æ¸²æŸ“é…ç½®æ ‡ç­¾é¡µ - ä¾¿æ·å‡½æ•°"""
    return unified_config_renderer.render_config_tab(tab_name, config_data, sections)
