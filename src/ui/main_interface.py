"""
ä¸»ç•Œé¢ç»„ä»¶ç®¡ç†å™¨
æå–è‡ª apppro.py çš„UIé€»è¾‘
"""

import streamlit as st
import time
from typing import Optional

from src.logging import LogManager
from src.query.query_handler import QueryHandler
from src.chat import HistoryManager, SuggestionManager
from src.chat_utils_improved import generate_follow_up_questions_safe as generate_follow_up_questions


class MainInterface:
    """ä¸»ç•Œé¢ç®¡ç†å™¨"""
    
    def __init__(self):
        self.logger = LogManager()
        self.query_handler = QueryHandler()
    
    def handle_kb_loading(self, active_kb_name: str, output_base: str, 
                         embed_provider: str, embed_model: str, 
                         embed_key: str, embed_url: str) -> bool:
        """å¤„ç†çŸ¥è¯†åº“åŠ è½½"""
        if active_kb_name and active_kb_name != st.session_state.current_kb_id:
            # åªåœ¨æ²¡æœ‰æ­£åœ¨å¤„ç†çš„é—®é¢˜æ—¶æ‰åˆ‡æ¢
            if not st.session_state.get('is_processing', False):
                st.session_state.current_kb_id = active_kb_name
                st.session_state.chat_engine = None
                with st.spinner("ğŸ“œ æ­£åœ¨åŠ è½½å¯¹è¯å†å²..."):
                    st.session_state.messages = HistoryManager.load(active_kb_name)
                st.session_state.suggestions_history = []
                return True
            else:
                st.warning("âš ï¸ æ­£åœ¨å¤„ç†é—®é¢˜ï¼Œè¯·ç­‰å¾…å®Œæˆåå†åˆ‡æ¢çŸ¥è¯†åº“")
                # æ¢å¤ä¹‹å‰çš„é€‰æ‹©
                st.session_state.current_nav = f"ğŸ“‚ {st.session_state.current_kb_id}"
                return False
        
        # åŠ è½½çŸ¥è¯†åº“å¼•æ“
        if active_kb_name and st.session_state.chat_engine is None:
            return self.query_handler.load_knowledge_base(
                active_kb_name, output_base, embed_provider, 
                embed_model, embed_key, embed_url
            )
        
        return True
    
    def render_chat_messages(self, messages: list, active_kb_name: str):
        """æ¸²æŸ“èŠå¤©æ¶ˆæ¯"""
        def click_btn(q):
            """ç‚¹å‡»è¿½é—®æŒ‰é’®ï¼Œå°†é—®é¢˜åŠ å…¥é˜Ÿåˆ—ï¼ˆå»é‡ï¼‰"""
            if st.session_state.chat_engine:
                # æ£€æŸ¥é˜Ÿåˆ—ä¸­æ˜¯å¦å·²å­˜åœ¨ç›¸åŒé—®é¢˜
                if q not in st.session_state.question_queue:
                    st.session_state.question_queue.append(q)
                else:
                    st.toast("âš ï¸ è¯¥é—®é¢˜å·²åœ¨é˜Ÿåˆ—ä¸­")
            st.rerun()
        
        for msg_idx, msg in enumerate(messages):
            role = msg["role"]
            avatar = "ğŸ¤–" if role == "assistant" else "ğŸ§‘ğŸ’»"
            
            with st.chat_message(role, avatar=avatar):
                st.markdown(msg["content"])
                
                # æ˜¾ç¤ºæ¥æº
                if role == "assistant" and "sources" in msg:
                    self._render_sources(msg["sources"])
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                if role == "assistant" and "stats" in msg:
                    self._render_stats(msg["stats"])
                
                # å¼•ç”¨æŒ‰é’®
                if role == "assistant":
                    if st.button("ğŸ“Œ å¼•ç”¨æ­¤å›å¤", key=f"quote_{msg_idx}", use_container_width=True):
                        st.session_state.quote_content = msg["content"]
                        st.rerun()
                
                # æ¸²æŸ“é™æ€å»ºè®®
                is_last_message = msg_idx == len(messages) - 1
                if ("suggestions" in msg and msg["suggestions"] and 
                    is_last_message and not st.session_state.suggestions_history):
                    st.write("")
                    for idx, q in enumerate(msg["suggestions"]):
                        if st.button(f"ğŸ‘‰ {q}", key=f"sug_{msg_idx}_{idx}", use_container_width=True):
                            click_btn(q)
            
            # åœ¨æœ€åä¸€æ¡ assistant æ¶ˆæ¯ä¹‹åæ˜¾ç¤ºåŠ¨æ€è¿½é—®æ¨è
            if (is_last_message and msg["role"] == "assistant" and 
                active_kb_name and st.session_state.chat_engine):
                self._render_dynamic_suggestions(msg, click_btn)
    
    def process_user_input(self, user_input: str, active_kb_name: str,
                          llm_provider: str, llm_model: str, llm_key: str, 
                          llm_url: str, temperature: float = 0.7):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        # æ£€æŸ¥é‡å¤æŸ¥è¯¢ï¼ˆæœ€è¿‘3æ¬¡ï¼‰
        recent_queries = [m['content'] for m in st.session_state.messages[-6:] if m['role'] == 'user']
        if user_input in recent_queries:
            st.info("ğŸ’¡ æ‚¨åˆšæ‰å·²ç»é—®è¿‡ç›¸åŒçš„é—®é¢˜ï¼Œå¯ä»¥æŸ¥çœ‹ä¸Šé¢çš„å›ç­”æˆ–å°è¯•æ¢ä¸ªè§’åº¦æé—®")
            st.stop()
        
        self.logger.log("INFO", f"ç”¨æˆ·æé—®: {user_input}", stage="æŸ¥è¯¢å¯¹è¯", 
                       details={"kb_name": active_kb_name})
        
        st.session_state.messages.append({"role": "user", "content": user_input})
        if active_kb_name: 
            HistoryManager.save(active_kb_name, st.session_state.messages)
        
        with st.chat_message("user", avatar="ğŸ§‘ğŸ’»"): 
            st.markdown(user_input)
        
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            message_placeholder = st.empty()
            full_text = ""
            sources = []
            stats = {}
            
            try:
                # å¤„ç†æŸ¥è¯¢
                for result in self.query_handler.process_question(
                    user_input, llm_provider, llm_model, llm_key, llm_url, temperature
                ):
                    if result['type'] == 'token':
                        full_text += result['content']
                        message_placeholder.markdown(full_text + "â–Œ")
                    elif result['type'] == 'complete':
                        full_text = result['content']
                        sources = result['sources']
                        stats = result['stats']
                        message_placeholder.markdown(full_text)
                        break
                    elif result['type'] == 'error':
                        st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {result['content']}")
                        return
                
                # æ˜¾ç¤ºæ¥æºå’Œç»Ÿè®¡
                if sources:
                    self._render_sources(sources)
                if stats:
                    self._render_stats(stats)
                
                # ä¿å­˜æ¶ˆæ¯
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_text, 
                    "sources": sources,
                    "stats": stats
                })
                
                if active_kb_name:
                    HistoryManager.save(active_kb_name, st.session_state.messages)
                
                # ç”Ÿæˆæ¨èé—®é¢˜
                self._generate_suggestions(full_text, active_kb_name)
                
            except Exception as e:
                st.error(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
                self.logger.error(f"âŒ ç”¨æˆ·è¾“å…¥å¤„ç†å¤±è´¥: {str(e)}")
    
    def _render_sources(self, sources: list):
        """æ¸²æŸ“æ¥æºä¿¡æ¯"""
        if sources:
            with st.expander("ğŸ“š å‚è€ƒ 3 ä¸ªç‰‡æ®µ", expanded=False):
                for i, source in enumerate(sources[:3], 1):
                    st.caption(f"**ç‰‡æ®µ {i}**: {source.get('file_name', 'æœªçŸ¥æ–‡ä»¶')}")
                    st.text(source.get('content', ''))
    
    def _render_stats(self, stats: dict):
        """æ¸²æŸ“ç»Ÿè®¡ä¿¡æ¯"""
        elapsed = stats.get('elapsed_time', 0)
        source_count = stats.get('source_count', 0)
        
        col1, col2 = st.columns(2)
        with col1:
            st.caption(f"â±ï¸ {elapsed:.1f}s")
        with col2:
            st.caption(f"ğŸ“„ {source_count} å­—ç¬¦")
    
    def _render_dynamic_suggestions(self, msg: dict, click_btn_func):
        """æ¸²æŸ“åŠ¨æ€æ¨èé—®é¢˜"""
        import hashlib
        msg_hash = hashlib.md5(msg['content'][:100].encode()).hexdigest()[:8]
        
        st.divider()
        
        @st.fragment
        def suggestions_fragment():
            # ä¼˜å…ˆæ˜¾ç¤ºå½“å‰æ¨èï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºå†å²æ¨è
            display_suggestions = (
                st.session_state.get('current_suggestions', []) or 
                st.session_state.get('suggestions_history', [])
            )
            
            if display_suggestions:
                st.markdown("##### ğŸš€ è¿½é—®æ¨è")
                for idx, q in enumerate(display_suggestions[:3]):  # åªæ˜¾ç¤º3ä¸ª
                    if st.button(f"ğŸ‘‰ {q}", key=f"dyn_sug_{msg_hash}_{idx}", use_container_width=True):
                        click_btn_func(q)
            
            if st.button("âœ¨ ç»§ç»­æ¨è 3 ä¸ªè¿½é—® (æ— é™è¿½é—®)", key=f"gen_more_{msg_hash}", 
                        type="secondary", use_container_width=True):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæ–°é—®é¢˜..."):
                    self._generate_more_suggestions(msg['content'])
        
        suggestions_fragment()
    
    def _generate_suggestions(self, context_text: str, active_kb_name: str):
        """ç”Ÿæˆåˆå§‹æ¨èé—®é¢˜"""
        try:
            existing_questions = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
            existing_questions.extend(st.session_state.question_queue)
            existing_questions.extend(st.session_state.suggestions_history)
            
            initial_sugs = generate_follow_up_questions(
                context_text, 
                num_questions=3,
                existing_questions=existing_questions,
                query_engine=st.session_state.chat_engine if st.session_state.get('chat_engine') else None
            )
            
            if initial_sugs:
                # ç´¯ç§¯å†å²æ¨èï¼Œé¿å…é‡å¤
                if not hasattr(st.session_state, 'suggestions_history'):
                    st.session_state.suggestions_history = []
                
                # è¿‡æ»¤æ‰å·²å­˜åœ¨çš„æ¨è
                new_suggestions = []
                for sugg in initial_sugs[:3]:
                    if sugg not in st.session_state.suggestions_history:
                        new_suggestions.append(sugg)
                
                # æ·»åŠ åˆ°å†å²è®°å½•
                st.session_state.suggestions_history.extend(new_suggestions)
                
                # è®¾ç½®å½“å‰æ˜¾ç¤ºçš„æ¨èï¼ˆæœ€æ–°çš„3ä¸ªï¼‰
                st.session_state.current_suggestions = new_suggestions[:3] if new_suggestions else initial_sugs[:3]
                
                # è¯¦ç»†æ—¥å¿—è®°å½•
                self.logger.info(f"âœ¨ ç”Ÿæˆ {len(new_suggestions)} ä¸ªæ–°æ¨èé—®é¢˜")
                if new_suggestions:
                    for i, q in enumerate(new_suggestions[:3], 1):
                        self.logger.info(f"   {i}. {q}")
                else:
                    self.logger.info("âš ï¸ æœªç”Ÿæˆæ–°æ¨èï¼Œä½¿ç”¨åŸå§‹æ¨è")
            else:
                self.logger.info("âš ï¸ æ¨èé—®é¢˜ç”Ÿæˆå¤±è´¥")
                
        except Exception as e:
            self.logger.error(f"âŒ æ¨èé—®é¢˜ç”Ÿæˆå¼‚å¸¸: {str(e)}")
    
    def _generate_more_suggestions(self, context_text: str):
        """ç”Ÿæˆæ›´å¤šæ¨èé—®é¢˜"""
        try:
            # æ”¶é›†æ‰€æœ‰å†å²é—®é¢˜ï¼Œç¡®ä¿ä¸é‡å¤
            all_history_questions = []
            
            # 1. ç”¨æˆ·é—®è¿‡çš„æ‰€æœ‰é—®é¢˜
            user_questions = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
            all_history_questions.extend(user_questions)
            
            # 2. æ‰€æœ‰å†å²æ¨èé—®é¢˜
            if hasattr(st.session_state, 'suggestions_history'):
                all_history_questions.extend(st.session_state.suggestions_history)
            
            # 3. é˜Ÿåˆ—ä¸­çš„é—®é¢˜
            if hasattr(st.session_state, 'question_queue'):
                all_history_questions.extend(st.session_state.question_queue)
            
            # 4. å½“å‰æ˜¾ç¤ºçš„æ¨èé—®é¢˜
            if hasattr(st.session_state, 'current_suggestions'):
                all_history_questions.extend(st.session_state.current_suggestions)
            
            # å»é‡
            all_history_questions = list(set(all_history_questions))
            
            new_sugs = generate_follow_up_questions(
                context_text=context_text, 
                num_questions=3,
                existing_questions=all_history_questions,
                query_engine=st.session_state.chat_engine if st.session_state.get('chat_engine') else None
            )
            
            if new_sugs:
                # ç´¯ç§¯å†å²æ¨èï¼Œé¿å…é‡å¤
                if not hasattr(st.session_state, 'suggestions_history'):
                    st.session_state.suggestions_history = []
                
                # è¿‡æ»¤æ‰å·²å­˜åœ¨çš„æ¨è
                new_suggestions = []
                for sugg in new_sugs:
                    if sugg not in st.session_state.suggestions_history:
                        new_suggestions.append(sugg)
                
                # æ·»åŠ åˆ°å†å²è®°å½•
                st.session_state.suggestions_history.extend(new_suggestions)
                
                # è®¾ç½®å½“å‰æ˜¾ç¤ºçš„æ¨è
                st.session_state.current_suggestions = new_suggestions[:3] if new_suggestions else new_sugs[:3]
                
                # è¯¦ç»†æ—¥å¿—è®°å½•
                self.logger.info(f"ğŸ”„ ç»§ç»­ç”Ÿæˆ {len(new_suggestions)} ä¸ªæ–°æ¨èé—®é¢˜")
                if new_suggestions:
                    for i, q in enumerate(new_suggestions[:3], 1):
                        self.logger.info(f"   {i}. {q}")
                else:
                    self.logger.info("âš ï¸ æœªç”Ÿæˆæ–°æ¨èï¼Œå¯èƒ½å·²è¾¾åˆ°é—®é¢˜åº“ä¸Šé™")
                
                st.rerun(scope="fragment")
            else:
                st.warning("æœªèƒ½ç”Ÿæˆæ›´å¤šè¿½é—®ï¼Œè¯·å°è¯•è¾“å…¥æ–°é—®é¢˜ã€‚")
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´å¤šæ¨èé—®é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            st.error("ç”Ÿæˆæ¨èé—®é¢˜æ—¶å‡ºé”™ï¼Œè¯·ç¨åå†è¯•ã€‚")
