# åˆå§‹åŒ–ç¯å¢ƒé…ç½®
# ç¯å¢ƒå˜é‡è®¾ç½® - å‡å°‘å¯åŠ¨è­¦å‘Š
__version__ = "2.7.2"

import os
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# æŠ‘åˆ¶çƒ¦äººçš„ Pydantic è­¦å‘Š
import warnings
warnings.filterwarnings("ignore", message=".*UnsupportedFieldAttributeWarning.*")


import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.core.environment import initialize_environment
initialize_environment()

import os
# åœ¨æœ€å¼€å§‹è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¦ç”¨PaddleOCRè¯¦ç»†æ—¥å¿—
import os

def get_default_model():
    """ç»Ÿä¸€è·å–é»˜è®¤æ¨¡å‹"""
    from src.services.config_service import get_config_service
    config_service = get_config_service()
    return config_service.get_default_model()

def update_all_model_configs(new_model):
    """ç»Ÿä¸€æ›´æ–°æ‰€æœ‰åœ°æ–¹çš„æ¨¡å‹é…ç½®"""
    from src.services.config_service import get_config_service
    config_service = get_config_service()
    
    success = config_service.update_model_config(new_model)
    
    if success:
        # æ›´æ–°session state
        import streamlit as st
        st.session_state.selected_model = new_model
        
        # æ›´æ–°å…¨å±€LLM
        ollama_url = config_service.get_config_value('llm_url_ollama', 'http://localhost:11434')
        set_global_llm_model("Ollama", new_model, api_url=ollama_url)
    
    return success
os.environ['GLOG_minloglevel'] = '3'  # åªæ˜¾ç¤ºè‡´å‘½é”™è¯¯
os.environ['FLAGS_logtostderr'] = '0'  # ä¸è¾“å‡ºåˆ°stderr
os.environ['PADDLE_LOG_LEVEL'] = '50'  # æœ€é«˜çº§åˆ«ï¼Œå‡ ä¹ä¸è¾“å‡º
os.environ['FLAGS_v'] = '0'  # ç¦ç”¨è¯¦ç»†æ—¥å¿—
os.environ['GLOG_v'] = '0'  # ç¦ç”¨GLOGè¯¦ç»†æ—¥å¿—

# è®¾ç½®å¤šè¿›ç¨‹ç›¸å…³ç¯å¢ƒå˜é‡ï¼Œå½±å“è¿›ç¨‹è°ƒåº¦
os.environ['OMP_NUM_THREADS'] = '1'  # æ¯ä¸ªè¿›ç¨‹åªç”¨1ä¸ªçº¿ç¨‹
os.environ['MKL_NUM_THREADS'] = '1'  # Intel MKLåªç”¨1ä¸ªçº¿ç¨‹
os.environ['OPENBLAS_NUM_THREADS'] = '1'  # OpenBLASåªç”¨1ä¸ªçº¿ç¨‹
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'  # Apple Accelerateåªç”¨1ä¸ªçº¿ç¨‹

import streamlit as st

# é˜²æ­¢HTMLå†…å®¹è¢«æˆªæ–­
st.set_page_config(
    page_title="RAG Pro Max",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®ä¸æˆªæ–­HTMLæ˜¾ç¤º
import streamlit.components.v1 as components

import shutil
import time
import requests
import ollama
import re
import subprocess
from urllib.parse import urlparse

# ğŸ§¹ å¯åŠ¨æ—¶è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
from src.common.utils import cleanup_temp_files

# æ‰§è¡Œå¯åŠ¨æ¸…ç†ï¼ˆä½¿ç”¨ä¸€å‘¨=168å°æ—¶ï¼‰
cleaned_count = cleanup_temp_files("temp_uploads", 168)
if cleaned_count > 0:
    print(f"ğŸ§¹ å·²æ¸…ç† {cleaned_count} ä¸ªä¸´æ—¶æ–‡ä»¶")

import json
import zipfile
import platform
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp

# å¼•å…¥æ–°å·¥å…·
from src.utils.file_system_utils import get_deep_file_attributes, reveal_in_file_manager, NotesManager, set_where_from_metadata
notes_manager = NotesManager()

# å¼•å…¥æ–°çš„ä¼˜åŒ–ç»„ä»¶
from src.utils.enhanced_ocr_optimizer import enhanced_ocr_optimizer
from src.ui.progress_monitor import progress_monitor
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, StorageContext, load_index_from_storage
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.ollama import Ollama
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.schema import Document

# å¯¼å…¥è‡ªå®šä¹‰åµŒå…¥
from src.custom_embeddings import create_custom_embedding

# å¼•å…¥æ—¥å¿—æ¨¡å—
from src.app_logging import LogManager
logger = LogManager()
# terminal_logger å·²è¢« logger æ›¿ä»£
from src.chat_utils_improved import generate_follow_up_questions_safe as generate_follow_up_questions
from src.chat.unified_suggestion_engine import get_unified_suggestion_engine

# å¼•å…¥å…ƒæ•°æ®ç®¡ç†
from src.metadata_manager import MetadataManager

# å¼•å…¥å·¥å…·æ¨¡å—
from src.utils.memory import cleanup_memory, get_memory_stats
from src.utils.model_manager import (
    load_embedding_model,
    load_llm_model,
    set_global_embedding_model,
    set_global_llm_model
)
from src.utils.document_processor import (
    sanitize_filename,
    get_file_size_str,
    get_file_type,
    get_file_info,
    get_relevance_label,
    load_pptx_file
)

# å¼•å…¥é…ç½®ç®¡ç†
from src.config import ConfigLoader, ManifestManager

# å¼•å…¥èŠå¤©ç®¡ç†
from src.chat.unified_suggestion_engine import get_unified_suggestion_engine
from src.chat import HistoryManager

# å¼•å…¥ UI æ¨¡å—
from src.ui.page_style import PageStyle
from src.ui.sidebar_config import SidebarConfig

# å¼•å…¥å·¥å…·å‡½æ•°
from src.utils.app_utils import (
    get_kb_embedding_dim,
    remove_file_from_manifest,
    show_first_time_guide,
    open_file_native,
    handle_kb_switching
)

# å¼•å…¥ä¸»æ§åˆ¶å™¨
from src.core.main_controller import MainController

# å¼•å…¥çŸ¥è¯†åº“å¤„ç†å™¨
from src.kb.kb_processor import KBProcessor

# å¼•å…¥æ–‡æ¡£è§£æå™¨
from src.processors.document_parser import _parse_single_doc, _parse_batch_docs

# å¼•å…¥èµ„æºä¿æŠ¤
from src.utils.adaptive_throttling import get_resource_guard
import psutil as psutil_main

# åˆå§‹åŒ–èµ„æºä¿æŠ¤
resource_guard = get_resource_guard()

# å¼•å…¥çŸ¥è¯†åº“ç®¡ç†
from src.kb import KBManager
kb_manager = KBManager()

# æ€§èƒ½ç›‘æ§ (v1.5.1)
from src.ui.performance_monitor import get_monitor
perf_monitor = get_monitor()

# æŸ¥è¯¢æ”¹å†™ (v1.6)
from src.query.query_rewriter import QueryRewriter

# çŸ¥è¯†åº“åç§°ä¼˜åŒ–å™¨
from src.utils.kb_name_optimizer import KBNameOptimizer, sanitize_filename

# æ–‡æ¡£é¢„è§ˆ (v1.6)
from src.kb.document_viewer import DocumentViewer
from src.ui.document_preview import show_upload_preview, show_kb_documents

# å¼•å…¥ç»Ÿä¸€UIç»„ä»¶
from src.ui.unified_dialogs import show_document_detail_dialog

from src.utils.kb_utils import generate_smart_kb_name
from src.utils.app_utils import initialize_session_state


# å¼•å…¥ RAG å¼•æ“
from src.rag_engine import RAGEngine

# å¼•å…¥èµ„æºç›‘æ§å’Œæ¨¡å‹å·¥å…·
from src.utils.resource_monitor import check_resource_usage, get_system_stats
from src.utils.model_utils import (
    check_ollama_status,
    fetch_remote_models,
    check_hf_model_exists,
    get_kb_embedding_dim,
    auto_switch_model,
    get_model_dimension
)

# å¼•å…¥ UI å±•ç¤ºç»„ä»¶ (Stage 3.1)
from src.ui.display_components import (
    render_message_stats,
    render_source_references,
    get_relevance_label
)

# å¼•å…¥ UI æ¨¡å‹é€‰æ‹©å™¨ (Stage 3.2.1)
from src.ui.model_selectors import (
    render_ollama_model_selector,
    render_openai_model_selector,
    render_hf_embedding_selector
)

# å¼•å…¥ UI é«˜çº§é…ç½® (Stage 3.2.3)

# å¼•å…¥ UI é…ç½®è¡¨å• (Stage 3.2.2)
from src.ui.config_forms import render_basic_config

# å¼•å…¥çŠ¶æ€ç®¡ç†å™¨ (Stage 3.3)
from src.core.state_manager import state

# å¼•å…¥æ–‡æ¡£å¤„ç†å™¨ (Stage 4.1)
from src.processors import UploadHandler, IndexBuilder

# âš ï¸ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œé¿å… OpenAI é»˜è®¤
# ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®© LlamaIndex ä½¿ç”¨æœ¬åœ°æ¨¡å‹
os.environ['LLAMA_INDEX_EMBED_MODEL'] = 'local'

# å…¼å®¹æ—§ä»£ç çš„åŒ…è£…å‡½æ•°
def get_embed(provider, model, key, url):
    """å…¼å®¹æ—§ä»£ç çš„åŒ…è£…å‡½æ•°"""
    return load_embedding_model(provider, model, key, url)

def get_llm(provider, model, key, url, temp):
    """å…¼å®¹æ—§ä»£ç çš„åŒ…è£…å‡½æ•°"""
    return load_llm_model(provider, model, key, url, temp)

# å¼•å…¥æ–‡ä»¶å¤„ç†æ¨¡å—
from src.file_processor import scan_directory_safe


# from src.ui.compact_sidebar import render_compact_sidebar  # å·²åˆ é™¤å†—ä½™æ¨¡å—
# å¢å¼ºåŠŸèƒ½æ¨¡å— (v1.7.4)
from src.utils.error_handler_enhanced import error_handler
from src.utils.memory_manager_enhanced import memory_manager
from src.ui.performance_dashboard_enhanced import performance_dashboard
from src.ui.user_experience_enhanced import ux_enhancer

# å¼•å…¥å¹¶è¡Œæ‰§è¡Œæ¨¡å—
from src.utils.parallel_executor import ParallelExecutor
from src.utils.safe_parallel_tasks import safe_process_node_worker as process_node_worker, extract_metadata_task

# å¼•å…¥èŠå¤©æ¨¡å— (Stage 7)
from src.chat import ChatEngine

# å¼•å…¥é…ç½®æ¨¡å— (Stage 8)
from src.config import ConfigLoader, ConfigValidator

# å¤šè¿›ç¨‹å‡½æ•°ï¼šæ–‡æ¡£åˆ†å—è§£æï¼ˆç§»åˆ°æ¨¡å—çº§åˆ«ï¼‰
# å¼•å…¥æ–‡æ¡£è§£æå™¨
from src.processors.document_parser import _parse_single_doc, _parse_batch_docs

# ==========================================
# 1. é¡µé¢é…ç½®ä¸æ ·å¼
# ==========================================
PageStyle.setup_page()

# æ³¨å…¥ CSS
st.markdown("""
<style>
    /* å½»åº•ç¦æ­¢æ¨ªå‘æ»šåŠ¨å’Œå·¦å³æ‹–åŠ¨æ‰‹åŠ¿ - å¼ºåˆ¶é”å®šå¸ƒå±€ */
    html, body, [data-testid="stAppViewContainer"], .stApp, [data-testid="stApp"] {
        overflow-x: hidden !important;
        max-width: 100vw !important;
        overscroll-behavior-x: none !important;
        position: relative !important;
    }
    
    /* å¼ºåˆ¶ç¦æ­¢ä»»ä½•å®¹å™¨äº§ç”Ÿæ¨ªå‘ä½ç§» */
    [data-testid="stMain"], [data-testid="stSidebar"] {
        overflow-x: hidden !important;
        max-width: 100% !important;
    }

    /* æè‡´å‹ç¼©ä¾§è¾¹æ é—´è· */
    section[data-testid="stSidebar"] .stSelectbox > div {
        margin-bottom: 1px !important;
    }
    
    section[data-testid="stSidebar"] .stTextInput > div {
        margin-bottom: 1px !important;
    }
    
    section[data-testid="stSidebar"] .stCaption {
        margin-bottom: 1px !important;
        margin-top: 1px !important;
    }
    
    section[data-testid="stSidebar"] .stContainer {
        margin-bottom: 1px !important;
        margin-top: 1px !important;
    }

    /* å¢åŠ ä¾§è¾¹æ å®½åº¦ï¼Œå›ºå®šå¤§å°å¹¶ç¦æ­¢æ‹–åŠ¨ç¼©æ”¾ */
    section[data-testid="stSidebar"] {
        min-width: 850px !important;
        width: 850px !important;
        max-width: 850px !important;
    }

    /* éšè—å¹¶ç¦ç”¨ä¾§è¾¹æ ç¼©æ”¾æ‰‹æŸ„ï¼ˆå½»åº•è§£å†³å·¦ä¸‹è§’å·¦å³æ‹–åŠ¨é—®é¢˜ï¼‰ */
    [data-testid="stSidebarResizer"] {
        display: none !important;
        pointer-events: none !important;
    }

    
    /* ç»Ÿè®¡åŒºåŸŸå®¹å™¨ */
    .stats-container {
        background: white !important;
        border-radius: 10px !important;
        padding: 1rem !important;
        margin: 1rem 0 !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1) !important;
    }
    

    /* æ–‡æ¡£è¯¦æƒ…æŠ˜å ä¼˜åŒ– */
    .document-details {
        background: #f8f9fa !important;
        border-radius: 6px !important;
        padding: 0.75rem !important;
        margin: 0.5rem 0 !important;
        border-left: 3px solid #1f77b4 !important;
    }
    
    .document-summary {
        background: white !important;
        padding: 0.5rem !important;
        border-radius: 4px !important;
        margin-top: 0.5rem !important;
        border: 1px solid #dee2e6 !important;
        font-size: 0.85rem !important;
        line-height: 1.4 !important;
    }
    
    /* æ‰¹é‡æ“ä½œæŒ‰é’® */
    .batch-operations {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 6px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 500 !important;
        transition: all 0.3s ease !important;
    }
    
    .batch-operations:hover {
        transform: translateY(-1px) !important;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3) !important;
    }
    
    /* å¿«é€Ÿé¢„è§ˆæç¤º */
    .preview-tooltip {
        position: absolute !important;
        background: rgba(0,0,0,0.9) !important;
        color: white !important;
        padding: 0.5rem !important;
        border-radius: 4px !important;
        font-size: 0.8rem !important;
        max-width: 300px !important;
        z-index: 1000 !important;
        pointer-events: none !important;
    }
    

        /* å®Œå…¨ä¿®å¤å‚è€ƒç‰‡æ®µæ˜¾ç¤º */
    .reference-snippet {
        background-color: #f8f9fa !important;
        border-left: 3px solid #1f77b4 !important;
        padding: 12px !important;
        margin: 10px 0 !important;
        border-radius: 6px !important;
        font-size: 0.9rem !important;
        line-height: 1.5 !important;
        word-wrap: break-word !important;
        overflow-wrap: break-word !important;
        white-space: pre-wrap !important;
        max-width: 100% !important;
    }
    
    .reference-header {
        font-size: 0.85rem !important;
        color: #666 !important;
        margin-bottom: 8px !important;
        font-weight: 500 !important;
    }
    
    .reference-content {
        color: #333 !important;
        background: white !important;
        padding: 8px 12px !important;
        border-radius: 4px !important;
        border: 1px solid #dee2e6 !important;
        max-height: none !important;
        overflow: visible !important;
        word-break: break-word !important;
    }
    
    /* ç¡®ä¿Streamlitä¸æˆªæ–­HTML */
    .stMarkdown > div {
        max-width: none !important;
        overflow: visible !important;
    }
    
    .stMarkdown div[style*="border-left"] {
        max-width: 100% !important;
        overflow: visible !important;
        word-wrap: break-word !important;
    }
    

    /* å‡å°‘é—´è· */
    .block-container {
        padding-top: 0.75rem !important;
        padding-bottom: 1rem !important;
    }

    .element-container {
        margin-bottom: 0.2rem !important;
    }
    
    h1, h2, h3 {
        margin: 0.2rem 0 !important;
    }
    
    [data-testid="column"] {
        padding: 0 0.3rem !important;
    }
    
    /* æ–‡ä»¶åˆ—è¡¨ */
    .file-item {
        font-size: 0.8rem !important;
        padding: 0.5rem !important;
        background: rgba(0,0,0,0.02) !important;
        border-radius: 6px !important;
        margin-bottom: 0.3rem !important;
        border: 1px solid rgba(0,0,0,0.05) !important;
    }
    
    /* æ¬¢è¿é¡µé¢ */
    .welcome-box {
        padding: 1.5rem !important;
        border-radius: 10px !important;
        background: rgba(255,75,75,0.02) !important;
        border: 1px solid rgba(255,75,75,0.1) !important;
        text-align: center !important;
        margin: 1rem 0 !important;
    }
    
    /* è¿›åº¦æ¡ */
    .stProgress > div > div {
        border-radius: 4px !important;
        height: 6px !important;
    }
    
    /* å“åº”å¼ */
    @media (max-width: 768px) {
        .main .block-container {
            padding: 0.5rem !important;
        }
    }
</style>""", unsafe_allow_html=True)

# åº”ç”¨å¯åŠ¨æ—¥å¿—
if 'app_initialized' not in st.session_state:
    logger.separator("RAG Pro Max å¯åŠ¨")
    logger.info("åº”ç”¨åˆå§‹åŒ–ä¸­...")
    
    # ç«‹å³è®¾ç½®å…¨å±€LLMï¼ˆç¡®ä¿æ‘˜è¦ç”Ÿæˆç­‰åŠŸèƒ½å¯ç”¨ï¼‰
    try:
        # ä½¿ç”¨ç»Ÿä¸€é…ç½®åŠ è½½å™¨ (è¯»å– rag_config.json)
        config = ConfigLoader.load()
        
        llm_provider = config.get('llm_provider', 'Ollama')
        
        # æå–é…ç½®
        if llm_provider == 'OpenAI-Compatible':
            llm_model = config.get('llm_model_other', '')
            llm_url = config.get('llm_url_other', '')
            llm_key = config.get('llm_key_other', '')
        elif llm_provider == 'OpenAI':
            llm_model = config.get('llm_model_openai', 'gpt-3.5-turbo')
            llm_url = config.get('llm_url_openai', 'https://api.openai.com/v1')
            llm_key = config.get('llm_key', '')
        else:  # Ollama & Default
            llm_model = config.get('llm_model_ollama', 'gpt-oss:20b')
            llm_url = config.get('llm_url_ollama', 'http://localhost:11434')
            llm_key = ""
        
        system_prompt = config.get('system_prompt', None)
        
        # è®¾ç½®å…¨å±€LLM
        if llm_model:
            set_global_llm_model(llm_provider, llm_model, llm_key, llm_url, system_prompt=system_prompt)
            
    except Exception as e:
        logger.warning(f"å…¨å±€LLMåˆå§‹åŒ–å¤±è´¥: {e}")
    
    st.session_state.app_initialized = True
    if 'current_session_id' not in st.session_state:
        st.session_state.current_session_id = None
    logger.success("åº”ç”¨åˆå§‹åŒ–å®Œæˆ")

# ==========================================
# 2. æœ¬åœ°æŒä¹…åŒ–ä¸å·¥å…·å‡½æ•°
# ==========================================
CONFIG_FILE = "rag_config.json"
HISTORY_DIR = "chat_histories"
UPLOAD_DIR = "temp_uploads" # ä¸´æ—¶ä¸Šä¼ ç›®å½•

# ç¡®ä¿ç›®å½•å­˜åœ¨
for d in [HISTORY_DIR, UPLOAD_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# ä½¿ç”¨æ–°çš„é…ç½®åŠ è½½å™¨ (Stage 8)
defaults = ConfigLoader.load()

from src.common.business import generate_doc_summary

with st.sidebar:
    # æ¨ªå‘æ ‡ç­¾é¡µå¸ƒå±€
    tab_main, tab_roles, tab_config, tab_monitor, tab_help = st.tabs(["ğŸ  ä¸»é¡µ", "ğŸ­ è§’è‰²", "âš™ï¸ é…ç½®", "ğŸ“Š ç›‘æ§", "â“ å¸®åŠ©"])
    
    with tab_main:

        # çŸ¥è¯†åº“æ§åˆ¶å°æ ‡é¢˜ä¸ä¸€é”®é…ç½®å®Œå…¨ä¸€è¡ŒåŒ–
        console_col1, console_col2, console_col3 = st.columns([4, 1, 0.5])
        with console_col1:
            st.markdown("**ğŸ’  çŸ¥è¯†åº“æ§åˆ¶å°**")
        with console_col2:
            if st.button("âš¡ ä¸€é”®é…ç½®", use_container_width=True, key="quick_config_inline"):
                ConfigLoader.quick_setup()
                st.success("âœ… å·²ä½¿ç”¨é»˜è®¤é…ç½®ï¼")
                time.sleep(1)
                st.rerun()
        with console_col3:
            st.markdown("â“", help="å¯æ‰‹åŠ¨é…ç½®ï¼Œé€‚åˆé«˜çº§ç”¨æˆ·")
        
        if "model_list" not in st.session_state: st.session_state.model_list = []

        # å­˜å‚¨æ ¹ç›®å½•å®Œå…¨ä¸€è¡ŒåŒ–
        storage_col1, storage_col2, storage_col3 = st.columns([0.6, 5.9, 0.5])
        with storage_col1:
            st.markdown("**è·¯å¾„:**")
        with storage_col2:
            default_output_path = os.path.join(os.getcwd(), "vector_db_storage")
            output_base = st.text_input("", value=default_output_path, help="çŸ¥è¯†åº“æ–‡ä»¶çš„ä¿å­˜ä½ç½®", label_visibility="collapsed")
        with storage_col3:
            if st.button("ğŸ“‚", help="æ‰“å¼€å­˜å‚¨ç›®å½•", use_container_width=True, key="open_storage_dir"):
                if output_base and os.path.exists(output_base):
                    import webbrowser, urllib.parse
                    try:
                        file_url = 'file://' + urllib.parse.quote(os.path.abspath(output_base))
                        webbrowser.open(file_url)
                        st.toast("âœ… å·²æ‰“å¼€")
                    except: pass
        if not output_base: output_base = default_output_path
            
        existing_kbs = (setattr(kb_manager, "base_path", output_base), kb_manager.list_all())[1]

        # --- æ ¸å¿ƒå¯¼èˆª ---
        base_kbs = kb_manager.list_all()
        
        # ä¸ºæ¯ä¸ªçŸ¥è¯†åº“åˆ›å»ºå¸¦å¤é€‰æ¡†çš„é€‰é¡¹
        from src.config.manifest_manager import ManifestManager
        nav_options = ["â• æ–°å»ºçŸ¥è¯†åº“...", "ğŸ’¬ çº¯å¯¹è¯æ¨¡å¼ (Pure Chat)"]
        for kb in base_kbs:
            # è·å–ç»Ÿè®¡ä¿¡æ¯ (v2.7.6: å¢å¼ºä¿¡æ¯å±•ç¤º)
            try:
                kb_path = os.path.join(output_base, kb)
                stats = ManifestManager.get_stats(kb_path)
                doc_count = stats.get('file_count', 0)
                size_str = ManifestManager.format_size(stats.get('total_size', 0))
                date_str = stats.get('created_time', '').split('T')[0] if stats.get('created_time') else 'N/A'
                info_str = f" (ğŸ“„{doc_count} | ğŸ’¾{size_str} | ğŸ•’{date_str})"
            except Exception:
                info_str = " (N/A)"

            # æ£€æŸ¥æ˜¯å¦è¢«é€‰ä¸­
            is_selected = st.session_state.get(f"kb_check_{kb}", False)
            checkbox_symbol = "â˜‘ï¸" if is_selected else "â˜"
            nav_options.append(f"{checkbox_symbol} ğŸ“‚ {kb}{info_str}")
        
        # ä¿å­˜é€‰ä¸­çš„çŸ¥è¯†åº“åˆ—è¡¨
        selected_kbs = [kb for kb in base_kbs if st.session_state.get(f"kb_check_{kb}", False)]
        st.session_state.selected_kbs = selected_kbs

        # æ£€æŸ¥æ˜¯å¦è¦æ˜¾ç¤ºé…ç½®é¡µé¢
        if st.session_state.get('show_industry_config'):
            from src.ui.industry_config_interface import render_industry_config_interface
            
            # è¿”å›æŒ‰é’®
            if st.button("â† è¿”å›ä¸»é¡µ"):
                st.session_state.show_industry_config = False
                st.rerun()
            
            # æ¸²æŸ“é…ç½®ç•Œé¢
            render_industry_config_interface()
            st.stop()  # åœæ­¢æ‰§è¡Œåç»­ä»£ç 

        default_idx = 0
        if "current_nav" in st.session_state:
            # å¼ºåŒ–åŒ¹é…é€»è¾‘ (v2.7.6): å…¼å®¹å¸¦ç»Ÿè®¡ä¿¡æ¯å’Œå¤é€‰æ¡†å›¾æ ‡çš„æƒ…å†µ
            # 1. ç§»é™¤å›¾æ ‡
            current_nav_clean = st.session_state.current_nav.replace("â˜‘ï¸ ", "").replace("â˜ ", "")
            # 2. ç§»é™¤ç»Ÿè®¡ä¿¡æ¯ (ğŸ“„... | ğŸ’¾... | ğŸ•’...)
            current_nav_clean = current_nav_clean.split(" (")[0].strip()
            
            for i, opt in enumerate(nav_options):
                # å¯¹å¾…åŒ¹é…é¡¹æ‰§è¡ŒåŒæ ·çš„æ¸…ç†
                opt_clean = opt.replace("â˜‘ï¸ ", "").replace("â˜ ", "").split(" (")[0].strip()
                if opt_clean == current_nav_clean:
                    default_idx = i
                    break
            
            # å…œåº•ï¼šå¦‚æœæ¸…ç†ååŒ¹é…åˆ°äº†ï¼Œæ›´æ–° session_state ç¡®ä¿åŒæ­¥æœ€æ–°æ ¼å¼
            if default_idx > 0 and nav_options[default_idx] != st.session_state.current_nav:
                st.session_state.current_nav = nav_options[default_idx]

        # çŸ¥è¯†åº“é€‰æ‹© - ç›´æ¥å¤é€‰æ¡†æ¨¡å¼
        select_col1, select_col2, select_col3 = st.columns([0.6, 5.9, 0.5])
        with select_col1:
            st.markdown("**é€‰æ‹©:**")
        with select_col2:
            selected_nav = st.selectbox("", nav_options, index=default_idx, label_visibility="collapsed")
            
            # è‡ªåŠ¨å¯åŠ¨çº¯å¯¹è¯æ¨¡å¼ (v2.7.6)
            if selected_nav == "ğŸ’¬ çº¯å¯¹è¯æ¨¡å¼ (Pure Chat)" and st.session_state.get('current_kb_id') != "pure_chat":
                try:
                    from llama_index.core.chat_engine import SimpleChatEngine
                    from src.config.prompt_manager import PromptManager
                    
                    # è·å–å½“å‰è§’è‰²æç¤ºè¯
                    current_role_id = st.session_state.get('current_prompt_id', 'default')
                    system_prompt = PromptManager.get_content(current_role_id)
                    
                    st.session_state.chat_engine = SimpleChatEngine.from_defaults(
                        system_prompt=system_prompt
                    )
                    st.session_state.current_kb_id = "pure_chat"
                    st.toast("âœ… çº¯å¯¹è¯æ¨¡å¼å·²è‡ªåŠ¨å¯åŠ¨")
                    st.rerun()
                except Exception as e:
                    st.error(f"å¯åŠ¨å¤±è´¥: {e}")

            # å¤„ç†å¤é€‰æ¡†ç‚¹å‡»é€»è¾‘ - åªæœ‰å½“ç”¨æˆ·æ‰‹åŠ¨æ›´æ”¹é€‰æ‹©æ—¶æ‰è§¦å‘
            if selected_nav != st.session_state.get('current_nav') and (selected_nav.startswith("â˜") or selected_nav.startswith("â˜‘ï¸")):
                # æå–çŸ¥è¯†åº“åç§° (æ”¯æŒå¸¦ç»Ÿè®¡ä¿¡æ¯çš„æ ¼å¼)
                kb_name = selected_nav.split("ğŸ“‚ ")[1].split(" (")[0].strip() if "ğŸ“‚ " in selected_nav else ""
                if kb_name:
                    # åˆ‡æ¢å¤é€‰æ¡†çŠ¶æ€
                    current_state = st.session_state.get(f"kb_check_{kb_name}", False)
                    new_state = not current_state
                    st.session_state[f"kb_check_{kb_name}"] = new_state
                    
                    # å…³é”®ä¿®å¤ï¼šç«‹å³æ›´æ–° current_nav å­—ç¬¦ä¸²ï¼Œç¡®ä¿ä¸‹æ¬¡ rerun æ—¶ index åŒ¹é…æ­£ç¡®
                    new_symbol = "â˜‘ï¸" if new_state else "â˜"
                    st.session_state.current_nav = f"{new_symbol} ğŸ“‚ {kb_name}"
                    st.rerun()
        with select_col3:
            if st.button("ğŸ”„", help="åˆ·æ–°çŸ¥è¯†åº“åˆ—è¡¨", use_container_width=True, key="refresh_kb_list"):
                st.rerun()

        # è‡ªåŠ¨å¯åŠ¨ç³»ç»Ÿé€»è¾‘ (æ›¿ä»£åŸæœ‰çš„å¯åŠ¨æŒ‰é’®)
        # çº¯å¯¹è¯æ¨¡å¼å·²åœ¨ä¸Šæ–¹ selectbox å¤„ç†ï¼Œæ­¤å¤„å¤„ç†çŸ¥è¯†åº“æ¨¡å¼
        is_pure_chat = (selected_nav == "ğŸ’¬ çº¯å¯¹è¯æ¨¡å¼ (Pure Chat)")
        
        # ä»…åœ¨éåˆ›å»ºæ¨¡å¼ä¸”éçº¯å¯¹è¯æ¨¡å¼ä¸‹æ‰§è¡Œè‡ªåŠ¨å¯åŠ¨
        if not is_pure_chat and selected_nav != "â• æ–°å»ºçŸ¥è¯†åº“...":
            target_kb_id = None
            selected_kbs = st.session_state.get('selected_kbs', [])
            
            if len(selected_kbs) == 1:
                target_kb_id = selected_kbs[0]
            elif len(selected_kbs) > 1:
                target_kb_id = "multi_kb_mode"
            
            # å¦‚æœç›®æ ‡IDæœ‰æ•ˆï¼Œä¸”ä¸å½“å‰è¿è¡Œçš„IDä¸ä¸€è‡´ï¼Œåˆ™è§¦å‘å¯åŠ¨
            if target_kb_id and target_kb_id != st.session_state.get('current_kb_id'):
                # æ˜¾ç¤ºåŠ è½½çŠ¶æ€ (ä»…åœ¨åˆæ¬¡åŠ è½½æˆ–åˆ‡æ¢æ—¶)
                if st.session_state.get('current_kb_id') is None:
                     status_text = f"æ­£åœ¨å¯åŠ¨: {target_kb_id}..."
                     spinner_ctx = st.spinner(status_text)
                else:
                     # åˆ‡æ¢æ—¶ä½¿ç”¨ toast ä»¥å‡å°‘å¹²æ‰°
                     status_text = None
                     spinner_ctx = st.empty()

                with spinner_ctx:
                    try:
                        if target_kb_id == "multi_kb_mode":
                            st.session_state.chat_engine = "multi_kb_mode"
                            st.session_state.current_kb_id = "multi_kb_mode"
                            st.toast(f"âœ… å¤šçŸ¥è¯†åº“æ¨¡å¼å·²å¯åŠ¨ ({len(selected_kbs)}ä¸ª)")
                        else:
                            # å•çŸ¥è¯†åº“
                            kb_name = target_kb_id
                            from src.rag_engine import create_rag_engine
                            rag_engine = create_rag_engine(kb_name)
                            if rag_engine:
                                st.session_state.chat_engine = rag_engine.get_query_engine()
                                st.session_state.current_kb_id = kb_name
                                st.toast(f"âœ… çŸ¥è¯†åº“ '{kb_name}' å·²å¯åŠ¨")
                            else:
                                st.error(f"âŒ æ— æ³•å¯åŠ¨çŸ¥è¯†åº“ '{kb_name}'")
                                st.session_state.current_kb_id = None
                        
                        # åªæœ‰åœ¨å¼•æ“å˜åŒ–æ—¶æ‰ rerunï¼Œç¡®ä¿ç•Œé¢åˆ·æ–°
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")
                        logger.error(f"Auto-start failed: {e}")

        # çŸ¥è¯†åº“æœç´¢/è¿‡æ»¤å·²æŒ‰ç”¨æˆ·è¦æ±‚ç§»é™¤

        # å¸è½½çŸ¥è¯†åº“æŒ‰é’®ï¼ˆé‡Šæ”¾å†…å­˜ï¼‰
        if not (selected_nav == "â• æ–°å»ºçŸ¥è¯†åº“...") and st.session_state.get('chat_engine') is not None:
            if st.button("ğŸ”“ å¸è½½çŸ¥è¯†åº“ï¼ˆé‡Šæ”¾å†…å­˜ï¼‰", use_container_width=True, help="é‡Šæ”¾å½“å‰çŸ¥è¯†åº“å ç”¨çš„å†…å­˜èµ„æº"):
                st.session_state.chat_engine = None
                st.session_state.current_kb_id = None
                cleanup_memory()
                st.toast("âœ… çŸ¥è¯†åº“å·²å¸è½½ï¼Œå†…å­˜å·²é‡Šæ”¾")
                st.rerun()

        # --- ä¼šè¯å†å² (Session History) v2.7.3 ---
        # æå–å½“å‰çš„ active_kb_name (å¦‚æœå·²é€‰æ‹©)
        current_active_kb = None
        # å±€éƒ¨åˆ¤æ–­æ˜¯å¦ä¸ºåˆ›å»ºæ¨¡å¼ï¼Œé¿å… NameError
        _is_creating = (selected_nav == "â• æ–°å»ºçŸ¥è¯†åº“...")
        if not _is_creating and "ğŸ“‚ " in selected_nav:
             current_active_kb = selected_nav.split("ğŸ“‚ ")[1].split(" (")[0].strip()
        
        if current_active_kb:
            st.markdown("---")
            with st.expander("ğŸ•’ å†å²ä¼šè¯", expanded=True):
                from src.chat.history_manager import HistoryManager
                sessions = HistoryManager.list_sessions(current_active_kb)
                
                # æ–°å»ºä¼šè¯æŒ‰é’®
                if st.button("â• æ–°å»ºä¼šè¯", use_container_width=True, key="sidebar_new_chat"):
                    import uuid
                    new_id = str(uuid.uuid4())[:8]
                    st.session_state.current_session_id = new_id
                    st.session_state.messages = []
                    st.session_state.suggestions_history = []
                    HistoryManager.save_session(current_active_kb, [], new_id)
                    st.rerun()
                
                # ä¼šè¯åˆ—è¡¨
                for sess in sessions:
                    sess_id = sess['id']
                    label = sess['title']
                    is_active = (sess_id == st.session_state.get('current_session_id'))
                    
                    if sess.get('is_default'):
                        label = "ğŸ“ é»˜è®¤ä¼šè¯"
                    
                    btn_type = "primary" if is_active else "secondary"
                    icon = "ğŸ“‚" if is_active else "ğŸ“„"
                    
                    if st.button(f"{icon} {label}", key=f"sess_{sess_id}", use_container_width=True, type=btn_type):
                        st.session_state.current_session_id = sess_id
                        st.session_state.messages = HistoryManager.load_session(current_active_kb, sess_id)
                        st.session_state.suggestions_history = []
                        st.rerun()

        if selected_nav != st.session_state.get('current_nav'):
            st.session_state.pop('suggestions_history', None) 

        st.session_state.current_nav = selected_nav

        is_create_mode = (selected_nav == "â• æ–°å»ºçŸ¥è¯†åº“...")
        
        # æ ¹æ®é€‰ä¸­çš„çŸ¥è¯†åº“ç¡®å®šå½“å‰æ¨¡å¼
        selected_kbs = st.session_state.get('selected_kbs', [])
        if len(selected_kbs) == 1:
            current_kb_name = selected_kbs[0]
        elif len(selected_kbs) > 1:
            current_kb_name = None  # å¤šçŸ¥è¯†åº“æ¨¡å¼
            st.info(f"ğŸ” å·²é€‰æ‹© {len(selected_kbs)} ä¸ªçŸ¥è¯†åº“: {', '.join(selected_kbs)}")
        else:
            if selected_nav == "ğŸ’¬ çº¯å¯¹è¯æ¨¡å¼ (Pure Chat)":
                current_kb_name = "pure_chat"
            else:
                # å…¼å®¹å¸¦ç»Ÿè®¡ä¿¡æ¯çš„æ ¼å¼
                raw_name = selected_nav.split("ğŸ“‚ ")[1] if "ğŸ“‚ " in selected_nav else ""
                current_kb_name = raw_name.split(" (")[0].strip() if not is_create_mode and raw_name else None

        # ç»Ÿä¸€çš„æ•°æ®æºå¤„ç†é€»è¾‘
        uploaded_files = None
        crawl_url = None
        search_keyword = None
        target_path = ""
        btn_start = False # Initialize early to avoid NameError and support APPEND mode
        source_mode = None # Initialize to avoid NameError in APPEND mode
        
        if is_create_mode:
            # æ³¨å…¥ CSS å¢å¼ºæ ¸å¿ƒåŠŸèƒ½è§†è§‰æ•ˆæœ
            st.markdown("""
            <style>
            /* æ”¾å¤§ 4x1 é€‰æ‹©å™¨çš„æ–‡å­—å’Œå›¾æ ‡ */
            div[data-testid="stRadio"] > div[role="radiogroup"] > label {
                padding: 10px 15px !important;
                border-radius: 8px !important;
                transition: all 0.2s ease !important;
            }
            div[data-testid="stRadio"] > div[role="radiogroup"] > label p {
                font-size: 1.15rem !important;
                font-weight: 600 !important;
                color: #31333F !important;
            }
            /* é€‰ä¸­çŠ¶æ€ç¨å¾®å˜è‰²æé†’ */
            div[data-testid="stRadio"] > div[role="radiogroup"] > label[data-baseweb="radio"]:has(input:checked) {
                background-color: rgba(255, 75, 75, 0.05) !important;
            }
            </style>
            """, unsafe_allow_html=True)

            # 4x1 æ°´å¹³æ•°æ®æºé€‰æ‹©
            source_mode = st.radio(
                "æ•°æ®æº", 
                ["ğŸ“‚ æ–‡ä»¶ä¸Šä¼ ", "ğŸ“ ç²˜è´´æ–‡æœ¬", "ğŸ”— ç½‘å€æŠ“å–", "ğŸ” æ™ºèƒ½æœç´¢"], 
                horizontal=True,
                label_visibility="collapsed",
                key="data_source_selector"
            )
            
            if source_mode == "ğŸ“‚ æ–‡ä»¶ä¸Šä¼ ":
                # åŒæ¨¡å¼ï¼šæ”¯æŒä¸Šä¼ å’Œæ‰‹åŠ¨è¾“å…¥è·¯å¾„
                uploaded_files = st.file_uploader(
                    "æ‹–å…¥æ–‡ä»¶", 
                    accept_multiple_files=True, 
                    key="uploader",
                    label_visibility="collapsed",
                    help="æ”¯æŒæ ¼å¼: PDF, DOCX, TXT, MD, Excel"
                )
                
                # æ¢å¤è·¯å¾„è¾“å…¥
                st.markdown("<div style='margin-top: -5px; margin-bottom: 5px;'><span style='font-size: 0.75rem; color: gray;'>æˆ–ç²˜è´´æœ¬åœ°ç›®å½•è·¯å¾„:</span></div>", unsafe_allow_html=True)
                manual_path = st.text_input(
                    "æœ¬åœ°è·¯å¾„",
                    placeholder="ä¾‹å¦‚: /Users/name/Documents/docs",
                    key="manual_path_input",
                    label_visibility="collapsed"
                )
                if manual_path and os.path.exists(manual_path):
                    st.session_state.uploaded_path = manual_path
            
            elif source_mode == "ğŸ“ ç²˜è´´æ–‡æœ¬":
                # æ³¨å…¥ CSS æ¨¡ä»¿ä¸Šä¼ æ¡†æ ·å¼ (è™šçº¿è¾¹æ¡† + ç°è‰²èƒŒæ™¯)
                st.markdown("""
                <style>
                .stTextArea textarea {
                    border: 2px dashed rgba(49, 51, 63, 0.2) !important;
                    background-color: rgba(240, 242, 246, 0.5) !important;
                    border-radius: 0.5rem !important;
                }
                </style>
                """, unsafe_allow_html=True)
                
                def on_text_paste():
                    content = st.session_state.paste_text_content
                    if content.strip():
                        try:
                            save_dir = os.path.join(UPLOAD_DIR, f"text_{int(time.time())}")
                            if not os.path.exists(save_dir): os.makedirs(save_dir)
                            safe_name = "manual_input.txt"
                            with open(os.path.join(save_dir, safe_name), 'w', encoding='utf-8') as f:
                                f.write(content)
                            
                            # æ ¸å¿ƒï¼šè®¾ç½®ä¸Šä¼ è·¯å¾„å’Œè‡ªåŠ¨åç§°ï¼Œè§¦å‘ä¸‹æ–¹è¾“å…¥æ¡†æ˜¾ç¤º
                            abs_path = os.path.abspath(save_dir)
                            st.session_state.uploaded_path = abs_path
                            st.session_state.path_input = abs_path
                            
                            # è‡ªåŠ¨ç”Ÿæˆæ›´å…·è¯†åˆ«åº¦çš„åç§°ï¼šå–å‰15ä¸ªå­—ç¬¦
                            preview = "".join(c for c in content[:15] if c.isalnum() or c.isspace()).strip()
                            st.session_state.upload_auto_name = f"Text_{preview}"
                            st.toast(f"âœ… å·²è‡ªåŠ¨è¯†åˆ«: {st.session_state.upload_auto_name}", icon="ğŸ“")
                        except Exception as e:
                            st.error(f"è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}")

                # é«˜åº¦ 68ï¼Œè¿™æ˜¯ Streamlit æ”¯æŒçš„æœ€å°å€¼ï¼Œå®Œç¾å¯¹é½ä¸¤è¡Œè§†è§‰
                text_input_content = st.text_area(
                    "æ–‡æœ¬å†…å®¹", 
                    height=68, 
                    placeholder="åœ¨æ­¤ç²˜è´´æ–‡æœ¬ï¼Œè‡ªåŠ¨ä¿å­˜...", 
                    label_visibility="collapsed",
                    key="paste_text_content",
                    on_change=on_text_paste
                )
        else:
            # ç®¡ç†æ¨¡å¼ - ä½¿ç”¨ä¸€è¡ŒåŒ–å¸ƒå±€ (1x2 ç´§å‡‘å¸ƒå±€)
            manage_title_col1, manage_title_col2 = st.columns([4, 1])
            with manage_title_col1:
                st.markdown("ğŸ“¤ **æ·»åŠ æ–‡æ¡£**")
            with manage_title_col2:
                if st.button("ğŸ”„", help="é‡å»ºç´¢å¼• (è¦†ç›–è¯¥åº“)", use_container_width=True):
                    # è§¦å‘é‡å»ºé€»è¾‘
                    st.session_state.uploaded_path = os.path.join("vector_db_storage", current_kb_name)
                    # è¿™é‡Œéœ€è¦ä¸€ç§æ–¹å¼æ ‡è®°ä¸º NEW æ¨¡å¼ï¼Œå¹¶é€šè¿‡ trigger_btn_start å¼ºåˆ¶è§¦å‘
                    st.session_state.trigger_rebuild = True
                    st.session_state.trigger_btn_start = True
                    st.rerun()

            # è¿½åŠ æ¨¡å¼çš„æ–‡ä»¶ä¸Šä¼ 
            action_mode = "APPEND"
            # å¦‚æœè§¦å‘äº†é‡å»ºï¼Œåˆ™å¼ºåˆ¶æ”¹ä¸º NEW
            if st.session_state.get('trigger_rebuild'):
                action_mode = "NEW"
                st.session_state.trigger_rebuild = False # æ¶ˆè´¹æ‰æ ‡è®°
            
            # åˆå§‹åŒ– btn_start
            if st.session_state.get('trigger_btn_start'):
                btn_start = True
                st.session_state.trigger_btn_start = False # æ¶ˆè´¹æ‰æ ‡è®°
            
            target_path = "" # ç®¡ç†æ¨¡å¼ä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®šè·¯å¾„ï¼Œä½¿ç”¨KBåŸæœ‰è·¯å¾„
            
            uploaded_files = st.file_uploader(
                "è¿½åŠ æ–‡ä»¶åˆ°å½“å‰çŸ¥è¯†åº“", 
                accept_multiple_files=True, 
                key="uploader_append",
                label_visibility="collapsed"
            )
            
            # æ·»åŠ æ›´æ–°çŸ¥è¯†åº“æŒ‰é’®
            if uploaded_files:
                # é«˜çº§é€‰é¡¹ (å¤ç”¨æ–°å»ºæ¨¡å¼çš„é€»è¾‘)
                with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹ (æœ¬æ¬¡æ›´æ–°æœ‰æ•ˆ)", expanded=False):
                    # å¸ƒå±€ä¼˜åŒ–ï¼šå…¨é€‰ + çŠ¶æ€æç¤ºåœ¨ä¸€è¡Œ
                    h_col1, h_col2 = st.columns([1.5, 2.5])
                    with h_col1:
                        select_all = st.checkbox("âœ… ä¸€é”®å…¨é€‰", value=False, key="kb_adv_select_all_update", help="å¼€å¯/å…³é—­æ‰€æœ‰é«˜çº§é€‰é¡¹")
                    with h_col2:
                        status_placeholder = st.empty()
                    
                    default_val = select_all
                    
                    opt_col1, opt_col2, opt_col3 = st.columns(3)
                    with opt_col1:
                        st.checkbox("ğŸ” OCRè¯†åˆ«", value=default_val, key="kb_use_ocr", help="è¯†åˆ«PDFä¸­çš„å›¾ç‰‡æ–‡å­—")
                    with opt_col2:
                        st.checkbox("ğŸ“Š å…ƒæ•°æ®", value=default_val, key="kb_extract_metadata", help="æå–æ–‡ä»¶åˆ†ç±»ã€å…³é”®è¯")
                    with opt_col3:
                        st.checkbox("ğŸ“ ç”Ÿæˆæ‘˜è¦", value=default_val, key="kb_generate_summary", help="ç”ŸæˆAIæ‘˜è¦")
                    
                    # æ›´æ–°çŠ¶æ€æç¤º
                    options = []
                    if st.session_state.get("kb_use_ocr"): options.append("OCR")
                    if st.session_state.get("kb_extract_metadata"): options.append("å…ƒæ•°æ®")
                    if st.session_state.get("kb_generate_summary"): options.append("æ‘˜è¦")
                    
                    if options:
                        status_placeholder.caption(f"ğŸ”§ å¯ç”¨: {'|'.join(options)}")
                    else:
                        status_placeholder.caption("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šå·²å…³é—­é«˜çº§é€‰é¡¹")

                st.info("ğŸ’¡ ä¸Šä¼ åè¯·ç‚¹å‡»ä¸‹æ–¹ 'æ›´æ–°çŸ¥è¯†åº“' æŒ‰é’®")
                if st.button("ğŸ”„ æ›´æ–°çŸ¥è¯†åº“", type="primary", use_container_width=True, key="update_kb_btn"):
                    # ç«‹å³å¤„ç†ä¸Šä¼ ï¼Œç¡®ä¿è·¯å¾„å­˜åœ¨ (Failsafe)
                    try:
                        from src.processors.upload_handler import UploadHandler
                        # UPLOAD_DIR is global/imported
                        handler = UploadHandler(UPLOAD_DIR, logger)
                        with st.spinner("æ­£åœ¨é¢„å¤„ç†æ–‡ä»¶..."):
                            result = handler.process_uploads(uploaded_files)
                            st.session_state.uploaded_path = os.path.abspath(result.batch_dir)
                            st.session_state.last_processed_path = st.session_state.uploaded_path
                            # Update hash to prevent double processing downstream
                            import hashlib
                            upload_hash = hashlib.md5("".join([f"{f.name}_{f.size}" for f in uploaded_files]).encode()).hexdigest()
                            st.session_state.last_upload_hash = upload_hash
                    except Exception as e:
                        logger.error(f"Immediate upload processing failed: {e}")
                    
                    btn_start = True
                    action_mode = "APPEND"
                    st.session_state.sidebar_state = "collapsed"
                    st.markdown("""
                    <style>
                    [data-testid="stSidebar"] {
                        width: 2.5rem !important;
                        min-width: 2.5rem !important;
                        max-width: 2.5rem !important;
                    }
                    [data-testid="stSidebar"] > div {
                        overflow: hidden !important;
                    }
                    </style>
                    """, unsafe_allow_html=True)

        # ç»Ÿä¸€çš„æ•°æ®æºå¤„ç†é€»è¾‘ï¼ˆä»…é’ˆå¯¹ Web æŠ“å–ä¿ç•™åœ¨å¤–éƒ¨ï¼Œæœ¬åœ°æ–‡ä»¶å·²åœ¨å†…éƒ¨å¤„ç†ï¼‰
        # btn_start already initialized above
        
        if is_create_mode:
            if source_mode == "ğŸ”— ç½‘å€æŠ“å–":
                # --- ç½‘å€æŠ“å–æ¨¡å¼ ---
                # è®¾ç½®åŒæ­¥çŠ¶æ€
                st.session_state.crawl_input_mode = "url"
                
                # åŠ è½½ä¼˜åŒ–å™¨
                try:
                    from src.processors.crawl_optimizer import CrawlOptimizer
                    if 'crawl_optimizer' not in st.session_state:
                        st.session_state.crawl_optimizer = CrawlOptimizer()
                    optimizer = st.session_state.crawl_optimizer
                except ImportError:
                    optimizer = None

                c_url, c_btn = st.columns([7, 1])
                with c_url:
                    crawl_url = st.text_input("ç½‘å€", placeholder="https://example.com", label_visibility="collapsed")
                    st.session_state.crawl_url = crawl_url
                with c_btn:
                    if st.button("ğŸ§ ", help="AIåˆ†æ", key="smart_analyze_url", use_container_width=True):
                        if crawl_url:
                            with st.spinner("ğŸ”"):
                                test_url = crawl_url if crawl_url.startswith(('http://', 'https://')) else f"https://{crawl_url}"
                                analysis = optimizer.analyze_website(test_url) if optimizer else None
                                if analysis: st.session_state.crawl_analysis = analysis
                        else:
                            st.toast("è¯·å…ˆè¾“å…¥ç½‘å€", icon="âš ï¸")
                
                # åˆ†æç»“æœ
                if 'crawl_analysis' in st.session_state:
                    analysis = st.session_state.crawl_analysis
                    with st.expander("ğŸ¯ æ¨è: " + analysis['site_type'].title(), expanded=True):
                        st.caption(f"ğŸ’¡ {analysis['description']}")

                # å‚æ•°è¡Œ (ç´§å‡‘ 4åˆ—å¸ƒå±€)
                c_p1, c_p2, c_p3, c_p4 = st.columns(4)
                with c_p1:
                    default_depth = st.session_state.crawl_analysis['recommended_depth'] if 'crawl_analysis' in st.session_state else 2
                    crawl_depth = st.number_input("é€’å½’æ·±åº¦", 1, 10, default_depth)
                    st.session_state.crawl_depth = crawl_depth
                with c_p2:
                    default_pages = st.session_state.crawl_analysis['recommended_pages'] if 'crawl_analysis' in st.session_state else 5
                    max_pages = st.number_input("æœ€å¤§é¡µæ•°", 1, 1000, default_pages)
                    st.session_state.max_pages = max_pages
                with c_p3:
                    parser_type = st.selectbox("è§£æå™¨", ["default", "article", "documentation"], label_visibility="visible")
                    st.session_state.parser_type = parser_type
                with c_p4:
                    # è´¨é‡ç­›é€‰ (ç®€åŒ–ä¸ºæ•°å­—è¾“å…¥ï¼Œ0è¡¨ç¤ºå…³é—­)
                    url_quality_threshold = st.number_input("è´¨é‡é˜ˆå€¼ (0=å…³)", 0.0, 100.0, 45.0, 5.0, help="å†…å®¹è´¨é‡è¯„åˆ†é˜ˆå€¼ï¼Œä½äºæ­¤åˆ†æ•°çš„é¡µé¢å°†è¢«ä¸¢å¼ƒ")
                    st.session_state.url_quality_threshold = url_quality_threshold
                    enable_url_filter = (url_quality_threshold > 0)
                
                search_keyword = None # äº’æ–¥

            elif source_mode == "ğŸ” æ™ºèƒ½æœç´¢":
                # --- æ™ºèƒ½æœç´¢æ¨¡å¼ ---
                # è®¾ç½®åŒæ­¥çŠ¶æ€
                st.session_state.crawl_input_mode = "search"
                crawl_url = None # äº’æ–¥
                
                # è¡Œä¸šé€‰æ‹© (ç´§å‡‘)
                try:
                    from src.config.unified_sites import get_industry_list
                    industries = get_industry_list()
                    sel_ind = st.selectbox("è¡Œä¸š", industries, label_visibility="collapsed")
                except:
                    sel_ind = "ğŸ”§ æŠ€æœ¯å¼€å‘"
                
                c_kw, c_btn = st.columns([7, 1])
                with c_kw:
                    search_keyword = st.text_input("å…³é”®è¯", placeholder="è¾“å…¥æœç´¢å†…å®¹...", label_visibility="collapsed")
                    st.session_state.search_keyword = search_keyword
                with c_btn:
                    st.button("ğŸ§ ", help="AIæ¨è", key="smart_analyze_search", use_container_width=True)

                # å‚æ•°è¡Œ (ç´§å‡‘ 4åˆ—å¸ƒå±€)
                c_s1, c_s2, c_s3, c_s4 = st.columns(4)
                with c_s1:
                    crawl_depth = st.number_input("æ·±åº¦", 1, 5, 2)
                    st.session_state.search_crawl_depth = crawl_depth
                with c_s2:
                    max_pages = st.number_input("æ€»é¡µæ•°", 1, 500, 5)
                    st.session_state.search_max_pages = max_pages
                with c_s3:
                    parser_type = st.selectbox("è§£æå™¨", ["default", "article", "documentation"], key="parser_search")
                    st.session_state.search_parser_type = parser_type
                with c_s4:
                    # è´¨é‡ç­›é€‰ (ç®€åŒ–ä¸ºæ•°å­—è¾“å…¥ï¼Œ0è¡¨ç¤ºå…³é—­)
                    quality_threshold = st.number_input("è´¨é‡é˜ˆå€¼ (0=å…³)", 0.0, 100.0, 0.0, 5.0, key="search_quality_threshold", help="å†…å®¹è´¨é‡è¯„åˆ†é˜ˆå€¼")
                    st.session_state.quality_threshold = quality_threshold
                
                # é¢„ä¼°æç¤º
                est_pages = max_pages ** crawl_depth
                if est_pages > 100: st.caption(f"â„¹ï¸ é¢„ä¼°æŠ“å–: {est_pages} é¡µ")
                
                selected_industry = sel_ind # ä¼ é€’å˜é‡

            # æ’é™¤é…ç½® (é€šç”¨)
            if source_mode in ["ğŸ”— ç½‘å€æŠ“å–", "ğŸ” æ™ºèƒ½æœç´¢"]:
                with st.expander("ğŸš« æ’é™¤é“¾æ¥", expanded=False):
                    exclude_text = st.text_area("æ¯è¡Œä¸€ä¸ª", height=68, placeholder="*/admin/*")
                    exclude_patterns = [line.strip() for line in exclude_text.split('\n') if line.strip()] if exclude_text else []
                
                # æŠ“å–æŒ‰é’® (å·²ç§»é™¤ï¼ŒåŠŸèƒ½åˆå¹¶è‡³ä¾§è¾¹æ æŒ‰é’®)

            # å¤„ç†ä¸Šä¼  (Stage 4.1 - ä½¿ç”¨ UploadHandler)
            if uploaded_files:
                # ä½¿ç”¨æ–‡ä»¶å+å¤§å°çš„ç»„åˆä½œä¸ºå“ˆå¸Œï¼Œåˆ¤æ–­æ–‡ä»¶åˆ—è¡¨æ˜¯å¦çœŸæ­£æ”¹å˜
                import hashlib
                upload_hash = hashlib.md5("".join([f"{f.name}_{f.size}" for f in uploaded_files]).encode()).hexdigest()
                
                print(f"DEBUG: Upload detected. Files: {len(uploaded_files)}, Hash: {upload_hash}")
                print(f"DEBUG: Last Hash: {st.session_state.get('last_upload_hash')}")
                
                # åªè¦å“ˆå¸Œä¸åŒï¼Œæˆ–è€…å½“å‰æ²¡æœ‰æœ‰æ•ˆçš„ä¸Šä¼ è·¯å¾„ï¼Œå°±é‡æ–°å¤„ç†
                # è¿™èƒ½ä¿®å¤â€œè·¯å¾„ä¸¢å¤±â€çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿ç•™å“ˆå¸Œä¼˜åŒ–
                if st.session_state.get('last_upload_hash') != upload_hash or not st.session_state.get('uploaded_path'):
                    print("DEBUG: New upload hash detected OR path missing. Processing...")
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    # ä½¿ç”¨ UploadHandler å¤„ç†ä¸Šä¼ 
                    handler = UploadHandler(UPLOAD_DIR, logger)
                    
                    # æ¨¡æ‹Ÿè¿›åº¦æ˜¾ç¤ºï¼ˆå®é™…å¤„ç†åœ¨ process_uploads å†…éƒ¨ï¼‰
                    status_text.text(f"æ­£åœ¨å¤„ç† {len(uploaded_files)} ä¸ªæ–‡ä»¶...")
                    progress_bar.progress(0.5)

                    result = handler.process_uploads(uploaded_files)
                    
                    print(f"DEBUG: Process result dir: {result.batch_dir}")

                    progress_bar.empty()
                    status_text.empty()

                    # è®°å½•å“ˆå¸Œï¼Œé˜²æ­¢é‡å¤å¤„ç†
                    st.session_state.last_upload_hash = upload_hash
                    st.session_state.uploaded_path = os.path.abspath(result.batch_dir)
                    st.session_state.last_processed_path = st.session_state.uploaded_path
                    
                    print(f"DEBUG: Saved uploaded_path: {st.session_state.uploaded_path}")

                    # æ˜¾ç¤ºä¸Šä¼ ç»“æœ
                    if result.success_count > 0:
                        st.toast(f"âœ… æˆåŠŸä¸Šä¼  {result.success_count} ä¸ªæ–‡ä»¶")

                    if result.skipped_count > 0:
                        st.warning(f"âš ï¸ è·³è¿‡ {result.skipped_count} ä¸ªæ–‡ä»¶")

                    # ä¸ºæ–‡ä»¶ä¸Šä¼ åœºæ™¯ç”Ÿæˆæ™ºèƒ½åç§°
                    if result.success_count > 0:
                        try:
                            file_types = {}
                            for f in uploaded_files:
                                ext = os.path.splitext(f.name)[1].lower()
                                file_types[ext] = file_types.get(ext, 0) + 1

                            folder_name = os.path.basename(result.batch_dir)
                            auto_name = generate_smart_kb_name(result.batch_dir, result.success_count, file_types, folder_name)
                            st.session_state.upload_auto_name = auto_name
                        except Exception:
                            st.session_state.upload_auto_name = None
                    
                    # å…³é”®ä¿®å¤ï¼šä¸å†å¼ºåˆ¶å…¨é¡µé¢ rerunï¼Œè€Œæ˜¯ä¾é  Streamlit è‡ªç„¶æµè½¬
                    # è¿™æ ·å¯ä»¥ä¿ç•™ uploader çš„çŠ¶æ€ï¼Œé¿å…å…¶å› åˆ·æ–°è€ŒæŠ¥é”™æˆ–é‡ç½®
                
                elif st.session_state.get('last_processed_path'):
                    # å¦‚æœå“ˆå¸ŒåŒ¹é…ï¼ˆè¯´æ˜æ˜¯ rerunï¼‰ï¼Œä¸”æœ‰å¤‡ä»½è·¯å¾„ï¼Œåˆ™æ¢å¤
                    print(f"DEBUG: Hash matched. Restoring path: {st.session_state.last_processed_path}")
                    st.session_state.uploaded_path = st.session_state.last_processed_path
                else:
                    print("DEBUG: Hash matched but no last_processed_path found!")


            # ä½¿ç”¨ä¸Šä¼ è·¯å¾„æˆ–æ‰‹åŠ¨è¾“å…¥çš„è·¯å¾„
            target_path = st.session_state.get('uploaded_path') or target_path

            auto_name = ""

            # ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶ä¸Šä¼ çš„æ™ºèƒ½åç§°
            if hasattr(st.session_state, 'upload_auto_name') and st.session_state.upload_auto_name:
                auto_name = st.session_state.upload_auto_name

            if target_path:
                if os.path.exists(target_path):
                    # ä½¿ç”¨ UploadHandler ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯ (Stage 4.1)
                    cnt, file_types, total_size = UploadHandler.get_folder_stats(target_path)

                    # ç¾åŒ–æ˜¾ç¤º
                    size_mb = total_size / (1024 * 1024)
                    folder_name = os.path.basename(target_path.rstrip('/'))

                    # æ™ºèƒ½è®¡ç®—åç§° (æå‰è®¡ç®—ä»¥ä¼˜åŒ–æ˜¾ç¤º)
                    if hasattr(st.session_state, 'upload_auto_name') and st.session_state.upload_auto_name:
                        auto_name = st.session_state.upload_auto_name
                    elif cnt > 0:
                        auto_name = generate_smart_kb_name(target_path, cnt, file_types, folder_name)
                    else:
                        auto_name = folder_name

                    # å†³å®šæ˜¾ç¤ºåç§°ï¼šå¦‚æœæ˜¯ä¸´æ—¶ç›®å½•åï¼Œåˆ™æ˜¾ç¤ºæ™ºèƒ½åç§°
                    display_name = folder_name
                    if folder_name.startswith(('batch_', 'Web_', 'Search_')) and auto_name:
                        display_name = auto_name

                    # --- æç®€ä¸€è¡ŒåŒ–ï¼šçŠ¶æ€å¾½ç«  + åç§°è¾“å…¥ ---
                    # é¿å…åœ¨å·¦ä¾§é‡å¤æ˜¾ç¤ºé•¿æ–‡ä»¶åï¼Œåªæ˜¾ç¤ºçŠ¶æ€ï¼Œåç§°åœ¨è¾“å…¥æ¡†ä¸­æ˜¾ç¤º
                    status_col, input_col = st.columns([1.2, 4])
                    
                    with status_col:
                        # å‚ç›´å±…ä¸­çš„çŠ¶æ€å¾½ç« 
                        st.markdown(
                            """<div style='
                                background: #f0fdf4; 
                                color: #15803d; 
                                padding: 6px 8px; 
                                border-radius: 6px; 
                                border: 1px solid #bbf7d0;
                                text-align: center; 
                                font-size: 0.85rem; 
                                font-weight: 500;
                                white-space: nowrap;
                                margin-top: 1px;
                            '>âœ… æºå°±ç»ª</div>""", 
                            unsafe_allow_html=True
                        )
                    
                    with input_col:
                        if is_create_mode:
                            final_kb_name = st.text_input(
                                "çŸ¥è¯†åº“åç§°", 
                                value=sanitize_filename(auto_name) if auto_name else "", 
                                placeholder="è¾“å…¥åº“å",
                                label_visibility="collapsed",
                                key="kb_name_inline_input"
                            )
                        else:
                            final_kb_name = current_kb_name
                            st.markdown(f"<div style='padding-top: 6px;'><b>{final_kb_name}</b></div>", unsafe_allow_html=True)

                    # ç±»å‹åˆ†å¸ƒï¼ˆç´§å‡‘åŒ–ï¼‰
                    if file_types:
                        sorted_types = sorted(file_types.items(), key=lambda x: x[1], reverse=True)[:5]
                        type_text = " Â· ".join([f"{ext.replace('.', '')}:{count}" for ext, count in sorted_types])
                        st.caption(f"ğŸ“Š {type_text} Â· æº: {display_name}")
                else:
                    st.error("âŒ è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
                    final_kb_name = current_kb_name if not is_create_mode else ""
            else:
                final_kb_name = current_kb_name if not is_create_mode else ""

            st.write("")

            # é«˜çº§é€‰é¡¹
            with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹", expanded=False):
                # å¸ƒå±€ä¼˜åŒ–ï¼šå…¨é€‰ + çŠ¶æ€æç¤ºåœ¨ä¸€è¡Œ
                h_col1, h_col2 = st.columns([1.5, 2.5])
                with h_col1:
                    select_all = st.checkbox("âœ… ä¸€é”®å…¨é€‰", value=False, key="kb_adv_select_all", help="å¼€å¯/å…³é—­æ‰€æœ‰é«˜çº§é€‰é¡¹")
                with h_col2:
                    status_placeholder = st.empty()
                
                # æ ¹æ®ä¸€é”®å…¨é€‰çŠ¶æ€è®¾ç½®é»˜è®¤å€¼
                default_val = select_all

                # é€‰é¡¹å¸ƒå±€ï¼šå¦‚æœéæ–°å»ºæ¨¡å¼ï¼Œæ˜¾ç¤ºå¼ºåˆ¶é‡å»ºç´¢å¼•
                # æ–°å»ºæ¨¡å¼ä¸‹éšè—å¼ºåˆ¶é‡å»ºï¼ˆæœ¬èº«å°±æ˜¯æ–°å»ºï¼‰
                if not is_create_mode:
                    force_reindex = st.checkbox("ğŸ”„ å¼ºåˆ¶é‡å»ºç´¢å¼•", value=default_val, key="kb_force_reindex", help="åˆ é™¤ç°æœ‰ç´¢å¼•ï¼Œé‡æ–°æ„å»º")
                else:
                    force_reindex = False

                # å‰©ä¸‹çš„3ä¸ªé€‰é¡¹æ˜¾ç¤ºåœ¨ä¸€è¡Œ
                opt_col1, opt_col2, opt_col3 = st.columns(3)
                with opt_col1:
                    use_ocr = st.checkbox("ğŸ” OCRè¯†åˆ«", value=default_val, key="kb_use_ocr", help="è¯†åˆ«PDFä¸­çš„å›¾ç‰‡æ–‡å­—")
                with opt_col2:
                    extract_metadata = st.checkbox("ğŸ“Š å…ƒæ•°æ®", value=default_val, key="kb_extract_metadata", help="æå–æ–‡ä»¶åˆ†ç±»ã€å…³é”®è¯")
                with opt_col3:
                    generate_summary = st.checkbox("ğŸ“ ç”Ÿæˆæ‘˜è¦", value=default_val, key="kb_generate_summary", help="ç”ŸæˆAIæ‘˜è¦")
                
                # ä¿å­˜åˆ°session state
                st.session_state.use_ocr = use_ocr
                st.session_state.generate_summary = generate_summary
                
                # æ›´æ–°çŠ¶æ€æç¤º
                options = []
                if force_reindex: options.append("é‡å»ºç´¢å¼•")
                if extract_metadata: options.append("å…ƒæ•°æ®")
                if use_ocr: options.append("OCR")
                if generate_summary: options.append("æ‘˜è¦")
                
                if options:
                    status_placeholder.caption(f"ğŸ”§ å¯ç”¨: {'|'.join(options)}")
                else:
                    status_placeholder.caption("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šå·²å…³é—­é«˜çº§é€‰é¡¹")


            st.write("")

            btn_label = "ğŸš€ ç«‹å³åˆ›å»º" if is_create_mode else ("â• æ‰§è¡Œè¿½åŠ " if action_mode=="APPEND" else "ğŸ”„ æ‰§è¡Œè¦†ç›–")
            btn_start = st.button(btn_label, type="primary", use_container_width=True, key="main_sidebar_start_btn")
            
            # è‡ªåŠ¨æ”¶èµ·ä¾§è¾¹æ 
            if btn_start:
                st.session_state.sidebar_state = "collapsed"
                st.markdown("""
                <style>
                [data-testid="stSidebar"] {
                    width: 2.5rem !important;
                    min-width: 2.5rem !important;
                    max-width: 2.5rem !important;
                }
                [data-testid="stSidebar"] > div {
                    overflow: hidden !important;
                }
                [data-testid="stSidebar"] .css-1d391kg {
                    display: none !important;
                }
                </style>
                """, unsafe_allow_html=True)
            
            # ç¡®ä¿ action_mode åœ¨æ­¤å®šä¹‰
            if 'action_mode' not in locals():
                action_mode = "NEW" if is_create_mode else "APPEND"

        # --- ç°æœ‰åº“çš„ç®¡ç† (å¡ç‰‡å¼å¸ƒå±€) ---
        if not is_create_mode:
            # æ³¨å…¥ CSS ä¿®å¤æŒ‰é’®å¯¹é½é—®é¢˜
            st.markdown("""
            <style>
            /* å¼ºåˆ¶ç»Ÿä¸€æ“ä½œæ æŒ‰é’®çš„é«˜åº¦å’Œå¯¹é½ */
            div[data-testid="column"] button, 
            div[data-testid="column"] a {
                min-height: 38px !important;
                display: flex !important;
                align-items: center !important;
                justify-content: center !important;
                margin-top: 0px !important;
            }
            /* ä¿®å¤ä¸‹è½½æŒ‰é’®å’Œé“¾æ¥æŒ‰é’®çš„æ–‡å­—åç§» */
            div[data-testid="stDownloadButton"] > button,
            div[data-testid="stLinkButton"] > a {
                padding-top: 0px !important;
                padding-bottom: 0px !important;
                line-height: 1 !important;
            }
            </style>
            """, unsafe_allow_html=True)
            
            with st.container(border=True):
                # é¡¶éƒ¨ä¿¡æ¯æ å·²ç§»é™¤ï¼ˆç”¨æˆ·åé¦ˆå†—ä½™ï¼‰
                
                # åº•éƒ¨ï¼šæ“ä½œæ  (ä¼˜åŒ–ä¸º 2x2 + 1 çš„ä¸‰è¡Œå¸ƒå±€)
                op_row1 = st.columns(2)
                op_row2 = st.columns(2)
                op_row3 = st.columns(1)
                
                # ç¬¬ä¸€è¡Œï¼šå¯¹è¯æ“ä½œ
                with op_row1[0]:
                    if st.button("ğŸ”„ æ’¤é”€", use_container_width=True, disabled=len(state.get_messages()) < 2, help="æ’¤é”€æœ€è¿‘ä¸€è½®å¯¹è¯"):
                        if len(state.get_messages()) >= 2:
                            st.session_state.messages.pop()
                            st.session_state.messages.pop()
                            if current_kb_name:
                                HistoryManager.save_session(current_kb_name, state.get_messages(), st.session_state.get('current_session_id'))
                            st.toast("âœ… å·²æ’¤é”€")
                            time.sleep(0.5)
                            st.rerun()
                
                with op_row1[1]:
                    if st.button("ğŸ§¹ æ¸…ç©º", use_container_width=True, disabled=len(state.get_messages()) == 0, help="æ¸…ç©ºå½“å‰å¯¹è¯è®°å½•"):
                        st.session_state.messages = []
                        st.session_state.suggestions_history = []
                        if current_kb_name:
                            HistoryManager.save_session(current_kb_name, [], st.session_state.get('current_session_id'))
                        st.toast("âœ… å·²æ¸…ç©º")
                        time.sleep(0.5)
                        st.rerun()
                
                # ç¬¬äºŒè¡Œï¼šå¯¼å‡ºä¸è§†å›¾
                with op_row2[0]:
                    export_content = ""
                    if len(state.get_messages()) > 0:
                        export_content = f"# å¯¹è¯è®°å½• - {current_kb_name}\n\n**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n---\n\n"
                        for i, msg in enumerate(st.session_state.messages, 1):
                            role = "ğŸ‘¤ ç”¨æˆ·" if msg["role"] == "user" else "ğŸ¤– åŠ©æ‰‹"
                            export_content += f"## {role} ({i})\n\n{msg['content']}\n\n"
                    
                    st.download_button("ğŸ“¥ å¯¼å‡º", export_content, file_name=f"chat_{current_kb_name}_{datetime.now().strftime('%Y%m%d')}.md", mime="text/markdown", use_container_width=True, disabled=len(state.get_messages()) == 0)

                with op_row2[1]:
                    st.link_button("ğŸ”€ æ–°çª—å£", "http://localhost:8501", use_container_width=True, help="æ‰“å¼€æ–°çª—å£")

                # ç¬¬ä¸‰è¡Œï¼šå±é™©æ“ä½œ
                with op_row3[0]:
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", use_container_width=True, type="primary", disabled=not current_kb_name, help="æ°¸ä¹…åˆ é™¤è¯¥çŸ¥è¯†åº“"):
                        st.session_state.confirm_delete = True
                        st.rerun()
            
            # åˆ é™¤ç¡®è®¤å¯¹è¯æ¡† (æ”¾åœ¨å¡ç‰‡å¤–ï¼Œé¿å…åµŒå¥—é—®é¢˜)
            if st.session_state.get('confirm_delete', False):
                st.warning(f"âš ï¸ ç¡®è®¤æ°¸ä¹…åˆ é™¤çŸ¥è¯†åº“ '{current_kb_name}' å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ï¼")
                confirm_col1, confirm_col2 = st.columns([1, 1])
                
                with confirm_col1:
                    if st.button("âœ… ç¡®è®¤åˆ é™¤", type="primary", use_container_width=True):
                        kb_manager.delete(current_kb_name) # ç¡®ä¿å®é™…è°ƒç”¨åˆ é™¤é€»è¾‘
                        st.toast(f"ğŸ—‘ï¸ å·²åˆ é™¤çŸ¥è¯†åº“: {current_kb_name}")
                        # é‡ç½®çŠ¶æ€
                        st.session_state.active_kb_name = None
                        st.session_state.confirm_delete = False
                        st.session_state.current_nav = "â• æ–°å»ºçŸ¥è¯†åº“..."
                        time.sleep(1)
                        st.rerun()
                
                with confirm_col2:
                    if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                        st.session_state.confirm_delete = False
                        st.rerun()
            
    
    with tab_roles:
        from src.ui.role_manager_ui import RoleManagerUI
        RoleManagerUI.render()

    with tab_config:
        st.session_state.current_tab = "config"
        
        # P0æ”¹è¿›3: ä¾§è¾¹æ åˆ†ç»„ - åŸºç¡€é…ç½®ï¼ˆé»˜è®¤å±•å¼€ï¼‰- ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.2.2)
        config_values = render_basic_config(defaults)

        # æå–é…ç½®å€¼ (æ”¯æŒæ–°çš„ extra_params)
        llm_provider = config_values.get('llm_provider', 'Ollama')
        llm_url = config_values.get('llm_url', 'http://localhost:11434')
        llm_model = config_values.get('llm_model', 'qwen2.5:7b')
        llm_key = config_values.get('llm_key', '')
        embed_provider = config_values.get('embed_provider', 'HuggingFace (æœ¬åœ°/æé€Ÿ)')
        embed_model = config_values.get('embed_model', 'sentence-transformers/all-MiniLM-L6-v2')
        embed_url = config_values.get('embed_url', '')
        embed_key = config_values.get('embed_key', '')

        # è®¾ç½®å…¨å±€LLMï¼ˆç¡®ä¿æŸ¥è¯¢æ”¹å†™ç­‰åŠŸèƒ½å¯ä»¥ä½¿ç”¨ï¼‰
        if not hasattr(Settings, 'llm') or Settings.llm is None:
            # ä¼ é€’æ‰€æœ‰é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬ api_version ç­‰é¢å¤–å‚æ•°
            set_global_llm_model(llm_provider, llm_model, llm_key, llm_url, **config_values)

        # P0æ”¹è¿›3: é«˜çº§åŠŸèƒ½ï¼ˆé»˜è®¤å±•å¼€ï¼‰- ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.2.3)
        from src.ui.sidebar_config import SidebarConfig
        advanced_config = SidebarConfig._render_advanced_config()

    with tab_monitor:
        # v2.3.0: æ™ºèƒ½ç›‘æ§é¢æ¿
        try:
            from src.core.v23_integration import get_v23_integration
            v23 = get_v23_integration()
            v23.render_monitoring_tab()
        except ImportError:
            # é™çº§åˆ°v1.5.1æ€§èƒ½ç›‘æ§é¢æ¿
            perf_monitor.render_panel()
    
    with tab_help:
        st.markdown("##### ğŸ“– å¸®åŠ©")
        st.info("RAG Pro Max v2.4.7 - Webçˆ¬å–ä¸æ•°æ®å¤„ç†å¢å¼ºç‰ˆ")

# ==========================================
# ä¸»åŠŸèƒ½åŒºåŸŸ
# ==========================================

# æ ¹æ®é€‰æ‹©çš„æ¨¡å¼æ˜¾ç¤ºå¯¹åº”åŠŸèƒ½
if st.session_state.get('main_mode', 'rag') == 'sql':
    # ==========================================
    # ğŸ“Š æ•°æ®åˆ†ææ¨¡å¼
    # ==========================================
    st.markdown("##### ğŸ“Š æ•°æ®åˆ†æ (Text-to-SQL)")
    
    # åˆå§‹åŒ–SQLå¼•æ“
    if 'sql_engine' not in st.session_state:
        try:
            from src.engines.sql_engine import SQLEngine
            st.session_state.sql_engine = SQLEngine()
        except ImportError:
            st.error("SQLå¼•æ“æ¨¡å—æœªæ‰¾åˆ°")
            st.stop()

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("###### ğŸ“ æ•°æ®å¯¼å…¥")
        
        uploaded_data = st.file_uploader(
            "ä¸Šä¼ Excel/CSVæ–‡ä»¶", 
            type=['xlsx', 'csv'],
            key="main_data_uploader"
        )
        
        if uploaded_data:
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_data.name.split('.')[-1]}") as tmp:
                tmp.write(uploaded_data.getvalue())
                tmp_path = tmp.name
            
            if st.button("ğŸ“¥ å¯¼å…¥æ•°æ®", type="primary", key="main_import"):
                with st.spinner("å¯¼å…¥ä¸­..."):
                    try:
                        result = st.session_state.sql_engine.import_excel_csv(tmp_path)
                        st.success(result)
                        st.session_state.main_data_imported = True
                    except Exception as e:
                        st.error(f"å¯¼å…¥å¤±è´¥: {str(e)}")
        
        # æ˜¾ç¤ºæ•°æ®ç»“æ„
        if st.session_state.get('main_data_imported'):
            st.markdown("###### ğŸ“‹ æ•°æ®ç»“æ„")
            try:
                schema = st.session_state.sql_engine.get_schema()
                for table, columns in schema.items():
                    with st.expander(f"ğŸ“Š {table}"):
                        st.write(f"å­—æ®µ: {', '.join(columns)}")
            except:
                st.write("æš‚æ— æ•°æ®")

    with col2:
        st.markdown("###### ğŸ’¬ æ•°æ®é—®ç­”")
        
        if st.session_state.get('main_data_imported'):
            data_query = st.text_input(
                "è¾“å…¥æ‚¨çš„æ•°æ®åˆ†æé—®é¢˜", 
                placeholder="ä¾‹å¦‚: ç»Ÿè®¡å„éƒ¨é—¨çš„æ€»äººæ•°ã€è®¡ç®—å¹³å‡å·¥èµ„",
                key="main_data_query"
            )
            
            if st.button("ğŸ” åˆ†æ", type="primary", key="main_analyze") and data_query:
                with st.spinner("æ­£åœ¨åˆ†æ..."):
                    try:
                        if not hasattr(st.session_state, 'llm') or not st.session_state.llm:
                            st.error("è¯·å…ˆåœ¨å·¦ä¾§é…ç½®é¡µé¢è®¾ç½®LLMæ¨¡å‹")
                        else:
                            sql = st.session_state.sql_engine.text_to_sql(data_query, st.session_state.llm)
                            
                            with st.expander("ğŸ“ ç”Ÿæˆçš„SQLè¯­å¥"):
                                st.code(sql, language="sql")
                            
                            result = st.session_state.sql_engine.execute_sql(sql)
                            
                            if result['success']:
                                st.success(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {result['rows']} è¡Œæ•°æ®")
                                if result['data']:
                                    import pandas as pd
                                    df = pd.DataFrame(result['data'])
                                    st.dataframe(df, use_container_width=True)
                                    
                                    # ç®€å•å›¾è¡¨
                                    if len(df.columns) >= 2 and len(df) > 1:
                                        chart_col1, chart_col2 = st.columns(2)
                                        with chart_col1:
                                            if st.button("ğŸ“Š æŸ±çŠ¶å›¾"):
                                                st.bar_chart(df.set_index(df.columns[0]))
                                        with chart_col2:
                                            if st.button("ğŸ“ˆ æŠ˜çº¿å›¾"):
                                                st.line_chart(df.set_index(df.columns[0]))
                                else:
                                    st.info("æŸ¥è¯¢æ— ç»“æœ")
                            else:
                                st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {result['error']}")
                    except Exception as e:
                        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        else:
            st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
            
    # åœæ­¢åç»­æ‰§è¡Œï¼Œç¡®ä¿åªæ˜¾ç¤ºæ•°æ®åˆ†æç•Œé¢
    st.stop()

# ==========================================
# ğŸ“„ RAGæ–‡æ¡£é—®ç­”æ¨¡å¼ (åŸæœ‰åŠŸèƒ½)
# ==========================================

# ==========================================
# 5. æ ¸å¿ƒé€»è¾‘ (RAG & Indexing)
# ==========================================

def jump_to_knowledge_base(kb_name: str, output_base: str):
    """ç»Ÿä¸€çš„çŸ¥è¯†åº“è·³è½¬é€»è¾‘"""
    logger.log("çŸ¥è¯†åº“è·³è½¬", "start", f"ğŸš€ è·³è½¬å‡½æ•°å¼€å§‹æ‰§è¡Œ: {kb_name}")
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"ğŸ”„ å‡†å¤‡è·³è½¬åˆ°çŸ¥è¯†åº“: {kb_name}")
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_base}")
    
    # å¼ºåˆ¶åˆ·æ–°çŸ¥è¯†åº“ç®¡ç†å™¨çš„ç¼“å­˜
    from src.kb.kb_manager import KBManager
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"ğŸ”§ åˆ›å»ºçŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹")
    kb_manager = KBManager(output_base)
    kb_list = kb_manager.list_all()
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"ğŸ“‹ å½“å‰çŸ¥è¯†åº“åˆ—è¡¨: {kb_list}")
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"ğŸ“Š çŸ¥è¯†åº“æ€»æ•°: {len(kb_list)}")
    
    # ç¡®è®¤æ–°çŸ¥è¯†åº“åœ¨åˆ—è¡¨ä¸­
    if kb_name in kb_list:
        logger.log("çŸ¥è¯†åº“è·³è½¬", "success", f"âœ… æ–°çŸ¥è¯†åº“å·²åœ¨åˆ—è¡¨ä¸­: {kb_name}")
    else:
        logger.log("çŸ¥è¯†åº“è·³è½¬", "warning", f"âš ï¸ æ–°çŸ¥è¯†åº“ä¸åœ¨åˆ—è¡¨ä¸­: {kb_name}")
    
    # è®¾ç½®è·³è½¬å‚æ•°
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"âš™ï¸ å¼€å§‹è®¾ç½®è·³è½¬å‚æ•°")
    old_nav = st.session_state.get('current_nav', 'None')
    old_kb_id = st.session_state.get('current_kb_id', 'None')
    
    # æ¸…é™¤å¤šé€‰çŠ¶æ€ï¼Œç¡®ä¿å•é€‰æ¨¡å¼
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"ğŸ§¹ æ¸…é™¤å¤šé€‰çŠ¶æ€")
    st.session_state.selected_kbs = []
    cleared_count = 0
    for kb in kb_list:
        if st.session_state.get(f"kb_check_{kb}", False):
            cleared_count += 1
        st.session_state[f"kb_check_{kb}"] = False
    
    # æ ¸å¿ƒä¿®å¤ï¼šåœ¨æ¸…ç†å®Œæ‰€æœ‰çŠ¶æ€åï¼Œå†è®¾ç½®ç›®æ ‡çŸ¥è¯†åº“çš„é€‰ä¸­çŠ¶æ€
    st.session_state[f"kb_check_{kb_name}"] = True
    st.session_state.current_nav = f"â˜‘ï¸ ğŸ“‚ {kb_name}"
    st.session_state.current_kb_id = kb_name
    st.session_state.chat_engine = None  # é‡ç½®èŠå¤©å¼•æ“ï¼Œè§¦å‘é‡æ–°åŠ è½½
    
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"ğŸ§¹ å·²æ¸…é™¤ {cleared_count} ä¸ªå¤é€‰æ¡†çŠ¶æ€")
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", f"âœ… è·³è½¬å‚æ•°å·²è®¾ç½®: current_nav={st.session_state.current_nav}")
    logger.log("çŸ¥è¯†åº“è·³è½¬", "info", "ğŸš€ æ‰§è¡Œé¡µé¢åˆ·æ–°...")
    logger.log("çŸ¥è¯†åº“è·³è½¬", "complete", f"âœ… è·³è½¬å‡½æ•°æ‰§è¡Œå®Œæˆ: {kb_name}")


def process_knowledge_base_logic(kb_name, action_mode="NEW", use_ocr=False, extract_metadata=False, generate_summary=False, force_reindex=False):
    """å¤„ç†çŸ¥è¯†åº“é€»è¾‘ (Stage 4.2 - ä½¿ç”¨ IndexBuilder)"""
    global logger
    
    persist_dir = os.path.join(output_base, kb_name)
    start_time = time.time()
    
    # èµ„æºä¿æŠ¤æ£€æŸ¥
    cpu = psutil_main.cpu_percent(interval=0.1)
    mem = psutil_main.virtual_memory().percent
    result = resource_guard.check_resources(cpu, mem, 0)
    throttle_info = result.get('throttle', {})
    if throttle_info.get('action') == 'reject':
        st.warning(f"âš ï¸ ç³»ç»Ÿèµ„æºç´§å¼ ï¼Œè¯·ç¨åå†è¯•")
        logger.warning(f"èµ„æºä¸è¶³ï¼Œæš‚åœå¤„ç†: CPU={cpu}%, MEM={mem}%")
        time.sleep(2)
        return

    # è®¾ç½®åµŒå…¥æ¨¡å‹
    logger.info(f"ğŸ”§ è®¾ç½®åµŒå…¥æ¨¡å‹: {embed_model} (provider: {embed_provider})")
    embed = get_embed(embed_provider, embed_model, embed_key, embed_url)
    if not embed:
        logger.warning(f"âš ï¸ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {embed_model}ï¼Œå°è¯•ç¦»çº¿æ¨¡å¼")
        try:
            from src.utils.offline_embeddings import get_offline_embeddings
            offline_embed = get_offline_embeddings("all-MiniLM-L6-v2")
            if offline_embed.load_model():
                logger.info("âœ… ç¦»çº¿åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
                # åˆ›å»ºä¸€ä¸ªç®€å•çš„åŒ…è£…å™¨
                class OfflineEmbedWrapper:
                    def __init__(self, offline_model):
                        self.offline_model = offline_model
                    def _get_text_embedding(self, text):
                        return self.offline_model.encode([text])[0]
                embed = OfflineEmbedWrapper(offline_embed)
            else:
                logger.error(f"âŒ ç¦»çº¿æ¨¡å¼ä¹Ÿå¤±è´¥ï¼Œæ— æ³•åŠ è½½åµŒå…¥æ¨¡å‹")
                st.error("âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ¨¡å‹é…ç½®")
                return
        except Exception as e:
            logger.error(f"âŒ ç¦»çº¿æ¨¡å¼å¼‚å¸¸: {e}")
            st.error("âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ¨¡å‹é…ç½®")
            return
    
    Settings.embed_model = embed
    try:
        actual_dim = len(embed._get_text_embedding("test"))
        logger.success(f"âœ… åµŒå…¥æ¨¡å‹å·²è®¾ç½®: {embed_model} ({actual_dim}ç»´)")
    except:
        logger.success(f"âœ… åµŒå…¥æ¨¡å‹å·²è®¾ç½®: {embed_model}")

    logger.log("INFO", f"å¼€å§‹å¤„ç†çŸ¥è¯†åº“: {kb_name}", stage="çŸ¥è¯†åº“å¤„ç†")
    
    # UI çŠ¶æ€å®¹å™¨
    status_container = st.status(f"ğŸš€ å¤„ç†çŸ¥è¯†åº“: {kb_name}", expanded=True)
    prog_bar = status_container.progress(0)
    status_container.write(f"â±ï¸ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
    
    # å›è°ƒå‡½æ•°ï¼šæ›´æ–° UI
    def status_callback(msg_type, *args):
        if msg_type == "step":
            step_num, step_desc = args
            status_container.write(f"ğŸ“‚ [æ­¥éª¤{step_num}/6] {step_desc}")
            logger.info(f"ğŸ“‚ [æ­¥éª¤ {step_num}/6] {step_desc}")
            prog_bar.progress(step_num * 15)
        elif msg_type == "info":
            info_msg = args[0]
            status_container.write(f"   {info_msg}")
            logger.info(f"   {info_msg}")
        elif msg_type == "warning":
            warn_msg = args[0]
            status_container.write(f"   âš ï¸  {warn_msg}")
            logger.warning(f"   âš ï¸  {warn_msg}")
    
    # è·å–æºè·¯å¾„
    current_target_path = st.session_state.get('uploaded_path') or st.session_state.get('path_input')
    if not current_target_path or not os.path.exists(current_target_path):
        status_container.update(label="âŒ è·¯å¾„æ— æ•ˆ", state="error")
        logger.error(f"âŒ è·¯å¾„æ— æ•ˆ: {current_target_path} (uploaded_path={st.session_state.get('uploaded_path')}, path_input={st.session_state.get('path_input')})")
        raise ValueError(f"è·¯å¾„æ— æ•ˆ: {current_target_path} - è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ä¸Šä¼ æˆ–è·¯å¾„æ˜¯å¦æ­£ç¡®")
    
    # ä½¿ç”¨ IndexBuilder æ„å»ºç´¢å¼•
    builder = IndexBuilder(
        kb_name=kb_name,
        persist_dir=persist_dir,
        embed_model=embed,
        embed_model_name=embed_model,
        use_ocr=use_ocr,  # ä¼ é€’OCRé€‰é¡¹
        extract_metadata=extract_metadata,  # ä¼ é€’æ€§èƒ½é€‰é¡¹
        generate_summary=generate_summary,  # ä¼ é€’æ‘˜è¦é€‰é¡¹
        logger=logger
    )
    
    result = builder.build(
        source_path=current_target_path,
        force_reindex=force_reindex,
        action_mode=action_mode,
        status_callback=status_callback
    )
    
    if not result.success:
        status_container.update(label=f"âŒ å¤„ç†å¤±è´¥: {result.error}", state="error")
        logger.error(f"âŒ å¤„ç†å¤±è´¥: {result.error}")
        raise ValueError(result.error)
    
    # ä¿å­˜ç´¢å¼•
    if result.index:
        result.index.storage_context.persist(persist_dir=persist_dir)
        logger.success(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ°: {persist_dir}")
    
    # æ›´æ–°è¿›åº¦
    prog_bar.progress(100)
    
    # è®¡ç®—è€—æ—¶
    duration = time.time() - start_time
    logger.separator("å¤„ç†å®Œæˆ")
    logger.success(f"âœ… çŸ¥è¯†åº“ '{kb_name}' å¤„ç†å®Œæˆ")
    logger.info(f"ğŸ“Š ç»Ÿè®¡: {result.file_count} ä¸ªæ–‡ä»¶, {result.doc_count} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
    logger.info(f"â±ï¸  è€—æ—¶: {duration:.1f} ç§’")
    
    logger.log("SUCCESS", f"çŸ¥è¯†åº“å¤„ç†å®Œæˆ: {kb_name}, æ–‡æ¡£æ•°: {result.doc_count}", stage="çŸ¥è¯†åº“å¤„ç†")
    
    status_container.update(label=f"âœ… çŸ¥è¯†åº“ '{kb_name}' å¤„ç†å®Œæˆ", state="complete", expanded=True)
    
    # è·³è½¬åˆ°æ–°åˆ›å»ºçš„çŸ¥è¯†åº“
    jump_to_knowledge_base(kb_name, output_base)
    
    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯å¹¶è‡ªåŠ¨è·³è½¬
    st.success(f"ğŸ‰ çŸ¥è¯†åº“ '{kb_name}' åˆ›å»ºæˆåŠŸï¼æ­£åœ¨è·³è½¬...")
    st.rerun()
    
    # èµ„æºæ¸…ç†
    resource_guard.throttler.cleanup_memory()
    logger.info("ğŸ§¹ èµ„æºå·²æ¸…ç†")
    
    return result.doc_count

# ==========================================
# 6. èŠå¤©ç•Œé¢ & æ— é™è¿½é—®åŠŸèƒ½
# ==========================================
st.markdown("""
<div style="
    display: flex;
    align-items: center;
    gap: 10px;
    padding-bottom: 0px;
    margin-bottom: 0px;
    border-bottom: 2px solid #f0f2f6;
">
    <div style="font-size: 1.8rem;">ğŸ›¡ï¸</div>
    <div style="
        font-size: 1.5rem;
        font-weight: 600;
        color: #1f2937;
        letter-spacing: -0.5px;
    ">RAG Pro Max</div>
</div>
""", unsafe_allow_html=True)

# å¼•å…¥æ–°çš„ä¼˜åŒ–ç»„ä»¶
from src.utils.enhanced_ocr_optimizer import enhanced_ocr_optimizer
from src.ui.progress_monitor import progress_monitor

# æ˜¾ç¤ºå®æ—¶è¿›åº¦ç›‘æ§
progress_monitor.render_all_tasks()

# ç´§å‡‘ä¾§è¾¹æ CSSæ ·å¼
st.markdown("""
<style>
/* ä¾§è¾¹æ ç´§å‡‘åŒ– */
.css-1d391kg, [data-testid="stSidebar"] {
    padding-top: 0.5rem;
    padding-bottom: 0.5rem;
}

/* ç¡®ä¿ä¾§è¾¹æ æ”¶èµ·æŒ‰é’®å¯è§å’Œå¯ç”¨ */
[data-testid="collapsedControl"] {
    display: block !important;
    visibility: visible !important;
    opacity: 1 !important;
}

/* ä¾§è¾¹æ æ”¶èµ·çŠ¶æ€ */
[data-testid="stSidebar"][aria-expanded="false"] {
    width: 0 !important;
    min-width: 0 !important;
}

/* å‡å°‘æ ‡é¢˜é—´è· */
.css-1lcbmhc {
    margin-bottom: 0.25rem;
    margin-top: 0.25rem;
}

/* ç´§å‡‘æŒ‰é’® */
.stButton > button {
    height: 1.8rem;
    padding: 0.2rem 0.4rem;
    font-size: 11px;
    margin-bottom: 0.2rem;
}

/* ç´§å‡‘è¾“å…¥æ¡† */
.stTextInput > div > div > input {
    height: 1.8rem;
    font-size: 12px;
}

/* ç´§å‡‘é€‰æ‹©æ¡† */
.stSelectbox > div > div > div {
    height: 1.8rem;
    font-size: 12px;
}

/* å‡å°‘expanderé—´è· */
.streamlit-expanderHeader {
    padding: 0.25rem 0.5rem;
    font-size: 13px;
}

/* ç´§å‡‘æŒ‡æ ‡ */
.css-1xarl3l {
    padding: 0.25rem;
}
</style>
""", unsafe_allow_html=True)


# åˆå§‹åŒ–çŠ¶æ€
initialize_session_state()

# é¦–æ¬¡ä½¿ç”¨å¼•å¯¼
if not st.session_state.first_time_guide_shown and len(existing_kbs) == 0:
    st.info("""
    ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ RAG Pro Maxï¼
    
    **å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼š**
    
    1ï¸âƒ£ **é…ç½® LLM**ï¼ˆå·¦ä¾§è¾¹æ ï¼‰
    - é€‰æ‹© Ollamaï¼ˆæœ¬åœ°ï¼‰æˆ– OpenAIï¼ˆäº‘ç«¯ï¼‰
    - è¾“å…¥ API ä¿¡æ¯
    
    2ï¸âƒ£ **åˆ›å»ºçŸ¥è¯†åº“**
    - ç‚¹å‡» "â• æ–°å»ºçŸ¥è¯†åº“..."
    - è¾“å…¥åç§°ï¼Œä¸Šä¼ æ–‡æ¡£
    
    3ï¸âƒ£ **å¼€å§‹å¯¹è¯**
    - é€‰æ‹©çŸ¥è¯†åº“
    - åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜
    
    ğŸ’¡ **æç¤º**ï¼šæ”¯æŒ PDFã€DOCXã€TXTã€MD ç­‰å¤šç§æ ¼å¼
    """)
    
    if st.button("âœ… æˆ‘çŸ¥é“äº†ï¼Œå¼€å§‹ä½¿ç”¨", use_container_width=True):
        st.session_state.first_time_guide_shown = True
        st.rerun()

from src.common.business import click_btn

# è®¡ç®—å½“å‰çš„ KB ID (æ ¹æ®ä¾§è¾¹æ é€‰æ‹©)
selected_kbs = st.session_state.get('selected_kbs', [])
if len(selected_kbs) == 1:
    active_kb_name = selected_kbs[0]
elif len(selected_kbs) > 1:
    active_kb_name = "multi_kb_mode"  # å¤šçŸ¥è¯†åº“æ¨¡å¼æ ‡è¯†
else:
    active_kb_name = current_kb_name if not is_create_mode else None

# è‡ªåŠ¨åŠ è½½é€»è¾‘
if active_kb_name and active_kb_name != st.session_state.current_kb_id:
    # åªåœ¨æ²¡æœ‰æ­£åœ¨å¤„ç†çš„é—®é¢˜æ—¶æ‰åˆ‡æ¢
    if not st.session_state.get('is_processing', False):
        st.session_state.current_kb_id = active_kb_name
        st.session_state.chat_engine = None
        with st.spinner("ğŸ“œ æ­£åœ¨åŠ è½½å¯¹è¯å†å²..."):
            st.session_state.messages = HistoryManager.load_session(active_kb_name, st.session_state.get('current_session_id'))
        st.session_state.suggestions_history = []
    else:
        st.warning("âš ï¸ æ­£åœ¨å¤„ç†é—®é¢˜ï¼Œè¯·ç­‰å¾…å®Œæˆåå†åˆ‡æ¢çŸ¥è¯†åº“")
        st.session_state.current_nav = f"ğŸ“‚ {st.session_state.current_kb_id}"

# çŸ¥è¯†åº“åŠ è½½é€»è¾‘ - è·³è¿‡å¤šçŸ¥è¯†åº“æ¨¡å¼çš„å•ä¸€åŠ è½½
if active_kb_name and st.session_state.chat_engine is None and active_kb_name != "multi_kb_mode":
    from src.kb.kb_loader import KnowledgeBaseLoader
    
    kb_loader = KnowledgeBaseLoader(output_base)
    chat_engine, error_msg, kb_index = kb_loader.load_knowledge_base(
        active_kb_name, embed_provider, embed_model, embed_key, embed_url
    )
    
    if chat_engine:
        st.session_state.chat_engine = chat_engine
        st.session_state.kb_index_obj = kb_index
        logger.success("é—®ç­”å¼•æ“å·²å¯ç”¨GPUåŠ é€Ÿ")
        logger.log("SUCCESS", f"çŸ¥è¯†åº“åŠ è½½æˆåŠŸ: {active_kb_name}", stage="çŸ¥è¯†åº“åŠ è½½")
        st.toast(f"âœ… çŸ¥è¯†åº“ '{active_kb_name}' æŒ‚è½½æˆåŠŸï¼")
        cleanup_memory()
    else:
        st.error(error_msg) 

# æŒ‰é’®å¤„ç†
if btn_start:
    print(f"DEBUG: btn_start triggered")
    print(f"DEBUG: is_create_mode = {is_create_mode}")
    print(f"DEBUG: crawl_input_mode = {st.session_state.get('crawl_input_mode')}")
    print(f"DEBUG: crawl_url = {st.session_state.get('crawl_url')}")
    print(f"DEBUG: search_keyword = {st.session_state.get('search_keyword')}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç½‘é¡µæŠ“å–æ¨¡å¼ - è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
    crawl_url = st.session_state.get('crawl_url', '').strip()
    search_keyword = st.session_state.get('search_keyword', '').strip()
    
    # è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼ï¼šæœ‰ç½‘å€å°±æ˜¯ç½‘å€æ¨¡å¼ï¼Œæœ‰å…³é”®è¯å°±æ˜¯æœç´¢æ¨¡å¼
    auto_detected_mode = None
    if crawl_url:
        auto_detected_mode = 'url'
    elif search_keyword:
        auto_detected_mode = 'search'
    
    is_web_crawl_mode = (is_create_mode and auto_detected_mode is not None)
    
    print(f"DEBUG: auto_detected_mode = {auto_detected_mode}")
    print(f"DEBUG: is_web_crawl_mode = {is_web_crawl_mode}")
    
    if is_web_crawl_mode:
        print("DEBUG: è¿›å…¥ç½‘é¡µæŠ“å–æ¨¡å¼")
        current_mode = auto_detected_mode
        
        print(f"DEBUG: current_mode = {current_mode}")
        print(f"DEBUG: crawl_url = {crawl_url}")
        print(f"DEBUG: search_keyword = {search_keyword}")
        
        # è·å–æŠ“å–å‚æ•°
        crawl_depth = st.session_state.get('crawl_depth', 2)
        max_pages = st.session_state.get('max_pages', 5)
        parser_type = st.session_state.get('parser_type', 'default')
        url_quality_threshold = st.session_state.get('url_quality_threshold', 45.0)
        quality_threshold = st.session_state.get('quality_threshold', 45.0)
        
        # æ‰§è¡Œç½‘é¡µæŠ“å–å¹¶åˆ›å»ºçŸ¥è¯†åº“çš„é€»è¾‘
        if current_mode == 'url' and crawl_url:
            print(f"DEBUG: âœ… è¿›å…¥ç½‘å€æŠ“å–åˆ†æ”¯ï¼ŒURL = {crawl_url}")
            logger.log("ç½‘é¡µæŠ“å–", "start", f"ğŸŒ å¼€å§‹ç½‘å€æŠ“å–æ¨¡å¼: {crawl_url}")
            # ç½‘å€æŠ“å–æ¨¡å¼ - å¤ç”¨ç°æœ‰é€»è¾‘
            try:
                # ä¼˜å…ˆä½¿ç”¨å¼‚æ­¥çˆ¬è™«
                try:
                    from src.processors.enhanced_web_crawler import run_async_crawl
                    use_async = True
                    st.info("ğŸš€ ä½¿ç”¨å¼‚æ­¥å¹¶å‘çˆ¬è™« (æ€§èƒ½æå‡10å€+, æ”¯æŒæ–­ç‚¹ç»­ä¼ , robots.txtæ£€æŸ¥)")
                except ImportError:
                    from src.processors.web_crawler import WebCrawler
                    use_async = False
                    st.info("ğŸ“¡ ä½¿ç”¨æ ‡å‡†çˆ¬è™«")
                
                # ä½¿ç”¨å¸¦åŸŸåçš„å”¯ä¸€ç›®å½•
                from urllib.parse import urlparse
                from datetime import datetime
                
                try:
                    domain = urlparse(crawl_url).netloc.replace('.', '_').replace(':', '')
                    if not domain: domain = "unknown"
                except:
                    domain = "unknown"
                    
                timestamp_dir = datetime.now().strftime('%Y%m%d_%H%M%S')
                unique_output_dir = os.path.join("temp_uploads", f"Web_{domain}_{timestamp_dir}")
                
                # æ‰§è¡ŒæŠ“å–
                if use_async:
                    # å¼‚æ­¥çˆ¬è™«é…ç½®
                    max_concurrent = 15
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    crawled_count = [0]
                    
                    def update_status(msg):
                        status_text.text(msg)
                        logger.info(f"ğŸŒ ç½‘é¡µçˆ¬å–: {msg}")
                        if "å·²çˆ¬å–" in msg or "å·²ä¿å­˜" in msg:
                            crawled_count[0] += 1
                            progress = min(crawled_count[0] / max(max_pages, 1), 1.0)
                            progress_bar.progress(progress)
                    
                    logger.info(f"ğŸŒ å¼€å§‹ç½‘é¡µçˆ¬å–: {crawl_url} (æ·±åº¦:{crawl_depth}, é¡µæ•°:{max_pages})")
                    
                    with st.spinner("å¼‚æ­¥æŠ“å–ä¸­..."):
                        result = run_async_crawl(
                            start_url=crawl_url,
                            max_depth=crawl_depth,
                            max_pages=max_pages,
                            status_callback=update_status,
                            max_concurrent=max_concurrent,
                            ignore_robots=True,
                            output_dir=unique_output_dir
                        )
                        saved_files = result if isinstance(result, list) else []
                        async_output_dir = unique_output_dir
                else:
                    # åŒæ­¥çˆ¬è™«é€»è¾‘
                    crawler = WebCrawler(output_dir=unique_output_dir)
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    crawled_count = [0]
                    
                    def update_status(msg):
                        status_text.text(f"ğŸ“¡ {msg}")
                        logger.info(f"ğŸŒ ç½‘é¡µçˆ¬å–: {msg}")
                        if "å·²ä¿å­˜" in msg:
                            crawled_count[0] += 1
                            progress = min(crawled_count[0] / max_pages, 1.0)
                            progress_bar.progress(progress)
                    
                    logger.info(f"ğŸŒ å¼€å§‹ç½‘é¡µçˆ¬å–: {crawl_url} (æ·±åº¦:{crawl_depth}, é¡µæ•°:{max_pages})")
                    
                    with st.spinner("ç½‘é¡µæŠ“å–ä¸­..."):
                        saved_files = crawler.crawl_website(
                            start_url=crawl_url,
                            max_depth=crawl_depth,
                            max_pages=max_pages,
                            parser_type=parser_type,
                            status_callback=update_status,
                            quality_threshold=url_quality_threshold
                        )
                
                # æŠ“å–å®Œæˆåè‡ªåŠ¨åˆ›å»ºçŸ¥è¯†åº“
                if saved_files:
                    st.success(f"âœ… ç½‘é¡µæŠ“å–å®Œæˆï¼å…±ä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶")
                    
                    # è®¾ç½®æŠ“å–ç›®å½•ä¸ºæ•°æ®æº
                    target_path = unique_output_dir
                    
                    # è‡ªåŠ¨ç”ŸæˆçŸ¥è¯†åº“åç§°
                    kb_name = f"Web_{domain}_{timestamp_dir}"
                    
                    # ç»§ç»­æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»ºé€»è¾‘
                    st.info("ğŸš€ å¼€å§‹åˆ›å»ºçŸ¥è¯†åº“...")
                    
                    # è·å–é«˜çº§é€‰é¡¹çŠ¶æ€
                    current_use_ocr = st.session_state.get('kb_use_ocr', False)
                    current_extract_metadata = st.session_state.get('kb_extract_metadata', False)
                    current_generate_summary = st.session_state.get('kb_generate_summary', False)
                    current_force_reindex = st.session_state.get('kb_force_reindex', False)
                    
                    # æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»º - ä½¿ç”¨ç°æœ‰çš„kb_interfaceæ–¹æ³•
                    from src.kb.kb_interface import KBInterface
                    
                    kb_interface = KBInterface()
                    
                    # æ„å»ºé€‰é¡¹å­—å…¸
                    options = {
                        'use_ocr': current_use_ocr,
                        'extract_metadata': current_extract_metadata,
                        'generate_summary': current_generate_summary,
                        'force_reindex': current_force_reindex
                    }
                    
                    try:
                        logger.log("ç½‘é¡µæŠ“å–", "info", f"ğŸš€ å¼€å§‹åˆ›å»ºçŸ¥è¯†åº“: {kb_name}")
                        logger.log("ç½‘é¡µæŠ“å–", "info", f"ğŸ“ ç›®æ ‡è·¯å¾„: {target_path}")
                        logger.log("ç½‘é¡µæŠ“å–", "info", f"âš™ï¸ é€‰é¡¹: {options}")
                        
                        kb_interface.create_knowledge_base(target_path, kb_name, options)
                        
                        logger.log("ç½‘é¡µæŠ“å–", "success", f"âœ… çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ: {kb_name}")
                        st.success(f"ğŸ‰ çŸ¥è¯†åº“ '{kb_name}' åˆ›å»ºæˆåŠŸï¼")
                        
                        # è·³è½¬åˆ°æ–°åˆ›å»ºçš„çŸ¥è¯†åº“
                        logger.log("ç½‘é¡µæŠ“å–", "info", f"ğŸ“ ç½‘é¡µæŠ“å–æ¨¡å¼: å‡†å¤‡è°ƒç”¨è·³è½¬å‡½æ•°")
                        jump_to_knowledge_base(kb_name, output_base)
                        logger.log("ç½‘é¡µæŠ“å–", "info", f"ğŸ“ ç½‘é¡µæŠ“å–æ¨¡å¼: è·³è½¬å‡½æ•°è°ƒç”¨å®Œæˆ")
                        
                        # æ¸…ç†session_stateä¸­çš„ç½‘é¡µæŠ“å–å‚æ•°
                        for key in ['crawl_url', 'crawl_depth', 'max_pages', 'parser_type', 'url_quality_threshold']:
                            if key in st.session_state:
                                del st.session_state[key]
                        
                        # è®¾ç½®æ ‡è®°ï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œæ–‡ä»¶å¤„ç†é€»è¾‘
                        st.session_state.web_crawl_completed = True
                        
                        logger.log("ç½‘é¡µæŠ“å–", "info", f"ğŸ”„ ç½‘é¡µæŠ“å–æ¨¡å¼: æ‰§è¡Œé¡µé¢åˆ·æ–°")
                        st.rerun()
                        
                    except Exception as e:
                        logger.log("ç½‘é¡µæŠ“å–", "error", f"âŒ çŸ¥è¯†åº“åˆ›å»ºå¼‚å¸¸: {str(e)}")
                        logger.log("ç½‘é¡µæŠ“å–", "error", f"ğŸ” å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                        st.error(f"âŒ çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {str(e)}")
                        logger.error(f"çŸ¥è¯†åº“åˆ›å»ºé”™è¯¯: {str(e)}")
                    
                else:
                    st.error("âŒ ç½‘é¡µæŠ“å–å¤±è´¥ï¼Œæœªè·å–åˆ°ä»»ä½•æ–‡ä»¶")
                    # åªæœ‰å¤±è´¥æ—¶æ‰åœæ­¢æ‰§è¡Œ
                    st.stop()
                    
            except Exception as e:
                st.error(f"âŒ ç½‘é¡µæŠ“å–å¤±è´¥: {str(e)}")
                logger.error(f"ç½‘é¡µæŠ“å–é”™è¯¯: {str(e)}")
                st.stop()
                
        elif current_mode == 'search' and search_keyword:
            print(f"DEBUG: âœ… è¿›å…¥æ™ºèƒ½æœç´¢åˆ†æ”¯ï¼Œå…³é”®è¯ = {search_keyword}")
            logger.log("æ™ºèƒ½æœç´¢", "start", f"ğŸ” å¼€å§‹æ™ºèƒ½æœç´¢æ¨¡å¼: {search_keyword}")
            # æ™ºèƒ½æœç´¢æ¨¡å¼ - å¤ç”¨ç°æœ‰é€»è¾‘
            try:
                # è·å–æœç´¢å‚æ•°
                crawl_depth = st.session_state.get('search_crawl_depth', 2)
                max_pages = st.session_state.get('search_max_pages', 5)
                parser_type = st.session_state.get('search_parser_type', 'default')
                quality_threshold = st.session_state.get('quality_threshold', 45.0)
                
                st.info(f"ğŸ” å¼€å§‹æ™ºèƒ½æœç´¢: {search_keyword}")
                
                # æ ¹æ®å…³é”®è¯æ™ºèƒ½é€‰æ‹©æœç´¢å¼•æ“
                def get_smart_search_engines(keyword):
                    """æ ¹æ®å…³é”®è¯æ™ºèƒ½é€‰æ‹©æœç´¢å¼•æ“"""
                    keyword_lower = keyword.lower()
                    
                    # åŒ»å­¦å…³é”®è¯
                    medical_keywords = [
                        'cancer', 'disease', 'medicine', 'health', 'treatment', 'diagnosis',
                        'ç™Œç—‡', 'ç–¾ç—…', 'åŒ»å­¦', 'å¥åº·', 'æ²»ç–—', 'è¯Šæ–­', 'è¯ç‰©', 'ç—‡çŠ¶', 'ç—…ç†',
                        'åµå·¢ç™Œ', 'è‚ºç™Œ', 'èƒƒç™Œ', 'è‚ç™Œ', 'ä¹³è…ºç™Œ', 'åŒ»é™¢', 'åŒ»ç”Ÿ', 'æ‰‹æœ¯'
                    ]
                    
                    # æŠ€æœ¯å…³é”®è¯
                    tech_keywords = [
                        'python', 'java', 'javascript', 'programming', 'coding', 'algorithm',
                        'ç¼–ç¨‹', 'ä»£ç ', 'ç®—æ³•', 'å¼€å‘', 'è½¯ä»¶', 'æŠ€æœ¯'
                    ]
                    
                    is_medical = any(med_word in keyword_lower for med_word in medical_keywords)
                    is_tech = any(tech_word in keyword_lower for tech_word in tech_keywords)
                    
                    if is_medical:
                        return [
                            "https://zh.wikipedia.org/",
                            "https://baike.baidu.com/",
                            "https://www.39.net/",
                            "https://www.xywy.com/",
                            "https://www.familydoctor.com.cn/"
                        ]
                    elif is_tech:
                        return [
                            "https://www.runoob.com/",
                            "https://docs.python.org/zh-cn/3/",
                            "https://help.aliyun.com/",
                            "https://zh.wikipedia.org/",
                            "https://www.zhihu.com/"
                        ]
                    else:
                        return [
                            "https://zh.wikipedia.org/",
                            "https://baike.baidu.com/",
                            "https://www.zhihu.com/",
                            "https://www.icourse163.org/",
                            "https://www.eastmoney.com/"
                        ]
                
                search_engines = get_smart_search_engines(search_keyword)
                
                # ç”Ÿæˆå”¯ä¸€è¾“å‡ºç›®å½•
                from datetime import datetime
                timestamp_dir = datetime.now().strftime('%Y%m%d_%H%M%S')
                unique_output_dir = os.path.join("temp_uploads", f"Search_{search_keyword.replace(' ', '_')}_{timestamp_dir}")
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_status(msg):
                    status_text.text(f"ğŸ” {msg}")
                    logger.info(f"ğŸ” æ™ºèƒ½æœç´¢: {msg}")
                
                logger.info(f"ğŸ” å¼€å§‹æ™ºèƒ½æœç´¢: {search_keyword} (æ·±åº¦:{crawl_depth}, é¡µæ•°:{max_pages})")
                
                with st.spinner("æ™ºèƒ½æœç´¢ä¸­..."):
                    # ä½¿ç”¨ç°æœ‰çš„å¹¶å‘çˆ¬è™«
                    from src.processors.concurrent_crawler import ConcurrentCrawler
                    from src.processors.content_analyzer import ContentQualityAnalyzer
                    
                    concurrent_crawler = ConcurrentCrawler(max_workers=3)
                    content_analyzer = ContentQualityAnalyzer()
                    
                    def enhanced_progress_callback(message, progress=None):
                        update_status(message)
                        if progress is not None:
                            progress_bar.progress(progress)
                    
                    # æ‰§è¡Œå¹¶å‘çˆ¬å–
                    crawl_results = concurrent_crawler.crawl_with_depth(
                        search_engines,
                        max_depth=crawl_depth,
                        max_pages_per_level=max_pages,
                        progress_callback=enhanced_progress_callback
                    )
                    
                    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                    saved_files = []
                    if crawl_results:
                        import os
                        os.makedirs(unique_output_dir, exist_ok=True)
                        
                        for i, result in enumerate(crawl_results):
                            if result['success'] and result['content']:
                                # ä½¿ç”¨ç½‘é¡µæ ‡é¢˜ä½œä¸ºæ–‡ä»¶åï¼Œå¦‚æœæ²¡æœ‰æ ‡é¢˜åˆ™ä½¿ç”¨é»˜è®¤åç§°
                                title = result.get('title', '').strip()
                                if title:
                                    # æ¸…ç†æ ‡é¢˜ï¼Œç§»é™¤ä¸åˆæ³•çš„æ–‡ä»¶åå­—ç¬¦
                                    safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).strip()
                                    safe_title = safe_title.replace(' ', '_')[:50]  # é™åˆ¶é•¿åº¦
                                    filename = f"{safe_title}_{i+1:03d}.txt"
                                else:
                                    filename = f"quality_content_{i+1:03d}.txt"
                                
                                filepath = os.path.join(unique_output_dir, filename)
                                
                                # ç¡®ä¿å¯¼å…¥ (é˜²æ­¢å¤šè¿›ç¨‹æˆ–åŠ¨æ€åŠ è½½å¯¼è‡´çš„ NameError)
                                from src.utils.file_system_utils import set_where_from_metadata
                                
                                with open(filepath, 'w', encoding='utf-8') as f:
                                    # ğŸ”¥ æ ¸å¿ƒä¿®æ­£ï¼šæ·»åŠ æ ‡å‡† URL: å¤´ï¼Œä»¥ä¾¿æº¯æºå¼•æ“è¯†åˆ«
                                    f.write(f"URL: {result['url']}\n")
                                    f.write(f"æ ‡é¢˜: {result['title']}\n")
                                    f.write(f"å†…å®¹:\n{result['content']}\n")
                                
                                # ä¸ºæ–‡ä»¶è®¾ç½® macOS ä¸‹è½½æ¥æºå…ƒæ•°æ®
                                set_where_from_metadata(filepath, result['url'])
                                
                                saved_files.append(filepath)
                
                # æœç´¢å®Œæˆåè‡ªåŠ¨åˆ›å»ºçŸ¥è¯†åº“
                if saved_files:
                    st.success(f"âœ… æ™ºèƒ½æœç´¢å®Œæˆï¼å…±ä¿å­˜ {len(saved_files)} ä¸ªæ–‡ä»¶")
                    
                    # è®¾ç½®æœç´¢ç›®å½•ä¸ºæ•°æ®æº
                    target_path = unique_output_dir
                    
                    # è‡ªåŠ¨ç”ŸæˆçŸ¥è¯†åº“åç§°
                    kb_name = f"Search_{search_keyword.replace(' ', '_')}_{timestamp_dir}"
                    
                    # ç»§ç»­æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»ºé€»è¾‘
                    st.info("ğŸš€ å¼€å§‹åˆ›å»ºçŸ¥è¯†åº“...")
                    
                    # è·å–é«˜çº§é€‰é¡¹çŠ¶æ€
                    current_use_ocr = st.session_state.get('kb_use_ocr', False)
                    current_extract_metadata = st.session_state.get('kb_extract_metadata', False)
                    current_generate_summary = st.session_state.get('kb_generate_summary', False)
                    current_force_reindex = st.session_state.get('kb_force_reindex', False)
                    
                    # æ‰§è¡ŒçŸ¥è¯†åº“åˆ›å»º - ä½¿ç”¨ç°æœ‰çš„kb_interfaceæ–¹æ³•
                    from src.kb.kb_interface import KBInterface
                    
                    kb_interface = KBInterface()
                    
                    # æ„å»ºé€‰é¡¹å­—å…¸
                    options = {
                        'use_ocr': current_use_ocr,
                        'extract_metadata': current_extract_metadata,
                        'generate_summary': current_generate_summary,
                        'force_reindex': current_force_reindex
                    }
                    
                    try:
                        kb_interface.create_knowledge_base(target_path, kb_name, options)
                        st.success(f"ğŸ‰ çŸ¥è¯†åº“ '{kb_name}' åˆ›å»ºæˆåŠŸï¼")
                        
                        # è·³è½¬åˆ°æ–°åˆ›å»ºçš„çŸ¥è¯†åº“
                        logger.log("æ™ºèƒ½æœç´¢", "info", f"ğŸ“ æ™ºèƒ½æœç´¢æ¨¡å¼: å‡†å¤‡è°ƒç”¨è·³è½¬å‡½æ•°")
                        jump_to_knowledge_base(kb_name, output_base)
                        logger.log("æ™ºèƒ½æœç´¢", "info", f"ğŸ“ æ™ºèƒ½æœç´¢æ¨¡å¼: è·³è½¬å‡½æ•°è°ƒç”¨å®Œæˆ")
                        
                        # æ¸…ç†session_stateä¸­çš„æœç´¢å‚æ•°
                        for key in ['search_keyword', 'search_crawl_depth', 'search_max_pages', 'search_parser_type', 'quality_threshold']:
                            if key in st.session_state:
                                del st.session_state[key]
                        
                        # è®¾ç½®æ ‡è®°ï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œæ–‡ä»¶å¤„ç†é€»è¾‘
                        st.session_state.smart_search_completed = True
                        
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"âŒ çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {str(e)}")
                        logger.error(f"çŸ¥è¯†åº“åˆ›å»ºé”™è¯¯: {str(e)}")
                        
                else:
                    st.error("âŒ æ™ºèƒ½æœç´¢å¤±è´¥ï¼Œæœªè·å–åˆ°ä»»ä½•æ–‡ä»¶")
                    # åªæœ‰å¤±è´¥æ—¶æ‰åœæ­¢æ‰§è¡Œ
                    st.stop()
                    
            except Exception as e:
                st.error(f"âŒ æ™ºèƒ½æœç´¢å¤±è´¥: {str(e)}")
                logger.error(f"æ™ºèƒ½æœç´¢é”™è¯¯: {str(e)}")
                st.stop()
        else:
            print(f"DEBUG: âŒ æœªåŒ¹é…ä»»ä½•ç½‘é¡µæŠ“å–åˆ†æ”¯")
            print(f"DEBUG: current_mode = '{current_mode}', crawl_url = '{crawl_url}', search_keyword = '{search_keyword}'")
            logger.log("ç½‘é¡µæŠ“å–", "warning", f"âš ï¸ æœªåŒ¹é…ç½‘é¡µæŠ“å–æ¡ä»¶: mode={current_mode}, url={bool(crawl_url)}, keyword={bool(search_keyword)}")
    
    print("DEBUG: è·³è¿‡ç½‘é¡µæŠ“å–æ¨¡å¼ï¼Œè¿›å…¥åŸæœ‰æ–‡ä»¶å¤„ç†é€»è¾‘")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»å®Œæˆäº†ç½‘é¡µæŠ“å–æˆ–æ™ºèƒ½æœç´¢ï¼Œé¿å…é‡å¤å¤„ç†
    if st.session_state.get('web_crawl_completed') or st.session_state.get('smart_search_completed'):
        logger.log("æ–‡ä»¶å¤„ç†", "info", "ğŸ”„ æ£€æµ‹åˆ°ç½‘é¡µæŠ“å–/æ™ºèƒ½æœç´¢å·²å®Œæˆï¼Œè·³è¿‡æ–‡ä»¶å¤„ç†é€»è¾‘")
        # æ¸…ç†æ ‡è®°
        st.session_state.pop('web_crawl_completed', None)
        st.session_state.pop('smart_search_completed', None)
        st.stop()
    
    # åŸæœ‰çš„æ–‡ä»¶å¤„ç†é€»è¾‘
    # ç¡®ä¿ action_mode å·²å®šä¹‰ (é˜²æ­¢ NameError)
    if 'action_mode' not in locals() and 'action_mode' not in globals():
        action_mode = "NEW" if is_create_mode else "APPEND"

    # æ˜¾å¼è·å–é«˜çº§é€‰é¡¹çŠ¶æ€ (ä¼˜å…ˆä» session_state è·å–)
    current_use_ocr = st.session_state.get('kb_use_ocr', False)
    current_extract_metadata = st.session_state.get('kb_extract_metadata', False)
    current_generate_summary = st.session_state.get('kb_generate_summary', False)
    current_force_reindex = st.session_state.get('kb_force_reindex', False)

    # ä¼˜åŒ–é…ç½®ä¿å­˜é€»è¾‘ï¼šè¯»å–-åˆå¹¶-ä¿å­˜
    existing_config = ConfigLoader.load()
    
    config_update = {
        "target_path": target_path,
        "output_path": output_base,
        "llm_provider": llm_provider, # ä¿å­˜ä¾›åº”å•†ç±»å‹
        "embed_provider_idx": ["HuggingFace (æœ¬åœ°/æé€Ÿ)", "OpenAI-Compatible", "Ollama"].index(embed_provider),
        "embed_model_hf": embed_model if embed_provider.startswith("HuggingFace") else "",
        "embed_url_ollama": embed_url if embed_provider.startswith("Ollama") else "",
        "embed_model_ollama": embed_model if embed_provider.startswith("Ollama") else ""
    }
    
    # æ ¹æ®ä¾›åº”å•†ç±»å‹ä¿å­˜å¯¹åº”å­—æ®µ
    if llm_provider == "OpenAI-Compatible":
        config_update["llm_url_other"] = llm_url
        config_update["llm_key_other"] = llm_key
        config_update["llm_model_other"] = llm_model
        # åŒæ—¶ä¹Ÿä¿å­˜é€šç”¨å­—æ®µä»¥ä¾¿å…¼å®¹
        config_update["llm_url"] = llm_url
        config_update["llm_key"] = llm_key
        config_update["llm_model"] = llm_model
        
    elif llm_provider == "OpenAI":
        config_update["llm_url_openai"] = llm_url
        config_update["llm_key"] = llm_key
        config_update["llm_model_openai"] = llm_model
        
    elif llm_provider == "Ollama":
        config_update["llm_url_ollama"] = llm_url
        config_update["llm_model_ollama"] = llm_model
    
    existing_config.update(config_update)
    ConfigLoader.save(existing_config)

    # Ensure final_kb_name is defined (crucial for APPEND mode where sidebar logic might differ)
    if 'final_kb_name' not in locals():
        if is_create_mode:
            final_kb_name = st.session_state.get('new_kb_name', '') # Try session state or empty
        else:
            final_kb_name = current_kb_name

    if not final_kb_name:
        st.error("è¯·è¾“å…¥çŸ¥è¯†åº“åç§°")
    else:
        try:
            # ä½¿ç”¨ä¼˜åŒ–å™¨ç”Ÿæˆå”¯ä¸€åç§°ï¼Œé¿å…é‡å¤å’Œæ—¶é—´æˆ³å†²çª
            # Only optimize name in NEW mode to avoid renaming existing KBs in APPEND mode
            if is_create_mode:
                optimized_name = KBNameOptimizer.generate_unique_name(final_kb_name, output_base)
                
                if not optimized_name: 
                    raise ValueError("çŸ¥è¯†åº“åç§°åŒ…å«éæ³•å­—ç¬¦æˆ–ä¸ºç©º")
                
                # å¦‚æœåç§°è¢«ä¼˜åŒ–äº†ï¼Œæç¤ºç”¨æˆ·
                if optimized_name != final_kb_name:
                    st.info(f"ğŸ’¡ åç§°å·²ä¼˜åŒ–: `{final_kb_name}` â†’ `{optimized_name}`")
                    
                # ä½¿ç”¨ä¼˜åŒ–åçš„åç§°
                final_kb_name = optimized_name
            
            # DEBUG: Check parameters
            print(f"DEBUG: Calling process_knowledge_base_logic with: kb={final_kb_name}, ocr={current_use_ocr}, meta={current_extract_metadata}, summary={current_generate_summary}")
            print(f"DEBUG: st.session_state.uploaded_path = {st.session_state.get('uploaded_path')}")
            print(f"DEBUG: uploaded_files present? = {bool(uploaded_files) if 'uploaded_files' in locals() else 'Not in locals'}")

            process_knowledge_base_logic(
                kb_name=final_kb_name,
                action_mode=action_mode,
                use_ocr=current_use_ocr,
                extract_metadata=current_extract_metadata,
                generate_summary=current_generate_summary,
                force_reindex=current_force_reindex
            )
            # st.session_state.current_nav ç­‰è·³è½¬é€»è¾‘å·²ç§»è‡³ process_knowledge_base_logic å†…éƒ¨çš„ jump_to_knowledge_base
            
            if action_mode == "NEW" or action_mode == "APPEND":
                st.session_state.messages = []
                st.session_state.suggestions_history = []
                hist_path = os.path.join(HISTORY_DIR, f"{final_kb_name}.json")
                if os.path.exists(hist_path): os.remove(hist_path)
            
            time.sleep(1); st.rerun()
        except Exception as e:
            st.error(f"æ‰§è¡Œå¤±è´¥: {e}")

# --- ä¸»è§†å›¾æ¸²æŸ“ ---
if active_kb_name == "multi_kb_mode":
    # å¤šçŸ¥è¯†åº“æ¨¡å¼ - æ˜¾ç¤ºç®€æ´çš„è”åˆæŸ¥è¯¢ç•Œé¢
    selected_kbs = st.session_state.get('selected_kbs', [])
    st.markdown(f"### ğŸ” å¤šçŸ¥è¯†åº“è”åˆæŸ¥è¯¢")
    st.info(f"å·²é€‰æ‹© {len(selected_kbs)} ä¸ªçŸ¥è¯†åº“: {', '.join(selected_kbs)}")
    st.markdown("ğŸ’¡ **ä½¿ç”¨è¯´æ˜**: ç›´æ¥åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä»æ‰€æœ‰é€‰ä¸­çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶æä¾›ç­”æ¡ˆã€‚")
    
elif active_kb_name:
    from src.documents.document_manager import DocumentManager
    
    db_path = os.path.join(output_base, active_kb_name)
    doc_manager = DocumentManager(db_path)
    stats = doc_manager.get_kb_statistics()

    # --- æ‰¹é‡æ“ä½œå¤„ç†é€»è¾‘ ---
    if st.session_state.get('trigger_batch_summary'):
        st.session_state.trigger_batch_summary = False
        run_summary = True # è§¦å‘ä¸‹æ–¹çš„æ‘˜è¦é€»è¾‘
    else:
        run_summary = False

    if st.session_state.get('trigger_batch_delete'):
        st.session_state.trigger_batch_delete = False
        selected_files = st.session_state.get('selected_for_summary', set())
        if selected_files:
            with st.status(f"æ­£åœ¨æ‰¹é‡åˆ é™¤ {len(selected_files)} ä¸ªæ–‡ä»¶...", expanded=True) as status:
                try:
                    from llama_index.core import StorageContext, load_index_from_storage
                    ctx = StorageContext.from_defaults(persist_dir=db_path)
                    idx = load_index_from_storage(ctx)
                    
                    for fname in selected_files:
                        file_info = next((f for f in doc_manager.manifest['files'] if f['name'] == fname), None)
                        if file_info:
                            for did in file_info.get('doc_ids', []):
                                try:
                                    idx.delete_ref_doc(did, delete_from_docstore=True)
                                except: pass
                    
                    idx.storage_context.persist(persist_dir=db_path)
                    
                    # æ›´æ–° manifest
                    doc_manager.manifest['files'] = [f for f in doc_manager.manifest['files'] if f['name'] not in selected_files]
                    with open(ManifestManager.get_path(db_path), 'w', encoding='utf-8') as mf:
                        json.dump(doc_manager.manifest, mf, indent=4, ensure_ascii=False)
                    
                    status.update(label="âœ… æ‰¹é‡åˆ é™¤æˆåŠŸ", state="complete")
                    st.session_state.selected_for_summary = set()
                    st.session_state.chat_engine = None
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"æ‰¹é‡åˆ é™¤å¤±è´¥: {e}")
    
    # é‡å‘½åé€»è¾‘å’Œç»Ÿè®¡æ˜¾ç¤º
    if st.session_state.renaming:
        def apply_rename():
            n = sanitize_filename(st.session_state.new_name_input)
            if n and n != active_kb_name:
                try:
                    kb_manager.base_path = output_base
                    success, msg = kb_manager.rename(active_kb_name, n)
                    if success:
                        st.session_state.current_nav = f"ğŸ“‚ {n}"
                        st.toast("âœ… é‡å‘½åæˆåŠŸ")
                    else:
                        st.error(f"é‡å‘½åå¤±è´¥: {msg}")
                except FileExistsError as e:
                    st.error(f"é‡å‘½åå¤±è´¥: {e}")
            st.session_state.renaming = False
        c1, c2 = st.columns([3, 1])
        c1.text_input("æ–°åç§°", value=active_kb_name, key="new_name_input", on_change=apply_rename)
        c2.button("å–æ¶ˆ", on_click=lambda: st.session_state.update({"renaming": False}))
    else:
        rename_col = doc_manager.render_statistics_overview(active_kb_name, stats)
        if rename_col.button("âœï¸", help="é‡å‘½å"): 
            st.session_state.renaming = True
    
    # æ–‡ä»¶ç®¡ç†
    with st.container(key="kb_details_container"):
        with st.expander("ğŸ“Š çŸ¥è¯†åº“è¯¦æƒ…ä¸ç®¡ç†", expanded=False):
            if not doc_manager.manifest['files']: 
                st.info("æš‚æ— æ–‡ä»¶")
            else:
                # ğŸ”§ é«˜çº§é€‰é¡¹å¤„ç†ç»Ÿè®¡
                total_files = len(doc_manager.manifest['files'])
                ocr_files = sum(1 for f in doc_manager.manifest['files'] if f.get('used_ocr', False))
                metadata_files = sum(1 for f in doc_manager.manifest['files'] if f.get('keywords') or f.get('category'))
                summary_files = sum(1 for f in doc_manager.manifest['files'] if f.get('summary'))
                total_chunks = sum(len(f.get('doc_ids', [])) for f in doc_manager.manifest['files'])
                storage_size = KBManager.format_size(stats.get('size', 0)) if stats else "æœªçŸ¥"
                
                # åªæœ‰å½“æœ‰é«˜çº§æ•°æ®æ—¶æ‰å±•å¼€
                has_advanced_data = (ocr_files + metadata_files + summary_files) > 0
                
                with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹å¤„ç†ç»Ÿè®¡", expanded=has_advanced_data):
                    # ä¼˜åŒ–ä¸ºå•è¡Œ 6 åˆ—å¸ƒå±€
                    adv_cols = st.columns(6)
                    
                    with adv_cols[0]:
                        st.metric("ğŸ“„ æ€»æ–‡æ¡£", total_files)
                    with adv_cols[1]:
                        st.metric("ğŸ§© æ€»ç‰‡æ®µ", total_chunks)
                        
                    with adv_cols[2]:
                        ocr_percentage = (ocr_files / total_files * 100) if total_files > 0 else 0
                        st.metric("ğŸ” OCRå¤„ç†", f"{ocr_files}", delta=f"{ocr_percentage:.1f}%")
                    with adv_cols[3]:
                        metadata_percentage = (metadata_files / total_files * 100) if total_files > 0 else 0
                        st.metric("ğŸ“Š å…ƒæ•°æ®æå–", f"{metadata_files}", delta=f"{metadata_percentage:.1f}%")
                        
                    with adv_cols[4]:
                        summary_percentage = (summary_files / total_files * 100) if total_files > 0 else 0
                        st.metric("ğŸ“ ç”Ÿæˆæ‘˜è¦", f"{summary_files}", delta=f"{summary_percentage:.1f}%")
                    with adv_cols[5]:
                        st.metric("ğŸ’¾ å­˜å‚¨å ç”¨", storage_size)
                    
                    # å¤„ç†å»ºè®®
                    if not has_advanced_data:
                        st.caption("ğŸ’¡ **æç¤º**: åœ¨ä¸Šä¼ æ–‡æ¡£æ—¶å¯ç”¨é«˜çº§é€‰é¡¹ï¼Œå¯ä»¥è·å¾—æ›´ä¸°å¯Œçš„æ–‡æ¡£ä¿¡æ¯å’Œæ›´å¥½çš„æ£€ç´¢æ•ˆæœ")
                    elif ocr_files < total_files // 2:
                        st.caption("ğŸ’¡ **å»ºè®®**: å¯¹äºåŒ…å«å›¾ç‰‡æˆ–æ‰«æå†…å®¹çš„PDFæ–‡æ¡£ï¼Œå»ºè®®å¯ç”¨OCRè¯†åˆ«åŠŸèƒ½")
                
                st.divider()
                
                # æ–‡æ¡£åˆ—è¡¨æŸ¥çœ‹ä¸ç»Ÿè®¡
                # tab1, tab2 = st.tabs(["ğŸ“Š ç»Ÿè®¡ä¿¡æ¯", "ğŸ“„ æ–‡æ¡£åˆ—è¡¨"])
                
                if True: # ç»Ÿè®¡ä¿¡æ¯
                    # è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
                    quality_info = doc_manager.render_detailed_statistics(stats)
                    st.divider()
                    
                    # åˆ†å¸ƒåˆ†æ
                    doc_manager.render_distribution_analysis(stats)
                    st.divider()
                    
                    # å…ƒæ•°æ®ç»Ÿè®¡
                    try:
                        metadata_mgr = MetadataManager(db_path)
                        if metadata_mgr.metadata or metadata_mgr.stats:
                            with st.expander("ğŸ“Š å…ƒæ•°æ®ç»Ÿè®¡", expanded=True):
                                stat_col1, stat_col2, stat_col3 = st.columns(3)
                                
                                with stat_col1:
                                    st.markdown("**ğŸ”¥ çƒ­é—¨æ–‡ä»¶ Top 5**")
                                    hot_files = metadata_mgr.get_hot_files(top_k=5)
                                    if hot_files:
                                        for i, (fname, count) in enumerate(hot_files, 1):
                                            st.caption(f"{i}. {fname[:20]}... ({count})")
                                    else:
                                        st.caption("æš‚æ— æ•°æ®")
                                
                                with stat_col2:
                                    st.markdown("**ğŸ“‚ æ–‡æ¡£åˆ†ç±»**")
                                    categories = metadata_mgr.get_all_categories()
                                    if categories:
                                        for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:5]:
                                            st.caption(f"{cat}: {count}")
                                    else:
                                        st.caption("æš‚æ— æ•°æ®")
                                
                                with stat_col3:
                                    st.markdown("**ğŸ·ï¸ çƒ­é—¨å…³é”®è¯**")
                                    keywords = metadata_mgr.get_all_keywords(top_k=8)
                                    if keywords:
                                        kw_text = " Â· ".join([f"{kw}({cnt})" for kw, cnt in keywords[:8]])
                                        st.caption(kw_text)
                                    else:
                                        st.caption("æš‚æ— æ•°æ®")
                                
                                # é‡å¤æ–‡ä»¶æ£€æµ‹
                                duplicates = metadata_mgr.find_duplicates()
                                if duplicates:
                                    st.divider()
                                    st.markdown(f"**âš ï¸ å‘ç° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶**")
                                    for i, (file_hash, files) in enumerate(list(duplicates.items())[:2], 1):
                                        st.caption(f"ç»„{i}: {', '.join([f[:15] for f in files[:3]])}...")
                    except:
                        pass  # å¦‚æœå…ƒæ•°æ®ä¸å­˜åœ¨ï¼Œé™é»˜è·³è¿‡
            
            st.divider()
            
            # å¿«é€Ÿæ“ä½œåŒº
            st.markdown("**âš¡ å¿«é€Ÿæ“ä½œ**")
            
            # å¿«é€Ÿæ“ä½œæŒ‰é’®ç»„ - åˆå¹¶ä¸ºå•è¡Œ
            op_col1, op_col2, op_col3, op_col4 = st.columns(4)
            
            # 1. æ‰“å¼€çŸ¥è¯†åº“ç›®å½•
            with op_col1:
                if st.button("ğŸ“‚ æ‰“å¼€ç›®å½•", use_container_width=True, help="åœ¨Finderä¸­æ‰“å¼€çŸ¥è¯†åº“æ–‡ä»¶å¤¹"):
                    import webbrowser
                    import urllib.parse
                    try:
                        file_url = 'file://' + urllib.parse.quote(os.path.abspath(db_path))
                        webbrowser.open(file_url)
                        st.toast("âœ… å·²åœ¨Finderä¸­æ‰“å¼€")
                    except Exception as e:
                        st.error(f"æ‰“å¼€å¤±è´¥: {e}")
            
            # 2. å¤åˆ¶è·¯å¾„
            with op_col2:
                if st.button("ğŸ“‹ å¤åˆ¶è·¯å¾„", use_container_width=True, help="å¤åˆ¶çŸ¥è¯†åº“è·¯å¾„åˆ°å‰ªè´´æ¿"):
                    try:
                        import subprocess
                        subprocess.run(["pbcopy"], input=db_path.encode(), check=True)
                        st.toast(f"âœ… å·²å¤åˆ¶")
                    except Exception as e:
                        st.info(f"ğŸ“ è·¯å¾„: {db_path}")
            
            # å‡†å¤‡æ‘˜è¦æ•°æ®
            files_without_summary = [f for f in doc_manager.manifest['files'] if not f.get('summary') and f.get('doc_ids')]
            if 'selected_for_summary' not in st.session_state:
                st.session_state.selected_for_summary = set()
            selected_count = len(st.session_state.selected_for_summary)
            
            # 3. ç”Ÿæˆæ‘˜è¦
            with op_col3:
                # å§‹ç»ˆæ˜¾ç¤ºæŒ‰é’®ï¼Œä½†æ ¹æ®é€‰ä¸­æ•°é‡å†³å®šæ˜¯å¦ç¦ç”¨
                button_label = f"âœ¨ æ‘˜è¦ ({selected_count})" if selected_count > 0 else "âœ¨ ç”Ÿæˆæ‘˜è¦"
                button_disabled = selected_count == 0
                
                if st.button(button_label, use_container_width=True, type="primary", disabled=button_disabled, help="ä¸ºé€‰ä¸­çš„æ–‡ä»¶ç”ŸæˆAIæ‘˜è¦"):
                    run_summary = True

            # 4. å¯¼å‡ºæ¸…å•
            with op_col4:
                if st.button("ğŸ“¥ å¯¼å‡ºæ¸…å•", use_container_width=True, help="å¯¼å‡ºå½“å‰æ–‡ä»¶åˆ—è¡¨"):
                    export_data = f"çŸ¥è¯†åº“: {active_kb_name}\næ–‡ä»¶æ•°: {stats['file_cnt']}\nç‰‡æ®µæ•°: {stats['total_chunks']}\n\næ–‡ä»¶åˆ—è¡¨:\n"
                    for f in doc_manager.manifest['files']:
                        export_data += f"- {f['name']} ({f['type']}, {len(f.get('doc_ids', []))} ç‰‡æ®µ)\n"
                    st.download_button("ä¸‹è½½", export_data, f"{active_kb_name}_æ¸…å•.txt", use_container_width=True)

            # æ‰§è¡Œæ‘˜è¦ç”Ÿæˆé€»è¾‘
            if run_summary and files_without_summary:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                from llama_index.core import StorageContext, load_index_from_storage as load_idx
                storage_context = StorageContext.from_defaults(persist_dir=db_path)
                idx = load_idx(storage_context)
                retriever = idx.as_retriever(similarity_top_k=3)
                
                success_count = 0
                for i, fname in enumerate(st.session_state.selected_for_summary):
                    status_text.text(f"æ­£åœ¨å¤„ç†: {fname} ({i+1}/{selected_count})")
                    try:
                        file_info = next((f for f in doc_manager.manifest['files'] if f['name'] == fname), None)
                        if file_info and file_info.get('doc_ids'):
                            # ä½¿ç”¨æ£€ç´¢å™¨è·å–æ–‡æ¡£å†…å®¹
                            nodes = retriever.retrieve(fname)
                            
                            doc_text = ""
                            for node in nodes:
                                if hasattr(node, 'node') and hasattr(node.node, 'text'):
                                    doc_text += node.node.text + "\n"
                                elif hasattr(node, 'text'):
                                    doc_text += node.text + "\n"
                                if len(doc_text) > 2000:
                                    break
                            
                            if doc_text.strip():
                                summary = generate_doc_summary(doc_text, fname)
                                if summary:
                                    file_info['summary'] = summary
                                    
                                    # å°†æ‘˜è¦æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
                                    try:
                                        from llama_index.core import Document
                                        summary_doc = Document(
                                            text=f"æ–‡æ¡£æ‘˜è¦ - {fname}:\n{summary}",
                                            metadata={
                                                "file_name": fname,
                                                "file_type": "summary",
                                                "source_file": fname
                                            }
                                        )
                                        idx.insert(summary_doc)
                                    except Exception as e:
                                        logger.warning(f"æ‘˜è¦æ·»åŠ åˆ°ç´¢å¼•å¤±è´¥: {e}")
                                    
                                    success_count += 1
                    except Exception as e:
                        st.warning(f"âš ï¸ {fname}: {str(e)}")
                        
                    progress_bar.progress((i + 1) / selected_count)
                
                # ä¿å­˜ç´¢å¼•å’Œ manifest
                try:
                    idx.storage_context.persist(persist_dir=db_path)
                except Exception as e:
                    logger.warning(f"ç´¢å¼•ä¿å­˜å¤±è´¥: {e}")
                    
                with open(ManifestManager.get_path(db_path), 'w', encoding='utf-8') as f:
                    json.dump(doc_manager.manifest, f, indent=4, ensure_ascii=False)
                
                status_text.empty()
                progress_bar.empty()
                st.success(f"âœ… å·²ç”Ÿæˆ {success_count}/{selected_count} ä¸ªæ‘˜è¦å¹¶æ·»åŠ åˆ°çŸ¥è¯†åº“")
                st.session_state.selected_for_summary = set()
                time.sleep(1)
                st.rerun()  # ç«‹å³åˆ·æ–°é¡µé¢æ˜¾ç¤ºæ‘˜è¦
            
            # æ–‡æ¡£åˆ—è¡¨æ ‡ç­¾é¡µ (v1.6) - å·²ç§»é™¤
            pass
            
            st.divider()
            
            # æœç´¢ç­›é€‰æ’åºï¼ˆå•è¡Œè¶…ç´§å‡‘å¸ƒå±€ï¼‰
            col1, col2, col3, col4, col5, col6, col7 = st.columns([2.5, 1.2, 1.2, 1.2, 1.2, 1.5, 1])
            search_term = col1.text_input("ğŸ”", "", key="file_search", placeholder="æœç´¢æ–‡ä»¶å...", label_visibility="collapsed")
            filter_type = col2.selectbox("ğŸ“‚", ["ğŸ“‚ ç±»å‹"] + sorted(set(f.get('type', 'Unknown') for f in doc_manager.manifest['files'])), label_visibility="collapsed")
            
            # åˆ†ç±»ç­›é€‰
            all_categories = set(f.get('category', 'å…¶ä»–') for f in doc_manager.manifest['files'] if f.get('category'))
            filter_category = col3.selectbox("ğŸ“‹", ["ğŸ“‹ åˆ†ç±»"] + sorted(all_categories), label_visibility="collapsed") if all_categories else "ğŸ“‹ åˆ†ç±»"
            
            # çƒ­åº¦ç­›é€‰
            filter_heat = col4.selectbox("ğŸ”¥", ["ğŸ”¥ çƒ­åº¦", "é«˜é¢‘", "ä¸­é¢‘", "ä½é¢‘", "æœªç”¨"], label_visibility="collapsed")
            
            # è´¨é‡ç­›é€‰
            filter_quality = col5.selectbox("âœ…", ["âœ… è´¨é‡", "ä¼˜ç§€", "æ­£å¸¸", "ä½è´¨", "ç©º"], label_visibility="collapsed")
            
            sort_by = col6.selectbox("æ’åº", ["æ—¶é—´â†“", "æ—¶é—´â†‘", "å¤§å°â†“", "å¤§å°â†‘", "åç§°", "çƒ­åº¦â†“", "ç‰‡æ®µâ†“"], label_visibility="collapsed")
            page_size = col7.selectbox("é¡µ", [5, 10, 20, 50], index=0, label_visibility="collapsed")
            
            # ç­›é€‰æ–‡ä»¶
            filtered_files = doc_manager.manifest['files']
            
            # æœç´¢
            if search_term:
                filtered_files = [f for f in filtered_files if search_term.lower() in f['name'].lower()]
            
            # ç±»å‹ç­›é€‰
            if filter_type != "ğŸ“‚ ç±»å‹":
                filtered_files = [f for f in filtered_files if f.get('type') == filter_type]
            
            # åˆ†ç±»ç­›é€‰
            if filter_category != "ğŸ“‹ åˆ†ç±»":
                filtered_files = [f for f in filtered_files if f.get('category') == filter_category]
            
            # çƒ­åº¦ç­›é€‰
            if filter_heat == "é«˜é¢‘":
                filtered_files = [f for f in filtered_files if f.get('hit_count', 0) > 10]
            elif filter_heat == "ä¸­é¢‘":
                filtered_files = [f for f in filtered_files if 3 < f.get('hit_count', 0) <= 10]
            elif filter_heat == "ä½é¢‘":
                filtered_files = [f for f in filtered_files if 0 < f.get('hit_count', 0) <= 3]
            elif filter_heat == "æœªç”¨":
                filtered_files = [f for f in filtered_files if f.get('hit_count', 0) == 0]
            
            # è´¨é‡ç­›é€‰
            if filter_quality == "ä¼˜ç§€":
                filtered_files = [f for f in filtered_files if len(f.get('doc_ids', [])) >= 10]
            elif filter_quality == "æ­£å¸¸":
                filtered_files = [f for f in filtered_files if 2 <= len(f.get('doc_ids', [])) < 10]
            elif filter_quality == "ä½è´¨":
                filtered_files = [f for f in filtered_files if 0 < len(f.get('doc_ids', [])) < 2]
            elif filter_quality == "ç©º":
                filtered_files = [f for f in filtered_files if len(f.get('doc_ids', [])) == 0]
            
            # æ’åº
            if sort_by == "æ—¶é—´â†“":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('added_at', ''), reverse=True)
            elif sort_by == "æ—¶é—´â†‘":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('added_at', ''))
            elif sort_by == "å¤§å°â†“":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('size_bytes', 0), reverse=True)
            elif sort_by == "å¤§å°â†‘":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('size_bytes', 0))
            elif sort_by == "åç§°A-Z":
                filtered_files = sorted(filtered_files, key=lambda x: x['name'].lower())
            elif sort_by == "çƒ­åº¦â†“":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('hit_count', 0), reverse=True)
            elif sort_by == "ç‰‡æ®µâ†“":
                filtered_files = sorted(filtered_files, key=lambda x: len(x.get('doc_ids', [])), reverse=True)
            
            # åˆ†é¡µ
            total_files = len(filtered_files)
            total_pages = (total_files + page_size - 1) // page_size if total_files > 0 else 1
            
            if 'file_page' not in st.session_state:
                st.session_state.file_page = 1
            
            # ç¡®ä¿é¡µç åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if st.session_state.file_page > total_pages:
                st.session_state.file_page = 1
            
            # åˆ†é¡µæ§åˆ¶å’Œç»Ÿè®¡
            if total_files == 0:
                st.info("âŒ æ— åŒ¹é…æ–‡ä»¶")
            else:
                # ç®€æ´çš„ç­›é€‰ç»“æœï¼ˆå•è¡Œï¼‰
                filters = []
                if search_term: filters.append(f"'{search_term}'")
                if filter_type != "ğŸ“‚ ç±»å‹": filters.append(filter_type)
                if filter_category != "ğŸ“‹ åˆ†ç±»": filters.append(filter_category)
                if filter_heat != "ğŸ”¥ çƒ­åº¦": filters.append(filter_heat)
                if filter_quality != "å…¨éƒ¨": filters.append(filter_quality)
                
                if filters:
                    st.caption(f"**{' Â· '.join(filters)}** â†’ {total_files} ä¸ª")
                
                # åˆ†é¡µæ§åˆ¶
                if total_pages > 1:
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        page_cols = st.columns([1, 3, 1])
                        if page_cols[0].button("â¬…ï¸ ä¸Šä¸€é¡µ", disabled=st.session_state.file_page <= 1):
                            st.session_state.file_page -= 1
                        page_cols[1].markdown(f"<div style='text-align:center'>ç¬¬ {st.session_state.file_page}/{total_pages} é¡µ</div>", unsafe_allow_html=True)
                        if page_cols[2].button("ä¸‹ä¸€é¡µ â¡ï¸", disabled=st.session_state.file_page >= total_pages):
                            st.session_state.file_page += 1
                
                # è®¡ç®—å½“å‰é¡µæ–‡ä»¶èŒƒå›´
                start_idx = (st.session_state.file_page - 1) * page_size
                end_idx = min(start_idx + page_size, total_files)
                
                # è¡¨å¤´
                cols = st.columns([0.5, 2.5, 1, 0.8, 1, 0.8, 1.2, 0.8])
                
                # å…¨é€‰å¤é€‰æ¡†
                current_page_files = [f['name'] for f in filtered_files[start_idx:end_idx] if not f.get('summary') and f.get('doc_ids')]
                if current_page_files:
                    all_selected = all(fname in st.session_state.selected_for_summary for fname in current_page_files)
                    
                    # ä½¿ç”¨é»˜è®¤å‚æ•°æ•è·å½“å‰å€¼
                    def toggle_select_all(files=current_page_files):
                        if st.session_state.get(f"select_all_page_{st.session_state.file_page}"):
                            st.session_state.selected_for_summary.update(files)
                        else:
                            st.session_state.selected_for_summary.difference_update(files)
                    
                    select_all = cols[0].checkbox(
                        "å…¨é€‰", 
                        value=all_selected, 
                        key=f"select_all_page_{st.session_state.file_page}", 
                        label_visibility="collapsed",
                        on_change=toggle_select_all
                    )
                else:
                    cols[0].markdown("**âœ¨**")
                
                cols[1].caption(f"**æ–‡ä»¶åˆ—è¡¨ (å…± {total_files} ä¸ª)**")
                cols[2].caption("**æ“ä½œ**")
                st.divider()
                
                # æ³¨å…¥æè‡´ç´§å‡‘ CSS
                st.markdown("""
                <style>
                /* æè‡´å‹ç¼©å‚ç›´é—´è· */
                div[data-testid="stVerticalBlock"] > div[data-testid="stVerticalBlock"] {
                    gap: 0.1rem !important;
                }
                /* å¡ç‰‡å†…éƒ¨ padding æœ€å°åŒ– */
                div[data-testid="stContainer"] {
                    padding: 0.3rem 0.6rem !important;
                    margin-bottom: 0.1rem !important;
                }
                /* Expander æ ‡é¢˜æ é«˜åº¦å‹ç¼© & ç§»é™¤å¤–è¾¹è· */
                .streamlit-expanderHeader {
                    height: 1.8rem !important;
                    padding-top: 0 !important;
                    padding-bottom: 0 !important;
                    min-height: unset !important;
                    margin-bottom: 0 !important; /* å…³é”® */
                }
                /* Expander æ•´ä½“ä¸Šç§» */
                div[data-testid="stExpander"] {
                    margin-top: -0.2rem !important;
                    border: none !important;
                    box-shadow: none !important;
                }
                /* Expander å†…å®¹åŒºåŸŸå»é¡¶è· */
                div[data-testid="stExpanderDetails"] {
                    padding-top: 0 !important;
                    padding-bottom: 0.2rem !important;
                }
                /* åˆ†å‰²çº¿ç´§å‡‘ */
                hr {
                    margin-top: 0.1rem !important;
                    margin-bottom: 0.1rem !important;
                }
                /* æ–‡æœ¬ç´§å‡‘ */
                p, h5, span {
                    margin: 0 !important;
                    padding: 0 !important;
                    line-height: 1.3 !important;
                }
                /* æŒ‰é’®ç´§å‡‘ */
                button {
                    height: 1.6rem !important;
                    padding-top: 0 !important;
                    padding-bottom: 0 !important;
                    min-height: unset !important;
                }
                </style>
                """, unsafe_allow_html=True)

                # æ¸²æŸ“æ–‡ä»¶åˆ—è¡¨ (One-Line Card æ¨¡å¼)
                for i in range(start_idx, end_idx):
                    f = filtered_files[i]
                    orig_idx = doc_manager.manifest['files'].index(f)
                    chunk_count = len(f.get('doc_ids', []))
                    
                    # å‡†å¤‡å…ƒæ•°æ®
                    display_date = f.get('creation_date', f.get('added_at', '')[:10])
                    
                    # è´¨é‡è¯„ä¼°
                    if chunk_count == 0:
                        q_icon = "âŒ"
                    elif chunk_count < 2:
                        q_icon = "âš ï¸"
                    elif chunk_count < 10:
                        q_icon = "âœ…"
                    else:
                        q_icon = "ğŸ‰"

                    # === æç®€å¡ç‰‡å®¹å™¨ ===
                    with st.container(border=True):
                        # å•è¡Œå¸ƒå±€ï¼šæ ‡é¢˜ + å…ƒæ•°æ® + æ‘˜è¦ + æ“ä½œ
                        col_info, col_summary, col_ops = st.columns([6, 2.5, 1.5])
                        
                        with col_info:
                            # æ ¸å¿ƒæ”¹åŠ¨ï¼šä¸€è¡Œæ˜¾ç¤ºæ‰€æœ‰å…³é”®ä¿¡æ¯
                            # æ ¼å¼ï¼šğŸ“„ ç½‘é¡µæ ‡é¢˜/æ–‡ä»¶å  [ç°è‰²å°å­—: 2.5MB Â· 2023-12-12 Â· è´¨é‡ Â· å‘½ä¸­3æ¬¡]
                            file_icon = f.get('icon', 'ğŸ“„')
                            
                            # æ™ºèƒ½æ ‡é¢˜æ˜¾ç¤ºï¼šå¦‚æœæ˜¯æŠ“å–çš„ç½‘é¡µï¼Œå°è¯•æ˜¾ç¤ºå®é™…æ ‡é¢˜
                            display_name = f['name']
                            tech_name = ""
                            
                            # å°è¯•è·å–çœŸå®æ ‡é¢˜ï¼ˆé’ˆå¯¹ crawler ç”Ÿæˆçš„ txtï¼‰
                            if f['name'].endswith('.txt') and 'page_' in f['name']:
                                # å°è¯•ä»æ–‡ä»¶å…ƒæ•°æ®ä¸­è¯»å–æ ‡é¢˜ï¼ˆå¦‚æœä¹‹å‰æœ‰ä¿å­˜ï¼‰
                                # æˆ–è€…ç®€å•åˆ¤æ–­æ˜¯å¦ä¸º crawler æ–‡ä»¶
                                try:
                                    # ç®€æ˜“ä¼˜åŒ–ï¼šå¦‚æœæ–‡ä»¶åæ˜¯ page_X_timestamp.txtï¼Œæ˜¾ç¤ºæ›´å‹å¥½çš„åç§°
                                    parts = f['name'].split('_')
                                    if len(parts) >= 3 and parts[0] == 'page':
                                        # æš‚æ—¶åªæ˜¾ç¤ºä¼˜åŒ–åçš„ IDï¼Œåç»­å¯å‡çº§ä¸ºè¯»å–æ–‡ä»¶å†…å®¹é¦–è¡Œ
                                        display_name = f"ç½‘é¡µ {parts[1]} ({parts[2][:8]})"
                                        tech_name = f['name']
                                except:
                                    pass
                            
                            if len(display_name) > 25: display_name = display_name[:23] + "..."
                            
                            # æ·»åŠ æ›´å¤šå…³é”®ä¿¡æ¯åˆ°ä¸€è¡Œä¸­
                            hit_count = f.get('hit_count', 0)
                            category = f.get('category', '')
                            hit_info = f"å‘½ä¸­{hit_count}æ¬¡" if hit_count > 0 else ""
                            category_info = f"{category}" if category and category != 'æœªåˆ†ç±»' else ""
                            
                            # ç»„åˆé¢å¤–ä¿¡æ¯
                            extra_info = " Â· ".join(filter(None, [hit_info, category_info]))
                            if extra_info:
                                extra_info = " Â· " + extra_info
                                
                            # è´¨é‡æç¤ºä¼˜åŒ–
                            q_tooltip = ""
                            if chunk_count < 2:
                                q_tooltip = "å†…å®¹è¾ƒå°‘ (<500å­—)ï¼Œå»ºè®®ä½œä¸ºè¡¥å……ææ–™"
                            
                            line_html = f"""
                            <div style='display: flex; align-items: baseline; white-space: nowrap; overflow: hidden;'>
                                <span style='font-weight: 600; font-size: 1rem; margin-right: 0.5rem;' title='{tech_name}'>{file_icon} {display_name}</span>
                                <span style='color: gray; font-size: 0.75rem;'>
                                    {f['size']} Â· {chunk_count}ç‰‡æ®µ Â· {display_date} Â· <span title="{q_tooltip}">{q_icon}</span>{extra_info}
                                </span>
                            </div>
                            """
                            if tech_name:
                                line_html += f"<div style='font-size: 0.7rem; color: #999; margin-top: -2px;'>ğŸ“„ {tech_name}</div>"
                                
                            st.markdown(line_html, unsafe_allow_html=True)
                            
                            # ğŸ”§ é«˜çº§é€‰é¡¹å¤„ç†çŠ¶æ€æ ‡è¯†
                            processing_badges = []
                            if f.get('used_ocr', False):
                                processing_badges.append('<span style="background: #e8f5e8; color: #2d5a2d; padding: 1px 4px; border-radius: 3px; font-size: 0.7rem; margin-right: 3px;">ğŸ”OCR</span>')
                            if f.get('keywords') or f.get('category'):
                                processing_badges.append('<span style="background: #e8f0ff; color: #1a4480; padding: 1px 4px; border-radius: 3px; font-size: 0.7rem; margin-right: 3px;">ğŸ“Šå…ƒæ•°æ®</span>')
                            if f.get('summary'):
                                processing_badges.append('<span style="background: #fff3e0; color: #8b4513; padding: 1px 4px; border-radius: 3px; font-size: 0.7rem; margin-right: 3px;">ğŸ“æ‘˜è¦</span>')
                            
                            if processing_badges:
                                badges_html = ''.join(processing_badges)
                                st.markdown(f'<div style="margin-top: 2px; margin-bottom: 4px;">{badges_html}</div>', unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºæ‘˜è¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                            if f.get('summary'):
                                summary_text = f['summary']
                                if len(summary_text) > 100:
                                    summary_text = summary_text[:97] + "..."
                                st.caption(f"ğŸ“ {summary_text}")
                            
                            # æ˜¾ç¤ºå…³é”®è¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                            if f.get('keywords'):
                                keywords = f['keywords'][:5]  # åªæ˜¾ç¤ºå‰5ä¸ªå…³é”®è¯
                                st.caption(f"ğŸ·ï¸ {', '.join(keywords)}")
                        
                        with col_summary:
                            # æ‘˜è¦ç”ŸæˆæŒ‰é’®
                            if not f.get('summary') and f.get('doc_ids'):
                                if st.button("âœ¨ æ‘˜è¦", key=f"summary_{i}", help="ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"):
                                    with st.spinner("ç”Ÿæˆä¸­..."):
                                        try:
                                            # ç›´æ¥ä»ç´¢å¼•è·å–æ–‡æ¡£å†…å®¹
                                            from llama_index.core import StorageContext, load_index_from_storage
                                            
                                            storage_context = StorageContext.from_defaults(persist_dir=db_path)
                                            index = load_index_from_storage(storage_context)
                                            retriever = index.as_retriever(similarity_top_k=3)
                                            
                                            nodes = retriever.retrieve(f['name'])
                                            
                                            doc_text = ""
                                            for node in nodes:
                                                if hasattr(node, 'node') and hasattr(node.node, 'text'):
                                                    doc_text += node.node.text + "\n"
                                                elif hasattr(node, 'text'):
                                                    doc_text += node.text + "\n"
                                                if len(doc_text) > 2000:
                                                    break
                                            
                                            if doc_text.strip():
                                                summary = generate_doc_summary(doc_text, f['name'])
                                                if summary:
                                                    # æ›´æ–°manifest
                                                    f['summary'] = summary
                                                    doc_manager.manifest['files'][orig_idx]['summary'] = summary
                                                    
                                                    # å°†æ‘˜è¦æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
                                                    try:
                                                        from llama_index.core import Document
                                                        summary_doc = Document(
                                                            text=f"æ–‡æ¡£æ‘˜è¦ - {f['name']}:\n{summary}",
                                                            metadata={
                                                                "file_name": f['name'],
                                                                "file_type": "summary",
                                                                "source_file": f['name']
                                                            }
                                                        )
                                                        index.insert(summary_doc)
                                                        index.storage_context.persist(persist_dir=db_path)
                                                    except Exception as e:
                                                        logger.warning(f"æ‘˜è¦æ·»åŠ åˆ°ç´¢å¼•å¤±è´¥: {e}")
                                                    
                                                    # ä¿å­˜manifest
                                                    from src.config.manifest_manager import ManifestManager
                                                    ManifestManager.save(db_path, doc_manager.manifest['files'], doc_manager.manifest.get('embed_model', 'Unknown'))
                                                    
                                                    st.success("âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸå¹¶å·²æ·»åŠ åˆ°çŸ¥è¯†åº“ï¼")
                                                    st.rerun()
                                                else:
                                                    st.error("âŒ ç”Ÿæˆå¤±è´¥")
                                            else:
                                                st.warning("âš ï¸ æ— å†…å®¹")
                                        except Exception as e:
                                            st.error(f"âŒ å¤±è´¥: {str(e)}")
                            elif f.get('summary'):
                                st.caption("ğŸ“– å·²æœ‰æ‘˜è¦")
                        
                        with col_ops:
                            # é¢„è§ˆå’Œåˆ é™¤
                            op_c1, op_c2 = st.columns([1, 1])
                            with op_c1:
                                if st.button("ğŸ‘ï¸", key=f"prev_{i}", help="åŸç”Ÿé¢„è§ˆ"):
                                    try:
                                        # ä¼˜å…ˆä½¿ç”¨è®°å½•çš„å®Œæ•´è·¯å¾„ï¼Œå¦åˆ™å›é€€åˆ°çŸ¥è¯†åº“ç›®å½•
                                        file_path = f.get('file_path')
                                        if not file_path or not os.path.exists(file_path):
                                            file_path = os.path.join(db_path, f['name'])
                                        
                                        if os.path.exists(file_path):
                                            # å¼‚æ­¥å¯åŠ¨é¢„è§ˆï¼Œä¸é˜»å¡ä¸»ç¨‹åº
                                            subprocess.Popen(["qlmanage", "-p", file_path], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)
                                            # å¯åŠ¨åå°è„šæœ¬å¼ºåˆ¶ç½®é¡¶çª—å£
                                            top_script = 'tell application "System Events"\n repeat until (exists process "qlmanage")\n delay 0.1\n end repeat\n set frontmost of process "qlmanage" to true\n end tell'
                                            subprocess.Popen(['osascript', '-e', top_script])
                                        else:
                                            st.warning(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {f['name']}")
                                    except Exception as e:
                                        st.error(f"é¢„è§ˆå¤±è´¥: {e}")
                            
                            with op_c2:
                                # æ“ä½œåŒºï¼šä»…ä¿ç•™åˆ é™¤æŒ‰é’®
                                if st.button("ğŸ—‘ï¸", key=f"del_{i}", help="åˆ é™¤æ–‡ä»¶"):
                                    with st.status(f"åˆ é™¤ä¸­...", expanded=True) as status:
                                        try:
                                            ctx = StorageContext.from_defaults(persist_dir=db_path)
                                            idx = load_index_from_storage(ctx)
                                            for did in f.get('doc_ids', []):
                                                idx.delete_ref_doc(did, delete_from_docstore=True)
                                            idx.storage_context.persist(persist_dir=db_path)
                                            remove_file_from_manifest(db_path, f['name'])
                                            status.update(label="å·²åˆ é™¤", state="complete")
                                            st.session_state.chat_engine = None
                                            time.sleep(0.5); st.rerun()
                                        except Exception as e: st.error(str(e))
                        
                        # è¯¦æƒ…ç›´æ¥å±•å¼€ (ä¸“ä¸šç‰ˆ)
                        with st.expander(f"ğŸ” æ·±åº¦æ¡£æ¡ˆä¸æ•°æ®å–è¯ - {f['name']}", expanded=False):
                            actual_file_path = f.get('file_path')
                            if not actual_file_path or not os.path.exists(actual_file_path):
                                actual_file_path = os.path.join(db_path, f['name'])
                            
                            # è·å–æ·±åº¦å±æ€§
                            deep_attrs = get_deep_file_attributes(actual_file_path)
                            
                            # 1. é¡¶éƒ¨ä¸“ä¸šä»ªè¡¨ç›˜ (Health Dashboard)
                            h_col1, h_col2, h_col3, h_col4 = st.columns(4)
                            
                            with h_col1:
                                indexed_status = "âœ… å·²ç´¢å¼•" if f.get('doc_ids') else "â³ æœªç´¢å¼•"
                                st.markdown(f"<div style='background:#f0f7ff; color:#0550ae; padding:4px 10px; border-radius:15px; text-align:center; font-size:0.8rem; font-weight:600;'>{indexed_status}</div>", unsafe_allow_html=True)
                            
                            with h_col2:
                                efficiency = deep_attrs.get('efficiency', '100%')
                                st.markdown(f"<div style='background:#f6ffed; color:#389e0d; padding:4px 10px; border-radius:15px; text-align:center; font-size:0.8rem; font-weight:600;'>ğŸ’¾ å­˜å‚¨æ•ˆç‡ {efficiency}</div>", unsafe_allow_html=True)
                                
                            with h_col3:
                                heat = "ğŸ”¥ çƒ­æ•°æ®" if f.get('hit_count', 0) > 5 else "â„ï¸ å†·æ•°æ®"
                                st.markdown(f"<div style='background:#fff7e6; color:#d46b08; padding:4px 10px; border-radius:15px; text-align:center; font-size:0.8rem; font-weight:600;'>ğŸ“ˆ {heat} ({f.get('hit_count', 0)})</div>", unsafe_allow_html=True)
                                
                            with h_col4:
                                days = deep_attrs.get('longevity_days', 0)
                                st.markdown(f"<div style='background:#fff1f0; color:#cf1322; padding:4px 10px; border-radius:15px; text-align:center; font-size:0.8rem; font-weight:600;'>ğŸ•’ å­˜æ´» {days} å¤©</div>", unsafe_allow_html=True)
                            
                            st.write("")
                            
                            # 2. 60/40 é»„é‡‘åˆ†å‰²å¸ƒå±€
                            detail_col_left, detail_col_right = st.columns([6, 4])
                            
                            with detail_col_left:
                                # --- å·¦ä¾§ï¼šæ™ºèƒ½æ´å¯Ÿ (60%) ---
                                if f.get('summary'):
                                    st.markdown("####### ğŸ§  æ™ºèƒ½æ‘˜è¦")
                                    st.info(f"{f['summary']}")
                                
                                # RAG é¢„ä¼°ä¸å¯†åº¦
                                st.markdown("####### ğŸ“Š RAG å†…å®¹åŠ¨åŠ›å­¦")
                                r_c1, r_c2, r_c3 = st.columns(3)
                                with r_c1:
                                    tokens = deep_attrs.get('token_estimate', 0)
                                    st.metric("é¢„ä¼° Token", f"~{tokens}", help="åŸºäºå­—ç¬¦æ•°çš„ä¼°ç®—å€¼")
                                with r_c2:
                                    chunks = len(f.get('doc_ids', []))
                                    st.metric("å‘é‡ç‰‡æ®µ", f"{chunks} Pkts")
                                with r_c3:
                                    # å¯†åº¦ = å­—ç¬¦/ç‰‡æ®µ
                                    density = tokens // chunks if chunks > 0 else 0
                                    st.metric("å†…å®¹å¯†åº¦", f"{density} c/p", help="å¹³å‡æ¯ä¸ªç‰‡æ®µåŒ…å«çš„å­—ç¬¦æ•°")

                                # å†…å®¹é‡‡æ ·
                                if os.path.exists(actual_file_path) and f.get('type', '').lower() in ['.txt', '.md', '.py', '.js', '.html', '.css', '.json']:
                                    st.markdown("####### ğŸ“„ æ–‡æœ¬å–è¯é‡‡æ ·")
                                    try:
                                        with open(actual_file_path, 'r', encoding='utf-8', errors='ignore') as preview_f:
                                            preview_content = preview_f.read(800)
                                            st.code(preview_content, language='text')
                                    except:
                                        st.caption("æ— æ³•è¯»å–å†…å®¹é¢„è§ˆ")
                                
                                # ç”¨æˆ·å¤‡æ³¨
                                st.markdown("####### ğŸ“ ç”¨æˆ·è‡ªå®šä¹‰å¤‡æ³¨")
                                file_hash = f.get('file_hash', 'no_hash')
                                current_note = notes_manager.get_note(file_hash)
                                new_note = st.text_area("å¤‡æ³¨ä¿¡æ¯", value=current_note, height=80, key=f"note_{i}", label_visibility="collapsed")
                                if new_note != current_note:
                                    notes_manager.set_note(file_hash, new_note)
                                    st.toast("âœ… å¤‡æ³¨å·²ä¿å­˜")

                            with detail_col_right:
                                # --- å³ä¾§ï¼šæŠ€æœ¯æ¡£æ¡ˆ (40%) ---
                                if "error" not in deep_attrs:
                                    # 1. ä¼˜å…ˆå±•ç¤ºç³»ç»Ÿè®°å½•çš„æº¯æº (é’ˆå¯¹æŠ“å–æ–‡ä»¶)
                                    if deep_attrs.get("header_url"):
                                        st.markdown("####### ğŸŒ æº¯æº (ç³»ç»Ÿè®°å½•)")
                                        st.caption(f"`{deep_attrs['header_url']}`")
                                        st.divider()

                                    # 2. macOS ä¸“å±å¢å¼ºå…ƒæ•°æ®
                                    if platform.system() == "Darwin":
                                        st.markdown("####### ğŸ macOS å¢å¼ºå…ƒæ•°æ®")
                                        m = deep_attrs.get("macos", {})
                                        if any([m.get("tags"), m.get("finder_comment"), m.get("where_from"), m.get("version")]):
                                            # å±•ç¤ºæ ‡ç­¾
                                            if m.get("tags"):
                                                tag_html = "".join([f"<span style='background:#f0f0f0; padding:2px 6px; border-radius:10px; font-size:0.7rem; margin-right:4px;'>ğŸ·ï¸ {t}</span>" for t in m["tags"]])
                                                st.markdown(tag_html, unsafe_allow_html=True)
                                            
                                            # å±•ç¤ºæ¥æº
                                            if m.get("where_from"):
                                                st.markdown("**ğŸŒ ä¸‹è½½æ¥æº**")
                                                for url in m["where_from"]:
                                                    st.caption(f"`{url}`")
                                            
                                            # å±•ç¤ºç³»ç»Ÿæ³¨é‡Š
                                            if m.get("finder_comment"):
                                                st.caption(f"ğŸ’¬ **Finder æ³¨é‡Š**: {m['finder_comment']}")
                                            
                                            if m.get("version"):
                                                st.caption(f"ğŸ”¢ **å†…éƒ¨ç‰ˆæœ¬**: {m['version']}")
                                        else:
                                            st.caption("â„¹ï¸ æœªå‘ç°æ‰©å±•å…ƒæ•°æ® (æ ‡ç­¾ã€æ¥æºç­‰)")
                                        
                                        st.divider()

                                    # å–è¯ä¸åº•å±‚
                                    st.markdown("####### ğŸ•µï¸ ç³»ç»Ÿå–è¯")
                                    st.caption(f"Magic Bytes: `{deep_attrs['magic_bytes']}`")
                                    st.caption(f"SHA-256: `{deep_attrs['sha256'][:32]}...`")
                                    st.caption(f"Inode: `{deep_attrs['inode']}` | FS: `{deep_attrs['fs_type']}`")
                                    
                                    # æ—¶é—´è½´ä¸ä½ç½®
                                    st.markdown("####### ğŸ•’ æ—¶é—´è½´ä¸ä½ç½®")
                                    st.caption(f"åˆ›å»º: `{deep_attrs['created']}`")
                                    st.caption(f"æœ€åè®¿é—®: `{deep_attrs['accessed']}`")
                                    
                                    st.markdown("####### ğŸ“ æ‹“æ‰‘ä½ç½®")
                                    st.caption(f"çœŸå®è·¯å¾„: `{deep_attrs['real_path'][:40]}...`")
                                    st.caption(f"ç¬¦å·é“¾æ¥: `{'æ˜¯' if deep_attrs['is_symlink'] else 'å¦'}`")
                                    
                                    # æƒé™ç³»ç»Ÿ
                                    st.markdown("####### ğŸ›¡ï¸ æƒé™ç³»ç»Ÿ")
                                    st.caption(f"Unixæƒé™: `{deep_attrs['permissions']}`")
                                    st.caption(f"æ‰€æœ‰è€…: `{deep_attrs['owner']}` | åªè¯»: `{'æ˜¯' if deep_attrs['is_readonly'] else 'å¦'}`")
                                else:
                                    st.warning(f"æ•°æ®æŠ“å–å¼‚å¸¸: {deep_attrs['error']}")
                                
                                # å¿«æ·åŠŸèƒ½æŒ‰é’®
                                st.divider()
                                btn_c1, btn_c2 = st.columns(2)
                                with btn_c1:
                                    if st.button("ğŸ“‚ åœ¨ Finder ä¸­æ˜¾ç¤º", key=f"reveal_{i}", use_container_width=True):
                                        reveal_in_file_manager(actual_file_path)
                                            
                                with btn_c2:
                                    if platform.system() == "Darwin":
                                        if st.button("ğŸ‘ï¸ QuickLook", key=f"ql_{i}", use_container_width=True):
                                            try:
                                                subprocess.Popen(["qlmanage", "-p", actual_file_path], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)
                                                # å¼ºåˆ¶ç½®é¡¶è„šæœ¬
                                                top_script = 'tell application "System Events"\n repeat 20 times\n if exists process "qlmanage" then\n set frontmost of process "qlmanage" to true\n exit repeat\n end if\n delay 0.1\n end repeat\n end tell'
                                                subprocess.Popen(['osascript', '-e', top_script])
                                            except Exception as e:
                                                st.error(f"é¢„è§ˆå¤±è´¥: {e}")
                                    else:
                                        if st.button("ğŸ“‹ å¤åˆ¶è·¯å¾„", key=f"copy_path_{i}", use_container_width=True):
                                            st.code(actual_file_path)

                            # å‘é‡ç‰‡æ®µID (æŠ˜å )
                            if f.get('doc_ids'):
                                with st.expander("ğŸ§¬ å‘é‡ç‰‡æ®µ ID åºåˆ— (RAW)", expanded=False):
                                    st.text_area("IDs", value='\n'.join(f['doc_ids']), height=100, label_visibility="collapsed", key=f"ids_raw_{i}")
                
                # åº•éƒ¨åˆ†é¡µ (æ–¹ä¾¿ç¿»é¡µ)
                if total_pages > 1:
                    st.divider()
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        page_cols = st.columns([1, 3, 1])
                        if page_cols[0].button("â¬…ï¸", key="prev_bottom", disabled=st.session_state.file_page <= 1):
                            st.session_state.file_page -= 1
                        page_cols[1].markdown(f"<div style='text-align:center'>ç¬¬ {st.session_state.file_page}/{total_pages} é¡µ Â· å…± {total_files} ä¸ªæ–‡ä»¶</div>", unsafe_allow_html=True)
                        if page_cols[2].button("â¡ï¸", key="next_bottom", disabled=st.session_state.file_page >= total_pages):
                            st.session_state.file_page += 1

# åˆ›å»ºæ¨¡å¼çš„æ¬¢è¿ç•Œé¢
if is_create_mode:
    st.markdown("""
    <div class="welcome-box">
        <h2>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨çŸ¥è¯†åº“</h2>
        <p>è¯·åœ¨å·¦ä¾§ <b>ä¾§è¾¹æ </b> é…ç½®æ•°æ®æº (æ”¯æŒç²˜è´´è·¯å¾„æˆ–æ‹–æ‹½æ–‡ä»¶)ï¼Œç‚¹å‡» <b>ğŸš€ ç«‹å³åˆ›å»º</b> å¼€å§‹ã€‚</p>
    </div>
    """, unsafe_allow_html=True)


# --- èåˆ ChatOllama é£æ ¼ï¼šä¼šè¯é¡¶æ  (v2.7.6) ---
if active_kb_name:
    with st.container():
        from src.config import ConfigLoader
        from src.config.prompt_manager import PromptManager
        from src.utils.model_manager import set_global_llm_model
        
        # åˆå§‹åŒ–å½“å‰é€‰æ‹© (ä¿®å¤ KeyError)
        if 'current_prompt_id' not in st.session_state:
            st.session_state.current_prompt_id = 'default'
        
        conf = ConfigLoader.load()
        # ä¼˜å…ˆä½¿ç”¨ä¼šè¯çº§ Context Limitï¼Œå¦åˆ™ä½¿ç”¨å…¨å±€é…ç½®
        ctx_limit = st.session_state.get('session_ctx_limit', conf.get('chat_history_limit', 10))
        current_model_name = st.session_state.get('selected_model', 'Default')
        
        # è®¡ç®—ä¼šè¯æ ‡é¢˜ (åŸºäºç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯)
        session_title = "æ–°å¯¹è¯"
        if st.session_state.messages:
            first_user_msg = next((m['content'] for m in st.session_state.messages if m['role'] == 'user'), None)
            if first_user_msg:
                session_title = first_user_msg[:12].strip() + ("..." if len(first_user_msg)>12 else "")

        # å¸ƒå±€ï¼š[æ ‡é¢˜åŒº] [æ¨¡å‹åŒº] [æ“ä½œåŒº]
        h_col1, h_col2, h_col3 = st.columns([3, 2, 2.5])
        
        with h_col1:
            st.markdown(f"#### ğŸ“ {session_title}")
            st.caption(f"ğŸ“‚ {active_kb_name}")
            
        with h_col2:
            current_role_id = st.session_state.get('current_prompt_id', 'default')
            # è·å–è§’è‰²åç§°
            all_prompts = PromptManager.load_prompts()
            role_name = next((p['name'] for p in all_prompts if p['id'] == current_role_id), "é»˜è®¤åŠ©æ‰‹")
            # ç®€åŒ–æ˜¾ç¤º
            short_role = role_name.split(' ')[0]
            st.markdown(f"<div style='text-align:center; padding-top:5px; color:#555'>ğŸ¤– {current_model_name}<br><span style='background:#f5f5f5; padding:1px 5px; border-radius:4px; font-size:0.75rem'>ğŸ­ {short_role} | ğŸ”„ {ctx_limit}</span></div>", unsafe_allow_html=True)

        with h_col3:
            c_set, c_new = st.columns([1, 2])
            with c_set:
                # âš™ï¸ ä¼šè¯è®¾ç½®å¼¹çª— (Popover)
                with st.popover("âš™ï¸", use_container_width=True, help="å½“å‰ä¼šè¯è®¾ç½®"):
                    st.markdown("##### ğŸ’¬ å½“å‰ä¼šè¯è®¾ç½®")
                    
                    # 1. è§’è‰²é€‰æ‹©
                    prompt_names = [p['name'] for p in all_prompts]
                    current_idx = 0
                    for i, p in enumerate(all_prompts):
                        if p['id'] == st.session_state.current_prompt_id:
                            current_idx = i; break
                    
                    selected_p_name = st.selectbox("ğŸ­ åˆ‡æ¢è§’è‰²", prompt_names, index=current_idx)
                    
                    # è§’è‰²åˆ‡æ¢é€»è¾‘
                    sel_p = next(p for p in all_prompts if p['name'] == selected_p_name)
                    if sel_p['id'] != st.session_state.current_prompt_id:
                        st.session_state.current_prompt_id = sel_p['id']
                        # çƒ­åˆ‡æ¢ LLM
                        try:
                            llm_provider = conf.get('llm_provider', 'Ollama')
                            llm_model = conf.get('llm_model_ollama', 'gpt-oss:20b')
                            llm_url = conf.get('llm_url_ollama', 'http://localhost:11434')
                            llm_key = ""
                            if llm_provider == "OpenAI":
                                llm_model = conf.get('llm_model_openai'); llm_url = conf.get('llm_url_openai'); llm_key = conf.get('llm_key')
                            elif llm_provider == "Azure OpenAI":
                                llm_model = conf.get('azure_deployment'); llm_url = conf.get('azure_endpoint'); llm_key = conf.get('azure_key')
                            
                            set_global_llm_model(llm_provider, llm_model, llm_key, llm_url, system_prompt=sel_p['content'])
                            st.toast(f"å·²åˆ‡æ¢: {sel_p['name']}")
                            st.rerun()
                        except: pass

                    # 2. Context Window (è¦†ç›–å…¨å±€)
                    new_limit = st.slider("ğŸ§  è®°å¿†æ·±åº¦ (Context)", 1, 50, ctx_limit, help="ä»…å¯¹å½“å‰ä¼šè¯ç”Ÿæ•ˆ")
                    if new_limit != ctx_limit:
                        st.session_state.session_ctx_limit = new_limit
                        st.rerun()
                    
                    st.divider()
                    
                    # 3. æ¸…ç©ºå†å²
                    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰è®°å½•", use_container_width=True, type="primary"):
                        st.session_state.messages = []
                        st.session_state.suggestions_history = []
                        from src.chat import HistoryManager
                        HistoryManager.save_session(active_kb_name, [], st.session_state.get('current_session_id'))
                        st.rerun()

            with c_new:
                if st.button("â• æ–°å¯¹è¯", use_container_width=True, type="secondary"):
                    import uuid
                    new_id = str(uuid.uuid4())[:8]
                    st.session_state.current_session_id = new_id
                    st.session_state.messages = []
                    st.session_state.suggestions_history = []
                    # é‡ç½®ä¼šè¯çº§è®¾ç½®
                    st.session_state.pop('session_ctx_limit', None)
                    
                    from src.chat import HistoryManager
                    HistoryManager.save_session(active_kb_name, [], new_id)
                    st.rerun()
    st.divider()

# è‡ªåŠ¨æ‘˜è¦ (ä»…åœ¨çŸ¥è¯†åº“é¦–æ¬¡åŠ è½½ä¸”æ— å†å²æ¶ˆæ¯æ—¶è§¦å‘)
if active_kb_name and st.session_state.chat_engine and not st.session_state.messages:
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        summary_placeholder = st.empty()
        with st.status("âœ¨ æ­£åœ¨åˆ†ææ–‡æ¡£ç”Ÿæˆæ‘˜è¦...", expanded=True) as status:
            try:
                # ä½¿ç”¨å½“å‰é€‰æ‹©çš„ LLM æ¨¡å‹åç§°
                current_model = st.session_state.get('selected_model', 'Ollama')
                logger.info(f"ğŸ’¬ æ‘˜è¦ç”Ÿæˆä½¿ç”¨æ¨¡å‹: {current_model}")
                
                prompt = "è¯·ç”¨ä¸€æ®µè¯ç®€è¦æ€»ç»“æ­¤çŸ¥è¯†åº“çš„æ ¸å¿ƒå†…å®¹ã€‚ç„¶åï¼Œæå‡º3ä¸ªç”¨æˆ·å¯èƒ½æœ€å…³å¿ƒçš„é—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦åºå·ã€‚"
                full = ""
                resp = st.session_state.chat_engine.stream_chat(prompt)
                
                for t in resp.response_gen:
                    # ğŸ›‘ æ£€æŸ¥åœæ­¢ä¿¡å·
                    if st.session_state.get('stop_generation'):
                        st.session_state.stop_generation = False
                        full += "\n\nâ¹ **ç”Ÿæˆå·²åœæ­¢**"
                        summary_placeholder.markdown(full)
                        break
                    
                    full += t
                    summary_placeholder.markdown(full + "â–Œ")
                
                status.update(label="âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ", state="complete")
                summary_placeholder.markdown(full)
                
                summary_lines = full.split('\n')
                summary = summary_lines[0]
                sug = [re.sub(r'^\d+\.\s*', '', q.strip()) for q in summary_lines[1:] if q.strip()][:3]

                st.session_state.messages.append({"role": "assistant", "content": summary, "suggestions": sug})
                HistoryManager.save_session(active_kb_name, state.get_messages(), st.session_state.get('current_session_id'))
                st.rerun()
            except Exception as e:
                error_msg = str(e)
                if "timed out" in error_msg.lower() or "timeout" in error_msg.lower():
                    status.update(label="â±ï¸ æ‘˜è¦ç”Ÿæˆè¶…æ—¶", state="error")
                    summary_placeholder.info("â±ï¸ LLM å“åº”è¶…æ—¶ï¼Œå·²è·³è¿‡è‡ªåŠ¨æ‘˜è¦ã€‚æ‚¨å¯ä»¥ç›´æ¥å¼€å§‹æé—®ã€‚")
                    logger.warning(f"â±ï¸ æ‘˜è¦ç”Ÿæˆè¶…æ—¶: {e}")
                else:
                    status.update(label="âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥", state="error")
                    summary_placeholder.warning(f"æ‘˜è¦ç”Ÿæˆå—é˜»: {e}")
                    logger.error(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
                st.session_state.messages.append({"role": "assistant", "content": "ğŸ‘‹ çŸ¥è¯†åº“å·²å°±ç»ªã€‚"})

# æ¸²æŸ“æ¶ˆæ¯
for msg_idx, msg in enumerate(state.get_messages()):
    role = msg["role"]
    avatar = "ğŸ¤–" if role == "assistant" else "ğŸ§‘â€ğŸ’»"
    with st.chat_message(role, avatar=avatar):
        # --- æ¸²æŸ“æŒä¹…åŒ–ç ”ç©¶è¯¦æƒ… (v2.9.4) ---
        if role == "assistant":
            # 1. è”ç½‘æœç´¢å†å²ç»“æœ
            if msg.get("search_results"):
                search_meta = msg["search_results"]
                # å…¼å®¹æ—§ç‰ˆæœ¬æ ¼å¼ (å¦‚æœ search_results ç›´æ¥æ˜¯åˆ—è¡¨)
                if isinstance(search_meta, list):
                    results_list = search_meta
                    opt_query = msg.get('optimized_query', 'æœªçŸ¥')
                    status_label = f"âœ… å·²è·å– {len(results_list)} æ¡è”ç½‘ç»“æœ"
                else:
                    results_list = search_meta.get('results', [])
                    opt_query = search_meta.get('optimized_query', 'æœªçŸ¥')
                    status_label = f"âœ… å·²ç²¾é€‰ {search_meta.get('selected')} æ¡é«˜åˆ†è”ç½‘ç»“æœ (æ£€ç´¢ {search_meta.get('total_raw')} æ¡, è€—æ—¶ {search_meta.get('duration')}s)"
                
                with st.status(status_label, expanded=False, state="complete"):
                    st.caption(f"ğŸ¯ æœç´¢å…³é”®è¯ï¼š{opt_query}")
                    for i, res in enumerate(results_list, 1):
                        emoji, label = res.get('quality_label', ("â­", "ä¸­ç­‰è´¨é‡"))
                        st.markdown(f"**{i}. {emoji} {res.get('title')}**")
                        st.caption(f"{res.get('summary', '')[:150]}...")
                        st.markdown(f"ğŸ”— [{urlparse(res.get('href', '')).netloc}]({res.get('href')})")
                        if i < len(results_list): st.divider()
            
            # 2. ä¸“å®¶ä¼šå®¡å†å²è¯¦æƒ…
            if msg.get("research_details"):
                res_meta = msg["research_details"]
                with st.status(f"âœ… ä¸“å®¶ä¼šå®¡å·²å®Œæˆ (ä¸“å®¶ç»„: {res_meta.get('roles')})", expanded=False, state="complete"):
                    st.write(f"ğŸ‘¥ **ä¸“å®¶ç»„**: {res_meta.get('roles')}")
                    st.markdown("**ğŸ’¡ ä¸“ä¸šæ´å¯Ÿè§†è§’:**")
                    st.write(res_meta.get('perspectives'))
                    with st.expander("ğŸ§ æŸ¥çœ‹å®¡è®¡ç»†èŠ‚"):
                        st.write(res_meta.get('critique'))

        # æ˜¾ç¤ºè§’è‰²æ ‡ç­¾ (v2.7.4)
        if role == "assistant" and msg.get("prompt_role"):
            st.markdown(f"""
            <div style="display: flex; align-items: center; margin-bottom: 8px;">
                <span style="background-color: rgba(0,0,0,0.05); padding: 2px 8px; border-radius: 4px; color: #666; font-size: 0.8rem; border: 1px solid rgba(0,0,0,0.1);">
                    ğŸ­ {msg['prompt_role']}
                </span>
            </div>
            """, unsafe_allow_html=True)
            
        st.markdown(msg["content"])
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰- ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.1)
        if "stats" in msg and msg["stats"]:
            render_message_stats(msg["stats"])
        
        # æ¸²æŸ“å¼•ç”¨æº - ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.1)
        if "sources" in msg and msg["sources"]:
            render_source_references(msg["sources"], expanded=False)
        
        # å¼•ç”¨æŒ‰é’® (P2 æ¢å¤åŠŸèƒ½)
        if role == "assistant":
            if st.button("ğŸ“Œ å¼•ç”¨æ­¤å›å¤", key=f"quote_{msg_idx}"):
                st.session_state.quote_content = msg["content"]
                st.rerun()

        # æ¸²æŸ“é™æ€å»ºè®® (ä»…ç”¨äºè‡ªåŠ¨æ‘˜è¦)
        is_last_message = msg_idx == len(state.get_messages()) - 1
        if "suggestions" in msg and msg["suggestions"] and is_last_message and not st.session_state.suggestions_history:
            st.write("")
            for idx, q in enumerate(msg["suggestions"]):
                if st.button(f"ğŸ‘‰ {q}", key=f"sug_{msg_idx}_{idx}", use_container_width=True):
                    click_btn(q)
    
    # åœ¨æœ€åä¸€æ¡ assistant æ¶ˆæ¯ä¹‹åæ˜¾ç¤ºåŠ¨æ€è¿½é—®æ¨èï¼ˆåœ¨ chat_message å®¹å™¨å¤–ï¼‰
    is_last_message = msg_idx == len(state.get_messages()) - 1
    
    # è°ƒè¯•ä¿¡æ¯
    debug_info = {
        'is_last_message': is_last_message,
        'role': msg.get("role"),
        'active_kb_name': bool(active_kb_name),
        'chat_engine': bool(st.session_state.get('chat_engine')),
        'suggestions_count': len(st.session_state.get('suggestions_history', []))
    }
    
    if is_last_message and msg["role"] == "assistant":
        import hashlib
        msg_hash = hashlib.md5(msg['content'][:100].encode()).hexdigest()[:8]
        
        st.divider()
        
        @st.fragment
        def suggestions_fragment():
            # 1. çŠ¶æ€æŒ‡ç¤ºä¸å¿«æ·æ“ä½œæ  (v2.9)
            cols = st.columns([0.25, 0.15, 0.15, 0.15, 0.15, 0.15])
            with cols[0]:
                st.markdown("ğŸ” **è¿½é—®æ¨è**")
            
            # æ˜¾ç¤ºå½“å‰å¼€å¯çš„åŠŸèƒ½çŠ¶æ€ (ä½œä¸ºç¾è§‚çš„æ ‡ç­¾)
            with cols[1]:
                if st.session_state.get('enable_query_optimization'):
                    st.caption("ğŸ§  æ€è€ƒä¸­")
                else:
                    st.caption("âšª æ€è€ƒ")
            
            with cols[2]:
                if st.session_state.get('enable_web_search'):
                    st.caption("ğŸŒ è”ç½‘ä¸­")
                else:
                    st.caption("âšª è”ç½‘")
            
            with cols[3]:
                st.caption("ğŸ” æœç´¢")
            
            with cols[4]:
                if st.session_state.get('enable_deep_research'):
                    st.caption("ğŸ”¬ ç ”ç©¶ä¸­")
                else:
                    st.caption("âšª ç ”ç©¶")
                    
            with cols[5]:
                # æ¢ä¸€æ‰¹æŒ‰é’®ç§»åˆ°è¿™ä¸€è¡Œï¼Œæ›´åŠ ç´§å‡‘
                # ä¿®å¤ï¼šå¢åŠ  msg_idx ç¡®ä¿ Key ç»å¯¹å”¯ä¸€ï¼Œé˜²æ­¢é‡å¤å†…å®¹å¯¼è‡´ Duplicate Key
                if st.button("ğŸ”„ æ¢ä¸€æ‰¹", key=f"gen_more_{msg_idx}_{msg_hash}", help="ç”Ÿæˆæ–°çš„æ¨èé—®é¢˜"):
                    with st.spinner(""):
                        all_history_questions = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
                        # ... (ä¿æŒåŸæœ‰ç”Ÿæˆé€»è¾‘ï¼Œä½†ä¸ºäº†ç²¾ç®€ï¼Œæˆ‘ç›´æ¥åœ¨è¿™é‡Œå†™æ ¸å¿ƒè°ƒç”¨)
                        engine = get_unified_suggestion_engine(active_kb_name)
                        context_text = msg['content']
                        if msg_idx > 0:
                            prev_msg = st.session_state.messages[msg_idx - 1]
                            if prev_msg['role'] == 'user':
                                context_text = f"ç”¨æˆ·é—®é¢˜: {prev_msg['content']}\nAIå›ç­”: {msg['content']}"
                        
                        new_sugs = engine.generate_suggestions(
                            context=context_text,
                            source_type='chat',
                            query_engine=st.session_state.chat_engine if st.session_state.get('chat_engine') else None,
                            num_questions=3
                        )
                        if new_sugs:
                            st.session_state.suggestions_history = new_sugs[:3]
                            st.rerun(scope="fragment")

            # 2. åŠ¨æ€è¿‡æ»¤ä¸æ¸²æŸ“æ¨èé—®é¢˜
            raw_suggestions = st.session_state.get('suggestions_history', [])
            forbidden_set = set()
            if hasattr(st.session_state, 'question_queue'):
                forbidden_set.update(st.session_state.question_queue)
            user_msgs = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
            forbidden_set.update(user_msgs[-20:])
            
            filtered_suggestions = [s for s in raw_suggestions if s not in forbidden_set]
            
            if filtered_suggestions:
                # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºæ¨èé—®é¢˜ï¼Œä½¿å…¶æ›´åƒå¡ç‰‡æˆ–æŒ‰é’®ç»„
                for idx, q in enumerate(filtered_suggestions):
                    # ä¿®å¤ï¼šå¢åŠ  msg_idx ç¡®ä¿ Key ç»å¯¹å”¯ä¸€
                    if st.button(f"ğŸ”¹ {q}", key=f"dyn_sug_{msg_idx}_{msg_hash}_{idx}", use_container_width=True):
                        click_btn(q)
            else:
                # å…œåº•ï¼šå¦‚æœæ²¡æ¨èï¼Œæ˜¾ç¤ºä¸€ä¸ªå°æç¤º
                st.caption("æš‚æ— æ›´å¤šæ¨èï¼Œæ‚¨å¯ä»¥å°è¯•å¼€å¯'æ·±åº¦æ€è€ƒ'æˆ–'è”ç½‘æœç´¢'æ¥è·å–æ›´æ·±å…¥çš„è¿½é—®ã€‚")

        suggestions_fragment()

# æç®€å·¥å…·æ ï¼šæ¨¡å‹ä¸è®¾ç½®
with st.container():
    # Tools: Leading Spacer | Provider | Model | Deep | Web | Research | Filter | Clear | Stop/Trailing Spacer
    # è°ƒæ•´æ¯”ä¾‹ä»¥å®¹çº³ æ™ºèƒ½ç ”ç©¶ (v2.9)
    if st.session_state.get('is_processing'):
        cols = st.columns([0.03, 0.12, 0.22, 0.11, 0.11, 0.11, 0.04, 0.04, 0.12], gap="small")
        c_lead, c_prov, c_model, c_deep, c_web, c_research, c_filter, c_clear, c_stop = cols
    else:
        cols = st.columns([0.03, 0.12, 0.22, 0.11, 0.11, 0.11, 0.04, 0.04, 0.12], gap="small")
        c_lead, c_prov, c_model, c_deep, c_web, c_research, c_filter, c_clear, c_spacer = cols
    
    # --- 0. å‰ç½®ç•™ç™½ (c_lead ä¸æ”¾ç½®å†…å®¹) ---

    # --- 1. å‚å•†/ä¾›åº”å•†é€‰æ‹© ---
    with c_prov:
        from src.config import ConfigLoader
        config = ConfigLoader.load()
        current_provider = config.get('llm_provider', 'Ollama')
        
        # ç»Ÿä¸€ä¾›åº”å•†å®Œæ•´å®šä¹‰ (ä¸ config_forms.py ä¸€è‡´)
        ALL_PROVIDERS = {
            "Ollama": "ğŸ¦™ Ollama (æœ¬åœ°)",
            "OpenAI": "â˜ï¸ OpenAI (äº‘ç«¯)",
            "OpenAI-Compatible": "ğŸ”Œ Other (å…¼å®¹åè®®)",
            "Azure OpenAI": "ğŸŸ¦ Azure OpenAI",
            "Anthropic": "ğŸ§  Anthropic (Claude)",
            "Moonshot": "ğŸŒ™ Moonshot (Kimi)",
            "Gemini": "ğŸ’ Gemini (Google)",
            "Groq": "âš¡ Groq (æé€Ÿ)"
        }
        
        # åŠ¨æ€è¡¥å……è‡ªå®šä¹‰ä¾›åº”å•† (v2.9.6)
        custom_providers_info = config.get("custom_llm_providers", {})
        for cp_id, cp_info in custom_providers_info.items():
            ALL_PROVIDERS[cp_id] = f"ğŸ¨ {cp_info.get('name', cp_id)}"
        
        # åŠ¨æ€ç­›é€‰ï¼šä»…æ˜¾ç¤ºå·²é…ç½®ï¼ˆæœ‰ Key æˆ– URLï¼‰çš„ä¾›åº”å•†
        configured_providers = []
        
        # Ollama é»˜è®¤å§‹ç»ˆæ£€æŸ¥
        configured_providers.append("Ollama")
        
        # æ£€æŸ¥å…¶ä»–ä¾›åº”å•†æ˜¯å¦æœ‰é…ç½®ä¿¡æ¯
        if config.get("llm_key") or config.get("llm_url_openai"): configured_providers.append("OpenAI")
        if config.get("llm_key_other") or config.get("llm_url_other"): configured_providers.append("OpenAI-Compatible")
        if config.get("azure_key") and config.get("azure_endpoint"): configured_providers.append("Azure OpenAI")
        if config.get("anthropic_key"): configured_providers.append("Anthropic")
        if config.get("moonshot_key"): configured_providers.append("Moonshot")
        if config.get("gemini_key"): configured_providers.append("Gemini")
        if config.get("groq_key"): configured_providers.append("Groq")
        
        # ç¡®ä¿å½“å‰ä½¿ç”¨çš„ä¾›åº”å•†åœ¨åˆ—è¡¨ä¸­
        if current_provider not in configured_providers:
            configured_providers.append(current_provider)
            
        # æŒ‰ ALL_PROVIDERS çš„é¡ºåºæ’åº
        display_providers = [p for p in ALL_PROVIDERS.keys() if p in configured_providers]
            
        def on_provider_change():
            new_prov = st.session_state.toolbar_provider_selector
            st.session_state.temp_provider = new_prov
        
        selected_provider = st.selectbox(
            "å‚å•†",
            options=display_providers,
            format_func=lambda x: ALL_PROVIDERS.get(x, x),
            index=display_providers.index(current_provider) if current_provider in display_providers else 0,
            key="toolbar_provider_selector",
            on_change=on_provider_change,
            label_visibility="collapsed"
        )

    # --- 2. æ¨¡å‹é€‰æ‹© ---
    with c_model:
        # è¯»å–å¯¹åº”ä¾›åº”å•†ä¿å­˜çš„æ¨¡å‹
        saved_models = {
            "Ollama": config.get("llm_model_ollama", "gpt-oss:20b"),
            "OpenAI": config.get("llm_model_openai", "gpt-3.5-turbo"),
            "OpenAI-Compatible": config.get("llm_model_other", ""),
            "Azure OpenAI": config.get("azure_deployment", ""),
            "Anthropic": config.get("config_anthropic_model", ""),
            "Moonshot": config.get("config_moonshot_model", ""),
            "Gemini": config.get("config_gemini_model", ""),
            "Groq": config.get("config_groq_model", "")
        }
        
        current_model = saved_models.get(selected_provider, "")
        available_models = []
        
        # --- æ ¸å¿ƒæ”¹è¿›ï¼šå·¥å…·æ æ¨¡å‹è‡ªåŠ¨åŒæ­¥ (v2.9.6) ---
        from src.utils.model_utils import fetch_remote_models
        
        # è·å–å½“å‰ä¾›åº”å•†çš„è¿æ¥å‚æ•° (v2.9.6 æ”¯æŒè‡ªå®šä¹‰ä¾›åº”å•†)
        provider_params = {
            "Ollama": (config.get('llm_url_ollama', "http://localhost:11434"), ""),
            "OpenAI": (config.get('llm_url_openai', "https://api.openai.com/v1"), config.get('llm_key', "")),
            "OpenAI-Compatible": (config.get('llm_url_other', ""), config.get('llm_key_other', "")),
            "Azure OpenAI": (config.get('azure_endpoint', ""), config.get('azure_key', "")),
            "Anthropic": ("", config.get('anthropic_key', "")),
            "Moonshot": ("https://api.moonshot.cn/v1", config.get('moonshot_key', "")),
            "Gemini": ("", config.get('gemini_key', "")),
            "Groq": ("https://api.groq.com/openai/v1", config.get('groq_key', ""))
        }
        
        # åŠ¨æ€è¡¥å……è‡ªå®šä¹‰ä¾›åº”å•†å‚æ•°
        custom_providers = config.get("custom_llm_providers", {})
        for cp_id, cp_info in custom_providers.items():
            provider_params[cp_id] = (cp_info.get('url', ""), cp_info.get('key', ""))
        
        url, key = provider_params.get(selected_provider, ("", ""))
        cache_key = f"models_{selected_provider}_{url}_{key}"
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if cache_key in st.session_state:
            available_models = st.session_state[cache_key]
        else:
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä¸”å‚æ•°å®Œæ•´ï¼Œå°è¯•è‡ªåŠ¨åŠ è½½ä¸€æ¬¡
            if (url or selected_provider in ["Anthropic", "Gemini"]) and not st.session_state.get(f"auto_load_{selected_provider}"):
                with st.spinner(""):
                    models, err = fetch_remote_models(url, key)
                    if models:
                        available_models = models
                        st.session_state[cache_key] = models
                        st.session_state[f"auto_load_{selected_provider}"] = True
            
        # ç¡®ä¿å½“å‰æ¨¡å‹åœ¨åˆ—è¡¨ä¸­
        if not available_models:
            available_models = [current_model] if current_model else ["æœªé…ç½®æ¨¡å‹"]
        elif current_model and current_model not in available_models:
            available_models.insert(0, current_model)
            
        idx = available_models.index(current_model) if current_model in available_models else 0

        def on_model_change():
            new_model = st.session_state.toolbar_model_selector
            if new_model not in ["æœªé…ç½®æ¨¡å‹", ""]:
                if update_all_model_configs(new_model):
                    config = ConfigLoader.load()
                    config['llm_provider'] = st.session_state.toolbar_provider_selector
                    prov = st.session_state.toolbar_provider_selector
                    # åŒæ­¥æ›´æ–°å¯¹åº”ä¾›åº”å•†çš„æ¨¡å‹å­—æ®µ
                    field_map = {
                        "Ollama": "llm_model_ollama", "OpenAI": "llm_model_openai",
                        "OpenAI-Compatible": "llm_model_other", "Azure OpenAI": "azure_deployment",
                        "Anthropic": "config_anthropic_model", "Moonshot": "config_moonshot_model",
                        "Gemini": "config_gemini_model", "Groq": "config_groq_model"
                    }
                    if prov in field_map: config[field_map[prov]] = new_model
                    ConfigLoader.save(config)
                    st.toast(f"âœ… å·²åˆ‡æ¢ä¸º: {new_model}", icon="ğŸ¤–")

        # å¢åŠ åˆ·æ–°å°å›¾æ ‡ï¼Œç´§å‡‘å¸ƒå±€ (v2.9.6)
        col_select, col_refresh = st.columns([0.85, 0.15])
        with col_select:
            st.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                options=available_models,
                index=idx,
                key="toolbar_model_selector",
                on_change=on_model_change,
                label_visibility="collapsed"
            )
        with col_refresh:
            if st.button("ğŸ”„", key="toolbar_model_refresh", help="åˆ·æ–°æ¨¡å‹åˆ—è¡¨"):
                with st.spinner(""):
                    models, err = fetch_remote_models(url, key)
                    if models:
                        st.session_state[cache_key] = models
                        st.toast(f"âœ… å·²åŒæ­¥ {len(models)} ä¸ªæ¨¡å‹")
                        st.rerun()
                    else:
                        st.error("åŒæ­¥å¤±è´¥")

    # --- 3. åŠŸèƒ½å¼€å…³ (Toggle) ---
    with c_deep:
        deep_on = st.toggle("æ·±åº¦æ€è€ƒ", value=st.session_state.get('enable_query_optimization', False), help="å¯ç”¨æ™ºèƒ½æŸ¥è¯¢ä¼˜åŒ–")
        st.session_state.enable_query_optimization = deep_on

    with c_web:
        web_search_on = st.toggle("è”ç½‘æœç´¢", value=st.session_state.get('enable_web_search', False), help="å¯ç”¨è”ç½‘æœç´¢")
        st.session_state.enable_web_search = web_search_on

    with c_research:
        research_on = st.toggle("æ™ºèƒ½ç ”ç©¶", value=st.session_state.get('enable_deep_research', False), help="å¯ç”¨æ·±åº¦ç ”ç©¶æ¨¡å¼ (v2.9)")
        st.session_state.enable_deep_research = research_on

    # --- 4. æ“ä½œæŒ‰é’® (Popover/Button) ---
    if st.session_state.get('is_processing'):
        with c_stop:
            if st.button("â¹ åœæ­¢", type="primary", use_container_width=True):
                st.session_state.is_processing = False
                st.session_state.stop_generation = True
                st.rerun()

# å¼•ç”¨å†…å®¹é¢„è§ˆåŒº
if st.session_state.get("quote_content"):
    quote_text = st.session_state.quote_content
    display_text = quote_text[:60].replace('\n', ' ') + "..." if len(quote_text) > 60 else quote_text
    
    with st.container():
        st.info(f"ğŸ“Œ **å·²å¼•ç”¨**: {display_text}")
        col1, col2 = st.columns([8, 2])
        col1.caption("åŸºäºæ­¤å†…å®¹æé—®...")
        if col2.button("å–æ¶ˆå¼•ç”¨", key="cancel_quote", use_container_width=True):
            st.session_state.quote_content = None
            st.rerun()

# å¤„ç†è¾“å…¥
# ä¿æŒè¾“å…¥æ¡†å½¢æ€ä¸€è‡´ï¼Œé¿å…å¸ƒå±€è·³åŠ¨
if st.session_state.get('is_processing'):
    st.chat_input("æ­£åœ¨ç”Ÿæˆå›ç­”ä¸­...", disabled=True)
else:
    # æ­£å¸¸è¾“å…¥çŠ¶æ€
    user_input = st.chat_input("è¾“å…¥é—®é¢˜...")
    
    # å¦‚æœæœ‰æ–°è¾“å…¥ï¼ŒåŠ å…¥é˜Ÿåˆ—
    if user_input:
        if active_kb_name == "multi_kb_mode":
            # å¤šçŸ¥è¯†åº“æ¨¡å¼ - ç›´æ¥å¤„ç†æŸ¥è¯¢
            selected_kbs = st.session_state.get('selected_kbs', [])
            if not selected_kbs:
                st.error("è¯·å…ˆé€‰æ‹©çŸ¥è¯†åº“")
            else:
                st.session_state.question_queue.append(user_input)
        elif not st.session_state.chat_engine:
            st.error("è¯·å…ˆç‚¹å‡»å·¦ä¾§ã€ğŸš€ æ‰§è¡Œå¤„ç†ã€‘å¯åŠ¨ç³»ç»Ÿ")
        else:
            st.session_state.question_queue.append(user_input)

# å¤„ç† prompt_triggerï¼ˆè¿½é—®æŒ‰é’®ï¼‰
if st.session_state.prompt_trigger:
    if st.session_state.chat_engine:
        st.session_state.question_queue.append(st.session_state.prompt_trigger)
    st.session_state.prompt_trigger = None

# æ˜¾ç¤ºé˜Ÿåˆ—çŠ¶æ€
queue_len = len(st.session_state.question_queue)
if st.session_state.get('is_processing'):
    # æ ¸å¿ƒå®‰å…¨æœºåˆ¶ï¼šæ£€æµ‹å¤„ç†æ—¶é•¿
    process_start = st.session_state.get('process_start_time', time.time())
    elapsed = time.time() - process_start
    if elapsed > 180: # 3 minutes
        st.warning(f"âš ï¸ å¤„ç†å·²æŒç»­ {elapsed:.0f}sï¼Œå¯èƒ½å‘ç”Ÿæ­»é”æˆ–å¼•æ“å“åº”è¿‡æ…¢ã€‚")
        if st.button("ğŸš¨ å¼ºåˆ¶é‡ç½®ç³»ç»ŸçŠ¶æ€", type="primary"):
            st.session_state.is_processing = False
            st.session_state.question_queue = []
            st.toast("âœ… ç³»ç»Ÿå·²å¼ºåˆ¶é‡ç½®")
            st.rerun()

    if queue_len > 0:
        # æ˜¾ç¤ºé˜Ÿåˆ—ä¸­çš„é—®é¢˜
        with st.expander(f"â³ æ­£åœ¨å¤„ç†é—®é¢˜ï¼Œé˜Ÿåˆ—ä¸­è¿˜æœ‰ {queue_len} ä¸ªé—®é¢˜ç­‰å¾…...", expanded=True):
            for i, q in enumerate(st.session_state.question_queue, 1):
                # æˆªæ–­è¿‡é•¿çš„é—®é¢˜
                display_q = q[:50] + "..." if len(q) > 50 else q
                st.caption(f"{i}. {display_q}")
            
            # æ·»åŠ é˜Ÿåˆ—é‡ç½®æŒ‰é’®
            if st.button("ğŸ”„ é‡ç½®é˜Ÿåˆ—ï¼ˆå¦‚æœå¡ä½ï¼‰", key="reset_queue"):
                st.session_state.is_processing = False
                st.session_state.question_queue = []
                st.success("âœ… é˜Ÿåˆ—å·²é‡ç½®")
                st.rerun()
    else:
        st.info("â³ æ­£åœ¨å¤„ç†é—®é¢˜...")
        # æ·»åŠ é‡ç½®æŒ‰é’®ï¼ˆé˜²æ­¢å¡ä½ï¼‰
        if st.button("ğŸ”„ é‡ç½®çŠ¶æ€", key="reset_processing"):
            st.session_state.is_processing = False
            st.success("âœ… å¤„ç†çŠ¶æ€å·²é‡ç½®")
            st.rerun()
elif queue_len > 0:
    # æ˜¾ç¤ºå¾…å¤„ç†çš„é—®é¢˜åˆ—è¡¨
    with st.expander(f"ğŸ“ é˜Ÿåˆ—ä¸­æœ‰ {queue_len} ä¸ªé—®é¢˜å¾…å¤„ç†", expanded=True):
        for i, q in enumerate(st.session_state.question_queue, 1):
            display_q = q[:50] + "..." if len(q) > 50 else q
            st.caption(f"{i}. {display_q}")
        
        # æ·»åŠ æ¸…ç©ºé˜Ÿåˆ—æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºé˜Ÿåˆ—", key="clear_queue"):
            st.session_state.question_queue = []
            st.success("âœ… é˜Ÿåˆ—å·²æ¸…ç©º")
            st.rerun()

# ä»é˜Ÿåˆ—ä¸­å–å‡ºé—®é¢˜å¤„ç†
if not st.session_state.get('is_processing', False) and st.session_state.question_queue:
    # è®°å½•å¼€å§‹æ—¶é—´ç”¨äºæ­»é”æ£€æµ‹
    st.session_state.process_start_time = time.time()
    final_prompt = st.session_state.question_queue.pop(0)
    
    # è®°å½•å½“å‰è§’è‰²çŠ¶æ€ (v2.7.4)
    from src.config.prompt_manager import PromptManager
    all_prompts = PromptManager.load_prompts()
    current_role_id = st.session_state.get('current_prompt_id', 'default')
    role_name = next((p['name'] for p in all_prompts if p['id'] == current_role_id), current_role_id)
    
    logger.info(f"ğŸ­ å½“å‰è§’è‰²: {role_name}")
    logger.info(f"ğŸš€ å¼€å§‹å¤„ç†é˜Ÿåˆ—é—®é¢˜: {final_prompt[:50]}...")
    
    if active_kb_name == "multi_kb_mode":
        # å¤šçŸ¥è¯†åº“æ¨¡å¼å¤„ç†
        selected_kbs = st.session_state.get('selected_kbs', [])
        st.session_state.is_processing = True
        logger.info("âœ… å¤šçŸ¥è¯†åº“æ¨¡å¼å¼€å§‹å¤„ç†")
        logger.info(f"ğŸ“‹ é€‰ä¸­çŸ¥è¯†åº“: {selected_kbs}")
        logger.info(f"â“ ç”¨æˆ·é—®é¢˜: {final_prompt}")
        
        # ä½¿ç”¨å¤šçŸ¥è¯†åº“æŸ¥è¯¢å¼•æ“
        from src.query.multi_kb_query_engine import MultiKBQueryEngine
        multi_engine = MultiKBQueryEngine(output_base)
        logger.info("ğŸ”§ å¤šçŸ¥è¯†åº“æŸ¥è¯¢å¼•æ“å·²åˆå§‹åŒ–")
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.write(final_prompt)
        
        # æ˜¾ç¤ºåŠ©æ‰‹å›å¤
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            
            # æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
            with st.spinner("ğŸ” æ­£åœ¨ä»å¤šä¸ªçŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯..."):
                try:
                    # æ‰§è¡Œå¤šçŸ¥è¯†åº“æŸ¥è¯¢
                    response = multi_engine.query(final_prompt, selected_kbs, embed_provider, embed_model, embed_key, embed_url)
                    
                except Exception as e:
                    error_msg = f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
                    logger.log("å¤šçŸ¥è¯†åº“æŸ¥è¯¢", "error", f"âŒ å¤šçŸ¥è¯†åº“æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
                    response_placeholder.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    st.session_state.is_processing = False
                    st.rerun()
            
            # æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
            response_placeholder.write(response)
            
            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
            st.session_state.messages.append({"role": "assistant", "content": response})
            logger.log("å¤šçŸ¥è¯†åº“æŸ¥è¯¢", "complete", "âœ… å¤šçŸ¥è¯†åº“æŸ¥è¯¢å®Œæˆ")
            
            st.session_state.is_processing = False
            st.rerun()
                
    elif st.session_state.chat_engine:
        # ä¸æ¸…ç©º suggestions_historyï¼Œä¿ç•™è¿½é—®æŒ‰é’®
        st.session_state.is_processing = True  # æ ‡è®°æ­£åœ¨å¤„ç†
        logger.info("âœ… è®¾ç½®å¤„ç†çŠ¶æ€ä¸º True")
        
        # å¼ºåˆ¶æ£€æµ‹çŸ¥è¯†åº“ç»´åº¦å¹¶åˆ‡æ¢æ¨¡å‹ï¼ˆé™é»˜å¤„ç†ï¼Œä¸æ˜¾ç¤ºåŠ è½½ï¼‰
        # ä¼˜åŒ–ï¼šåªåœ¨é¦–æ¬¡æˆ–åˆ‡æ¢çŸ¥è¯†åº“æ—¶æ£€æµ‹ï¼Œé¿å…æ¯æ¬¡é—®ç­”éƒ½é‡å¤
        if active_kb_name:  # åªæœ‰åœ¨å•çŸ¥è¯†åº“æ¨¡å¼ä¸‹æ‰æ£€æµ‹ç»´åº¦
            db_path = os.path.join(output_base, active_kb_name)
            
            # å§‹ç»ˆæ£€æµ‹ç»´åº¦ï¼Œç¡®ä¿æ¨¡å‹åŒ¹é…
            kb_dim = get_kb_embedding_dim(db_path)
            
            # ç»´åº¦æ˜ å°„
            model_map = {
                512: "sentence-transformers/all-MiniLM-L6-v2",
                768: "BAAI/bge-large-zh-v1.5",
                1024: "BAAI/bge-m3"
            }
            
            # å¦‚æœæ£€æµ‹åˆ°ç»´åº¦ï¼Œå¼ºåˆ¶åˆ‡æ¢
            if kb_dim and kb_dim in model_map:
                required_model = model_map[kb_dim]
                if embed_model != required_model:
                    print(f"ğŸ”„ å¼ºåˆ¶åˆ‡æ¢æ¨¡å‹: {embed_model} â†’ {required_model} (ç»´åº¦: {kb_dim}D)")
                    embed_model = required_model
                    embed = get_embed(embed_provider, embed_model, embed_key, embed_url)
                    if embed:
                        Settings.embed_model = embed
                        print(f"âœ… æ¨¡å‹å·²åˆ‡æ¢")
            else:
                # ç»´åº¦æ£€æµ‹å¤±è´¥æ—¶ï¼Œä¸å¼ºåˆ¶åˆ‡æ¢ï¼Œä½†è®°å½•æ—¥å¿—
                if not kb_dim:
                    print(f"âš ï¸ æ— æ³•æ£€æµ‹çŸ¥è¯†åº“ç»´åº¦ï¼Œä¿æŒå½“å‰æ¨¡å‹: {embed_model}")
        
        logger.separator("çŸ¥è¯†åº“æŸ¥è¯¢")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šçŸ¥è¯†åº“æ¨¡å¼
        if len(st.session_state.get('selected_kbs', [])) > 1:
            # å¤šçŸ¥è¯†åº“æŸ¥è¯¢æ¨¡å¼
            selected_kbs = st.session_state.get('selected_kbs', [])
            logger.start_operation("å¤šçŸ¥è¯†åº“æŸ¥è¯¢", f"çŸ¥è¯†åº“: {', '.join(selected_kbs)}")
            
            # å¯¼å…¥å¤šçŸ¥è¯†åº“æŸ¥è¯¢å¼•æ“
            from src.query.multi_kb_query_engine import query_single_kb_worker
            from concurrent.futures import ProcessPoolExecutor, as_completed
            import multiprocessing as mp
            
            # æ‰§è¡Œå¤šçŸ¥è¯†åº“æŸ¥è¯¢
            start_time = time.time()
            
            # --- å¤šåº“æ¨¡å¼ä¸‹çš„æ™ºèƒ½ç ”ç©¶æ³¨å…¥ (v2.9.2) ---
            if st.session_state.get('enable_deep_research', False):
                with st.status("ğŸ”¬ å¤šåº“æ™ºèƒ½ç ”ç©¶ï¼šä¸“å®¶ç»„ä¼šå®¡ä¸­...", expanded=False) as status:
                    try:
                        from llama_index.core import Settings
                        llm = Settings.llm
                        st.write("ğŸ­ æ­£åœ¨å¬é›†è·¨é¢†åŸŸä¸“å®¶åˆ†æå¤šåº“é—®é¢˜...")
                        role_res = llm.complete(f"é’ˆå¯¹å¤šçŸ¥è¯†åº“é—®é¢˜ï¼š'{final_prompt}'ï¼Œåˆ—å‡º3ä¸ªä¸“ä¸šè§’è‰²ã€‚")
                        roles = role_res.text.strip()
                        st.write(f"ğŸ’¬ å¾è¯¢ä¸“å®¶æ„è§: {roles}...")
                        syn_res = llm.complete(f"ä»¥ã€{roles}ã€‘è§†è§’åˆ†æé—®é¢˜ï¼š{final_prompt}")
                        final_prompt = f"ã€å¤šåº“ç ”ç©¶è§†è§’ã€‘:\n{syn_res.text}\n\nã€åŸå§‹é—®é¢˜ã€‘: {final_prompt}"
                        status.update(label="âœ… å¤šåº“ä¼šå®¡å®Œæˆ", state="complete")
                        logger.log("INFO", f"ğŸ”¬ å¤šåº“ç ”ç©¶å¼€å¯: {roles}", stage="å¤šåº“æŸ¥è¯¢")
                    except Exception as e:
                        logger.error(f"å¤šåº“ç ”ç©¶æ¨¡å¼å¼‚å¸¸: {e}")
            
            results = {}
            max_workers = min(mp.cpu_count(), len(selected_kbs), 3)
            
            try:
                with ProcessPoolExecutor(max_workers=max_workers) as executor:
                    future_to_kb = {
                        executor.submit(query_single_kb_worker, kb_name, final_prompt, 3): kb_name 
                        for kb_name in selected_kbs
                    }
                    
                    for future in as_completed(future_to_kb, timeout=60):
                        kb_name = future_to_kb[future]
                        try:
                            result = future.result(timeout=30)
                            results[kb_name] = result
                        except Exception as e:
                            results[kb_name] = {
                                "kb_name": kb_name,
                                "success": False,
                                "error": f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
                                "results": []
                            }
            except Exception as e:
                logger.error(f"å¤šè¿›ç¨‹æŸ¥è¯¢å¤±è´¥: {e}")
                # å›é€€åˆ°å•çº¿ç¨‹
                for kb_name in selected_kbs:
                    try:
                        result = query_single_kb_worker(kb_name, final_prompt, 3)
                        results[kb_name] = result
                    except Exception as kb_error:
                        results[kb_name] = {
                            "kb_name": kb_name,
                            "success": False,
                            "error": f"æŸ¥è¯¢å¤±è´¥: {str(kb_error)}",
                            "results": []
                        }
            
            # ç”Ÿæˆæ•´åˆç­”æ¡ˆ
            successful_results = [r for r in results.values() if r["success"]]
            total_time = time.time() - start_time
            
            if successful_results:
                # æ„å»ºæ•´åˆç­”æ¡ˆ
                integrated_answer = f"**åŸºäº {len(successful_results)} ä¸ªçŸ¥è¯†åº“çš„æŸ¥è¯¢ç»“æœï¼š**\n\n"
                
                for i, result in enumerate(successful_results, 1):
                    kb_name = result["kb_name"]
                    answer = result.get("answer", "æ— ç­”æ¡ˆ")
                    integrated_answer += f"#### ğŸ“š çŸ¥è¯†åº“ {i}: {kb_name}\n{answer}\n\n"
                
                integrated_answer += f"---\n**æŸ¥è¯¢ç»Ÿè®¡**: {len(successful_results)}/{len(selected_kbs)} ä¸ªçŸ¥è¯†åº“å“åº”æˆåŠŸï¼Œè€—æ—¶ {total_time:.2f} ç§’"
                
                # æ˜¾ç¤ºç»“æœ
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    st.markdown(integrated_answer)
                    
                    # è¯¦ç»†ç»“æœ
                    with st.expander("ğŸ“‹ è¯¦ç»†ç»“æœ"):
                        for kb_name, result in results.items():
                            if result["success"] and result["results"]:
                                st.write(f"**ğŸ“š {kb_name}**")
                                for i, doc in enumerate(result["results"][:2], 1):
                                    st.write(f"ğŸ“„ {doc['source']} (ç›¸å…³åº¦: {doc['score']:.3f})")
                                    st.caption(doc['content'][:200] + "...")
                
                # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                st.session_state.messages.append({"role": "user", "content": final_prompt})
                st.session_state.messages.append({"role": "assistant", "content": integrated_answer})
                
            else:
                st.error("âŒ æ‰€æœ‰çŸ¥è¯†åº“æŸ¥è¯¢éƒ½å¤±è´¥äº†")
            
            st.session_state.is_processing = False
            st.rerun()
            
        else:
            # å•çŸ¥è¯†åº“æŸ¥è¯¢æ¨¡å¼ï¼ˆåŸé€»è¾‘ï¼‰
            logger.start_operation("æŸ¥è¯¢", f"çŸ¥è¯†åº“: {active_kb_name}")
        
        # æŸ¥è¯¢æ”¹å†™ (v1.6) - åœ¨å¤„ç†å¼•ç”¨å†…å®¹ä¹‹å‰
        # åªæœ‰åœ¨ç”¨æˆ·å¯ç”¨æŸ¥è¯¢ä¼˜åŒ–æ—¶æ‰è¿›è¡Œ
        if st.session_state.get('enable_query_optimization', False):
            logger.info("ğŸ§  æ·±åº¦æ€è€ƒ(æŸ¥è¯¢ä¼˜åŒ–)å·²æ¿€æ´»")
            query_rewriter = QueryRewriter(Settings.llm)
            should_rewrite, reason = query_rewriter.should_rewrite(final_prompt)
            
            if should_rewrite:
                logger.info(f"ğŸ’¡ æ·±åº¦æ€è€ƒ: æ£€æµ‹åˆ°éœ€è¦æ”¹å†™æŸ¥è¯¢ - {reason}")
                rewritten_query = query_rewriter.suggest_rewrite(final_prompt)
                
                if rewritten_query and rewritten_query != final_prompt:
                    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®ï¼Œè®©ç”¨æˆ·é€‰æ‹©
                    with st.chat_message("assistant", avatar="ğŸ¤–"):
                        st.info(f"ğŸ’¡ **æŸ¥è¯¢ä¼˜åŒ–å»ºè®®**\n\nåŸé—®é¢˜ï¼š{final_prompt}\n\nä¼˜åŒ–åï¼š{rewritten_query}")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            if st.button("âœ… ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢", key=f"use_optimized_{len(st.session_state.messages)}"):
                                final_prompt = rewritten_query
                                logger.info(f"âœ… æ·±åº¦æ€è€ƒ: ç”¨æˆ·é€‰æ‹©ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢ - {rewritten_query}")
                                st.rerun()
                        with col2:
                            if st.button("ğŸ“ ä½¿ç”¨åŸé—®é¢˜", key=f"use_original_{len(st.session_state.messages)}"):
                                logger.info(f"ğŸ“ æ·±åº¦æ€è€ƒ: ç”¨æˆ·é€‰æ‹©ä½¿ç”¨åŸé—®é¢˜ - {final_prompt}")
                                st.rerun()
                        
                        # æ ¸å¿ƒä¿®å¤ï¼šåœæ­¢å‰é‡Šæ”¾å¤„ç†é”ï¼Œä½†æ ‡è®°å½“å‰é—®é¢˜ï¼Œé¿å…ä¸¢å¤±æˆ–é‡å…¥
                        st.session_state.is_processing = False
                        st.stop()  # ç­‰å¾…ç”¨æˆ·é€‰æ‹©
            else:
                logger.info(f"ğŸ§  æ·±åº¦æ€è€ƒ: æŸ¥è¯¢æ¸…æ™°ï¼Œæ— éœ€æ”¹å†™ ({reason})")

        user_display_prompt = final_prompt  # ä¿å­˜åŸå§‹æé—®ç”¨äº UI æ˜¾ç¤º
        if st.session_state.get('enable_web_search', False):
            try:
                from duckduckgo_search import DDGS
                from src.utils.search_quality import search_quality_analyzer
                from urllib.parse import urlparse
                
                logger.info(f"ğŸŒ å¯åŠ¨è”ç½‘æœç´¢è§„åˆ’...")
                search_start_time = time.time()
                
                # æ¢å¤ä¸ºé»˜è®¤æ”¶èµ·ï¼Œç”¨æˆ·å¯æ ¹æ®éœ€è¦ç‚¹å¼€æŸ¥çœ‹è¿‡ç¨‹ (v2.9.2)
                with st.status("ğŸŒ æ­£åœ¨è§„åˆ’æœç´¢å…³é”®è¯å¹¶è”ç½‘...", expanded=False) as status:
                    # --- æœç´¢æ„å›¾æ‹†è§£ (v2.9.2 æ–°å¢) ---
                    from llama_index.core import Settings
                    llm = Settings.llm
                    
                    st.write("ğŸ§  æ­£åœ¨åˆ†æé—®é¢˜æ„å›¾å¹¶æ‹†è§£ä¸­è‹±æ–‡å…³é”®è¯...")
                    planning_prompt = (
                        f"ç”¨æˆ·é—®é¢˜ï¼š'{final_prompt}'\n"
                        "è¯·å°†è¯¥é—®é¢˜æ‹†è§£ä¸ºæœ€ç²¾å‡†çš„æœç´¢å…³é”®è¯æˆ–çŸ­è¯­ï¼Œä»¥ä¾¿æœåˆ°å…·ä½“æ¡ˆä¾‹æˆ–æ·±åº¦è§£é‡Šã€‚\n"
                        "è¦æ±‚ï¼š\n"
                        "1. æå–æ ¸å¿ƒåè¯å’ŒåŠ¨ä½œã€‚å¦‚æœé—®é¢˜æ¶‰åŠ'å¦‚ä½•å®šä½'ï¼Œè¯·æœç´¢'å®šä½å·¥å…·'æˆ–'æŸ¥æ‰¾æŠ€å·§'ã€‚\n"
                        "2. è¾“å‡º 2 ä¸ªä¸­æ–‡å…³é”®è¯ï¼Œ1 ä¸ªè‹±æ–‡å…³é”®è¯ã€‚\n"
                        "3. ä¸è¦ç”¨å¯¹è¯å¥å¼ï¼Œæ¯ä¸ªè¯æ§åˆ¶åœ¨ 15 å­—ä»¥å†…ã€‚\n"
                        "åªéœ€è¾“å‡ºå…³é”®è¯ï¼Œç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—ã€‚"
                    )
                    planning_res = llm.complete(planning_prompt)
                    # é²æ£’æ€§æ”¹è¿›ï¼šå¤„ç†å¤šç§åˆ†éš”ç¬¦å¹¶è¿‡æ»¤è¯´æ˜æ€§æ–‡å­—
                    raw_text = planning_res.text.strip()
                    # å°è¯•æ‹†åˆ†ï¼šå…ˆç»Ÿä¸€åˆ†éš”ç¬¦ä¸ºè‹±æ–‡é€—å·
                    norm_text = raw_text.replace('ï¼Œ', ',').replace('\n', ',').replace('ã€', ',')
                    keyword_list = [k.strip() for k in norm_text.split(',') if k.strip() and len(k.strip()) > 1]
                    
                    # é™åˆ¶å…³é”®è¯æ•°é‡ï¼Œé˜²æ­¢è¿‡é•¿
                    keyword_list = keyword_list[:4]
                    optimized_query = " | ".join(keyword_list)
                    
                    logger.log("INFO", f"ğŸ¯ ä¸­è‹±åŒè¯­è§„åˆ’å®Œæˆ: {keyword_list}", stage="è”ç½‘æœç´¢")
                    
                    all_raw_results = []
                    with DDGS() as ddgs:
                        for kw in keyword_list:
                            st.write(f"ğŸ” æ­£åœ¨æ£€ç´¢: {kw}...")
                            try:
                                # æ™ºèƒ½åˆ¤æ–­è¯­è¨€å¹¶é€‰æ‹© Region (v2.9.2)
                                is_english = any(c.isalpha() for c in kw) and not any('\u4e00' <= c <= '\u9fff' for c in kw)
                                target_region = 'us-en' if is_english else 'cn-zh'
                                
                                # å°è¯• 1ï¼šå¸¦åŒºåŸŸé”å®šæ£€ç´¢
                                kw_results = list(ddgs.text(kw, max_results=10, region=target_region))
                                
                                # å°è¯• 2ï¼šé™çº§ç­–ç•¥ (v2.9.2 è¡¥å¼º)
                                # å¦‚æœåŒºåŸŸé”å®šæœä¸åˆ°ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å…¨å±€æ¨¡å¼ (wt-wt)
                                if not kw_results:
                                    logger.info(f"   - å…³é”®è¯ '{kw}' åŒºåŸŸ [{target_region}] æ— ç»“æœï¼Œå°è¯•å…¨å±€æ£€ç´¢...")
                                    kw_results = list(ddgs.text(kw, max_results=10))
                                
                                all_raw_results.extend(kw_results)
                                logger.info(f"   - å…³é”®è¯ '{kw}' æœ€ç»ˆå‘½ä¸­ {len(kw_results)} æ¡")
                            except Exception as e:
                                logger.warning(f"   - å…³é”®è¯ '{kw}' æ£€ç´¢å¼‚å¸¸: {e}")
                    
                    # å»é‡å¤„ç†
                    unique_results = []
                    seen_urls = set()
                    for r in all_raw_results:
                        if r['href'] not in seen_urls:
                            unique_results.append(r)
                            seen_urls.add(r['href'])
                    
                    results = unique_results
                    search_duration = round(time.time() - search_start_time, 2)
                    
                    if results:
                        # è´¨é‡åˆ†æå’Œæ’åº (v2.9.3 è¯­ä¹‰å¯¹ç…§ç‰ˆ)
                        analyzed_results = []
                        for res in results:
                            # ä¼ é€’ user_display_prompt è¿›è¡Œç›¸å…³æ€§æ ¡éªŒ
                            quality_info = search_quality_analyzer.analyze_result_quality(res, user_display_prompt)
                            res.update(quality_info)
                            
                            # å™ªéŸ³ç¡¬è¿‡æ»¤ï¼šç›´æ¥å‰”é™¤è¢«åˆ¤å®šä¸ºå™ªéŸ³çš„å†…å®¹
                            if not res.get('is_noise', False):
                                analyzed_results.append(res)
                        
                        # æŒ‰ç›¸å…³æ€§ + è´¨é‡ç»¼åˆè¯„åˆ†æ’åº
                        analyzed_results.sort(key=lambda x: x['quality_score'], reverse=True)
                        
                        logger.log("INFO", f"ğŸ“Š æ£€ç´¢åˆ° 20 æ¡ç»“æœï¼Œæ­£åœ¨æ‰§è¡Œè´¨é‡è¯„ä¼°ä¸å¤šæ ·æ€§è¿‡æ»¤...", stage="è”ç½‘æœç´¢")
                        
                        # ç­–ç•¥ä¼˜åŒ–ï¼šåŸŸåå¤šæ ·æ€§è¿‡æ»¤ (v2.9.2)
                        diverse_results = []
                        domain_counts = {}
                        
                        for res in analyzed_results:
                            domain = urlparse(res.get('href', '')).netloc.lower()
                            count = domain_counts.get(domain, 0)
                            if count < 3:
                                diverse_results.append(res)
                                domain_counts[domain] = count + 1
                            if len(diverse_results) >= 12:
                                break
                        
                        top_results = diverse_results
                        
                        # è®°å½•æœç´¢ç»“æœå…ƒæ•°æ® (v2.9.4)
                        st.session_state.last_search_results = {
                            'results': top_results,
                            'optimized_query': optimized_query,
                            'duration': search_duration,
                            'total_raw': 20,
                            'selected': len(top_results)
                        }
                        
                        # ç»ˆç«¯è¯¦ç»†æ—¥å¿—è¾“å‡º (Top 5 è¯„åˆ†å±•ç¤º)
                        logger.info("ğŸ† è”ç½‘æœç´¢è´¨é‡æ’è¡Œ (Top 5):")
                        for idx, res in enumerate(top_results[:5], 1):
                            domain = urlparse(res['href']).netloc
                            logger.info(f"   [{idx}] {res['quality_score']} | {domain} | {res['title'][:40]}...")
                        
                        # ç”Ÿæˆå¢å¼ºçš„æœç´¢ç»“æœå±•ç¤º
                        web_context_parts = []
                        quality_summary = []
                        
                        # åœ¨çŠ¶æ€æ å†…éƒ¨æ¸²æŸ“ç»“æœè¯¦æƒ…ï¼Œé»˜è®¤æŠ˜å 
                        st.markdown(f"#### ğŸ” è”ç½‘æœç´¢ç²¾é€‰ç»“æœ (Top {len(top_results)})")
                        st.caption(f"ğŸ¯ æœç´¢å…³é”®è¯ï¼š{optimized_query}")
                        for i, res in enumerate(top_results, 1):
                            emoji, label = res['quality_label']
                            quality_summary.append(f"{emoji} {label}")
                            
                            # æ„å»ºç»“æœå†…å®¹ (ç”¨äºæ³¨å…¥ Prompt)
                            result_content = f"[{i}] {emoji} {res['title']}\n"
                            result_content += f"ğŸ“ æ‘˜è¦: {res['summary']}\n"
                            if res['key_points']:
                                result_content += f"ğŸ¯ è¦ç‚¹: {'; '.join(res['key_points'][:2])}\n"
                            result_content += f"ğŸ”— æ¥æº: {res['href']}"
                            
                            web_context_parts.append(result_content)
                            
                            # å‰ç«¯æ˜¾ç¤º
                            with st.container():
                                st.markdown(f"**{i}. {emoji} {res['title']}**")
                                st.caption(f"{res['summary'][:150]}...")
                                st.markdown(f"ğŸ”— [{urlparse(res['href']).netloc}]({res['href']})")
                                if i < len(top_results): st.divider()
                        
                        # ç”Ÿæˆæœç´¢ç»Ÿè®¡ä¿¡æ¯
                        stats_info = f"â±ï¸ æœç´¢è€—æ—¶: {search_duration}ç§’ | ğŸ“Š æ£€ç´¢é‡: 20æ¡ | ğŸ† ç²¾é€‰æ³¨å…¥: {len(top_results)}æ¡ | ğŸ“ˆ è´¨é‡åˆ†å¸ƒ: {', '.join(quality_summary[:3])}..."
                        
                        web_context = f"\n\n#### è”ç½‘æœç´¢å®æ—¶ä¿¡æ¯\n{stats_info}\n\n" + "\n\n".join(web_context_parts) + "\n\n"
                        # æ ¸å¿ƒï¼šå°†è”ç½‘ä¿¡æ¯æ³¨å…¥ä¸Šä¸‹æ–‡
                        final_prompt = f"{web_context}\nç”¨æˆ·åŸå§‹é—®é¢˜ï¼š{user_display_prompt}"
                        
                        logger.info(f"âœ… è”ç½‘æœç´¢å®Œæˆï¼Œå·²å°†ä¿¡æ¯æ³¨å…¥ä¸Šä¸‹æ–‡")
                        status.update(label=f"âœ… å·²ç²¾é€‰ {len(top_results)} æ¡é«˜åˆ†è”ç½‘ç»“æœ (æ£€ç´¢ 20 æ¡, è€—æ—¶ {search_duration}s)", state="complete")
                    else:
                        logger.warning("âš ï¸ è”ç½‘æœç´¢æœªè¿”å›ç»“æœ")
                        status.update(label="âš ï¸ è”ç½‘æœç´¢æœªæ‰¾åˆ°ç›¸å…³ç»“æœ", state="error")
            except ImportError:
                logger.error("âŒ æœªå®‰è£… duckduckgo_search åº“")
                st.error("æœªå®‰è£…è”ç½‘æœç´¢ä¾èµ–ï¼Œè¯·è¿è¡Œ `pip install duckduckgo-search`")
            except Exception as e:
                logger.error(f"âŒ è”ç½‘æœç´¢å¼‚å¸¸: {str(e)}")
                st.warning("è”ç½‘æœç´¢æš‚æ—¶ä¸å¯ç”¨ï¼Œå°†ä»…ä½¿ç”¨æœ¬åœ°çŸ¥è¯†åº“å›ç­”")
        
        
        # å¤„ç†å¼•ç”¨å†…å®¹
        if st.session_state.get("quote_content"):
            quoted_text = st.session_state.quote_content
            # é™åˆ¶å¼•ç”¨é•¿åº¦ï¼Œé˜²æ­¢ prompt è¿‡é•¿
            if len(quoted_text) > 2000:
                quoted_text = quoted_text[:2000] + "...(å·²æˆªæ–­)"
            
            # æ„å»ºåŒ…å«å¼•ç”¨çš„ prompt
            original_prompt_temp = final_prompt
            final_prompt = f"åŸºäºä»¥ä¸‹å¼•ç”¨å†…å®¹ï¼š\n> {quoted_text}\n\n{original_prompt_temp}"
            # æ›´æ–°æ˜¾ç¤ºç”¨çš„ promptï¼ŒåŠ å…¥å¼•ç”¨æ ·å¼
            user_display_prompt = f"ğŸ“Œ **å¼•ç”¨å†…å®¹**:\n> {quoted_text[:100]}...\n\n{user_display_prompt}"
            
            # æ¸…é™¤å¼•ç”¨çŠ¶æ€
            st.session_state.quote_content = None
            logger.info("ğŸ“Œ å·²åº”ç”¨å¼•ç”¨å†…å®¹")
        
        # --- æ™ºèƒ½ç ”ç©¶ (Deep Research) è¿›é˜¶æ¨¡å¼ (v2.9.2) - ä¸“å®¶ä¼šå®¡ä¸å¤šç»´åˆæˆ ---
        research_critique = ""
        expert_perspectives = ""
        if st.session_state.get('enable_deep_research', False):
            # ä¸“å®¶ä¼šå®¡å¿…é¡»åœ¨æ£€ç´¢ä¹‹å‰å®Œæˆï¼Œå› ä¸ºå…¶ç»“æœè¦ä½œä¸ºæ£€ç´¢çš„å¢å¼ºèƒŒæ™¯
            with st.status("ğŸ”¬ æ™ºèƒ½ç ”ç©¶ï¼šä¸“å®¶ç»„ä¼šå®¡ä¸­...", expanded=False) as status:
                try:
                    from llama_index.core import Settings
                    llm = Settings.llm
                    
                    if st.session_state.get('stop_generation'): raise InterruptedError("User stopped")

                    # 1. è§’è‰²åˆ¤å®š (åŸºäºåŸå§‹é—®é¢˜ï¼Œé¿å…å—ç½‘é¡µå™ªéŸ³å¹²æ‰°)
                    st.write("ğŸ­ æ­£åœ¨å¬é›†ç›¸å…³é¢†åŸŸä¸“å®¶...")
                    role_response = llm.complete(f"é’ˆå¯¹é—®é¢˜ï¼š'{user_display_prompt}'ï¼Œåˆ—å‡º3ä¸ªæœ€ä¸“ä¸šçš„è§’è‰²åç§°ï¼Œé€—å·åˆ†éš”ã€‚")
                    roles = role_response.text.strip()
                    logger.log("INFO", f"ğŸ­ æ™ºèƒ½ç ”ç©¶ï¼šè¯†åˆ«åˆ°ä¸“å®¶è§’è‰² - {roles}", stage="æ™ºèƒ½ç ”ç©¶")
                    
                    if st.session_state.get('stop_generation'): raise InterruptedError("User stopped")

                    # 2. ä¸“å®¶è§†è§’ç¢°æ’ (ä¸“å®¶ä»¬éœ€è¦å‚è€ƒè”ç½‘ä¿¡æ¯ï¼)
                    st.write(f"ğŸ’¬ æ­£åœ¨å¾è¯¢ä¸“å®¶æ„è§: {roles}...")
                    synthesis_prompt = (
                        f"ä½œä¸ºã€{roles}ã€‘ï¼Œè¯·ç»“åˆä»¥ä¸‹å‚è€ƒä¿¡æ¯å’Œç”¨æˆ·é—®é¢˜ï¼Œæä¾›æ·±åº¦ä¸“ä¸šæ´å¯Ÿï¼š\n"
                        f"{final_prompt}\n\n"
                        "è¦æ±‚ï¼šæ¯ä¸ªè§†è§’çº¦ 100 å­—ï¼Œä¾§é‡äºæŠ€æœ¯å¯è¡Œæ€§ã€æ½œåœ¨é£é™©æˆ–å‰ç»æ€§å»ºè®®ã€‚"
                    )
                    synthesis_response = llm.complete(synthesis_prompt)
                    expert_perspectives = synthesis_response.text
                    
                    if st.session_state.get('stop_generation'): raise InterruptedError("User stopped")

                    # 3. é€»è¾‘å®¡è®¡
                    st.write("ğŸ§  æ­£åœ¨æ‰§è¡Œé€»è¾‘å®¡è®¡ä¸ä¸€è‡´æ€§æ£€æŸ¥...")
                    critique_prompt = f"è¯·å®¡è®¡ä»¥ä¸‹ä¸“å®¶è§‚ç‚¹æ˜¯å¦å­˜åœ¨é€»è¾‘çŸ›ç›¾æˆ–ä¿¡æ¯åå·®ï¼š\n{expert_perspectives}"
                    critique_response = llm.complete(critique_prompt)
                    research_critique = critique_response.text
                    
                    # 4. æœ€ç»ˆåˆæˆå…¨æ™¯ç ”ç©¶ Prompt
                    final_prompt = (
                        f"ã€ç ”ç©¶èƒŒæ™¯ (è”ç½‘ä¿¡æ¯)ã€‘:\n{final_prompt}\n\n"
                        f"ã€ä¸“å®¶ä¼šå®¡è§†è§’ã€‘:\n{expert_perspectives}\n\n"
                        f"ã€å®¡è®¡ä¿®æ­£æ„è§ã€‘: {research_critique}\n\n"
                        f"ã€æŒ‡ä»¤ã€‘: è¯·ç»“åˆä¸Šè¿°è”ç½‘èƒŒæ™¯ã€å¤šç»´è§†è§’å’Œå®¡è®¡æ„è§ï¼Œå¹¶å»ä½ çš„æœ¬åœ°çŸ¥è¯†åº“ä¸­æ£€ç´¢è¿›ä¸€æ­¥çš„äº‹å®ï¼Œä¸ºç”¨æˆ·æä¾›ä¸€ä»½æœ€ç»ˆçš„ã€æå…·æ·±åº¦çš„ä¸“ä¸šå…¨æ™¯ç ”ç©¶æŠ¥å‘Šã€‚"
                    )
                    status.update(label="âœ… ä¸“å®¶ä¼šå®¡å®Œæˆï¼Œæ­£åœ¨æ±‡æ€»å…¨æ™¯æŠ¥å‘Š", state="complete")
                    st.write(f"ğŸ‘¥ **ä¸“å®¶ç»„**: {roles}")
                    with st.expander("ğŸ§ æŸ¥çœ‹å®¡è®¡ç»†èŠ‚"):
                        st.write(research_critique)
                    
                    # è®°å½•ä¸“å®¶ä¼šå®¡å…ƒæ•°æ® (v2.9.4)
                    st.session_state.last_research_details = {
                        'roles': roles,
                        'perspectives': expert_perspectives,
                        'critique': research_critique
                    }
                    
                    logger.log("SUCCESS", "âœ… ä¸“å®¶ä¼šå®¡å…¨æµç¨‹å®Œæˆ", stage="æ™ºèƒ½ç ”ç©¶", details={"experts": roles})
                
                except InterruptedError:
                    status.update(label="â¹ ç ”ç©¶è¿›ç¨‹å·²åœæ­¢", state="error")
                except Exception as e:
                    status.update(label="âš ï¸ ä¸“å®¶ä¼šå®¡é™çº§", state="error")
                    logger.error(f"ğŸ”¬ æ™ºèƒ½ç ”ç©¶å¼‚å¸¸: {e}")
        
        logger.log("INFO", f"ç”¨æˆ·æé—®: {final_prompt}", stage="æŸ¥è¯¢å¯¹è¯", details={"kb_name": active_kb_name})
        
        # æ£€æŸ¥é‡å¤æŸ¥è¯¢ï¼ˆæœ€è¿‘3æ¬¡ï¼‰
        recent_queries = [m['content'] for m in st.session_state.messages[-6:] if m['role'] == 'user']
        if final_prompt in recent_queries:
            st.info("ğŸ’¡ æ‚¨åˆšæ‰å·²ç»é—®è¿‡ç›¸åŒçš„é—®é¢˜ï¼Œå¯ä»¥æŸ¥çœ‹ä¸Šé¢çš„å›ç­”æˆ–å°è¯•æ¢ä¸ªè§’åº¦æé—®")
            st.session_state.is_processing = False
            st.stop()
        
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        if active_kb_name: HistoryManager.save_session(active_kb_name, state.get_messages(), st.session_state.get('current_session_id'))

        # UI ä»…æ˜¾ç¤ºåŸå§‹é—®é¢˜æˆ–å¸¦å¼•ç”¨çš„ç®€æ´ç‰ˆ
        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"): st.markdown(user_display_prompt)
        
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            msg_placeholder = st.empty()
            
            # ä½¿ç”¨ä¸€ä¸ªè¿è´¯çš„spinneråŒ…è£…æ•´ä¸ªé—®ç­”æµç¨‹
            with st.spinner("ğŸ¤– æ­£åœ¨æ€è€ƒå¹¶å‡†å¤‡å®Œæ•´å›ç­”..."):
                try:
                    # å¼€å§‹è®¡æ—¶
                    start_time = time.time()
                    
                    # æ˜¾ç¤ºå¯ç”¨çš„æ£€ç´¢å¢å¼ºåŠŸèƒ½
                    enhancements = []
                    if st.session_state.get('enable_bm25', False):
                        enhancements.append("BM25æ··åˆæ£€ç´¢")
                    if st.session_state.get('enable_rerank', False):
                        enhancements.append("Re-rankingé‡æ’åº")
                    
                    if enhancements:
                        enhancement_str = " + ".join(enhancements)
                        logger.info(f"ğŸ¯ æ£€ç´¢å¢å¼º: {enhancement_str}")
                        logger.log("INFO", f"æ£€ç´¢å¢å¼º: {enhancement_str}", stage="æŸ¥è¯¢å¯¹è¯")
                    
                    with logger.timer("æ£€ç´¢ç›¸å…³æ–‡æ¡£"):
                        logger.log("INFO", "å¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£", stage="æŸ¥è¯¢å¯¹è¯", details={"kb_name": active_kb_name})
                        
                        # ç¡®ä¿ embedding æ¨¡å‹å·²è®¾ç½®
                        embed = get_embed(embed_provider, embed_model, embed_key, embed_url)
                        if embed:
                            Settings.embed_model = embed
                        
                        # æ£€æŸ¥ chat_engine çŠ¶æ€
                        if not st.session_state.get('chat_engine'):
                            raise Exception("èŠå¤©å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆé€‰æ‹©çŸ¥è¯†åº“")
                        
                        # GPUåŠ é€Ÿæ£€ç´¢ - æ‰¹é‡å¤„ç†
                        retrieval_start = time.time()
                        logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢: {final_prompt[:100]}...")
                        response = st.session_state.chat_engine.stream_chat(final_prompt)
                        retrieval_time = time.time() - retrieval_start
                        
                        logger.info(f"ğŸ” æ£€ç´¢è€—æ—¶: {retrieval_time:.2f}s (GPUåŠ é€Ÿ)")
                        
                        full_text = ""
                        # æµå¼è¾“å‡º + èµ„æºæ§åˆ¶
                        token_count = 0 # è¿™é‡Œçš„è®¡æ•°ä»…ç”¨äºè¿›åº¦ä¼°ç®—
                        full_text = ""
                        
                        for token in response.response_gen:
                            # ğŸ›‘ æ£€æŸ¥åœæ­¢ä¿¡å·
                            if st.session_state.get('stop_generation'):
                                st.session_state.stop_generation = False
                                full_text += "\n\nâ¹ **ç”Ÿæˆå·²åœæ­¢**"
                                msg_placeholder.markdown(full_text)
                                break
                            
                            full_text += token
                            msg_placeholder.markdown(full_text + "â–Œ")
                            token_count += 1
                        
                        msg_placeholder.markdown(full_text)
                    
                    # æå– token ç»Ÿè®¡ (ä¼˜å…ˆä½¿ç”¨çœŸå®æ•°æ®)
                    prompt_tokens = 0
                    completion_tokens = 0
                    
                    if hasattr(response, 'raw') and response.raw:
                        usage = response.raw.get('usage', {})
                        prompt_tokens = usage.get('prompt_tokens', 0)
                        completion_tokens = usage.get('completion_tokens', 0)
                    
                    # å¦‚æœæ²¡æœ‰çœŸå® Usageï¼Œåˆ™è¿›è¡Œä¼°ç®—
                    if completion_tokens == 0:
                        # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦çº¦0.6 tokenï¼Œè‹±æ–‡å­—ç¬¦çº¦0.25 token (WordCount)
                        # è¿™é‡Œä½¿ç”¨æ›´é€šç”¨çš„ä¼°ç®—ï¼šä¸­æ–‡ * 1.5, è‹±æ–‡ * 0.5 (token count)
                        # æˆ–è€…ç›´æ¥æ˜¾ç¤ºå­—ç¬¦æ•°æ›´å‡†ç¡®
                        total_chars = len(full_text)
                        chinese_chars = len(re.findall(r'[\u4e00-\u9fa5]', full_text))
                        # æ··åˆä¼°ç®—
                        completion_tokens = int((chinese_chars * 1.5) + ((total_chars - chinese_chars) * 0.3))
                        token_count = completion_tokens # æ›´æ–°ä¸ºæ›´å‡†ç¡®çš„ä¼°ç®—å€¼
                    else:
                        token_count = completion_tokens # ä½¿ç”¨çœŸå®å€¼

                    # å¤šæ ¸å¹¶è¡Œå¤„ç†èŠ‚ç‚¹
                    srcs = []
                    if response.source_nodes:
                        logger.log("INFO", f"æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³æ–‡æ¡£", stage="æŸ¥è¯¢å¯¹è¯", details={"kb_name": active_kb_name})
                        logger.data_summary("æ£€ç´¢ç»“æœ", {
                            "æŸ¥è¯¢": final_prompt[:50] + "..." if len(final_prompt) > 50 else final_prompt,
                            "ç›¸å…³æ–‡æ¡£": len(response.source_nodes),
                            "çŸ¥è¯†åº“": active_kb_name
                        })
                        
                        # å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†èŠ‚ç‚¹ï¼ˆçœŸæ­£åˆ©ç”¨å¤šæ ¸CPUï¼‰
                        max_workers = max(2, os.cpu_count() - 1)  # ä¿ç•™1æ ¸ç»™ç³»ç»Ÿ
                        
                        # æå–èŠ‚ç‚¹æ•°æ®ï¼ˆåºåˆ—åŒ–å‹å¥½ï¼‰
                        node_data = []
                        for node in response.source_nodes:
                            # å®‰å…¨æå–æ–‡æœ¬
                            text = ''
                            try:
                                if hasattr(node, 'get_text'):
                                    text = node.get_text()
                                elif hasattr(node, 'text'):
                                    text = node.text
                                elif hasattr(node, 'node') and hasattr(node.node, 'text'):
                                    text = node.node.text
                                else:
                                    text = str(node)[:150]
                            except:
                                text = str(node)[:150]
                            
                            node_data.append({
                                'metadata': getattr(node, 'metadata', {}),
                                'score': getattr(node, 'score', 0.0),
                                'text': text
                            })
                        
                        # ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œå™¨å¤„ç†èŠ‚ç‚¹ï¼ˆä¼˜åŒ–å¹¶è¡Œé˜ˆå€¼ï¼‰
                        executor = ParallelExecutor()
                        tasks = [(d, active_kb_name) for d in node_data]
                        # å¯ç”¨çœŸæ­£çš„å¹¶è¡Œå¤„ç†ï¼Œé™ä½é˜ˆå€¼åˆ°2ä¸ªèŠ‚ç‚¹
                        parallel_threshold = 2
                        srcs = [s for s in executor.execute(process_node_worker, tasks, threshold=parallel_threshold) if s]
                        
                        if len(node_data) >= parallel_threshold:
                            logger.info(f"âš¡ å¹¶è¡Œå¤„ç†: {len(srcs)} ä¸ªèŠ‚ç‚¹ (é˜ˆå€¼: {parallel_threshold})")
                        else:
                            logger.info(f"âš¡ å•èŠ‚ç‚¹å¤„ç†: {len(srcs)} ä¸ªèŠ‚ç‚¹")
                    
                    logger.log("SUCCESS", "å›ç­”ç”Ÿæˆå®Œæˆ", stage="æŸ¥è¯¢å¯¹è¯", details={
                        "kb_name": active_kb_name, 
                        "model": llm_model, 
                        "role": role_name,
                        "tokens": token_count, 
                        "prompt_tokens": prompt_tokens, 
                        "completion_tokens": completion_tokens
                    })
                    
                    # è®¡ç®—æ€»è€—æ—¶
                    total_time = time.time() - start_time
                    logger.complete_operation(f"æŸ¥è¯¢å®Œæˆ (è€—æ—¶ {total_time:.2f}s)")
                    
                    # å‡†å¤‡ç»Ÿè®¡ä¿¡æ¯
                    tokens_per_sec = token_count / total_time if total_time > 0 else 0
                    stats = {
                        "time": total_time,
                        "tokens": token_count,
                        "tokens_per_sec": tokens_per_sec,
                        "prompt_tokens": prompt_tokens,
                        "completion_tokens": completion_tokens
                    }
                    
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": full_text, 
                        "sources": srcs,
                        "stats": stats,
                        "prompt_role": role_name,
                        "search_results": st.session_state.get('last_search_results'),
                        "research_details": st.session_state.get('last_research_details')
                    })
                    
                    # æ¸…ç†å•æ¬¡ä¼šè¯ä¸´æ—¶å˜é‡
                    st.session_state.last_search_results = None
                    st.session_state.last_optimized_query = None
                    st.session_state.last_research_details = None
                    
                    # ç”Ÿæˆæ¨èé—®é¢˜ï¼ˆåœ¨spinnerå†…å®Œæˆï¼‰
                    # ç»„åˆä¸Šä¸‹æ–‡ï¼šç”¨æˆ·é—®é¢˜ + AIå›ç­”
                    existing_questions = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
                    last_user_query = existing_questions[-1] if existing_questions else ""
                    combined_context = f"ç”¨æˆ·é—®é¢˜: {last_user_query}\nAIå›ç­”: {full_text}"
                    
                    existing_questions.extend(st.session_state.question_queue)
                    existing_questions.extend(st.session_state.get('suggestions_history', []))
                    
                    # ä½¿ç”¨ç»Ÿä¸€æ¨èå¼•æ“
                    # ä¼˜å…ˆä½¿ç”¨ active_kb_name ç¡®ä¿é…ç½®æ­£ç¡®åŠ è½½
                    suggestion_kb = active_kb_name or st.session_state.get('current_kb_name')
                    engine = get_unified_suggestion_engine(suggestion_kb)
                    
                    initial_sugs = engine.generate_suggestions(
                        context=combined_context,
                        source_type='chat',
                        query_engine=st.session_state.chat_engine if st.session_state.get('chat_engine') else None,
                        num_questions=3,
                        existing_history=existing_questions
                    )
                    
                    logger.info(f"ğŸ”§ æ¨èå¼•æ“è¿”å› {len(initial_sugs)} ä¸ªé—®é¢˜")
                    
                    if initial_sugs:
                        st.session_state.suggestions_history = initial_sugs[:3]
                        logger.info(f"âœ¨ ç”Ÿæˆ {len(initial_sugs)} ä¸ªæ¨èé—®é¢˜")
                        for i, q in enumerate(initial_sugs[:3], 1):
                            logger.info(f"   {i}. {q}")
                    else:
                        logger.warning("âš ï¸ æ¨èå¼•æ“æœªè¿”å›ä»»ä½•é—®é¢˜ (ä¸¥æ ¼æ¨¡å¼)")
                        st.session_state.suggestions_history = []
                    
                    # å»¶è¿Ÿä¿å­˜ï¼šç¡®è®¤æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸåå†ä¿å­˜
                    if active_kb_name: HistoryManager.save_session(active_kb_name, state.get_messages(), st.session_state.get('current_session_id'))
                    
                    # é‡Šæ”¾å†…å­˜
                    cleanup_memory()
                    logger.info("ğŸ§¹ å¯¹è¯å®Œæˆï¼Œå†…å­˜å·²æ¸…ç†")
                    
                    st.session_state.is_processing = False  # å¤„ç†å®Œæˆ
                    
                    # æ•´ä½“å¤„ç†å®Œæˆåé¦ˆ
                    st.toast("âœ… å›ç­”ç”Ÿæˆå®Œæ¯•", icon="ğŸ‰")
                    st.rerun()
                
                except Exception as e: 
                    error_msg = str(e)
                    print(f"âŒ æŸ¥è¯¢å‡ºé”™: {error_msg}\n")
                    logger.error(f"æŸ¥è¯¢å¤„ç†å¤±è´¥: {error_msg}")
                    
                    # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                    if "èŠå¤©å¼•æ“æœªåˆå§‹åŒ–" in error_msg:
                        st.error("âŒ èŠå¤©å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆé€‰æ‹©çŸ¥è¯†åº“")
                    elif "stream_chat" in error_msg:
                        st.error("âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€")
                    else:
                        st.error(f"âŒ æŸ¥è¯¢å‡ºé”™: {error_msg}")
                    
                    # å‘ç”Ÿé”™è¯¯ï¼Œå›æ»šæœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯ assistant ç”Ÿæˆçš„ï¼‰
                    if st.session_state.messages and st.session_state.messages[-1]['role'] == 'assistant':
                        st.session_state.messages.pop()
                    
                    # é‡Šæ”¾å†…å­˜
                    cleanup_memory()
                    logger.info("ğŸ§¹ é”™è¯¯å¤„ç†å®Œæˆï¼Œå†…å­˜å·²æ¸…ç†")
                    st.session_state.is_processing = False
                    st.rerun()
