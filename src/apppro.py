# åˆå§‹åŒ–ç¯å¢ƒé…ç½®
# ç¯å¢ƒå˜é‡è®¾ç½® - å‡å°‘å¯åŠ¨è­¦å‘Š
import os
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'


import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.core.environment import initialize_environment
initialize_environment()

import os
# åœ¨æœ€å¼€å§‹è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¦ç”¨PaddleOCRè¯¦ç»†æ—¥å¿—
import os
os.environ['GLOG_minloglevel'] = '3'  # åªæ˜¾ç¤ºè‡´å‘½é”™è¯¯
os.environ['FLAGS_logtostderr'] = '0'  # ä¸è¾“å‡ºåˆ°stderr
os.environ['PADDLE_LOG_LEVEL'] = '50'  # æœ€é«˜çº§åˆ«ï¼Œå‡ ä¹ä¸è¾“å‡º
os.environ['FLAGS_v'] = '0'  # ç¦ç”¨è¯¦ç»†æ—¥å¿—
os.environ['GLOG_v'] = '0'  # ç¦ç”¨GLOGè¯¦ç»†æ—¥å¿—

# è®¾ç½®å¤šè¿›ç¨‹ç›¸å…³ç¯å¢ƒå˜é‡ï¼Œå½±å“è¿›ç¨‹è°ƒåº¦
os.environ['OMP_NUM_THREADS'] = '1'  # æ¯ä¸ªè¿›ç¨‹åªç”¨1ä¸ªçº¿ç¨‹
os.environ['MKL_NUM_THREADS'] = '1'  # Intel MKLåªç”¨1ä¸ªçº¿ç¨‹
os.environ['OPENBLAS_NUM_THREADS'] = '1'  # OpenBLASåªç”¨1ä¸ªçº¿ç¨‹
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'  # Apple Accelerateåªç”¨1ä¸ªçº¿ç¨‹

import streamlit as st

# é˜²æ­¢HTMLå†…å®¹è¢«æˆªæ–­
st.set_page_config(
    page_title="RAG Pro Max",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®ä¸æˆªæ–­HTMLæ˜¾ç¤º
import streamlit.components.v1 as components

import shutil
import time
import requests
import ollama
import re
import json
import zipfile
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp

# å¼•å…¥æ–°çš„ä¼˜åŒ–ç»„ä»¶
from src.utils.enhanced_ocr_optimizer import enhanced_ocr_optimizer
from src.ui.progress_monitor import progress_monitor
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, StorageContext, load_index_from_storage
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.ollama import Ollama
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.schema import Document

# å¯¼å…¥è‡ªå®šä¹‰åµŒå…¥
from src.custom_embeddings import create_custom_embedding

# å¼•å…¥æ—¥å¿—æ¨¡å—
from src.app_logging import LogManager
logger = LogManager()
# terminal_logger å·²è¢« logger æ›¿ä»£
from src.chat_utils_improved import generate_follow_up_questions_safe as generate_follow_up_questions

# å¼•å…¥å…ƒæ•°æ®ç®¡ç†
from src.metadata_manager import MetadataManager

# å¼•å…¥å·¥å…·æ¨¡å—
from src.utils.memory import cleanup_memory, get_memory_stats
from src.utils.model_manager import (
    load_embedding_model,
    load_llm_model,
    set_global_embedding_model,
    set_global_llm_model
)
from src.utils.document_processor import (
    sanitize_filename,
    get_file_size_str,
    get_file_type,
    get_file_info,
    get_relevance_label,
    load_pptx_file
)

# å¼•å…¥é…ç½®ç®¡ç†
from src.config import ConfigLoader, ManifestManager

# å¼•å…¥èŠå¤©ç®¡ç†
from src.chat import HistoryManager, SuggestionManager

# å¼•å…¥ UI æ¨¡å—
from src.ui.page_style import PageStyle
from src.ui.sidebar_config import SidebarConfig

# å¼•å…¥å·¥å…·å‡½æ•°
from src.utils.app_utils import (
    get_kb_embedding_dim,
    generate_doc_summary,
    remove_file_from_manifest,
    initialize_session_state,
    show_first_time_guide,
    handle_kb_switching
)

# å¼•å…¥ä¸»æ§åˆ¶å™¨
from src.core.main_controller import MainController

# å¼•å…¥çŸ¥è¯†åº“å¤„ç†å™¨
from src.kb.kb_processor import KnowledgeBaseProcessor

# å¼•å…¥æ–‡æ¡£è§£æå™¨
from src.processors.document_parser import _parse_single_doc, _parse_batch_docs

# å¼•å…¥èµ„æºä¿æŠ¤
from src.utils.adaptive_throttling import get_resource_guard
import psutil as psutil_main

# åˆå§‹åŒ–èµ„æºä¿æŠ¤
resource_guard = get_resource_guard()

# å¼•å…¥çŸ¥è¯†åº“ç®¡ç†
from src.kb import KBManager
kb_manager = KBManager()

# æ€§èƒ½ç›‘æ§ (v1.5.1)
from src.ui.performance_monitor import get_monitor
perf_monitor = get_monitor()

# æŸ¥è¯¢æ”¹å†™ (v1.6)
from src.query.query_rewriter import QueryRewriter

# çŸ¥è¯†åº“åç§°ä¼˜åŒ–å™¨
from src.utils.kb_name_optimizer import KBNameOptimizer, sanitize_filename

# æ–‡æ¡£é¢„è§ˆ (v1.6)
from src.kb.document_viewer import DocumentViewer
from src.ui.document_preview import show_upload_preview, show_kb_documents

# æ–‡æ¡£è¯¦æƒ…å¯¹è¯æ¡†
@st.dialog("ğŸ“„ æ–‡æ¡£è¯¦æƒ…")
def show_document_detail_dialog(kb_name: str, file_info: dict) -> None:
    """æ˜¾ç¤ºæ–‡æ¡£è¯¦æƒ…å¯¹è¯æ¡†"""
    st.subheader(f"ğŸ“„ {file_info['name']}")
    
    # åŸºæœ¬ä¿¡æ¯ - ä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“Š åŸºæœ¬ä¿¡æ¯")
        st.markdown(f"**ğŸ“‚ è·¯å¾„**: `{file_info.get('file_path', 'N/A')}`")
        st.markdown(f"**ğŸ“ å¤§å°**: {file_info.get('size', 'æœªçŸ¥')} ({file_info.get('size_bytes', 0):,} å­—èŠ‚)")
        st.markdown(f"**ğŸ“„ ç±»å‹**: {file_info.get('type', 'æœªçŸ¥')}")
        st.markdown(f"**ğŸŒ è¯­è¨€**: {file_info.get('language', 'æœªçŸ¥')}")
        
    with col2:
        st.markdown("### ğŸ•’ æ—¶é—´ä¿¡æ¯")
        st.markdown(f"**ğŸ“… æ·»åŠ æ—¶é—´**: {file_info.get('added_at', 'æœªçŸ¥')}")
        st.markdown(f"**ğŸ•’ æœ€åè®¿é—®**: {file_info.get('last_accessed', 'ä»æœªè®¿é—®') or 'ä»æœªè®¿é—®'}")
        st.markdown(f"**ğŸ“ ç›®å½•**: {file_info.get('parent_folder', 'æœªçŸ¥')}")
        st.markdown(f"**ğŸ” å“ˆå¸Œ**: `{file_info.get('file_hash', 'N/A')}`")
    
    # ç»Ÿè®¡ä¿¡æ¯
    st.markdown("### ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
    stat_col1, stat_col2, stat_col3 = st.columns(3)
    stat_col1.metric("ğŸ§© å‘é‡ç‰‡æ®µ", len(file_info.get('doc_ids', [])))
    stat_col2.metric("ğŸ”¥ æŸ¥è¯¢å‘½ä¸­", file_info.get('hit_count', 0))
    stat_col3.metric("â­ å¹³å‡è¯„åˆ†", f"{file_info.get('avg_score', 0.0):.2f}" if file_info.get('avg_score') else 'N/A')
    
    # åˆ†ç±»å’Œå…³é”®è¯
    if file_info.get('category') or file_info.get('keywords'):
        st.markdown("### ğŸ·ï¸ åˆ†ç±»æ ‡ç­¾")
        tag_col1, tag_col2 = st.columns(2)
        tag_col1.markdown(f"**ğŸ“š åˆ†ç±»**: {file_info.get('category', 'æœªåˆ†ç±»')}")
        if file_info.get('keywords'):
            tag_col2.markdown(f"**ğŸ·ï¸ å…³é”®è¯**: {', '.join(file_info.get('keywords', [])[:8])}")
    
    # å‘é‡ç‰‡æ®µID
    if file_info.get('doc_ids'):
        st.markdown("### ğŸ§¬ å‘é‡ç‰‡æ®µID")
        with st.expander(f"æŸ¥çœ‹ {len(file_info['doc_ids'])} ä¸ªç‰‡æ®µID", expanded=False):
            st.text_area(
                "ç‰‡æ®µIDåˆ—è¡¨", 
                value='\n'.join(file_info['doc_ids']), 
                height=200,
                label_visibility="collapsed"
            )
    
    # å…³é—­æŒ‰é’®
    if st.button("âœ… å…³é—­", use_container_width=True):
        st.session_state.show_doc_detail = None
        st.session_state.show_doc_detail_kb = None
        st.rerun()

def generate_smart_kb_name(target_path, cnt, file_types, folder_name):
    """æ™ºèƒ½ç”ŸæˆçŸ¥è¯†åº“åç§° - ä½¿ç”¨ä¼˜åŒ–å™¨ç¡®ä¿å”¯ä¸€æ€§"""
    # ä½¿ç”¨ä¼˜åŒ–å™¨çš„å»ºè®®åç§°åŠŸèƒ½
    suggested_name = KBNameOptimizer.suggest_name_from_content(target_path, cnt, list(file_types.keys()))
    
    # å¦‚æœæ²¡æœ‰å»ºè®®åç§°ï¼Œä½¿ç”¨å¤‡ç”¨é€»è¾‘
    if not suggested_name:
        # åˆ†ææ–‡ä»¶ç±»å‹
        main_types = sorted(file_types.items(), key=lambda x: x[1], reverse=True)
        if not main_types:
            suggested_name = "æ–‡æ¡£çŸ¥è¯†åº“"
        else:
            main_ext = main_types[0][0].replace('.', '').upper()
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹ç”ŸæˆåŸºç¡€åç§°
            type_names = {
                'PDF': 'PDFæ–‡æ¡£åº“', 'DOCX': 'Wordæ–‡æ¡£åº“', 'DOC': 'Wordæ–‡æ¡£åº“',
                'MD': 'Markdownç¬”è®°', 'TXT': 'æ–‡æœ¬æ–‡æ¡£åº“',
                'PY': 'Pythonä»£ç åº“', 'JS': 'JavaScriptä»£ç åº“', 'JAVA': 'Javaä»£ç åº“',
                'XLSX': 'Excelæ•°æ®åº“', 'CSV': 'CSVæ•°æ®é›†',
                'PPT': 'PPTæ¼”ç¤ºåº“', 'PPTX': 'PPTæ¼”ç¤ºåº“',
                'HTML': 'ç½‘é¡µæ–‡æ¡£åº“', 'JSON': 'JSONé…ç½®åº“'
            }
            
            if len(main_types) == 1:
                suggested_name = type_names.get(main_ext, f"{main_ext}æ–‡æ¡£åº“")
            else:
                suggested_name = f"æ··åˆæ–‡æ¡£åº“_{cnt}ä¸ªæ–‡ä»¶"
    
    # ä½¿ç”¨ä¼˜åŒ–å™¨ç¡®ä¿åç§°å”¯ä¸€æ€§ï¼ˆä¼šåœ¨éœ€è¦æ—¶æ·»åŠ æ—¶é—´æˆ³ï¼‰
    from src.core.app_config import output_base
    return KBNameOptimizer.generate_unique_name(suggested_name, output_base)

# å¼•å…¥ RAG å¼•æ“
from src.rag_engine import RAGEngine

# å¼•å…¥èµ„æºç›‘æ§å’Œæ¨¡å‹å·¥å…·
from src.utils.resource_monitor import check_resource_usage, get_system_stats
from src.utils.model_utils import (
    check_ollama_status,
    fetch_remote_models,
    check_hf_model_exists,
    get_kb_embedding_dim,
    auto_switch_model,
    get_model_dimension
)

# å¼•å…¥ UI å±•ç¤ºç»„ä»¶ (Stage 3.1)
from src.ui.display_components import (
    render_message_stats,
    render_source_references,
    get_relevance_label
)

# å¼•å…¥ UI æ¨¡å‹é€‰æ‹©å™¨ (Stage 3.2.1)
from src.ui.model_selectors import (
    render_ollama_model_selector,
    render_openai_model_selector,
    render_hf_embedding_selector
)

# å¼•å…¥ UI é«˜çº§é…ç½® (Stage 3.2.3)

# å¼•å…¥ UI é…ç½®è¡¨å• (Stage 3.2.2)
from src.ui.config_forms import render_basic_config

# å¼•å…¥çŠ¶æ€ç®¡ç†å™¨ (Stage 3.3)
from src.core.state_manager import state

# å¼•å…¥æ–‡æ¡£å¤„ç†å™¨ (Stage 4.1)
from src.processors import UploadHandler, IndexBuilder

# âš ï¸ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œé¿å… OpenAI é»˜è®¤
# ä¸´æ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®© LlamaIndex ä½¿ç”¨æœ¬åœ°æ¨¡å‹
os.environ['LLAMA_INDEX_EMBED_MODEL'] = 'local'

# å…¼å®¹æ—§ä»£ç çš„åŒ…è£…å‡½æ•°
def get_embed(provider, model, key, url):
    """å…¼å®¹æ—§ä»£ç çš„åŒ…è£…å‡½æ•°"""
    return load_embedding_model(provider, model, key, url)

def get_llm(provider, model, key, url, temp):
    """å…¼å®¹æ—§ä»£ç çš„åŒ…è£…å‡½æ•°"""
    return load_llm_model(provider, model, key, url, temp)

# å¼•å…¥æ–‡ä»¶å¤„ç†æ¨¡å—
from src.file_processor import scan_directory_safe


from src.ui.compact_sidebar import render_compact_sidebar
# å¢å¼ºåŠŸèƒ½æ¨¡å— (v1.7.4)
from src.utils.error_handler_enhanced import error_handler
from src.utils.memory_manager_enhanced import memory_manager
from src.ui.performance_dashboard_enhanced import performance_dashboard
from src.ui.user_experience_enhanced import ux_enhancer

# å¼•å…¥å¹¶è¡Œæ‰§è¡Œæ¨¡å—
from src.utils.parallel_executor import ParallelExecutor
from src.utils.safe_parallel_tasks import safe_process_node_worker as process_node_worker, extract_metadata_task

# å¼•å…¥èŠå¤©æ¨¡å— (Stage 7)
from src.chat import ChatEngine, SuggestionManager

# å¼•å…¥é…ç½®æ¨¡å— (Stage 8)
from src.config import ConfigLoader, ConfigValidator

# å¤šè¿›ç¨‹å‡½æ•°ï¼šæ–‡æ¡£åˆ†å—è§£æï¼ˆç§»åˆ°æ¨¡å—çº§åˆ«ï¼‰
# å¼•å…¥æ–‡æ¡£è§£æå™¨
from src.processors.document_parser import _parse_single_doc, _parse_batch_docs

# ==========================================
# 1. é¡µé¢é…ç½®ä¸æ ·å¼
# ==========================================
PageStyle.setup_page()

# æ³¨å…¥ CSS
st.markdown("""
<style>
                        /* ä¿®å¤ç»Ÿè®¡å¡ç‰‡æ˜¾ç¤º */
    [data-testid="metric-container"] {
        background: rgba(248, 249, 251, 0.8) !important;
        border: 1px solid rgba(0, 0, 0, 0.08) !important;
        border-radius: 8px !important;
        padding: 0.75rem !important;
        margin: 0.25rem !important;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1) !important;
        transition: all 0.2s ease !important;
        min-height: 80px !important;
        display: flex !important;
        flex-direction: column !important;
        justify-content: center !important;
    }
    
    [data-testid="metric-container"]:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15) !important;
        border-color: rgba(31, 119, 180, 0.3) !important;
    }
    
    /* ç»Ÿè®¡æ•°å€¼æ ·å¼ */
    [data-testid="metric-container"] [data-testid="metric-value"] {
        font-size: 1.5rem !important;
        font-weight: 700 !important;
        color: #1f77b4 !important;
        line-height: 1.2 !important;
        margin-bottom: 0.25rem !important;
    }
    
    /* ç»Ÿè®¡æ ‡ç­¾æ ·å¼ */
    [data-testid="metric-container"] [data-testid="metric-label"] {
        font-size: 0.85rem !important;
        color: #6c757d !important;
        font-weight: 500 !important;
        text-transform: uppercase !important;
        letter-spacing: 0.5px !important;
    }
    
    /* ç¡®ä¿ç»Ÿè®¡åŒºåŸŸå¸ƒå±€æ­£å¸¸ */
    .stMetric {
        background: transparent !important;
    }
    
    /* ä¿®å¤å¯èƒ½çš„å¸ƒå±€é—®é¢˜ */
    div[data-testid="column"] > div {
        height: auto !important;
    }
    
    /* ä¿®å¤ä¸‹æ‹‰æ¡†æ–‡å­—æˆªæ–­é—®é¢˜ */
    div[data-testid="stSelectbox"] > div > div {
        white-space: normal !important;
        height: auto !important;
        min-height: 40px !important;
    }
    
    /* å¢åŠ ä¾§è¾¹æ å®½åº¦ï¼Œé˜²æ­¢å†…å®¹è¿‡çª„ */
    section[data-testid="stSidebar"] {
        min-width: 350px !important;
        width: 350px !important;
    }
    
    /* ç»Ÿè®¡åŒºåŸŸå®¹å™¨ */
    .stats-container {
        background: white !important;
        border-radius: 10px !important;
        padding: 1rem !important;
        margin: 1rem 0 !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1) !important;
    }
    

    /* æ–‡æ¡£è¯¦æƒ…æŠ˜å ä¼˜åŒ– */
    .document-details {
        background: #f8f9fa !important;
        border-radius: 6px !important;
        padding: 0.75rem !important;
        margin: 0.5rem 0 !important;
        border-left: 3px solid #1f77b4 !important;
    }
    
    .document-summary {
        background: white !important;
        padding: 0.5rem !important;
        border-radius: 4px !important;
        margin-top: 0.5rem !important;
        border: 1px solid #dee2e6 !important;
        font-size: 0.85rem !important;
        line-height: 1.4 !important;
    }
    
    /* æ‰¹é‡æ“ä½œæŒ‰é’® */
    .batch-operations {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 6px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 500 !important;
        transition: all 0.3s ease !important;
    }
    
    .batch-operations:hover {
        transform: translateY(-1px) !important;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3) !important;
    }
    
    /* å¿«é€Ÿé¢„è§ˆæç¤º */
    .preview-tooltip {
        position: absolute !important;
        background: rgba(0,0,0,0.9) !important;
        color: white !important;
        padding: 0.5rem !important;
        border-radius: 4px !important;
        font-size: 0.8rem !important;
        max-width: 300px !important;
        z-index: 1000 !important;
        pointer-events: none !important;
    }
    

        /* å®Œå…¨ä¿®å¤å‚è€ƒç‰‡æ®µæ˜¾ç¤º */
    .reference-snippet {
        background-color: #f8f9fa !important;
        border-left: 3px solid #1f77b4 !important;
        padding: 12px !important;
        margin: 10px 0 !important;
        border-radius: 6px !important;
        font-size: 0.9rem !important;
        line-height: 1.5 !important;
        word-wrap: break-word !important;
        overflow-wrap: break-word !important;
        white-space: pre-wrap !important;
        max-width: 100% !important;
    }
    
    .reference-header {
        font-size: 0.85rem !important;
        color: #666 !important;
        margin-bottom: 8px !important;
        font-weight: 500 !important;
    }
    
    .reference-content {
        color: #333 !important;
        background: white !important;
        padding: 8px 12px !important;
        border-radius: 4px !important;
        border: 1px solid #dee2e6 !important;
        max-height: none !important;
        overflow: visible !important;
        word-break: break-word !important;
    }
    
    /* ç¡®ä¿Streamlitä¸æˆªæ–­HTML */
    .stMarkdown > div {
        max-width: none !important;
        overflow: visible !important;
    }
    
    .stMarkdown div[style*="border-left"] {
        max-width: 100% !important;
        overflow: visible !important;
        word-wrap: break-word !important;
    }
    

    /* å‡å°‘é—´è· */
    .block-container {
        padding-top: 1rem !important;
        padding-bottom: 1rem !important;
    }

    .element-container {
        margin-bottom: 0.2rem !important;
    }
    
    h1, h2, h3 {
        margin: 0.2rem 0 !important;
    }
    
    [data-testid="column"] {
        padding: 0 0.3rem !important;
    }
    
    /* æ–‡ä»¶åˆ—è¡¨ */
    .file-item {
        font-size: 0.8rem !important;
        padding: 0.5rem !important;
        background: rgba(0,0,0,0.02) !important;
        border-radius: 6px !important;
        margin-bottom: 0.3rem !important;
        border: 1px solid rgba(0,0,0,0.05) !important;
    }
    
    /* æ¬¢è¿é¡µé¢ */
    .welcome-box {
        padding: 1.5rem !important;
        border-radius: 10px !important;
        background: rgba(255,75,75,0.02) !important;
        border: 1px solid rgba(255,75,75,0.1) !important;
        text-align: center !important;
        margin: 1rem 0 !important;
    }
    
    /* è¿›åº¦æ¡ */
    .stProgress > div > div {
        border-radius: 4px !important;
        height: 6px !important;
    }
    
    /* å“åº”å¼ */
    @media (max-width: 768px) {
        .main .block-container {
            padding: 0.5rem !important;
        }
    }
</style>""", unsafe_allow_html=True)

# åº”ç”¨å¯åŠ¨æ—¥å¿—
if 'app_initialized' not in st.session_state:
    logger.separator("RAG Pro Max å¯åŠ¨")
    logger.info("åº”ç”¨åˆå§‹åŒ–ä¸­...")
    
    # ç«‹å³è®¾ç½®å…¨å±€LLMï¼ˆç¡®ä¿æ‘˜è¦ç”Ÿæˆç­‰åŠŸèƒ½å¯ç”¨ï¼‰
    try:
        # è¯»å–é…ç½®æ–‡ä»¶è·å–LLMè®¾ç½®
        config_file = "app_config.json"
        if os.path.exists(config_file):
            with open(config_file, 'r') as f:
                config = json.load(f)
            
            llm_provider = config.get('llm_provider', 'Ollama')
            if config.get('llm_type_idx', 0) == 0:  # Ollama
                llm_model = config.get('llm_model_ollama', 'gpt-oss:20b')
                llm_url = config.get('llm_url_ollama', 'http://localhost:11434')
                llm_key = ""
            else:  # OpenAI
                llm_model = config.get('llm_model_openai', 'gpt-3.5-turbo')
                llm_url = config.get('llm_url_openai', 'https://api.openai.com/v1')
                llm_key = config.get('llm_key', '')
            
            # è®¾ç½®å…¨å±€LLM
            set_global_llm_model(llm_provider, llm_model, llm_key, llm_url)
    except Exception as e:
        logger.warning(f"å…¨å±€LLMåˆå§‹åŒ–å¤±è´¥: {e}")
    
    st.session_state.app_initialized = True
    logger.success("åº”ç”¨åˆå§‹åŒ–å®Œæˆ")

# ==========================================
# 2. æœ¬åœ°æŒä¹…åŒ–ä¸å·¥å…·å‡½æ•°
# ==========================================
CONFIG_FILE = "rag_config.json"
HISTORY_DIR = "chat_histories"
UPLOAD_DIR = "temp_uploads" # ä¸´æ—¶ä¸Šä¼ ç›®å½•

# ç¡®ä¿ç›®å½•å­˜åœ¨
for d in [HISTORY_DIR, UPLOAD_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# ä½¿ç”¨æ–°çš„é…ç½®åŠ è½½å™¨ (Stage 8)
defaults = ConfigLoader.load()

def generate_doc_summary(doc_text, filename):
    """
    ç”Ÿæˆå•ä¸ªæ–‡æ¡£çš„æ‘˜è¦ï¼Œä½¿ç”¨å½“å‰çš„ LLM è®¾ç½®ã€‚
    """
    # å±è”½å¤šçº¿ç¨‹è­¦å‘Š
    import warnings
    import logging
    warnings.filterwarnings('ignore')
    logging.getLogger('streamlit').setLevel(logging.ERROR)
    
    if not hasattr(Settings, 'llm'): return "æ€»ç»“å¤±è´¥: LLMæœªåˆå§‹åŒ–"
    try:
        llm = Settings.llm
        summary_prompt = (
            f"ä»¥ä¸‹æ˜¯æ–‡æ¡£ '{filename}' çš„ä¸€ä¸ªç‰‡æ®µå†…å®¹ï¼Œè¯·ç”¨ä¸€æ®µç®€çŸ­çš„ä¸­æ–‡è¯æ€»ç»“å…¶æ ¸å¿ƒå†…å®¹ (ä¸è¶…è¿‡ 80 å­—)ï¼Œç”¨äºæ–‡ä»¶æ¸…å•é¢„è§ˆã€‚å†…å®¹:\n---\n{doc_text[:2000]}..."
        )
        response = llm.complete(summary_prompt)
        return response.text.strip().replace('\n', ' ')\
                             .replace('æ€»ç»“:', '').replace('æ€»ç»“æ˜¯ï¼š', '').strip()
        
    except Exception as e:
        return f"æ€»ç»“å¤±è´¥: {str(e)}"

with st.sidebar:
    # æ¨ªå‘æ ‡ç­¾é¡µå¸ƒå±€
    tab_main, tab_config, tab_monitor, tab_tools, tab_help = st.tabs(["ğŸ  ä¸»é¡µ", "âš™ï¸ é…ç½®", "ğŸ“Š ç›‘æ§", "ğŸ”§ å·¥å…·", "â“ å¸®åŠ©"])
    
    with tab_main:
        # P0æ”¹è¿›1: å¿«é€Ÿå¼€å§‹æ¨¡å¼
        st.markdown("### âš¡ å¿«é€Ÿå¼€å§‹")

        if st.button("âš¡ ä¸€é”®é…ç½®ï¼ˆæ¨èæ–°æ‰‹ï¼‰", type="primary", use_container_width=True, help="è‡ªåŠ¨é…ç½®é»˜è®¤è®¾ç½®ï¼Œ1åˆ†é’Ÿå¼€å§‹ä½¿ç”¨"):
            # ä½¿ç”¨æ–°çš„é…ç½®åŠ è½½å™¨å¿«é€Ÿé…ç½® (Stage 8)
            ConfigLoader.quick_setup()
            st.success("âœ… å·²ä½¿ç”¨é»˜è®¤é…ç½®ï¼\n\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼šåˆ›å»ºçŸ¥è¯†åº“ â†’ ä¸Šä¼ æ–‡æ¡£ â†’ å¼€å§‹å¯¹è¯")
            time.sleep(2)
            st.rerun()

        st.caption("ğŸ’¡ æˆ–æ‰‹åŠ¨é…ç½®ï¼ˆé«˜çº§ç”¨æˆ·ï¼‰")

        st.markdown("---")
        st.markdown("### ğŸ’  çŸ¥è¯†åº“æ§åˆ¶å°")
        if "model_list" not in st.session_state: st.session_state.model_list = []

        # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ vector_db_storage
        default_output_path = os.path.join(os.getcwd(), "vector_db_storage")
        output_base = st.text_input("å­˜å‚¨æ ¹ç›®å½•", value=default_output_path)
        existing_kbs = (setattr(kb_manager, "base_path", output_base), kb_manager.list_all())[1]

        # --- æ ¸å¿ƒå¯¼èˆª ---
        st.markdown("#### ğŸ“š çŸ¥è¯†åº“ç®¡ç†")

        # çŸ¥è¯†åº“æœç´¢/è¿‡æ»¤
        if len(existing_kbs) > 5:
            search_kb = st.text_input(
                "ğŸ” æœç´¢çŸ¥è¯†åº“",
                placeholder="è¾“å…¥å…³é”®è¯è¿‡æ»¤...",
                key="search_kb",
                label_visibility="collapsed"
            )
            if search_kb:
                filtered_kbs = [kb for kb in existing_kbs if search_kb.lower() in kb.lower()]
                st.caption(f"æ‰¾åˆ° {len(filtered_kbs)} ä¸ªåŒ¹é…çš„çŸ¥è¯†åº“")
            else:
                filtered_kbs = existing_kbs
        else:
            filtered_kbs = existing_kbs

        nav_options = ["â• æ–°å»ºçŸ¥è¯†åº“..."] + [f"ğŸ“‚ {kb}" for kb in filtered_kbs]

        # é»˜è®¤é€‰æ‹©"æ–°å»ºçŸ¥è¯†åº“"ï¼Œé¿å…è‡ªåŠ¨åŠ è½½å¤§çŸ¥è¯†åº“
        default_idx = 0
        if "current_nav" in st.session_state and st.session_state.current_nav in nav_options:
            default_idx = nav_options.index(st.session_state.current_nav)
        # æ³¨é‡Šæ‰è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“çš„é€»è¾‘
        # elif len(nav_options) > 1:
        #     default_idx = 1 

        selected_nav = st.selectbox("é€‰æ‹©å½“å‰çŸ¥è¯†åº“", nav_options, index=default_idx, label_visibility="collapsed")

        # å¸è½½çŸ¥è¯†åº“æŒ‰é’®ï¼ˆé‡Šæ”¾å†…å­˜ï¼‰
        if not (selected_nav == "â• æ–°å»ºçŸ¥è¯†åº“...") and st.session_state.get('chat_engine') is not None:
            if st.button("ğŸ”“ å¸è½½çŸ¥è¯†åº“ï¼ˆé‡Šæ”¾å†…å­˜ï¼‰", use_container_width=True, help="é‡Šæ”¾å½“å‰çŸ¥è¯†åº“å ç”¨çš„å†…å­˜èµ„æº"):
                st.session_state.chat_engine = None
                st.session_state.current_kb_id = None
                cleanup_memory()
                st.toast("âœ… çŸ¥è¯†åº“å·²å¸è½½ï¼Œå†…å­˜å·²é‡Šæ”¾")
                st.rerun()

        if selected_nav != st.session_state.get('current_nav'):
            st.session_state.pop('suggestions_history', None) 

        st.session_state.current_nav = selected_nav

        is_create_mode = (selected_nav == "â• æ–°å»ºçŸ¥è¯†åº“...")
        current_kb_name = selected_nav.replace("ğŸ“‚ ", "") if not is_create_mode else None

        # --- æ•°æ®æºé…ç½®åŒº ---
        if is_create_mode:
            st.caption("ğŸ› ï¸ åˆ›å»ºæ–°çŸ¥è¯†åº“")
        else:
            st.caption(f"ğŸ› ï¸ ç®¡ç†: {current_kb_name}")

        with st.container(border=True):
            # å¤´éƒ¨æ§åˆ¶åŒº - å•è¡Œå¸ƒå±€
            if "path_val" not in st.session_state: 
                st.session_state.path_val = os.path.abspath(defaults.get("target_path", ""))
            if 'path_input' not in st.session_state:
                st.session_state.path_input = ""
            if st.session_state.get('uploaded_path') and not st.session_state.path_input:
                st.session_state.path_input = st.session_state.uploaded_path

            # åˆ›å»ºå¸ƒå±€åˆ—
            if is_create_mode:
                action_mode = "NEW"
                path_col1, path_col2 = st.columns([5, 1])
                
                with path_col1:
                    target_path = st.text_input(
                        "æ–‡ä»¶/æ–‡ä»¶å¤¹è·¯å¾„", 
                        value=st.session_state.path_input,
                        placeholder="ğŸ“ /Users/username/docs æˆ–ä¸Šä¼ åè‡ªåŠ¨ç”Ÿæˆ",
                        key="path_input_display",
                        label_visibility="collapsed"
                    )
                with path_col2:
                    if st.button("ğŸ“‚", help="åœ¨Finderä¸­æ‰“å¼€", use_container_width=True):
                        # ... Finder æ‰“å¼€é€»è¾‘ ...
                        if target_path and os.path.exists(target_path):
                            import webbrowser
                            import urllib.parse
                            try:
                                file_url = 'file://' + urllib.parse.quote(os.path.abspath(target_path))
                                webbrowser.open(file_url)
                                st.toast("âœ… å·²æ‰“å¼€")
                            except: pass
                        else:
                            st.warning("è¯·å…ˆè¾“å…¥è·¯å¾„")
            else:
                # ç®¡ç†æ¨¡å¼ï¼šå·¦ä¾§æ“ä½œæ¨¡å¼ï¼Œå³ä¾§è·¯å¾„
                mode_col, path_col1, path_col2 = st.columns([2, 4, 1])
                
                with mode_col:
                    action_mode_sel = st.radio("æ¨¡å¼", ["â• è¿½åŠ ", "ğŸ”„ è¦†ç›–"], horizontal=True, label_visibility="collapsed")
                    action_mode = "APPEND" if "è¿½åŠ " in action_mode_sel else "NEW"
                
                with path_col1:
                    target_path = st.text_input(
                        "è·¯å¾„",
                        value=st.session_state.path_input,
                        placeholder="ğŸ“ è·¯å¾„",
                        key="path_input_display",
                        label_visibility="collapsed"
                    )
                with path_col2:
                    if st.button("ğŸ“‚", help="æ‰“å¼€", use_container_width=True):
                         if target_path and os.path.exists(target_path):
                            import webbrowser
                            import urllib.parse
                            try:
                                file_url = 'file://' + urllib.parse.quote(os.path.abspath(target_path))
                                webbrowser.open(file_url)
                                st.toast("âœ… å·²æ‰“å¼€")
                            except: pass

            if target_path != st.session_state.path_input:
                st.session_state.path_input = target_path


            # æ•°æ®æºè¾“å…¥é€‰é¡¹å¡
            st.write("")
            src_tab_local, src_tab_web = st.tabs(["ğŸ“‚ æœ¬åœ°æ–‡ä»¶", "ğŸŒ ç½‘é¡µæŠ“å–"])
            
            with src_tab_local:
                local_type = st.radio("æ–¹å¼", ["ğŸ“„ ä¸Šä¼ æ–‡ä»¶", "âœï¸ ç²˜è´´æ–‡æœ¬"], horizontal=True, label_visibility="collapsed")
                
                uploaded_files = None  # åˆå§‹åŒ–å˜é‡
                
                if "ä¸Šä¼ æ–‡ä»¶" in local_type:
                    uploaded_files = st.file_uploader(
                        "æ‹–å…¥æ–‡ä»¶ (PDF, DOCX, TXT, MD)", 
                        accept_multiple_files=True, 
                        key="uploader",
                        label_visibility="collapsed"
                    )
                    st.caption("æ”¯æŒæ ¼å¼: PDF, DOCX, TXT, MD, Excel | å•ä¸ªæ–‡ä»¶æœ€å¤§ 100MB")
                else:
                    text_input_content = st.text_area("ç›´æ¥è¾“å…¥æ–‡æœ¬å†…å®¹", height=200, placeholder="åœ¨æ­¤ç²˜è´´æˆ–è¾“å…¥éœ€è¦åˆ†æçš„æ–‡æœ¬å†…å®¹...")
                    col_txt1, col_txt2 = st.columns([1, 4])
                    txt_filename = col_txt1.text_input("æ–‡ä»¶å", value="manual_input.txt", label_visibility="collapsed")
                    
                    if col_txt2.button("ğŸ’¾ ä¿å­˜æ–‡æœ¬", use_container_width=True):
                        if text_input_content.strip():
                            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
                            try:
                                save_dir = os.path.join(UPLOAD_DIR, f"text_{int(time.time())}")
                                if not os.path.exists(save_dir):
                                    os.makedirs(save_dir)
                                
                                safe_name = sanitize_filename(txt_filename) or "manual_input.txt"
                                if not safe_name.endswith('.txt'): safe_name += ".txt"
                                
                                with open(os.path.join(save_dir, safe_name), 'w', encoding='utf-8') as f:
                                    f.write(text_input_content)
                                    
                                st.session_state.uploaded_path = os.path.abspath(save_dir)
                                st.session_state.upload_auto_name = f"Text_{safe_name.split('.')[0]}"
                                st.success("âœ… æ–‡æœ¬å·²ä¿å­˜")
                                time.sleep(0.5)
                                st.rerun()
                            except Exception as e:
                                st.error(f"ä¿å­˜å¤±è´¥: {e}")
                        else:
                            st.warning("å†…å®¹ä¸èƒ½ä¸ºç©º")
            
            with src_tab_web:
                # è¾“å…¥æ–¹å¼é€‰æ‹© - ä½¿ç”¨æ›´ç´§å‡‘çš„å¸ƒå±€
                col1, col2 = st.columns(2)
                with col1:
                    url_mode = st.button("ğŸ”— ç½‘å€æŠ“å–", use_container_width=True, key="url_mode_btn")
                with col2:
                    search_mode = st.button("ğŸ” å…³é”®è¯æœç´¢", use_container_width=True, key="search_mode_btn")
                
                # æ ¹æ®æŒ‰é’®ç‚¹å‡»ç¡®å®šæ¨¡å¼
                if url_mode:
                    st.session_state.crawl_input_mode = "url"
                elif search_mode:
                    st.session_state.crawl_input_mode = "search"
                
                # è·å–å½“å‰æ¨¡å¼
                current_mode = st.session_state.get('crawl_input_mode', 'url')
                
                if current_mode == "url":
                    # ç½‘å€æŠ“å–æ¨¡å¼
                    crawl_url = st.text_input("ğŸ”— ç½‘å€", placeholder="python.org", help="æ”¯æŒè‡ªåŠ¨æ·»åŠ https://")
                    search_keyword = None
                    
                    # æŠ“å–å‚æ•°
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        crawl_depth = st.number_input("é€’å½’æ·±åº¦", 1, 10, 2, help="æŠ“å–å¤šå°‘å±‚é“¾æ¥")
                    with col2:
                        max_pages = st.number_input("æ¯å±‚é¡µæ•°", 1, 1000, 20, help="æ¯å±‚æœ€å¤šæŠ“å–é¡µæ•°")
                    with col3:
                        parser_type = st.selectbox("è§£æå™¨", ["default", "article", "documentation"])
                    
                else:  # current_mode == "search"
                    # å…³é”®è¯æœç´¢æ¨¡å¼
                    crawl_url = None
                    search_keyword = st.text_input("ğŸ” æœç´¢å…³é”®è¯", placeholder="Pythonç¼–ç¨‹ã€æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½", help="å…¨ç½‘æœç´¢ç›¸å…³å†…å®¹")
                    
                    # æœç´¢å‚æ•°
                    col1, col2 = st.columns(2)
                    with col1:
                        max_pages = st.number_input("æ¯å¼•æ“é¡µæ•°", 10, 500, 50, help="æ¯ä¸ªæœç´¢å¼•æ“æŠ“å–çš„é¡µæ•°ï¼ˆå…±5ä¸ªå¼•æ“ï¼šGoogleã€Bingã€ç»´åŸºç™¾ç§‘ã€çŸ¥ä¹ã€ç™¾åº¦ç™¾ç§‘ï¼‰")
                    with col2:
                        parser_type = st.selectbox("è§£æå™¨", ["default", "article", "documentation"])
                    
                    crawl_depth = 1  # æœç´¢æ¨¡å¼å›ºå®šæ·±åº¦1
                
                # æ’é™¤é…ç½® - å¯é€‰
                with st.expander("ğŸš« æ’é™¤é“¾æ¥ (å¯é€‰)", expanded=False):
                    exclude_text = st.text_area("æ¯è¡Œä¸€ä¸ªï¼Œæ”¯æŒ * é€šé…ç¬¦", 
                                               placeholder="*/admin/*\n*.pdf", 
                                               height=68)
                    exclude_patterns = [line.strip() for line in exclude_text.split('\n') if line.strip()] if exclude_text else []
                
                # çŸ¥è¯†åº“è®¾ç½®
                st.write("### ğŸ“š çŸ¥è¯†åº“è®¾ç½®")
                
                web_kb_name = st.text_input(
                    "çŸ¥è¯†åº“åç§°", 
                    placeholder="ç•™ç©ºè‡ªåŠ¨ç”Ÿæˆï¼ˆæ¨èï¼‰", 
                    help="æ¯æ¬¡æŠ“å–åˆ›å»ºç‹¬ç«‹çš„çŸ¥è¯†åº“ï¼Œä¾¿äºç®¡ç†ä¸åŒæ—¶é—´çš„å†…å®¹"
                )
                
                st.caption("ğŸ’¡ æ¯æ¬¡æŠ“å–éƒ½ä¼šåˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„çŸ¥è¯†åº“ï¼ŒåŒ…å«æœ¬æ¬¡æŠ“å–çš„æ‰€æœ‰ç½‘é¡µ")
                
                # æŠ“å–æŒ‰é’®
                btn_disabled = not crawl_url and not search_keyword
                if st.button("ğŸš€ æŠ“å–å¹¶åˆ›å»ºçŸ¥è¯†åº“", use_container_width=True, type="primary", disabled=btn_disabled):
                    if crawl_url:
                        # ç½‘å€æŠ“å–æ¨¡å¼
                        try:
                            from src.processors.web_crawler import WebCrawler
                            # ä½¿ç”¨å¸¦åŸŸåçš„å”¯ä¸€ç›®å½•
                            from urllib.parse import urlparse
                            from datetime import datetime
                            
                            try:
                                domain = urlparse(crawl_url).netloc.replace('.', '_').replace(':', '')
                                if not domain: domain = "unknown"
                            except:
                                domain = "unknown"
                                
                            timestamp_dir = datetime.now().strftime('%Y%m%d_%H%M%S')
                            unique_output_dir = os.path.join("temp_uploads", f"Web_{domain}_{timestamp_dir}")
                            
                            crawler = WebCrawler(output_dir=unique_output_dir)
                            
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            crawled_count = [0]
                            
                            def update_status(msg):
                                status_text.text(f"ğŸ“¡ {msg}")
                                # æ·»åŠ æ—¥å¿—è®°å½•
                                logger.info(f"ğŸŒ ç½‘é¡µçˆ¬å–: {msg}")
                                if "å·²ä¿å­˜" in msg:
                                    crawled_count[0] += 1
                                    progress = min(crawled_count[0] / max_pages, 1.0)
                                    progress_bar.progress(progress)
                            
                            # è®°å½•çˆ¬å–å¼€å§‹
                            logger.info(f"ğŸŒ å¼€å§‹ç½‘é¡µçˆ¬å–: {crawl_url} (æ·±åº¦:{crawl_depth}, é¡µæ•°:{max_pages})")
                            
                            with st.spinner("æŠ“å–ä¸­..."):
                                saved_files = crawler.crawl_advanced(
                                    start_url=crawl_url,
                                    max_depth=crawl_depth,
                                    max_pages=max_pages,
                                    exclude_patterns=exclude_patterns,
                                    parser_type=parser_type,
                                    status_callback=update_status
                                )
                            
                            progress_bar.progress(1.0)
                            
                            # è®°å½•çˆ¬å–ç»“æœ
                            logger.success(f"ğŸŒ ç½‘é¡µçˆ¬å–å®Œæˆ: è·å– {len(saved_files)} ä¸ªé¡µé¢")
                            
                            if saved_files:
                                # ç”ŸæˆçŸ¥è¯†åº“åç§°
                                if web_kb_name:
                                    kb_name = web_kb_name
                                else:
                                    # ä½¿ç”¨ç»Ÿä¸€çš„å‘½åä¼˜åŒ–å™¨
                                    from src.core.app_config import output_base
                                    kb_name = KBNameOptimizer.generate_name_from_url(crawl_url, output_base)

                                # ç¡®ä¿åç§°å”¯ä¸€ï¼ˆgenerate_name_from_url å†…éƒ¨å·²è°ƒç”¨ generate_unique_nameï¼‰
                                # ä½†ä¸ºäº†ä¿é™©å†æ¬¡ç¡®è®¤ï¼ˆå¦‚æœæ˜¯ç”¨æˆ·è¾“å…¥çš„è‡ªå®šä¹‰åç§°ï¼‰
                                if web_kb_name:
                                    kb_name = KBNameOptimizer.generate_unique_name(kb_name, output_base)
                                
                                st.success(f"âœ… æŠ“å–å®Œæˆï¼è·å– {len(saved_files)} é¡µï¼Œæ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“: {kb_name}")
                                
                                # è®¾ç½®çŸ¥è¯†åº“æ„å»ºå‚æ•°
                                st.session_state.uploaded_path = os.path.abspath(crawler.output_dir)
                                st.session_state.upload_auto_name = kb_name
                                st.session_state.auto_build_kb = True
                                st.session_state.selected_kb = kb_name
                                
                                # è§¦å‘çŸ¥è¯†åº“æ„å»º
                                with st.spinner(f"æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“: {kb_name}"):
                                    st.session_state.auto_build_kb = True
                                    st.session_state.selected_kb = kb_name  # è‡ªåŠ¨è·³è½¬åˆ°æ–°çŸ¥è¯†åº“
                                    time.sleep(1)
                                
                                st.success(f"ğŸ‰ çŸ¥è¯†åº“ '{kb_name}' æ„å»ºå®Œæˆï¼å·²è‡ªåŠ¨åˆ‡æ¢")
                                
                                # ç®€æ´çš„ç»“æœæ˜¾ç¤º
                                with st.expander("ğŸ“Š æ„å»ºè¯¦æƒ…", expanded=False):
                                    st.write(f"**çŸ¥è¯†åº“åç§°**: {kb_name}")
                                    st.write(f"**æŠ“å–é¡µé¢**: {len(saved_files)} é¡µ")
                                    st.write(f"**åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                                    for i, file_path in enumerate(saved_files[:3], 1):
                                        file_name = os.path.basename(file_path)
                                        st.text(f"{i}. {file_name}")
                                    if len(saved_files) > 3:
                                        st.text(f"... è¿˜æœ‰ {len(saved_files) - 3} ä¸ªæ–‡ä»¶")
                                
                                # æ¨èé—®é¢˜
                                try:
                                    from src.chat.web_suggestion_engine import WebSuggestionEngine
                                    web_engine = WebSuggestionEngine()
                                    web_suggestions = web_engine.generate_suggestions_from_crawl(crawl_url, saved_files)
                                    
                                    if web_suggestions:
                                        st.markdown("**ğŸ’¡ æ¨èé—®é¢˜:**")
                                        for i, suggestion in enumerate(web_suggestions[:3], 1):
                                            if st.button(suggestion, key=f"web_q_{i}", use_container_width=True):
                                                st.session_state.suggested_question = suggestion
                                                st.rerun()
                                except:
                                    pass
                                
                                st.rerun()
                            
                            else:
                                st.warning("æœªè·å–åˆ°å†…å®¹")
                                
                        except Exception as e:
                            st.error(f"æŠ“å–å¤±è´¥: {str(e)}")
                    
                    elif search_keyword:
                        # å…³é”®è¯å…¨ç½‘æœç´¢
                        try:
                            from src.processors.web_crawler import WebCrawler
                            # ä½¿ç”¨å¸¦å…³é”®è¯çš„å”¯ä¸€ç›®å½•
                            from datetime import datetime
                            
                            # æ¸…ç†å…³é”®è¯æ–‡ä»¶å
                            safe_keyword = "".join([c for c in search_keyword if c.isalnum() or c in (' ', '_', '-')]).strip().replace(' ', '_')[:30]
                            if not safe_keyword: safe_keyword = "keyword"
                            
                            timestamp_dir = datetime.now().strftime('%Y%m%d_%H%M%S')
                            unique_output_dir = os.path.join("temp_uploads", f"Search_{safe_keyword}_{timestamp_dir}")
                            
                            crawler = WebCrawler(output_dir=unique_output_dir)
                            
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            all_saved_files = []
                            
                            def update_status(msg):
                                status_text.text(f"ğŸ” {msg}")
                                # æ·»åŠ æ—¥å¿—è®°å½•
                                logger.info(f"ğŸ” å…³é”®è¯æœç´¢: {msg}")
                            
                            # å…¨ç½‘æœç´¢ç½‘ç«™åˆ—è¡¨
                            search_engines = [
                                f"https://www.google.com/search?q={search_keyword}",
                                f"https://www.bing.com/search?q={search_keyword}",
                                f"https://zh.wikipedia.org/wiki/Special:Search?search={search_keyword}",
                                f"https://www.zhihu.com/search?type=content&q={search_keyword}",
                                f"https://baike.baidu.com/search?word={search_keyword}"
                            ]
                            
                            # è®°å½•æœç´¢å¼€å§‹
                            logger.info(f"ğŸ” å¼€å§‹å…³é”®è¯æœç´¢: '{search_keyword}' (æ¯ä¸ªå¼•æ“:{max_pages}é¡µ, å…±{len(search_engines)}ä¸ªå¼•æ“)")
                            
                            # åœ¨å¤šä¸ªæœç´¢å¼•æ“ä¸­æœç´¢
                            for i, search_url in enumerate(search_engines):
                                engine_name = ["Google", "Bing", "ç»´åŸºç™¾ç§‘", "çŸ¥ä¹", "ç™¾åº¦ç™¾ç§‘"][i]
                                update_status(f"æ­£åœ¨æœç´¢ {engine_name}: {search_keyword}")
                                logger.info(f"ğŸ” æœç´¢å¼•æ“: {engine_name} - {search_url}")
                                
                                try:
                                    with st.spinner(f"æœç´¢ {engine_name}..."):
                                        saved_files = crawler.crawl_advanced(
                                            start_url=search_url,
                                            max_depth=2,  # æ·±åº¦2æ‰èƒ½æŠ“å–æœç´¢ç»“æœé“¾æ¥æŒ‡å‘çš„é¡µé¢
                                            max_pages=max_pages,  # æ¯ä¸ªæœç´¢å¼•æ“ä½¿ç”¨å®Œæ•´çš„é¡µæ•°
                                            exclude_patterns=exclude_patterns,
                                            parser_type=parser_type,
                                            status_callback=update_status
                                        )
                                        all_saved_files.extend(saved_files)
                                        
                                    progress_bar.progress((i + 1) / len(search_engines))
                                    
                                except Exception as e:
                                    update_status(f"âŒ {engine_name} æœç´¢å¤±è´¥: {e}")
                                    continue
                            
                            progress_bar.progress(1.0)
                            
                            if all_saved_files:
                                # ç”ŸæˆåŸºç¡€åç§°
                                if web_kb_name:
                                    kb_name = web_kb_name
                                    # ç¡®ä¿è‡ªå®šä¹‰åç§°å”¯ä¸€
                                    from src.core.app_config import output_base
                                    kb_name = KBNameOptimizer.generate_unique_name(kb_name, output_base)
                                else:
                                    # ä½¿ç”¨ç»Ÿä¸€çš„å‘½åä¼˜åŒ–å™¨
                                    from src.core.app_config import output_base
                                    kb_name = KBNameOptimizer.generate_name_from_keyword(search_keyword, output_base)
                                
                                st.success(f"âœ… å…¨ç½‘æœç´¢å®Œæˆï¼è·å– {len(all_saved_files)} é¡µï¼Œæ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“: {kb_name}")
                                
                                # è®°å½•æœç´¢å®Œæˆ
                                logger.success(f"ğŸ” å…³é”®è¯æœç´¢å®Œæˆ: '{search_keyword}' - è·å– {len(all_saved_files)} ä¸ªé¡µé¢")
                                
                                # è®¾ç½®çŸ¥è¯†åº“æ„å»ºå‚æ•°
                                st.session_state.uploaded_path = os.path.abspath(crawler.output_dir)
                                st.session_state.upload_auto_name = kb_name
                                st.session_state.auto_build_kb = True
                                st.session_state.selected_kb = kb_name
                                
                                # è§¦å‘çŸ¥è¯†åº“æ„å»º
                                with st.spinner(f"æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“: {kb_name}"):
                                    st.session_state.auto_build_kb = True
                                    st.session_state.selected_kb = kb_name  # è‡ªåŠ¨è·³è½¬åˆ°æ–°çŸ¥è¯†åº“
                                    time.sleep(1)
                                
                                st.success(f"ğŸ‰ çŸ¥è¯†åº“ '{kb_name}' æ„å»ºå®Œæˆï¼å·²è‡ªåŠ¨åˆ‡æ¢")
                                
                                # ç®€æ´çš„ç»“æœæ˜¾ç¤º
                                with st.expander("ğŸ“Š æ„å»ºè¯¦æƒ…", expanded=False):
                                    st.write(f"**çŸ¥è¯†åº“åç§°**: {kb_name}")
                                    st.write(f"**æœç´¢å…³é”®è¯**: {search_keyword}")
                                    st.write(f"**æœç´¢æ–¹å¼**: å…¨ç½‘æœç´¢")
                                    st.write(f"**æŠ“å–é¡µé¢**: {len(all_saved_files)} é¡µ")
                                    st.write(f"**åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                                
                                st.rerun()
                            
                            else:
                                st.warning("æœªæœç´¢åˆ°ç›¸å…³å†…å®¹")
                                
                        except Exception as e:
                            st.error(f"æœç´¢å¤±è´¥: {str(e)}")
                
                # ç®€æ´çš„ä½¿ç”¨æç¤º
                st.caption("ğŸ’¡ æ”¯æŒ python.org ç­‰ç®€åŒ–è¾“å…¥ï¼Œè‡ªåŠ¨æ·»åŠ  https:// å‰ç¼€")

            # å¤„ç†ä¸Šä¼  (Stage 4.1 - ä½¿ç”¨ UploadHandler)
            if uploaded_files:
                if 'last_uploaded_names' not in st.session_state:
                    st.session_state.last_uploaded_names = []

                current_names = [f.name for f in uploaded_files]

                # åªåœ¨æ–‡ä»¶åˆ—è¡¨å˜åŒ–æ—¶å¤„ç†
                if set(current_names) != set(st.session_state.last_uploaded_names):
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    # ä½¿ç”¨ UploadHandler å¤„ç†ä¸Šä¼ 
                    handler = UploadHandler(UPLOAD_DIR, logger)

                    for idx, f in enumerate(uploaded_files):
                        status_text.text(f"éªŒè¯ä¸­: {f.name} ({idx+1}/{len(uploaded_files)})")
                        progress_bar.progress((idx + 1) / len(uploaded_files))

                    result = handler.process_uploads(uploaded_files)

                    progress_bar.empty()
                    status_text.empty()

                    st.session_state.last_uploaded_names = current_names
                    st.session_state.uploaded_path = os.path.abspath(result.batch_dir)

                    # æ˜¾ç¤ºä¸Šä¼ ç»“æœ
                    if result.success_count > 0:
                        st.success(f"âœ… æˆåŠŸä¸Šä¼  {result.success_count} ä¸ªæ–‡ä»¶")

                    if result.skipped_count > 0:
                        st.warning(f"âš ï¸ è·³è¿‡ {result.skipped_count} ä¸ªæ–‡ä»¶")
                        with st.expander("æŸ¥çœ‹è·³è¿‡è¯¦æƒ…", expanded=True):
                            for reason in result.skip_reasons:
                                st.text(f"â€¢ {reason}")

                    # ä¸ºæ–‡ä»¶ä¸Šä¼ åœºæ™¯ç”Ÿæˆæ™ºèƒ½åç§°
                    if result.success_count > 0:
                        try:
                            # è®¡ç®—æ–‡ä»¶ç±»å‹åˆ†å¸ƒ
                            file_types = {}
                            for filename in current_names:
                                ext = os.path.splitext(filename)[1].lower()
                                file_types[ext] = file_types.get(ext, 0) + 1

                            # ä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶åç”Ÿæˆæ™ºèƒ½åç§°
                            folder_name = os.path.basename(result.batch_dir)  # batch_xxx
                            auto_name = generate_smart_kb_name(result.batch_dir, result.success_count, file_types, folder_name)

                            # å­˜å‚¨æ™ºèƒ½ç”Ÿæˆçš„åç§°
                            st.session_state.upload_auto_name = auto_name
                        except Exception as e:
                            st.session_state.upload_auto_name = None

                    time.sleep(1)
                    if result.success_count > 0:
                        st.rerun()


            # ä½¿ç”¨ä¸Šä¼ è·¯å¾„æˆ–æ‰‹åŠ¨è¾“å…¥çš„è·¯å¾„
            target_path = st.session_state.get('uploaded_path') or target_path

            auto_name = ""

            # ä¼˜å…ˆä½¿ç”¨æ–‡ä»¶ä¸Šä¼ çš„æ™ºèƒ½åç§°
            if hasattr(st.session_state, 'upload_auto_name') and st.session_state.upload_auto_name:
                auto_name = st.session_state.upload_auto_name

            if target_path:
                if os.path.exists(target_path):
                    # ä½¿ç”¨ UploadHandler ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯ (Stage 4.1)
                    cnt, file_types, total_size = UploadHandler.get_folder_stats(target_path)

                    # ç¾åŒ–æ˜¾ç¤º
                    size_mb = total_size / (1024 * 1024)
                    folder_name = os.path.basename(target_path.rstrip('/'))

                    st.success(f"âœ… **æœ‰æ•ˆæ•°æ®æº**: `{folder_name}`")

                    # ä¸‰åˆ—ç»Ÿè®¡å¡ç‰‡
                    stat_col1, stat_col2, stat_col3 = st.columns(3)
                    stat_col1.metric("ğŸ“„ æ–‡ä»¶æ•°", f"{cnt}")
                    stat_col2.metric("ğŸ’¾ æ€»å¤§å°", f"{size_mb:.1f}MB" if size_mb > 1 else f"{total_size/1024:.0f}KB")
                    stat_col3.metric("ğŸ“‚ ç±»å‹", f"{len(file_types)} ç§")

                    # ç±»å‹åˆ†å¸ƒï¼ˆåªæ˜¾ç¤ºå‰5ç§ï¼‰
                    if file_types:
                        st.caption("**æ–‡ä»¶ç±»å‹åˆ†å¸ƒ**")
                        sorted_types = sorted(file_types.items(), key=lambda x: x[1], reverse=True)[:5]
                        type_text = " Â· ".join([f"{ext.replace('.', '')}: {count}" for ext, count in sorted_types])
                        if len(file_types) > 5:
                            type_text += f" Â· å…¶ä»–: {sum(c for _, c in sorted(file_types.items(), key=lambda x: x[1], reverse=True)[5:])}"
                        st.caption(type_text)

                    # ä»…åœ¨æ²¡æœ‰é¢„è®¾åç§°æ—¶ä½¿ç”¨æ–‡ä»¶å¤¹å
                    if not (hasattr(st.session_state, 'upload_auto_name') and st.session_state.upload_auto_name):
                        auto_name = folder_name

                    # æ™ºèƒ½ç”ŸæˆçŸ¥è¯†åº“åç§°
                    if cnt > 0:
                        # å¦‚æœå·²æœ‰æ¥è‡ªçˆ¬è™«çš„ç‰¹å®šåç§°ï¼Œä¸è¦è¦†ç›–
                        if not (hasattr(st.session_state, 'upload_auto_name') and st.session_state.upload_auto_name):
                            auto_name = generate_smart_kb_name(target_path, cnt, file_types, folder_name)
                else:
                    st.error("âŒ è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")

            # final_kb_name å¿…é¡»åœ¨ if/else ä¸­è¢«å®šä¹‰ï¼Œä»¥ç¡®ä¿å…¶åœ¨æ¨¡å—ä½œç”¨åŸŸå†…
            st.write("")
            if is_create_mode:
                st.markdown("**çŸ¥è¯†åº“åç§°**")

                # æ˜¾ç¤ºæ™ºèƒ½å»ºè®®
                if auto_name:
                    st.caption(f"ğŸ’¡ å»ºè®®åç§°ï¼š{auto_name}")

                final_kb_name = st.text_input(
                    "çŸ¥è¯†åº“åç§°", 
                    value=sanitize_filename(auto_name) if auto_name else "", 
                    placeholder="ç•™ç©ºè‡ªåŠ¨ç”Ÿæˆï¼Œæˆ–è¾“å…¥è‡ªå®šä¹‰åç§°",
                    label_visibility="collapsed",
                    help="ç•™ç©ºå°†è‡ªåŠ¨ç”Ÿæˆæœ‰æ„ä¹‰çš„åç§°"
                )

                # å¦‚æœç”¨æˆ·æ²¡è¾“å…¥ï¼Œä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„åç§°
                if not final_kb_name and auto_name:
                    final_kb_name = sanitize_filename(auto_name)
            else:
                final_kb_name = current_kb_name

            # é«˜çº§é€‰é¡¹
            with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹", expanded=False):
                # ç¬¬ä¸€è¡Œï¼šç´¢å¼•å’Œå…ƒæ•°æ®é€‰é¡¹
                adv_col1, adv_col2 = st.columns(2)
                with adv_col1:
                    force_reindex = st.checkbox("ğŸ”„ å¼ºåˆ¶é‡å»ºç´¢å¼•", False, help="åˆ é™¤ç°æœ‰ç´¢å¼•ï¼Œé‡æ–°æ„å»º")
                    use_ocr = st.checkbox("ğŸ” å¯ç”¨OCRè¯†åˆ«", value=False, help="è¯†åˆ«PDFä¸­çš„å›¾ç‰‡æ–‡å­—ï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰", key="kb_use_ocr")
                with adv_col2:
                    extract_metadata = st.checkbox("ğŸ“Š æå–å…ƒæ•°æ®", value=False, help="æå–æ–‡ä»¶åˆ†ç±»ã€å…³é”®è¯ç­‰ä¿¡æ¯")
                    generate_summary = st.checkbox("ğŸ“ ç”Ÿæˆæ–‡æ¡£æ‘˜è¦", value=False, help="ä¸ºæ¯ä¸ªæ–‡æ¡£ç”ŸæˆAIæ‘˜è¦", key="kb_generate_summary")
                
                # ä¿å­˜åˆ°session state
                st.session_state.use_ocr = use_ocr
                st.session_state.generate_summary = generate_summary
                
                # ç®€åŒ–çš„å¤„ç†æ¨¡å¼æç¤º
                if use_ocr or generate_summary or extract_metadata or force_reindex:
                    options = []
                    if force_reindex: options.append("é‡å»ºç´¢å¼•")
                    if extract_metadata: options.append("æå–å…ƒæ•°æ®")
                    if use_ocr: options.append("OCRè¯†åˆ«")
                    if generate_summary: options.append("ç”Ÿæˆæ‘˜è¦")
                    st.caption(f"ğŸ”§ å¯ç”¨é€‰é¡¹: {' | '.join(options)}")
                else:
                    st.caption("âš¡ å¿«é€Ÿæ¨¡å¼ï¼šæ‰€æœ‰é«˜çº§é€‰é¡¹å·²å…³é—­")


            st.write("")

            btn_label = "ğŸš€ ç«‹å³åˆ›å»º" if is_create_mode else ("â• æ‰§è¡Œè¿½åŠ " if action_mode=="APPEND" else "ğŸ”„ æ‰§è¡Œè¦†ç›–")
            btn_start = st.button(btn_label, type="primary", use_container_width=True)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ„å»ºçŸ¥è¯†åº“ï¼ˆç½‘é¡µæŠ“å–è§¦å‘ï¼‰
            if st.session_state.get('auto_build_kb', False):
                st.session_state.auto_build_kb = False  # æ¸…é™¤æ ‡è®°
                btn_start = True  # è‡ªåŠ¨è§¦å‘æ„å»º

        # --- ç°æœ‰åº“çš„ç®¡ç† ---
        if not is_create_mode:
            st.write("")
            
            # ğŸ’¬ èŠå¤©æ§åˆ¶ - 2Ã—2å¸ƒå±€
            st.write("**ğŸ’¬ èŠå¤©æ§åˆ¶**")
            row1_col1, row1_col2 = st.columns(2)
            row2_col1, row2_col2 = st.columns(2)
            
            with row1_col1:
                if st.button("ğŸ”„ æ’¤é”€", use_container_width=True, disabled=len(state.get_messages()) < 2):
                    if len(state.get_messages()) >= 2:
                        st.session_state.messages.pop()
                        st.session_state.messages.pop()
                        if current_kb_name:
                            HistoryManager.save(current_kb_name, state.get_messages())
                        st.toast("âœ… å·²æ’¤é”€")
                        time.sleep(0.5)
                        st.rerun()
            
            with row1_col2:
                if st.button("ğŸ§¹ æ¸…ç©º", use_container_width=True, disabled=len(state.get_messages()) == 0):
                    st.session_state.messages = []
                    st.session_state.suggestions_history = []
                    if current_kb_name:
                        HistoryManager.save(current_kb_name, [])
                    st.toast("âœ… å·²æ¸…ç©º")
                    time.sleep(0.5)
                    st.rerun()
            
            with row2_col1:
                export_content = ""
                if len(state.get_messages()) > 0:
                    export_content = f"# å¯¹è¯è®°å½• - {current_kb_name}\n\n**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n---\n\n"
                    for i, msg in enumerate(st.session_state.messages, 1):
                        role = "ğŸ‘¤ ç”¨æˆ·" if msg["role"] == "user" else "ğŸ¤– åŠ©æ‰‹"
                        export_content += f"## {role} ({i})\n\n{msg['content']}\n\n"
                
                st.download_button("ğŸ“¥ å¯¼å‡º", export_content, file_name=f"chat_{current_kb_name}_{datetime.now().strftime('%Y%m%d')}.md", mime="text/markdown", use_container_width=True, disabled=len(state.get_messages()) == 0)
            
            with row2_col2:
                if st.button("ğŸ“Š ç»Ÿè®¡", use_container_width=True, disabled=len(state.get_messages()) == 0):
                    qa_count = len(state.get_messages()) // 2
                    total_chars = sum(len(msg["content"]) for msg in st.session_state.messages)
                    st.toast(f"ğŸ’¬ {qa_count} è½®å¯¹è¯ | ğŸ“ {total_chars} å­—ç¬¦")
            
            st.write("")
            
            # ğŸ› ï¸ ç³»ç»Ÿæ“ä½œ - 1Ã—2å¸ƒå±€
            st.write("**ğŸ› ï¸ ç³»ç»Ÿæ“ä½œ**")
            sys_col1, sys_col2 = st.columns(2)
            
            with sys_col1:
                st.link_button("ğŸ”€ æ–°çª—å£", "http://localhost:8501", use_container_width=True)
            
            with sys_col2:
                if st.button("ğŸ—‘ï¸ åˆ é™¤çŸ¥è¯†åº“", use_container_width=True, disabled=not current_kb_name):
                    st.session_state.confirm_delete = True
                    st.rerun()
            
            # åˆ é™¤ç¡®è®¤å¯¹è¯æ¡†
            if st.session_state.get('confirm_delete', False):
                st.warning(f"âš ï¸ ç¡®è®¤åˆ é™¤çŸ¥è¯†åº“ '{current_kb_name}' å—ï¼Ÿ")
                confirm_col1, confirm_col2 = st.columns(2)
                
                with confirm_col1:
                    if st.button("âœ… ç¡®è®¤åˆ é™¤", type="primary", use_container_width=True):
                        st.toast(f"ğŸ—‘ï¸ å·²åˆ é™¤çŸ¥è¯†åº“: {current_kb_name}")
                        st.session_state.current_nav = "â• æ–°å»ºçŸ¥è¯†åº“..."
                        st.session_state.confirm_delete = False
                        st.rerun()
                
                with confirm_col2:
                    if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                        st.session_state.confirm_delete = False
                        st.rerun()

            # åº•éƒ¨å·¥å…·æ  - å•è¡Œå¸ƒå±€
            st.write("")
            tool_cols = st.columns(3)
            
    
    with tab_config:
        st.session_state.current_tab = "config"
        st.markdown("### âš™ï¸ æ¨¡å‹é…ç½®")
        
        # P0æ”¹è¿›3: ä¾§è¾¹æ åˆ†ç»„ - åŸºç¡€é…ç½®ï¼ˆé»˜è®¤å±•å¼€ï¼‰- ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.2.2)
        config_values = render_basic_config(defaults)

        # æå–é…ç½®å€¼
        llm_provider = config_values.get('llm_provider', 'Ollama')
        llm_url = config_values.get('llm_url', 'http://localhost:11434')
        llm_model = config_values.get('llm_model', 'qwen2.5:7b')
        llm_key = config_values.get('llm_key', '')
        embed_provider = config_values.get('embed_provider', 'HuggingFace (æœ¬åœ°/æé€Ÿ)')
        embed_model = config_values.get('embed_model', 'BAAI/bge-small-zh-v1.5')
        embed_url = config_values.get('embed_url', '')
        embed_key = config_values.get('embed_key', '')

        # è®¾ç½®å…¨å±€LLMï¼ˆç¡®ä¿æŸ¥è¯¢æ”¹å†™ç­‰åŠŸèƒ½å¯ä»¥ä½¿ç”¨ï¼‰
        if not hasattr(Settings, 'llm') or Settings.llm is None:
            set_global_llm_model(llm_provider, llm_model, llm_key, llm_url)

        # P0æ”¹è¿›3: é«˜çº§åŠŸèƒ½ï¼ˆé»˜è®¤å±•å¼€ï¼‰- ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.2.3)
        from src.ui.sidebar_config import SidebarConfig
        advanced_config = SidebarConfig._render_advanced_config()

    with tab_monitor:
        # v2.3.0: æ™ºèƒ½ç›‘æ§é¢æ¿
        try:
            from src.core.v23_integration import get_v23_integration
            v23 = get_v23_integration()
            v23.render_monitoring_tab()
        except ImportError:
            # é™çº§åˆ°v1.5.1æ€§èƒ½ç›‘æ§é¢æ¿
            perf_monitor.render_panel()
    
    with tab_tools:
        st.markdown("### ğŸ”§ å·¥å…·ç®±")
        
        # P0æ”¹è¿›3: ç³»ç»Ÿå·¥å…·ï¼ˆé»˜è®¤å±•å¼€ï¼‰
        with st.expander("ğŸ› ï¸ ç³»ç»Ÿå·¥å…·", expanded=True):
            # ç³»ç»Ÿç›‘æ§
            auto_refresh = st.checkbox("ğŸ”„ è‡ªåŠ¨åˆ·æ–° (2ç§’)", value=False, key="tools_auto_refresh")

            monitor_placeholder = st.empty()

            import psutil
            import subprocess
            cpu_percent = psutil.cpu_percent(interval=0.1)
            mem = psutil.virtual_memory()
            disk = psutil.disk_usage('/System/Volumes/Data')

            gpu_active = False
            try:
                result = subprocess.run(['ioreg', '-r', '-d', '1', '-w', '0', '-c', 'IOAccelerator'],
                                      capture_output=True, text=True, timeout=1)
                if 'PerformanceStatistics' in result.stdout:
                    gpu_active = True
            except:
                pass

            with monitor_placeholder.container():
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.metric("CPU ä½¿ç”¨ç‡", f"{cpu_percent:.1f}%")
                with col2:
                    st.caption(f"{psutil.cpu_count()} æ ¸")
                st.progress(cpu_percent / 100)

                col1, col2 = st.columns([4, 1])
                with col1:
                    st.metric("GPU çŠ¶æ€", "æ´»è·ƒ" if gpu_active else "ç©ºé—²")
                with col2:
                    st.caption("32 æ ¸")
                if gpu_active:
                    st.progress(0.5)
                else:
                    st.progress(0.0)

                col1, col2 = st.columns([4, 1])
                with col1:
                    st.metric("å†…å­˜ä½¿ç”¨", f"{mem.percent:.1f}%")
                with col2:
                    st.caption(f"{mem.used/1024**3:.1f}GB")
                st.progress(mem.percent / 100)

                col1, col2 = st.columns([4, 1])
                with col1:
                    st.metric("ç£ç›˜ä½¿ç”¨", f"{disk.percent:.1f}%")
                with col2:
                    st.caption(f"{disk.used/1024**3:.0f}GB")
                st.progress(disk.percent / 100)

                current_proc = psutil.Process()
                proc_mem = current_proc.memory_info().rss / 1024**3
                st.caption(f"ğŸ” è¿›ç¨‹: {proc_mem:.1f}GB | {current_proc.num_threads()} çº¿ç¨‹")
                st.caption("ğŸ’¡ GPU è¯¦ç»†ä¿¡æ¯éœ€è¦: `sudo python3 system_monitor.py`")

            if auto_refresh:
                import time
                time.sleep(2)
                st.rerun()
        
        st.markdown("---")
        st.markdown("#### â¬†ï¸ å¿«é€Ÿä¸Šä¼ ")
        uploaded_file = st.file_uploader("é€‰æ‹©æ–‡ä»¶", type=['pdf', 'txt', 'docx', 'md'], key="tools_uploader")
        if uploaded_file:
            st.success(f"âœ… å·²é€‰æ‹©: {uploaded_file.name}")
            st.info("ğŸ’¡ è¯·åˆ°ä¸»é¡µå®Œæˆå¤„ç†")
    
    with tab_help:
        st.markdown("### ğŸ“– å¸®åŠ©")
        st.info("RAG Pro Max v2.2.1 - æ¨ªå‘æ ‡ç­¾é¡µç‰ˆæœ¬")

# ==========================================
# ä¸»åŠŸèƒ½åŒºåŸŸ
# ==========================================

# æ ¹æ®é€‰æ‹©çš„æ¨¡å¼æ˜¾ç¤ºå¯¹åº”åŠŸèƒ½
if st.session_state.get('main_mode', 'rag') == 'sql':
    # ==========================================
    # ğŸ“Š æ•°æ®åˆ†ææ¨¡å¼
    # ==========================================
    st.markdown("### ğŸ“Š æ•°æ®åˆ†æ (Text-to-SQL)")
    
    # åˆå§‹åŒ–SQLå¼•æ“
    if 'sql_engine' not in st.session_state:
        try:
            from src.engines.sql_engine import SQLEngine
            st.session_state.sql_engine = SQLEngine()
        except ImportError:
            st.error("SQLå¼•æ“æ¨¡å—æœªæ‰¾åˆ°")
            st.stop()

    col1, col2 = st.columns([1, 2])

    with col1:
        st.markdown("#### ğŸ“ æ•°æ®å¯¼å…¥")
        
        uploaded_data = st.file_uploader(
            "ä¸Šä¼ Excel/CSVæ–‡ä»¶", 
            type=['xlsx', 'csv'],
            key="main_data_uploader"
        )
        
        if uploaded_data:
            import tempfile
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_data.name.split('.')[-1]}") as tmp:
                tmp.write(uploaded_data.getvalue())
                tmp_path = tmp.name
            
            if st.button("ğŸ“¥ å¯¼å…¥æ•°æ®", type="primary", key="main_import"):
                with st.spinner("å¯¼å…¥ä¸­..."):
                    try:
                        result = st.session_state.sql_engine.import_excel_csv(tmp_path)
                        st.success(result)
                        st.session_state.main_data_imported = True
                    except Exception as e:
                        st.error(f"å¯¼å…¥å¤±è´¥: {str(e)}")
        
        # æ˜¾ç¤ºæ•°æ®ç»“æ„
        if st.session_state.get('main_data_imported'):
            st.markdown("#### ğŸ“‹ æ•°æ®ç»“æ„")
            try:
                schema = st.session_state.sql_engine.get_schema()
                for table, columns in schema.items():
                    with st.expander(f"ğŸ“Š {table}"):
                        st.write(f"å­—æ®µ: {', '.join(columns)}")
            except:
                st.write("æš‚æ— æ•°æ®")

    with col2:
        st.markdown("#### ğŸ’¬ æ•°æ®é—®ç­”")
        
        if st.session_state.get('main_data_imported'):
            data_query = st.text_input(
                "è¾“å…¥æ‚¨çš„æ•°æ®åˆ†æé—®é¢˜", 
                placeholder="ä¾‹å¦‚: ç»Ÿè®¡å„éƒ¨é—¨çš„æ€»äººæ•°ã€è®¡ç®—å¹³å‡å·¥èµ„",
                key="main_data_query"
            )
            
            if st.button("ğŸ” åˆ†æ", type="primary", key="main_analyze") and data_query:
                with st.spinner("æ­£åœ¨åˆ†æ..."):
                    try:
                        if not hasattr(st.session_state, 'llm') or not st.session_state.llm:
                            st.error("è¯·å…ˆåœ¨å·¦ä¾§é…ç½®é¡µé¢è®¾ç½®LLMæ¨¡å‹")
                        else:
                            sql = st.session_state.sql_engine.text_to_sql(data_query, st.session_state.llm)
                            
                            with st.expander("ğŸ“ ç”Ÿæˆçš„SQLè¯­å¥"):
                                st.code(sql, language="sql")
                            
                            result = st.session_state.sql_engine.execute_sql(sql)
                            
                            if result['success']:
                                st.success(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {result['rows']} è¡Œæ•°æ®")
                                if result['data']:
                                    import pandas as pd
                                    df = pd.DataFrame(result['data'])
                                    st.dataframe(df, use_container_width=True)
                                    
                                    # ç®€å•å›¾è¡¨
                                    if len(df.columns) >= 2 and len(df) > 1:
                                        chart_col1, chart_col2 = st.columns(2)
                                        with chart_col1:
                                            if st.button("ğŸ“Š æŸ±çŠ¶å›¾"):
                                                st.bar_chart(df.set_index(df.columns[0]))
                                        with chart_col2:
                                            if st.button("ğŸ“ˆ æŠ˜çº¿å›¾"):
                                                st.line_chart(df.set_index(df.columns[0]))
                                else:
                                    st.info("æŸ¥è¯¢æ— ç»“æœ")
                            else:
                                st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {result['error']}")
                    except Exception as e:
                        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        else:
            st.info("ğŸ‘† è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
            
    # åœæ­¢åç»­æ‰§è¡Œï¼Œç¡®ä¿åªæ˜¾ç¤ºæ•°æ®åˆ†æç•Œé¢
    st.stop()

# ==========================================
# ğŸ“„ RAGæ–‡æ¡£é—®ç­”æ¨¡å¼ (åŸæœ‰åŠŸèƒ½)
# ==========================================

# ==========================================
# 5. æ ¸å¿ƒé€»è¾‘ (RAG & Indexing)
# ==========================================

def process_knowledge_base_logic():
    """å¤„ç†çŸ¥è¯†åº“é€»è¾‘ (Stage 4.2 - ä½¿ç”¨ IndexBuilder)"""
    global logger
    persist_dir = os.path.join(output_base, final_kb_name)
    start_time = time.time()
    
    # èµ„æºä¿æŠ¤æ£€æŸ¥
    cpu = psutil_main.cpu_percent(interval=0.1)
    mem = psutil_main.virtual_memory().percent
    result = resource_guard.check_resources(cpu, mem, 0)
    throttle_info = result.get('throttle', {})
    if throttle_info.get('action') == 'reject':
        st.warning(f"âš ï¸ ç³»ç»Ÿèµ„æºç´§å¼ ï¼Œè¯·ç¨åå†è¯•")
        logger.warning(f"èµ„æºä¸è¶³ï¼Œæš‚åœå¤„ç†: CPU={cpu}%, MEM={mem}%")
        time.sleep(2)
        return

    # è®¾ç½®åµŒå…¥æ¨¡å‹
    logger.info(f"ğŸ”§ è®¾ç½®åµŒå…¥æ¨¡å‹: {embed_model} (provider: {embed_provider})")
    embed = get_embed(embed_provider, embed_model, embed_key, embed_url)
    if not embed:
        logger.error(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {embed_model}")
        raise ValueError(f"æ— æ³•åŠ è½½åµŒå…¥æ¨¡å‹: {embed_model}")
    
    Settings.embed_model = embed
    try:
        actual_dim = len(embed._get_text_embedding("test"))
        logger.success(f"âœ… åµŒå…¥æ¨¡å‹å·²è®¾ç½®: {embed_model} ({actual_dim}ç»´)")
    except:
        logger.success(f"âœ… åµŒå…¥æ¨¡å‹å·²è®¾ç½®: {embed_model}")

    logger.log("INFO", f"å¼€å§‹å¤„ç†çŸ¥è¯†åº“: {final_kb_name}", stage="çŸ¥è¯†åº“å¤„ç†")
    
    # UI çŠ¶æ€å®¹å™¨
    status_container = st.status(f"ğŸš€ å¤„ç†çŸ¥è¯†åº“: {final_kb_name}", expanded=True)
    prog_bar = status_container.progress(0)
    status_container.write(f"â±ï¸ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
    
    # å›è°ƒå‡½æ•°ï¼šæ›´æ–° UI
    def status_callback(msg_type, *args):
        if msg_type == "step":
            step_num, step_desc = args
            status_container.write(f"ğŸ“‚ [æ­¥éª¤{step_num}/6] {step_desc}")
            logger.info(f"ğŸ“‚ [æ­¥éª¤ {step_num}/6] {step_desc}")
            prog_bar.progress(step_num * 15)
        elif msg_type == "info":
            info_msg = args[0]
            status_container.write(f"   {info_msg}")
            logger.info(f"   {info_msg}")
        elif msg_type == "warning":
            warn_msg = args[0]
            status_container.write(f"   âš ï¸  {warn_msg}")
            logger.warning(f"   âš ï¸  {warn_msg}")
    
    # è·å–æºè·¯å¾„
    current_target_path = st.session_state.get('uploaded_path') or st.session_state.path_input
    if not current_target_path or not os.path.exists(current_target_path):
        status_container.update(label="âŒ è·¯å¾„æ— æ•ˆ", state="error")
        logger.error(f"âŒ è·¯å¾„æ— æ•ˆ: {current_target_path}")
        raise ValueError(f"è·¯å¾„æ— æ•ˆ: {current_target_path}")
    
    # ä½¿ç”¨ IndexBuilder æ„å»ºç´¢å¼•
    builder = IndexBuilder(
        kb_name=final_kb_name,
        persist_dir=persist_dir,
        embed_model=embed,
        embed_model_name=embed_model,
        extract_metadata=extract_metadata,  # ä¼ é€’æ€§èƒ½é€‰é¡¹
        logger=logger
    )
    
    result = builder.build(
        source_path=current_target_path,
        force_reindex=force_reindex,
        action_mode=action_mode,
        status_callback=status_callback
    )
    
    if not result.success:
        status_container.update(label=f"âŒ å¤„ç†å¤±è´¥: {result.error}", state="error")
        logger.error(f"âŒ å¤„ç†å¤±è´¥: {result.error}")
        raise ValueError(result.error)
    
    # ä¿å­˜ç´¢å¼•
    if result.index:
        result.index.storage_context.persist(persist_dir=persist_dir)
        logger.success(f"ğŸ’¾ ç´¢å¼•å·²ä¿å­˜åˆ°: {persist_dir}")
    
    # æ›´æ–°è¿›åº¦
    prog_bar.progress(100)
    
    # è®¡ç®—è€—æ—¶
    duration = time.time() - start_time
    logger.separator("å¤„ç†å®Œæˆ")
    logger.success(f"âœ… çŸ¥è¯†åº“ '{final_kb_name}' å¤„ç†å®Œæˆ")
    logger.info(f"ğŸ“Š ç»Ÿè®¡: {result.file_count} ä¸ªæ–‡ä»¶, {result.doc_count} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
    logger.info(f"â±ï¸  è€—æ—¶: {duration:.1f} ç§’")
    
    logger.log("SUCCESS", f"çŸ¥è¯†åº“å¤„ç†å®Œæˆ: {final_kb_name}, æ–‡æ¡£æ•°: {result.doc_count
    }", stage="çŸ¥è¯†åº“å¤„ç†")
    
    status_container.update(label=f"âœ… çŸ¥è¯†åº“ '{final_kb_name}' å¤„ç†å®Œæˆ", state="complete", expanded=True)
    
    # èµ„æºæ¸…ç†
    resource_guard.throttler.cleanup_memory()
    logger.info("ğŸ§¹ èµ„æºå·²æ¸…ç†")
    
    # è‡ªåŠ¨è·³è½¬åˆ°æ–°å»ºçš„çŸ¥è¯†åº“
    st.session_state.current_nav = f"ğŸ“‚ {final_kb_name}"
    st.success(f"ğŸ‰ çŸ¥è¯†åº“ '{final_kb_name}' æ„å»ºå®Œæˆï¼å·²è‡ªåŠ¨åˆ‡æ¢åˆ°è¯¥çŸ¥è¯†åº“")
    
    time.sleep(1.5)
    st.rerun()  # åˆ·æ–°é¡µé¢ï¼Œæ˜¾ç¤ºæ–°çŸ¥è¯†åº“
    
    return result.doc_count

# ==========================================
# 6. èŠå¤©ç•Œé¢ & æ— é™è¿½é—®åŠŸèƒ½
# ==========================================
st.title("ğŸ›¡ï¸ RAG Pro Max")

# å¼•å…¥æ–°çš„ä¼˜åŒ–ç»„ä»¶
from src.utils.enhanced_ocr_optimizer import enhanced_ocr_optimizer
from src.ui.progress_monitor import progress_monitor

# æ˜¾ç¤ºå®æ—¶è¿›åº¦ç›‘æ§
progress_monitor.render_all_tasks()

# åœ¨ä¾§è¾¹æ æ·»åŠ æ€§èƒ½ç»Ÿè®¡
with st.sidebar:
    # v2.3.0: æ™ºèƒ½ç›‘æ§çŠ¶æ€
    try:
        from src.core.v23_integration import get_v23_integration
        v23 = get_v23_integration()
        v23.render_v23_sidebar()
    except ImportError:
        pass
    
    with st.expander("ğŸ“Š æ€§èƒ½ç»Ÿè®¡", expanded=True):
        stats = enhanced_ocr_optimizer.get_performance_stats()
        for key, value in stats.items():
            st.write(f"**{key}**: {value}")
        
        if st.button("ğŸ§ª è¿è¡Œæ€§èƒ½æµ‹è¯•"):
            with st.spinner("æ­£åœ¨è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•..."):
                benchmark_results = enhanced_ocr_optimizer.benchmark_performance()
                st.json(benchmark_results)

# ç´§å‡‘ä¾§è¾¹æ CSSæ ·å¼
st.markdown("""
<style>
/* ä¾§è¾¹æ ç´§å‡‘åŒ– */
.css-1d391kg, [data-testid="stSidebar"] {
    padding-top: 0.5rem;
    padding-bottom: 0.5rem;
}

/* ç¡®ä¿ä¾§è¾¹æ æ”¶èµ·æŒ‰é’®å¯è§å’Œå¯ç”¨ */
[data-testid="collapsedControl"] {
    display: block !important;
    visibility: visible !important;
    opacity: 1 !important;
}

/* ä¾§è¾¹æ æ”¶èµ·çŠ¶æ€ */
[data-testid="stSidebar"][aria-expanded="false"] {
    width: 0 !important;
    min-width: 0 !important;
}

/* å‡å°‘æ ‡é¢˜é—´è· */
.css-1lcbmhc {
    margin-bottom: 0.25rem;
    margin-top: 0.25rem;
}

/* ç´§å‡‘æŒ‰é’® */
.stButton > button {
    height: 1.8rem;
    padding: 0.2rem 0.4rem;
    font-size: 11px;
    margin-bottom: 0.2rem;
}

/* ç´§å‡‘è¾“å…¥æ¡† */
.stTextInput > div > div > input {
    height: 1.8rem;
    font-size: 12px;
}

/* ç´§å‡‘é€‰æ‹©æ¡† */
.stSelectbox > div > div > div {
    height: 1.8rem;
    font-size: 12px;
}

/* å‡å°‘expanderé—´è· */
.streamlit-expanderHeader {
    padding: 0.25rem 0.5rem;
    font-size: 13px;
}

/* ç´§å‡‘æŒ‡æ ‡ */
.css-1xarl3l {
    padding: 0.25rem;
}
</style>
""", unsafe_allow_html=True)


# åˆå§‹åŒ–çŠ¶æ€
initialize_session_state()

# é¦–æ¬¡ä½¿ç”¨å¼•å¯¼
if not st.session_state.first_time_guide_shown and len(existing_kbs) == 0:
    st.info("""
    ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ RAG Pro Maxï¼
    
    **å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼š**
    
    1ï¸âƒ£ **é…ç½® LLM**ï¼ˆå·¦ä¾§è¾¹æ ï¼‰
    - é€‰æ‹© Ollamaï¼ˆæœ¬åœ°ï¼‰æˆ– OpenAIï¼ˆäº‘ç«¯ï¼‰
    - è¾“å…¥ API ä¿¡æ¯
    
    2ï¸âƒ£ **åˆ›å»ºçŸ¥è¯†åº“**
    - ç‚¹å‡» "â• æ–°å»ºçŸ¥è¯†åº“..."
    - è¾“å…¥åç§°ï¼Œä¸Šä¼ æ–‡æ¡£
    
    3ï¸âƒ£ **å¼€å§‹å¯¹è¯**
    - é€‰æ‹©çŸ¥è¯†åº“
    - åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜
    
    ğŸ’¡ **æç¤º**ï¼šæ”¯æŒ PDFã€DOCXã€TXTã€MD ç­‰å¤šç§æ ¼å¼
    """)
    
    if st.button("âœ… æˆ‘çŸ¥é“äº†ï¼Œå¼€å§‹ä½¿ç”¨", use_container_width=True):
        st.session_state.first_time_guide_shown = True
        st.rerun()

def click_btn(q):
    """ç‚¹å‡»è¿½é—®æŒ‰é’®ï¼Œå°†é—®é¢˜åŠ å…¥é˜Ÿåˆ—ï¼ˆå»é‡ï¼‰"""
    from src.queue.queue_manager import QueueManager
    queue_manager = QueueManager()
    queue_manager.add_question(q)
    st.rerun()

# è®¡ç®—å½“å‰çš„ KB ID (æ ¹æ®ä¾§è¾¹æ é€‰æ‹©)
active_kb_name = current_kb_name if not is_create_mode else None

# è‡ªåŠ¨åŠ è½½é€»è¾‘
if active_kb_name and active_kb_name != st.session_state.current_kb_id:
    # åªåœ¨æ²¡æœ‰æ­£åœ¨å¤„ç†çš„é—®é¢˜æ—¶æ‰åˆ‡æ¢
    if not st.session_state.get('is_processing', False):
        st.session_state.current_kb_id = active_kb_name
        st.session_state.chat_engine = None
        with st.spinner("ğŸ“œ æ­£åœ¨åŠ è½½å¯¹è¯å†å²..."):
            st.session_state.messages = HistoryManager.load(active_kb_name)
        st.session_state.suggestions_history = []
    else:
        st.warning("âš ï¸ æ­£åœ¨å¤„ç†é—®é¢˜ï¼Œè¯·ç­‰å¾…å®Œæˆåå†åˆ‡æ¢çŸ¥è¯†åº“")
        st.session_state.current_nav = f"ğŸ“‚ {st.session_state.current_kb_id}"

# çŸ¥è¯†åº“åŠ è½½é€»è¾‘
if active_kb_name and st.session_state.chat_engine is None:
    from src.kb.kb_loader import KnowledgeBaseLoader
    
    kb_loader = KnowledgeBaseLoader(output_base)
    chat_engine, error_msg = kb_loader.load_knowledge_base(
        active_kb_name, embed_provider, embed_model, embed_key, embed_url
    )
    
    if chat_engine:
        st.session_state.chat_engine = chat_engine
        logger.success("é—®ç­”å¼•æ“å·²å¯ç”¨GPUåŠ é€Ÿ")
        logger.log("SUCCESS", f"çŸ¥è¯†åº“åŠ è½½æˆåŠŸ: {active_kb_name}", stage="çŸ¥è¯†åº“åŠ è½½")
        st.toast(f"âœ… çŸ¥è¯†åº“ '{active_kb_name}' æŒ‚è½½æˆåŠŸï¼")
        cleanup_memory()
    else:
        logger.log("ERROR", f"çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {active_kb_name} - {error_msg}", stage="çŸ¥è¯†åº“åŠ è½½")
        if "ç»´åº¦ä¸åŒ¹é…" in error_msg:
            # å¤„ç†ç»´åº¦ä¸åŒ¹é…çš„ç‰¹æ®Šæƒ…å†µ
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ é‡å»ºç´¢å¼•", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨æ¸…ç†æ—§ç´¢å¼•..."):
                        import shutil
                        db_path = os.path.join(output_base, active_kb_name)
                        shutil.rmtree(db_path, ignore_errors=True)
                        st.success("âœ… ç´¢å¼•å·²æ¸…ç†ï¼Œè¯·é‡æ–°ä¸Šä¼ æ–‡æ¡£")
                        time.sleep(2)
                        st.rerun()
            with col2:
                if st.button("â†©ï¸ åˆ‡æ¢æ¨¡å‹", use_container_width=True):
                    st.info("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©åŸæ¨¡å‹ï¼ˆé€šå¸¸æ˜¯ bge-small-zh-v1.5ï¼‰")
            st.stop()
        else:
            st.error(f"çŸ¥è¯†åº“æŒ‚è½½å¤±è´¥ï¼š{error_msg}")
            st.session_state.chat_engine = None 

# æŒ‰é’®å¤„ç†
if btn_start:
    config_to_save = {
        "target_path": target_path,
        "output_path": output_base,
        "llm_type_idx": 0 if llm_provider == "Ollama" else 1,
        "llm_url_ollama": llm_url if llm_provider == "Ollama" else "",
        "llm_model_ollama": llm_model if llm_provider == "Ollama" else "",
        "llm_url_openai": llm_url if llm_provider != "Ollama" else "",
        "llm_key": llm_key,
        "llm_model_openai": llm_model if llm_provider != "Ollama" else "",
        "embed_provider_idx": ["HuggingFace (æœ¬åœ°/æé€Ÿ)", "OpenAI-Compatible", "Ollama"].index(embed_provider),
        "embed_model_hf": embed_model if embed_provider.startswith("HuggingFace") else "",
        "embed_url_ollama": embed_url if embed_provider.startswith("Ollama") else "",
        "embed_model_ollama": embed_model if embed_provider.startswith("Ollama") else ""
    }
    ConfigLoader.save(config_to_save)

    if not final_kb_name:
        st.error("è¯·è¾“å…¥çŸ¥è¯†åº“åç§°")
    else:
        try:
            # ä½¿ç”¨ä¼˜åŒ–å™¨ç”Ÿæˆå”¯ä¸€åç§°ï¼Œé¿å…é‡å¤å’Œæ—¶é—´æˆ³å†²çª
            optimized_name = KBNameOptimizer.generate_unique_name(final_kb_name, output_base)
            
            if not optimized_name: 
                raise ValueError("çŸ¥è¯†åº“åç§°åŒ…å«éæ³•å­—ç¬¦æˆ–ä¸ºç©º")
            
            # å¦‚æœåç§°è¢«ä¼˜åŒ–äº†ï¼Œæç¤ºç”¨æˆ·
            if optimized_name != final_kb_name:
                st.info(f"ğŸ’¡ åç§°å·²ä¼˜åŒ–: `{final_kb_name}` â†’ `{optimized_name}`")
                
            # ä½¿ç”¨ä¼˜åŒ–åçš„åç§°
            final_kb_name = optimized_name
            
            process_knowledge_base_logic()
            st.session_state.current_nav = f"ğŸ“‚ {final_kb_name}"
            st.session_state.current_kb_id = None 
            
            if action_mode == "NEW" or action_mode == "APPEND":
                st.session_state.messages = []
                st.session_state.suggestions_history = []
                hist_path = os.path.join(HISTORY_DIR, f"{final_kb_name}.json")
                if os.path.exists(hist_path): os.remove(hist_path)
            
            time.sleep(1); st.rerun()
        except Exception as e:
            st.error(f"æ‰§è¡Œå¤±è´¥: {e}")

# --- ä¸»è§†å›¾æ¸²æŸ“ ---
if active_kb_name:
    from src.documents.document_manager import DocumentManager
    
    db_path = os.path.join(output_base, active_kb_name)
    doc_manager = DocumentManager(db_path)
    stats = doc_manager.get_kb_statistics()
    
    # é‡å‘½åé€»è¾‘å’Œç»Ÿè®¡æ˜¾ç¤º
    if st.session_state.renaming:
        def apply_rename():
            n = sanitize_filename(st.session_state.new_name_input)
            if n and n != active_kb_name:
                try:
                    kb_manager.base_path = output_base
                    success, msg = kb_manager.rename(active_kb_name, n)
                    if success:
                        st.session_state.current_nav = f"ğŸ“‚ {n}"
                        st.toast("âœ… é‡å‘½åæˆåŠŸ")
                    else:
                        st.error(f"é‡å‘½åå¤±è´¥: {msg}")
                except FileExistsError as e:
                    st.error(f"é‡å‘½åå¤±è´¥: {e}")
            st.session_state.renaming = False
        c1, c2 = st.columns([3, 1])
        c1.text_input("æ–°åç§°", value=active_kb_name, key="new_name_input", on_change=apply_rename)
        c2.button("å–æ¶ˆ", on_click=lambda: st.session_state.update({"renaming": False}))
    else:
        rename_col = doc_manager.render_statistics_overview(active_kb_name, stats)
        if rename_col.button("âœï¸", help="é‡å‘½å"): 
            st.session_state.renaming = True
    
    # æ–‡ä»¶ç®¡ç†
    with st.expander("ğŸ“Š çŸ¥è¯†åº“è¯¦æƒ…ä¸ç®¡ç†", expanded=False):
        if not doc_manager.manifest['files']: 
            st.info("æš‚æ— æ–‡ä»¶")
        else:
            # æ–‡æ¡£åˆ—è¡¨æŸ¥çœ‹
            tab1, tab2 = st.tabs(["ğŸ“Š ç»Ÿè®¡ä¿¡æ¯", "ğŸ“„ æ–‡æ¡£åˆ—è¡¨"])
            
            with tab1:
                # è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
                quality_info = doc_manager.render_detailed_statistics(stats)
                st.divider()
                
                # åˆ†å¸ƒåˆ†æ
                doc_manager.render_distribution_analysis(stats)
                st.divider()
                
                # å…ƒæ•°æ®ç»Ÿè®¡
                try:
                    metadata_mgr = MetadataManager(db_path)
                    if metadata_mgr.metadata or metadata_mgr.stats:
                        with st.expander("ğŸ“Š å…ƒæ•°æ®ç»Ÿè®¡", expanded=True):
                            stat_col1, stat_col2, stat_col3 = st.columns(3)
                            
                            with stat_col1:
                                st.markdown("**ğŸ”¥ çƒ­é—¨æ–‡ä»¶ Top 5**")
                                hot_files = metadata_mgr.get_hot_files(top_k=5)
                                if hot_files:
                                    for i, (fname, count) in enumerate(hot_files, 1):
                                        st.caption(f"{i}. {fname[:20]}... ({count})")
                                else:
                                    st.caption("æš‚æ— æ•°æ®")
                            
                            with stat_col2:
                                st.markdown("**ğŸ“‚ æ–‡æ¡£åˆ†ç±»**")
                                categories = metadata_mgr.get_all_categories()
                                if categories:
                                    for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:5]:
                                        st.caption(f"{cat}: {count}")
                                else:
                                    st.caption("æš‚æ— æ•°æ®")
                            
                            with stat_col3:
                                st.markdown("**ğŸ·ï¸ çƒ­é—¨å…³é”®è¯**")
                                keywords = metadata_mgr.get_all_keywords(top_k=8)
                                if keywords:
                                    kw_text = " Â· ".join([f"{kw}({cnt})" for kw, cnt in keywords[:8]])
                                    st.caption(kw_text)
                                else:
                                    st.caption("æš‚æ— æ•°æ®")
                            
                            # é‡å¤æ–‡ä»¶æ£€æµ‹
                            duplicates = metadata_mgr.find_duplicates()
                            if duplicates:
                                st.divider()
                                st.markdown(f"**âš ï¸ å‘ç° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶**")
                                for i, (file_hash, files) in enumerate(list(duplicates.items())[:2], 1):
                                    st.caption(f"ç»„{i}: {', '.join([f[:15] for f in files[:3]])}...")
                except:
                    pass  # å¦‚æœå…ƒæ•°æ®ä¸å­˜åœ¨ï¼Œé™é»˜è·³è¿‡
            
            st.divider()
            
            # å¿«é€Ÿæ“ä½œåŒº
            st.markdown("**âš¡ å¿«é€Ÿæ“ä½œ**")
            
            # å¿«é€Ÿæ“ä½œæŒ‰é’®ç»„ - åˆå¹¶ä¸ºå•è¡Œ
            op_col1, op_col2, op_col3, op_col4 = st.columns(4)
            
            # 1. æ‰“å¼€çŸ¥è¯†åº“ç›®å½•
            with op_col1:
                if st.button("ğŸ“‚ æ‰“å¼€ç›®å½•", use_container_width=True, help="åœ¨Finderä¸­æ‰“å¼€çŸ¥è¯†åº“æ–‡ä»¶å¤¹"):
                    import webbrowser
                    import urllib.parse
                    try:
                        file_url = 'file://' + urllib.parse.quote(os.path.abspath(db_path))
                        webbrowser.open(file_url)
                        st.toast("âœ… å·²åœ¨Finderä¸­æ‰“å¼€")
                    except Exception as e:
                        st.error(f"æ‰“å¼€å¤±è´¥: {e}")
            
            # 2. å¤åˆ¶è·¯å¾„
            with op_col2:
                if st.button("ğŸ“‹ å¤åˆ¶è·¯å¾„", use_container_width=True, help="å¤åˆ¶çŸ¥è¯†åº“è·¯å¾„åˆ°å‰ªè´´æ¿"):
                    try:
                        import subprocess
                        subprocess.run(["pbcopy"], input=db_path.encode(), check=True)
                        st.toast(f"âœ… å·²å¤åˆ¶")
                    except Exception as e:
                        st.info(f"ğŸ“ è·¯å¾„: {db_path}")
            
            # å‡†å¤‡æ‘˜è¦æ•°æ®
            files_without_summary = [f for f in doc_manager.manifest['files'] if not f.get('summary') and f.get('doc_ids')]
            if 'selected_for_summary' not in st.session_state:
                st.session_state.selected_for_summary = set()
            selected_count = len(st.session_state.selected_for_summary)
            
            # 3. ç”Ÿæˆæ‘˜è¦
            run_summary = False
            with op_col3:
                # å§‹ç»ˆæ˜¾ç¤ºæŒ‰é’®ï¼Œä½†æ ¹æ®é€‰ä¸­æ•°é‡å†³å®šæ˜¯å¦ç¦ç”¨
                button_label = f"âœ¨ æ‘˜è¦ ({selected_count})" if selected_count > 0 else "âœ¨ ç”Ÿæˆæ‘˜è¦"
                button_disabled = selected_count == 0
                
                if st.button(button_label, use_container_width=True, type="primary", disabled=button_disabled, help="ä¸ºé€‰ä¸­çš„æ–‡ä»¶ç”ŸæˆAIæ‘˜è¦"):
                    run_summary = True

            # 4. å¯¼å‡ºæ¸…å•
            with op_col4:
                if st.button("ğŸ“¥ å¯¼å‡ºæ¸…å•", use_container_width=True, help="å¯¼å‡ºå½“å‰æ–‡ä»¶åˆ—è¡¨"):
                    export_data = f"çŸ¥è¯†åº“: {active_kb_name}\næ–‡ä»¶æ•°: {stats['file_cnt']}\nç‰‡æ®µæ•°: {stats['total_chunks']}\n\næ–‡ä»¶åˆ—è¡¨:\n"
                    for f in doc_manager.manifest['files']:
                        export_data += f"- {f['name']} ({f['type']}, {len(f.get('doc_ids', []))} ç‰‡æ®µ)\n"
                    st.download_button("ä¸‹è½½", export_data, f"{active_kb_name}_æ¸…å•.txt", use_container_width=True)

            # æ‰§è¡Œæ‘˜è¦ç”Ÿæˆé€»è¾‘
            if run_summary and files_without_summary:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                from llama_index.core import StorageContext, load_index_from_storage as load_idx
                storage_context = StorageContext.from_defaults(persist_dir=db_path)
                idx = load_idx(storage_context)
                retriever = idx.as_retriever(similarity_top_k=3)
                
                success_count = 0
                for i, fname in enumerate(st.session_state.selected_for_summary):
                    status_text.text(f"æ­£åœ¨å¤„ç†: {fname} ({i+1}/{selected_count})")
                    try:
                        file_info = next((f for f in doc_manager.manifest['files'] if f['name'] == fname), None)
                        if file_info and file_info.get('doc_ids'):
                            # ä½¿ç”¨æ£€ç´¢å™¨è·å–æ–‡æ¡£å†…å®¹
                            nodes = retriever.retrieve(fname)
                            
                            doc_text = ""
                            for node in nodes:
                                if hasattr(node, 'node') and hasattr(node.node, 'text'):
                                    doc_text += node.node.text + "\n"
                                elif hasattr(node, 'text'):
                                    doc_text += node.text + "\n"
                                if len(doc_text) > 2000:
                                    break
                            
                            if doc_text.strip():
                                summary = generate_doc_summary(doc_text, fname)
                                file_info['summary'] = summary
                                success_count += 1
                    except Exception as e:
                        st.warning(f"âš ï¸ {fname}: {str(e)}")
                        
                        progress_bar.progress((i + 1) / selected_count)
                    
                    # ä¿å­˜ manifest
                    with open(ManifestManager.get_path(db_path), 'w', encoding='utf-8') as f:
                        json.dump(doc_manager.manifest, f, indent=4, ensure_ascii=False)
                    
                    status_text.empty()
                    progress_bar.empty()
                    st.success(f"âœ… å·²ç”Ÿæˆ {success_count}/{selected_count} ä¸ªæ‘˜è¦")
                    st.session_state.selected_for_summary = set()
                    time.sleep(1)
                    st.rerun()  # ç«‹å³åˆ·æ–°é¡µé¢æ˜¾ç¤ºæ‘˜è¦
            
            # æ–‡æ¡£åˆ—è¡¨æ ‡ç­¾é¡µ (v1.6)
            with tab2:
                show_kb_documents(active_kb_name)
            
            st.divider()
            
            # æœç´¢ç­›é€‰æ’åºï¼ˆå•è¡Œè¶…ç´§å‡‘å¸ƒå±€ï¼‰
            col1, col2, col3, col4, col5, col6, col7 = st.columns([2.5, 1.2, 1.2, 1.2, 1.2, 1.5, 1])
            search_term = col1.text_input("ğŸ”", "", key="file_search", placeholder="æœç´¢æ–‡ä»¶å...", label_visibility="collapsed")
            filter_type = col2.selectbox("ğŸ“‚", ["å…¨éƒ¨"] + sorted(set(f.get('type', 'Unknown') for f in doc_manager.manifest['files'])), label_visibility="collapsed")
            
            # åˆ†ç±»ç­›é€‰
            all_categories = set(f.get('category', 'å…¶ä»–') for f in doc_manager.manifest['files'] if f.get('category'))
            filter_category = col3.selectbox("ğŸ“‹", ["å…¨éƒ¨"] + sorted(all_categories), label_visibility="collapsed") if all_categories else "å…¨éƒ¨"
            
            # çƒ­åº¦ç­›é€‰
            filter_heat = col4.selectbox("ğŸ”¥", ["å…¨éƒ¨", "é«˜é¢‘", "ä¸­é¢‘", "ä½é¢‘", "æœªç”¨"], label_visibility="collapsed")
            
            # è´¨é‡ç­›é€‰
            filter_quality = col5.selectbox("âœ…", ["å…¨éƒ¨", "ä¼˜ç§€", "æ­£å¸¸", "ä½è´¨", "ç©º"], label_visibility="collapsed")
            
            sort_by = col6.selectbox("æ’åº", ["æ—¶é—´â†“", "æ—¶é—´â†‘", "å¤§å°â†“", "å¤§å°â†‘", "åç§°", "çƒ­åº¦â†“", "ç‰‡æ®µâ†“"], label_visibility="collapsed")
            page_size = col7.selectbox("é¡µ", [10, 20, 50, 100], index=0, label_visibility="collapsed")
            
            # ç­›é€‰æ–‡ä»¶
            filtered_files = doc_manager.manifest['files']
            
            # æœç´¢
            if search_term:
                filtered_files = [f for f in filtered_files if search_term.lower() in f['name'].lower()]
            
            # ç±»å‹ç­›é€‰
            if filter_type != "å…¨éƒ¨":
                filtered_files = [f for f in filtered_files if f.get('type') == filter_type]
            
            # åˆ†ç±»ç­›é€‰
            if filter_category != "å…¨éƒ¨":
                filtered_files = [f for f in filtered_files if f.get('category') == filter_category]
            
            # çƒ­åº¦ç­›é€‰
            if filter_heat == "é«˜é¢‘":
                filtered_files = [f for f in filtered_files if f.get('hit_count', 0) > 10]
            elif filter_heat == "ä¸­é¢‘":
                filtered_files = [f for f in filtered_files if 3 < f.get('hit_count', 0) <= 10]
            elif filter_heat == "ä½é¢‘":
                filtered_files = [f for f in filtered_files if 0 < f.get('hit_count', 0) <= 3]
            elif filter_heat == "æœªç”¨":
                filtered_files = [f for f in filtered_files if f.get('hit_count', 0) == 0]
            
            # è´¨é‡ç­›é€‰
            if filter_quality == "ä¼˜ç§€":
                filtered_files = [f for f in filtered_files if len(f.get('doc_ids', [])) >= 10]
            elif filter_quality == "æ­£å¸¸":
                filtered_files = [f for f in filtered_files if 2 <= len(f.get('doc_ids', [])) < 10]
            elif filter_quality == "ä½è´¨":
                filtered_files = [f for f in filtered_files if 0 < len(f.get('doc_ids', [])) < 2]
            elif filter_quality == "ç©º":
                filtered_files = [f for f in filtered_files if len(f.get('doc_ids', [])) == 0]
            
            # æ’åº
            if sort_by == "æ—¶é—´â†“":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('added_at', ''), reverse=True)
            elif sort_by == "æ—¶é—´â†‘":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('added_at', ''))
            elif sort_by == "å¤§å°â†“":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('size_bytes', 0), reverse=True)
            elif sort_by == "å¤§å°â†‘":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('size_bytes', 0))
            elif sort_by == "åç§°A-Z":
                filtered_files = sorted(filtered_files, key=lambda x: x['name'].lower())
            elif sort_by == "çƒ­åº¦â†“":
                filtered_files = sorted(filtered_files, key=lambda x: x.get('hit_count', 0), reverse=True)
            elif sort_by == "ç‰‡æ®µâ†“":
                filtered_files = sorted(filtered_files, key=lambda x: len(x.get('doc_ids', [])), reverse=True)
            
            # åˆ†é¡µ
            total_files = len(filtered_files)
            total_pages = (total_files + page_size - 1) // page_size if total_files > 0 else 1
            
            if 'file_page' not in st.session_state:
                st.session_state.file_page = 1
            
            # ç¡®ä¿é¡µç åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if st.session_state.file_page > total_pages:
                st.session_state.file_page = 1
            
            # åˆ†é¡µæ§åˆ¶å’Œç»Ÿè®¡
            if total_files == 0:
                st.info("âŒ æ— åŒ¹é…æ–‡ä»¶")
            else:
                # ç®€æ´çš„ç­›é€‰ç»“æœï¼ˆå•è¡Œï¼‰
                filters = []
                if search_term: filters.append(f"'{search_term}'")
                if filter_type != "å…¨éƒ¨": filters.append(filter_type)
                if filter_category != "å…¨éƒ¨": filters.append(filter_category)
                if filter_heat != "å…¨éƒ¨": filters.append(filter_heat)
                if filter_quality != "å…¨éƒ¨": filters.append(filter_quality)
                
                if filters:
                    st.caption(f"**{' Â· '.join(filters)}** â†’ {total_files} ä¸ª")
                
                # åˆ†é¡µæ§åˆ¶
                if total_pages > 1:
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        page_cols = st.columns([1, 3, 1])
                        if page_cols[0].button("â¬…ï¸ ä¸Šä¸€é¡µ", disabled=st.session_state.file_page <= 1):
                            st.session_state.file_page -= 1
                        page_cols[1].markdown(f"<div style='text-align:center'>ç¬¬ {st.session_state.file_page}/{total_pages} é¡µ</div>", unsafe_allow_html=True)
                        if page_cols[2].button("ä¸‹ä¸€é¡µ â¡ï¸", disabled=st.session_state.file_page >= total_pages):
                            st.session_state.file_page += 1
                
                # è®¡ç®—å½“å‰é¡µæ–‡ä»¶èŒƒå›´
                start_idx = (st.session_state.file_page - 1) * page_size
                end_idx = min(start_idx + page_size, total_files)
                
                # è¡¨å¤´
                cols = st.columns([0.5, 2.5, 1, 0.8, 1, 0.8, 1.2, 0.8])
                
                # å…¨é€‰å¤é€‰æ¡†
                current_page_files = [f['name'] for f in filtered_files[start_idx:end_idx] if not f.get('summary') and f.get('doc_ids')]
                if current_page_files:
                    all_selected = all(fname in st.session_state.selected_for_summary for fname in current_page_files)
                    
                    # ä½¿ç”¨é»˜è®¤å‚æ•°æ•è·å½“å‰å€¼
                    def toggle_select_all(files=current_page_files):
                        if st.session_state.get(f"select_all_page_{st.session_state.file_page}"):
                            st.session_state.selected_for_summary.update(files)
                        else:
                            st.session_state.selected_for_summary.difference_update(files)
                    
                    select_all = cols[0].checkbox(
                        "å…¨é€‰", 
                        value=all_selected, 
                        key=f"select_all_page_{st.session_state.file_page}", 
                        label_visibility="collapsed",
                        on_change=toggle_select_all
                    )
                else:
                    cols[0].markdown("**âœ¨**")
                
                cols[1].caption(f"**æ–‡ä»¶åˆ—è¡¨ (å…± {total_files} ä¸ª)**")
                cols[2].caption("**æ“ä½œ**")
                st.divider()
                
                # æ³¨å…¥æè‡´ç´§å‡‘ CSS
                st.markdown("""
                <style>
                /* æè‡´å‹ç¼©å‚ç›´é—´è· */
                div[data-testid="stVerticalBlock"] > div[data-testid="stVerticalBlock"] {
                    gap: 0.1rem !important;
                }
                /* å¡ç‰‡å†…éƒ¨ padding æœ€å°åŒ– */
                div[data-testid="stContainer"] {
                    padding: 0.3rem 0.6rem !important;
                    margin-bottom: 0.1rem !important;
                }
                /* Expander æ ‡é¢˜æ é«˜åº¦å‹ç¼© & ç§»é™¤å¤–è¾¹è· */
                .streamlit-expanderHeader {
                    height: 1.8rem !important;
                    padding-top: 0 !important;
                    padding-bottom: 0 !important;
                    min-height: unset !important;
                    margin-bottom: 0 !important; /* å…³é”® */
                }
                /* Expander æ•´ä½“ä¸Šç§» */
                div[data-testid="stExpander"] {
                    margin-top: -0.2rem !important;
                    border: none !important;
                    box-shadow: none !important;
                }
                /* Expander å†…å®¹åŒºåŸŸå»é¡¶è· */
                div[data-testid="stExpanderDetails"] {
                    padding-top: 0 !important;
                    padding-bottom: 0.2rem !important;
                }
                /* åˆ†å‰²çº¿ç´§å‡‘ */
                hr {
                    margin-top: 0.1rem !important;
                    margin-bottom: 0.1rem !important;
                }
                /* æ–‡æœ¬ç´§å‡‘ */
                p, h5, span {
                    margin: 0 !important;
                    padding: 0 !important;
                    line-height: 1.3 !important;
                }
                /* æŒ‰é’®ç´§å‡‘ */
                button {
                    height: 1.6rem !important;
                    padding-top: 0 !important;
                    padding-bottom: 0 !important;
                    min-height: unset !important;
                }
                </style>
                """, unsafe_allow_html=True)

                # æ¸²æŸ“æ–‡ä»¶åˆ—è¡¨ (One-Line Card æ¨¡å¼)
                for i in range(start_idx, end_idx):
                    f = filtered_files[i]
                    orig_idx = doc_manager.manifest['files'].index(f)
                    chunk_count = len(f.get('doc_ids', []))
                    
                    # å‡†å¤‡å…ƒæ•°æ®
                    display_date = f.get('creation_date', f.get('added_at', '')[:10])
                    
                    # è´¨é‡è¯„ä¼°
                    if chunk_count == 0:
                        q_icon = "âŒ"
                    elif chunk_count < 2:
                        q_icon = "âš ï¸"
                    elif chunk_count < 10:
                        q_icon = "âœ…"
                    else:
                        q_icon = "ğŸ‰"

                    # === æç®€å¡ç‰‡å®¹å™¨ ===
                    with st.container(border=True):
                        # å•è¡Œå¸ƒå±€ï¼šæ ‡é¢˜ + å…ƒæ•°æ® + æ‘˜è¦ + è¯¦æƒ… + æ“ä½œ
                        col_info, col_summary, col_detail, col_ops = st.columns([5.5, 1.5, 1.5, 1.5])
                        
                        with col_info:
                            # æ ¸å¿ƒæ”¹åŠ¨ï¼šä¸€è¡Œæ˜¾ç¤ºæ‰€æœ‰å…³é”®ä¿¡æ¯
                            # æ ¼å¼ï¼šğŸ“„ æ–‡ä»¶å.pdf  [ç°è‰²å°å­—: 2.5MB Â· 2023-12-12 Â· è´¨é‡ Â· å‘½ä¸­3æ¬¡]
                            file_icon = f.get('icon', 'ğŸ“„')
                            
                            # æˆªæ–­è¶…é•¿æ–‡ä»¶å
                            fname = f['name']
                            if len(fname) > 25: fname = fname[:23] + "..."
                            
                            # æ·»åŠ æ›´å¤šå…³é”®ä¿¡æ¯åˆ°ä¸€è¡Œä¸­
                            hit_count = f.get('hit_count', 0)
                            category = f.get('category', '')
                            hit_info = f"å‘½ä¸­{hit_count}æ¬¡" if hit_count > 0 else ""
                            category_info = f"{category}" if category and category != 'æœªåˆ†ç±»' else ""
                            
                            # ç»„åˆé¢å¤–ä¿¡æ¯
                            extra_info = " Â· ".join(filter(None, [hit_info, category_info]))
                            if extra_info:
                                extra_info = " Â· " + extra_info
                            
                            line_html = f"""
                            <div style='display: flex; align-items: baseline; white-space: nowrap; overflow: hidden;'>
                                <span style='font-weight: 600; font-size: 1rem; margin-right: 0.5rem;'>{file_icon} {fname}</span>
                                <span style='color: gray; font-size: 0.75rem;'>
                                    {f['size']} Â· {chunk_count}ç‰‡æ®µ Â· {display_date} Â· {q_icon}{extra_info}
                                </span>
                            </div>
                            """
                            st.markdown(line_html, unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºæ‘˜è¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                            if f.get('summary'):
                                summary_text = f['summary']
                                if len(summary_text) > 100:
                                    summary_text = summary_text[:97] + "..."
                                st.caption(f"ğŸ“ {summary_text}")
                        
                        with col_summary:
                            # æ‘˜è¦ç”ŸæˆæŒ‰é’®
                            if not f.get('summary') and f.get('doc_ids'):
                                if st.button("âœ¨ æ‘˜è¦", key=f"summary_{i}", help="ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"):
                                    with st.spinner("ç”Ÿæˆä¸­..."):
                                        try:
                                            # ç›´æ¥ä»ç´¢å¼•è·å–æ–‡æ¡£å†…å®¹
                                            from llama_index.core import StorageContext, load_index_from_storage
                                            
                                            storage_context = StorageContext.from_defaults(persist_dir=db_path)
                                            index = load_index_from_storage(storage_context)
                                            retriever = index.as_retriever(similarity_top_k=3)
                                            
                                            nodes = retriever.retrieve(f['name'])
                                            
                                            doc_text = ""
                                            for node in nodes:
                                                if hasattr(node, 'node') and hasattr(node.node, 'text'):
                                                    doc_text += node.node.text + "\n"
                                                elif hasattr(node, 'text'):
                                                    doc_text += node.text + "\n"
                                                if len(doc_text) > 2000:
                                                    break
                                            
                                            if doc_text.strip():
                                                summary = generate_doc_summary(doc_text, f['name'])
                                                if summary:
                                                    # æ›´æ–°manifest
                                                    f['summary'] = summary
                                                    doc_manager.manifest['files'][orig_idx]['summary'] = summary
                                                    
                                                    # ä¿å­˜manifest
                                                    from src.config.manifest_manager import ManifestManager
                                                    ManifestManager.save(db_path, doc_manager.manifest['files'], doc_manager.manifest.get('embed_model', 'Unknown'))
                                                    
                                                    st.success("âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸï¼")
                                                    st.rerun()
                                                else:
                                                    st.error("âŒ ç”Ÿæˆå¤±è´¥")
                                            else:
                                                st.warning("âš ï¸ æ— å†…å®¹")
                                        except Exception as e:
                                            st.error(f"âŒ å¤±è´¥: {str(e)}")
                            elif f.get('summary'):
                                st.caption("ğŸ“– å·²æœ‰æ‘˜è¦")
                        
                        with col_detail:
                            # æ›´å¤šè¯¦æƒ…æŒ‰é’® - æ‰“å¼€æ–‡æ¡£è¯¦æƒ…å¯¹è¯æ¡†
                            if st.button("ğŸ” è¯¦æƒ…", key=f"detail_{i}", help="æŸ¥çœ‹æ–‡æ¡£è¯¦æƒ…"):
                                st.session_state['show_doc_detail'] = f
                                st.session_state['show_doc_detail_kb'] = active_kb_name
                        
                        with col_ops:
                            # æ“ä½œåŒºï¼šä»…ä¿ç•™åˆ é™¤æŒ‰é’®ï¼ŒèŠ‚çœç©ºé—´
                            # è¿™é‡Œçš„ key å¿…é¡»å”¯ä¸€
                            if st.button("ğŸ—‘ï¸", key=f"del_{i}", help="åˆ é™¤æ–‡ä»¶"):
                                with st.status(f"åˆ é™¤ä¸­...", expanded=True) as status:
                                    try:
                                        ctx = StorageContext.from_defaults(persist_dir=db_path)
                                        idx = load_index_from_storage(ctx)
                                        for did in f.get('doc_ids', []):
                                            idx.delete_ref_doc(did, delete_from_docstore=True)
                                        idx.storage_context.persist(persist_dir=db_path)
                                        remove_file_from_manifest(db_path, f['name'])
                                        status.update(label="å·²åˆ é™¤", state="complete")
                                        st.session_state.chat_engine = None
                                        time.sleep(0.5); st.rerun()
                                    except Exception as e: st.error(str(e))
                
                # åº•éƒ¨åˆ†é¡µï¼ˆæ–¹ä¾¿ç¿»é¡µï¼‰
                if total_pages > 1:
                    st.divider()
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        page_cols = st.columns([1, 3, 1])
                        if page_cols[0].button("â¬…ï¸", key="prev_bottom", disabled=st.session_state.file_page <= 1):
                            st.session_state.file_page -= 1
                        page_cols[1].markdown(f"<div style='text-align:center'>ç¬¬ {st.session_state.file_page}/{total_pages} é¡µ Â· å…± {total_files} ä¸ªæ–‡ä»¶</div>", unsafe_allow_html=True)
                        if page_cols[2].button("â¡ï¸", key="next_bottom", disabled=st.session_state.file_page >= total_pages):
                            st.session_state.file_page += 1

# æ–‡æ¡£è¯¦æƒ…å¯¹è¯æ¡†è°ƒç”¨
if st.session_state.get('show_doc_detail') and st.session_state.get('show_doc_detail_kb'):
    show_document_detail_dialog(st.session_state.show_doc_detail_kb, st.session_state.show_doc_detail)

# åˆ›å»ºæ¨¡å¼çš„æ¬¢è¿ç•Œé¢
if is_create_mode:
    st.markdown("""
    <div class="welcome-box">
        <h2>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨çŸ¥è¯†åº“</h2>
        <p>è¯·åœ¨å·¦ä¾§ <b>ä¾§è¾¹æ </b> é…ç½®æ•°æ®æº (æ”¯æŒç²˜è´´è·¯å¾„æˆ–æ‹–æ‹½æ–‡ä»¶)ï¼Œç‚¹å‡» <b>ğŸš€ ç«‹å³åˆ›å»º</b> å¼€å§‹ã€‚</p>
    </div>
    """, unsafe_allow_html=True)


# è‡ªåŠ¨æ‘˜è¦ (ä»…åœ¨çŸ¥è¯†åº“é¦–æ¬¡åŠ è½½ä¸”æ— å†å²æ¶ˆæ¯æ—¶è§¦å‘)
if active_kb_name and st.session_state.chat_engine and not st.session_state.messages:
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        summary_placeholder = st.empty()
        with st.status("âœ¨ æ­£åœ¨åˆ†ææ–‡æ¡£ç”Ÿæˆæ‘˜è¦...", expanded=True) as status:
            try:
                # ä½¿ç”¨çŸ¥è¯†åº“çš„æ¨¡å‹ï¼ˆå·²åœ¨æŒ‚è½½æ—¶è®¾ç½®ï¼Œæ— éœ€é‡å¤è®¾ç½®ï¼‰
                current_model = getattr(Settings.embed_model, '_model_name', 'Unknown')
                logger.info(f"ğŸ’¬ æ‘˜è¦ç”Ÿæˆä½¿ç”¨æ¨¡å‹: {current_model}")
                
                prompt = "è¯·ç”¨ä¸€æ®µè¯ç®€è¦æ€»ç»“æ­¤çŸ¥è¯†åº“çš„æ ¸å¿ƒå†…å®¹ã€‚ç„¶åï¼Œæå‡º3ä¸ªç”¨æˆ·å¯èƒ½æœ€å…³å¿ƒçš„é—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦åºå·ã€‚"
                full = ""
                resp = st.session_state.chat_engine.stream_chat(prompt)
                
                for t in resp.response_gen:
                    full += t
                    summary_placeholder.markdown(full + "â–Œ")
                
                status.update(label="âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ", state="complete")
                summary_placeholder.markdown(full)
                
                summary_lines = full.split('\n')
                summary = summary_lines[0]
                sug = [re.sub(r'^\d+\.\s*', '', q.strip()) for q in summary_lines[1:] if q.strip()][:3]

                st.session_state.messages.append({"role": "assistant", "content": summary, "suggestions": sug})
                HistoryManager.save(active_kb_name, state.get_messages())
                st.rerun()
            except Exception as e:
                error_msg = str(e)
                if "timed out" in error_msg.lower() or "timeout" in error_msg.lower():
                    status.update(label="â±ï¸ æ‘˜è¦ç”Ÿæˆè¶…æ—¶", state="error")
                    summary_placeholder.info("â±ï¸ LLM å“åº”è¶…æ—¶ï¼Œå·²è·³è¿‡è‡ªåŠ¨æ‘˜è¦ã€‚æ‚¨å¯ä»¥ç›´æ¥å¼€å§‹æé—®ã€‚")
                    logger.warning(f"â±ï¸ æ‘˜è¦ç”Ÿæˆè¶…æ—¶: {e}")
                else:
                    status.update(label="âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥", state="error")
                    summary_placeholder.warning(f"æ‘˜è¦ç”Ÿæˆå—é˜»: {e}")
                    logger.error(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
                st.session_state.messages.append({"role": "assistant", "content": "ğŸ‘‹ çŸ¥è¯†åº“å·²å°±ç»ªã€‚"})

# æ¸²æŸ“æ¶ˆæ¯
for msg_idx, msg in enumerate(state.get_messages()):
    role = msg["role"]
    avatar = "ğŸ¤–" if role == "assistant" else "ğŸ§‘â€ğŸ’»"
    with st.chat_message(role, avatar=avatar):
        st.markdown(msg["content"])
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰- ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.1)
        if "stats" in msg and msg["stats"]:
            render_message_stats(msg["stats"])
        
        # æ¸²æŸ“å¼•ç”¨æº - ä½¿ç”¨æ–°ç»„ä»¶ (Stage 3.1)
        if "sources" in msg:
            render_source_references(msg["sources"], expanded=True)
        
        # å¼•ç”¨æŒ‰é’® (P2 æ¢å¤åŠŸèƒ½)
        if role == "assistant":
            if st.button("ğŸ“Œ å¼•ç”¨æ­¤å›å¤", key=f"quote_{msg_idx}"):
                st.session_state.quote_content = msg["content"]
                st.rerun()

        # æ¸²æŸ“é™æ€å»ºè®® (ä»…ç”¨äºè‡ªåŠ¨æ‘˜è¦)
        is_last_message = msg_idx == len(state.get_messages()) - 1
        if "suggestions" in msg and msg["suggestions"] and is_last_message and not st.session_state.suggestions_history:
            st.write("")
            for idx, q in enumerate(msg["suggestions"]):
                if st.button(f"ğŸ‘‰ {q}", key=f"sug_{msg_idx}_{idx}", use_container_width=True):
                    click_btn(q)
    
    # åœ¨æœ€åä¸€æ¡ assistant æ¶ˆæ¯ä¹‹åæ˜¾ç¤ºåŠ¨æ€è¿½é—®æ¨èï¼ˆåœ¨ chat_message å®¹å™¨å¤–ï¼‰
    is_last_message = msg_idx == len(state.get_messages()) - 1
    if is_last_message and msg["role"] == "assistant" and active_kb_name and st.session_state.chat_engine:
        import hashlib
        msg_hash = hashlib.md5(msg['content'][:100].encode()).hexdigest()[:8]
        
        st.divider()
        
        @st.fragment
        def suggestions_fragment():
            if st.session_state.suggestions_history:
                st.markdown("##### ğŸš€ è¿½é—®æ¨è")
                for idx, q in enumerate(st.session_state.suggestions_history):
                    if st.button(f"ğŸ‘‰ {q}", key=f"dyn_sug_{msg_hash}_{idx}", use_container_width=True):
                        click_btn(q)
            
            if st.button("âœ¨ ç»§ç»­æ¨è 3 ä¸ªè¿½é—® (æ— é™è¿½é—®)", key=f"gen_more_{msg_hash}", type="secondary", use_container_width=True):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæ–°é—®é¢˜..."):
                    all_history_questions = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
                    all_history_questions.extend(st.session_state.suggestions_history)
                    # æ’é™¤é˜Ÿåˆ—ä¸­çš„é—®é¢˜
                    all_history_questions.extend(st.session_state.question_queue)
                    
                    # è·å–LLMæ¨¡å‹
                    llm_model = None
                    if st.session_state.get('chat_engine'):
                        chat_engine = st.session_state.chat_engine
                        if hasattr(chat_engine, '_llm'):
                            llm_model = chat_engine._llm
                        elif hasattr(chat_engine, 'llm'):
                            llm_model = chat_engine.llm
                    
                    new_sugs = generate_follow_up_questions(
                        context_text=msg['content'], 
                        num_questions=3,
                        existing_questions=all_history_questions,
                        query_engine=st.session_state.chat_engine if st.session_state.get('chat_engine') else None,
                        llm_model=llm_model
                    )
                    
                    if new_sugs:
                        # è¯¦ç»†æ—¥å¿—è®°å½•
                        logger.info(f"ğŸ”„ ç»§ç»­ç”Ÿæˆ {len(new_sugs)} ä¸ªæ–°æ¨èé—®é¢˜")
                        for i, q in enumerate(new_sugs[:3], 1):
                            logger.info(f"   {i}. {q}")
                        
                        # ç´¯ç§¯å†å²æ¨èï¼Œé¿å…é‡å¤
                        if not hasattr(st.session_state, 'suggestions_history'):
                            st.session_state.suggestions_history = []
                        
                        # è¿‡æ»¤é‡å¤é—®é¢˜
                        new_suggestions = []
                        for sugg in new_sugs:
                            if sugg not in st.session_state.suggestions_history:
                                new_suggestions.append(sugg)
                        
                        # æ›´æ–°æ˜¾ç¤ºï¼ˆä½¿ç”¨æ–°ç”Ÿæˆçš„é—®é¢˜ï¼‰
                        st.session_state.suggestions_history = new_suggestions[:3] if new_suggestions else new_sugs[:3]
                        st.rerun(scope="fragment")
                    else:
                        logger.info("âš ï¸ æœªèƒ½ç”Ÿæˆæ›´å¤šè¿½é—®")
                        st.warning("æœªèƒ½ç”Ÿæˆæ›´å¤šè¿½é—®ï¼Œè¯·å°è¯•è¾“å…¥æ–°é—®é¢˜ã€‚")
            
        suggestions_fragment()

# æ¨¡å‹ä¸ä»»åŠ¡è®¾ç½®
with st.expander("ğŸ¤– æ¨¡å‹ä¸ä»»åŠ¡è®¾ç½®", expanded=False):
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    try:
        ollama_url = st.session_state.get('llm_url', "http://localhost:11434")
        models, error = fetch_remote_models(ollama_url, "")
        
        if models:
            available_models = models
        else:
            # logger.warning(f"æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {error}")
            available_models = ["llama3", "mistral", "gemma", "deepseek-coder", "qwen2.5:7b"] # Fallback list
    except Exception as e:
        # logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¼‚å¸¸: {e}")
        available_models = ["llama3", "mistral", "qwen2.5:7b"]
        
    # è·å–å½“å‰æ¨¡å‹
    current_model = st.session_state.get('selected_model', 'qwen2.5:7b')
    if current_model not in available_models:
        # å¦‚æœå½“å‰æ¨¡å‹ä¸åœ¨åˆ—è¡¨ä¸­ï¼ˆå¯èƒ½æ˜¯åˆæ¬¡åŠ è½½ï¼‰ï¼Œå°è¯•åŒ¹é…
        if available_models:
            # ä¼˜å…ˆä¿æŒå½“å‰è®¾ç½®ï¼ˆå¦‚æœåªæ˜¯åˆ—è¡¨è·å–å¤±è´¥ï¼‰ï¼Œå¦åˆ™é€‰ç¬¬ä¸€ä¸ª
            if current_model not in ["llama3", "mistral", "qwen2.5:7b"]:
                 current_model = available_models[0]
            
    # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
    selected_model_new = st.selectbox(
        "é€‰æ‹© AI æ¨¡å‹ (æ ¹æ®ä»»åŠ¡éœ€æ±‚åˆ‡æ¢)",
        options=available_models,
        index=available_models.index(current_model) if current_model in available_models else 0,
        key="model_selector_dropdown",
        help="Code: å†™ä»£ç  | Vision: çœ‹å›¾ | Chat: é—²èŠ"
    )
    
    # æ£€æµ‹æ¨¡å‹å˜æ›´
    if selected_model_new != st.session_state.get('selected_model'):
        st.session_state.selected_model = selected_model_new
        # åˆ‡æ¢å…¨å±€ LLM
        # å‡è®¾éƒ½æ˜¯ Ollama æ¨¡å‹ï¼Œå¦‚æœæœ‰å…¶ä»– provider éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
        if set_global_llm_model("Ollama", selected_model_new, api_url=ollama_url):
            st.toast(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: {selected_model_new}", icon="ğŸ¤–")
        else:
            st.toast(f"âŒ åˆ‡æ¢æ¨¡å‹å¤±è´¥: {selected_model_new}", icon="âš ï¸")

# å¼•ç”¨å†…å®¹é¢„è§ˆåŒº
if st.session_state.get("quote_content"):
    quote_text = st.session_state.quote_content
    display_text = quote_text[:60].replace('\n', ' ') + "..." if len(quote_text) > 60 else quote_text
    
    with st.container():
        st.info(f"ğŸ“Œ **å·²å¼•ç”¨**: {display_text}")
        col1, col2 = st.columns([8, 2])
        col1.caption("åŸºäºæ­¤å†…å®¹æé—®...")
        if col2.button("å–æ¶ˆå¼•ç”¨", key="cancel_quote", use_container_width=True):
            st.session_state.quote_content = None
            st.rerun()

# æŸ¥è¯¢ä¼˜åŒ–è®¾ç½®
with st.expander("ğŸ”§ æŸ¥è¯¢è®¾ç½®", expanded=False):
    enable_query_optimization = st.checkbox(
        "ğŸ’¡ å¯ç”¨æŸ¥è¯¢ä¼˜åŒ–", 
        value=st.session_state.get('enable_query_optimization', False),
        help="AIä¼šåˆ†æå¹¶ä¼˜åŒ–ä½ çš„é—®é¢˜ï¼Œæå‡æ£€ç´¢å‡†ç¡®æ€§"
    )
    st.session_state.enable_query_optimization = enable_query_optimization
    
    if enable_query_optimization:
        st.caption("âœ… ç³»ç»Ÿä¼šå»ºè®®ä¼˜åŒ–æŸ¥è¯¢ï¼Œç”±ä½ é€‰æ‹©æ˜¯å¦ä½¿ç”¨")
    else:
        st.caption("ğŸ“ ç›´æ¥ä½¿ç”¨åŸé—®é¢˜è¿›è¡Œæ£€ç´¢")

# å¤„ç†è¾“å…¥
user_input = st.chat_input("è¾“å…¥é—®é¢˜...")

# å¦‚æœæœ‰æ–°è¾“å…¥ï¼ŒåŠ å…¥é˜Ÿåˆ—
if user_input:
    if not st.session_state.chat_engine:
        st.error("è¯·å…ˆç‚¹å‡»å·¦ä¾§ã€ğŸš€ æ‰§è¡Œå¤„ç†ã€‘å¯åŠ¨ç³»ç»Ÿ")
    else:
        st.session_state.question_queue.append(user_input)

# å¤„ç† prompt_triggerï¼ˆè¿½é—®æŒ‰é’®ï¼‰
if st.session_state.prompt_trigger:
    if st.session_state.chat_engine:
        st.session_state.question_queue.append(st.session_state.prompt_trigger)
    st.session_state.prompt_trigger = None

# æ˜¾ç¤ºé˜Ÿåˆ—çŠ¶æ€
queue_len = len(st.session_state.question_queue)
if st.session_state.get('is_processing'):
    if queue_len > 0:
        # æ˜¾ç¤ºé˜Ÿåˆ—ä¸­çš„é—®é¢˜
        with st.expander(f"â³ æ­£åœ¨å¤„ç†é—®é¢˜ï¼Œé˜Ÿåˆ—ä¸­è¿˜æœ‰ {queue_len} ä¸ªé—®é¢˜ç­‰å¾…...", expanded=True):
            for i, q in enumerate(st.session_state.question_queue, 1):
                # æˆªæ–­è¿‡é•¿çš„é—®é¢˜
                display_q = q[:50] + "..." if len(q) > 50 else q
                st.caption(f"{i}. {display_q}")
            
            # æ·»åŠ é˜Ÿåˆ—é‡ç½®æŒ‰é’®
            if st.button("ğŸ”„ é‡ç½®é˜Ÿåˆ—ï¼ˆå¦‚æœå¡ä½ï¼‰", key="reset_queue"):
                st.session_state.is_processing = False
                st.session_state.question_queue = []
                st.success("âœ… é˜Ÿåˆ—å·²é‡ç½®")
                st.rerun()
    else:
        st.info("â³ æ­£åœ¨å¤„ç†é—®é¢˜...")
        # æ·»åŠ é‡ç½®æŒ‰é’®ï¼ˆé˜²æ­¢å¡ä½ï¼‰
        if st.button("ğŸ”„ é‡ç½®çŠ¶æ€", key="reset_processing"):
            st.session_state.is_processing = False
            st.success("âœ… å¤„ç†çŠ¶æ€å·²é‡ç½®")
            st.rerun()
elif queue_len > 0:
    # æ˜¾ç¤ºå¾…å¤„ç†çš„é—®é¢˜åˆ—è¡¨
    with st.expander(f"ğŸ“ é˜Ÿåˆ—ä¸­æœ‰ {queue_len} ä¸ªé—®é¢˜å¾…å¤„ç†", expanded=True):
        for i, q in enumerate(st.session_state.question_queue, 1):
            display_q = q[:50] + "..." if len(q) > 50 else q
            st.caption(f"{i}. {display_q}")
        
        # æ·»åŠ æ¸…ç©ºé˜Ÿåˆ—æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºé˜Ÿåˆ—", key="clear_queue"):
            st.session_state.question_queue = []
            st.success("âœ… é˜Ÿåˆ—å·²æ¸…ç©º")
            st.rerun()

# ä»é˜Ÿåˆ—ä¸­å–å‡ºé—®é¢˜å¤„ç†
if not st.session_state.get('is_processing', False) and st.session_state.question_queue:
    final_prompt = st.session_state.question_queue.pop(0)
    logger.info(f"ğŸš€ å¼€å§‹å¤„ç†é˜Ÿåˆ—é—®é¢˜: {final_prompt[:50]}...")
    
    if st.session_state.chat_engine:
        # ä¸æ¸…ç©º suggestions_historyï¼Œä¿ç•™è¿½é—®æŒ‰é’®
        st.session_state.is_processing = True  # æ ‡è®°æ­£åœ¨å¤„ç†
        logger.info("âœ… è®¾ç½®å¤„ç†çŠ¶æ€ä¸º True")
        
        # å¼ºåˆ¶æ£€æµ‹çŸ¥è¯†åº“ç»´åº¦å¹¶åˆ‡æ¢æ¨¡å‹ï¼ˆé™é»˜å¤„ç†ï¼Œä¸æ˜¾ç¤ºåŠ è½½ï¼‰
        # ä¼˜åŒ–ï¼šåªåœ¨é¦–æ¬¡æˆ–åˆ‡æ¢çŸ¥è¯†åº“æ—¶æ£€æµ‹ï¼Œé¿å…æ¯æ¬¡é—®ç­”éƒ½é‡å¤
        db_path = os.path.join(output_base, active_kb_name)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ£€æµ‹ï¼ˆçŸ¥è¯†åº“åˆ‡æ¢æˆ–é¦–æ¬¡ï¼‰
        last_checked_kb = st.session_state.get('_last_checked_kb')
        if last_checked_kb != active_kb_name:
            kb_dim = get_kb_embedding_dim(db_path)
            
            # ä¸ºå†å²çŸ¥è¯†åº“è‡ªåŠ¨ä¿å­˜ä¿¡æ¯
            kb_name = os.path.basename(db_path)
            kb_manager.save_info(kb_name, embed_model, 0)
            
            # ç»´åº¦æ˜ å°„
            model_map = {
                512: "BAAI/bge-small-zh-v1.5",
                768: "BAAI/bge-large-zh-v1.5",
                1024: "BAAI/bge-m3"
            }
            
            # å¦‚æœæ£€æµ‹åˆ°ç»´åº¦ï¼Œå¼ºåˆ¶åˆ‡æ¢
            if kb_dim and kb_dim in model_map:
                required_model = model_map[kb_dim]
                if embed_model != required_model:
                    print(f"ğŸ”„ å¼ºåˆ¶åˆ‡æ¢æ¨¡å‹: {embed_model} â†’ {required_model} (ç»´åº¦: {kb_dim}D)")
                    embed_model = required_model
                    embed = get_embed(embed_provider, embed_model, embed_key, embed_url)
                    if embed:
                        Settings.embed_model = embed
                        print(f"âœ… æ¨¡å‹å·²åˆ‡æ¢")
            else:
                # ç»´åº¦æ£€æµ‹å¤±è´¥æ—¶ï¼Œé™çº§åˆ°æœ€å°æ¨¡å‹ï¼ˆ512ç»´ï¼‰
                print(f"âš ï¸ ç»´åº¦æ£€æµ‹å¤±è´¥ï¼Œé™çº§åˆ°æœ€å°æ¨¡å‹")
                fallback_model = "BAAI/bge-small-zh-v1.5"
                if embed_model != fallback_model:
                    print(f"ğŸ”„ é™çº§åˆ‡æ¢: {embed_model} â†’ {fallback_model}")
                    embed_model = fallback_model
                    embed = get_embed(embed_provider, embed_model, embed_key, embed_url)
                    if embed:
                        Settings.embed_model = embed
                        print(f"âœ… å·²é™çº§åˆ°æœ€å°æ¨¡å‹")
            
            # æ ‡è®°å·²æ£€æµ‹
            st.session_state._last_checked_kb = active_kb_name
        
        logger.separator("çŸ¥è¯†åº“æŸ¥è¯¢")
        logger.start_operation("æŸ¥è¯¢", f"çŸ¥è¯†åº“: {active_kb_name}")
        
        # æŸ¥è¯¢æ”¹å†™ (v1.6) - åœ¨å¤„ç†å¼•ç”¨å†…å®¹ä¹‹å‰
        # åªæœ‰åœ¨ç”¨æˆ·å¯ç”¨æŸ¥è¯¢ä¼˜åŒ–æ—¶æ‰è¿›è¡Œ
        if st.session_state.get('enable_query_optimization', False):
            query_rewriter = QueryRewriter(Settings.llm)
            should_rewrite, reason = query_rewriter.should_rewrite(final_prompt)
            
            if should_rewrite:
                logger.info(f"ğŸ’¡ æ£€æµ‹åˆ°éœ€è¦æ”¹å†™æŸ¥è¯¢: {reason}")
                rewritten_query = query_rewriter.suggest_rewrite(final_prompt)
                
                if rewritten_query and rewritten_query != final_prompt:
                    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®ï¼Œè®©ç”¨æˆ·é€‰æ‹©
                    with st.chat_message("assistant", avatar="ğŸ¤–"):
                        st.info(f"ğŸ’¡ **æŸ¥è¯¢ä¼˜åŒ–å»ºè®®**\n\nåŸé—®é¢˜ï¼š{final_prompt}\n\nä¼˜åŒ–åï¼š{rewritten_query}")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            if st.button("âœ… ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢", key=f"use_optimized_{len(st.session_state.messages)}"):
                                final_prompt = rewritten_query
                                logger.info(f"âœ… ç”¨æˆ·é€‰æ‹©ä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢: {rewritten_query}")
                                st.rerun()
                        with col2:
                            if st.button("ğŸ“ ä½¿ç”¨åŸé—®é¢˜", key=f"use_original_{len(st.session_state.messages)}"):
                                logger.info(f"ğŸ“ ç”¨æˆ·é€‰æ‹©ä½¿ç”¨åŸé—®é¢˜: {final_prompt}")
                                st.rerun()
                        
                        st.stop()  # ç­‰å¾…ç”¨æˆ·é€‰æ‹©
        
        
        # å¤„ç†å¼•ç”¨å†…å®¹
        if st.session_state.get("quote_content"):
            quoted_text = st.session_state.quote_content
            # é™åˆ¶å¼•ç”¨é•¿åº¦ï¼Œé˜²æ­¢ prompt è¿‡é•¿
            if len(quoted_text) > 2000:
                quoted_text = quoted_text[:2000] + "...(å·²æˆªæ–­)"
            
            # æ„å»ºåŒ…å«å¼•ç”¨çš„ prompt
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¿®æ”¹ final_prompt å‘é€ç»™ LLMï¼Œä½†åœ¨ UI ä¸Šç”¨æˆ·åªçœ‹åˆ°è‡ªå·±çš„ç®€çŸ­è¾“å…¥
            # ä¸ºäº†å†å²è®°å½•çš„å®Œæ•´æ€§ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¿å­˜ç»„åˆåçš„ promptï¼Œæˆ–è€…åˆ†å¼€ä¿å­˜
            # è¿™é‡Œé€‰æ‹©ä¿®æ”¹ final_promptï¼Œè¿™æ ·å†å²è®°å½•é‡Œä¹Ÿæ˜¯å®Œæ•´çš„ï¼Œæ–¹ä¾¿åç»­å›é¡¾
            original_prompt = final_prompt
            final_prompt = f"åŸºäºä»¥ä¸‹å¼•ç”¨å†…å®¹ï¼š\n> {quoted_text}\n\næˆ‘çš„é—®é¢˜æ˜¯ï¼š{original_prompt}"
            
            # æ¸…é™¤å¼•ç”¨çŠ¶æ€
            st.session_state.quote_content = None
            logger.info("ğŸ“Œ å·²åº”ç”¨å¼•ç”¨å†…å®¹")
        
        logger.log("INFO", f"ç”¨æˆ·æé—®: {final_prompt}", stage="æŸ¥è¯¢å¯¹è¯", details={"kb_name": active_kb_name})
        
        # æ£€æŸ¥é‡å¤æŸ¥è¯¢ï¼ˆæœ€è¿‘3æ¬¡ï¼‰
        recent_queries = [m['content'] for m in st.session_state.messages[-6:] if m['role'] == 'user']
        if final_prompt in recent_queries:
            st.info("ğŸ’¡ æ‚¨åˆšæ‰å·²ç»é—®è¿‡ç›¸åŒçš„é—®é¢˜ï¼Œå¯ä»¥æŸ¥çœ‹ä¸Šé¢çš„å›ç­”æˆ–å°è¯•æ¢ä¸ªè§’åº¦æé—®")
            st.stop()
        
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        if active_kb_name: HistoryManager.save(active_kb_name, state.get_messages())

        with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"): st.markdown(final_prompt)
        
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            msg_placeholder = st.empty()
            
            # ä½¿ç”¨ä¸€ä¸ªè¿è´¯çš„spinneråŒ…è£…æ•´ä¸ªé—®ç­”æµç¨‹
            with st.spinner("ğŸ¤– æ­£åœ¨æ€è€ƒå¹¶å‡†å¤‡å®Œæ•´å›ç­”..."):
                try:
                    # å¼€å§‹è®¡æ—¶
                    start_time = time.time()
                    
                    # æ˜¾ç¤ºå¯ç”¨çš„æ£€ç´¢å¢å¼ºåŠŸèƒ½
                    enhancements = []
                    if st.session_state.get('enable_bm25', False):
                        enhancements.append("BM25æ··åˆæ£€ç´¢")
                    if st.session_state.get('enable_rerank', False):
                        enhancements.append("Re-rankingé‡æ’åº")
                    
                    if enhancements:
                        enhancement_str = " + ".join(enhancements)
                        logger.info(f"ğŸ¯ æ£€ç´¢å¢å¼º: {enhancement_str}")
                        logger.log("INFO", f"æ£€ç´¢å¢å¼º: {enhancement_str}", stage="æŸ¥è¯¢å¯¹è¯")
                    
                    with logger.timer("æ£€ç´¢ç›¸å…³æ–‡æ¡£"):
                        logger.log("INFO", "å¼€å§‹æ£€ç´¢ç›¸å…³æ–‡æ¡£", stage="æŸ¥è¯¢å¯¹è¯", details={"kb_name": active_kb_name})
                        
                        # ç¡®ä¿ embedding æ¨¡å‹å·²è®¾ç½®
                        embed = get_embed(embed_provider, embed_model, embed_key, embed_url)
                        if embed:
                            Settings.embed_model = embed
                        
                        # GPUåŠ é€Ÿæ£€ç´¢ - æ‰¹é‡å¤„ç†
                        retrieval_start = time.time()
                        response = st.session_state.chat_engine.stream_chat(final_prompt)
                        retrieval_time = time.time() - retrieval_start
                        
                        logger.info(f"ğŸ” æ£€ç´¢è€—æ—¶: {retrieval_time:.2f}s (GPUåŠ é€Ÿ)")
                        
                        full_text = ""
                        # æµå¼è¾“å‡º + èµ„æºæ§åˆ¶
                        token_count = 0 # è¿™é‡Œçš„è®¡æ•°ä»…ç”¨äºè¿›åº¦ä¼°ç®—
                        full_text = ""
                        
                        for token in response.response_gen:
                            full_text += token
                            msg_placeholder.markdown(full_text + "â–Œ")
                            token_count += 1
                        
                        msg_placeholder.markdown(full_text)
                    
                    # æå– token ç»Ÿè®¡ (ä¼˜å…ˆä½¿ç”¨çœŸå®æ•°æ®)
                    prompt_tokens = 0
                    completion_tokens = 0
                    
                    if hasattr(response, 'raw') and response.raw:
                        usage = response.raw.get('usage', {})
                        prompt_tokens = usage.get('prompt_tokens', 0)
                        completion_tokens = usage.get('completion_tokens', 0)
                    
                    # å¦‚æœæ²¡æœ‰çœŸå® Usageï¼Œåˆ™è¿›è¡Œä¼°ç®—
                    if completion_tokens == 0:
                        # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦çº¦0.6 tokenï¼Œè‹±æ–‡å­—ç¬¦çº¦0.25 token (WordCount)
                        # è¿™é‡Œä½¿ç”¨æ›´é€šç”¨çš„ä¼°ç®—ï¼šä¸­æ–‡ * 1.5, è‹±æ–‡ * 0.5 (token count)
                        # æˆ–è€…ç›´æ¥æ˜¾ç¤ºå­—ç¬¦æ•°æ›´å‡†ç¡®
                        total_chars = len(full_text)
                        chinese_chars = len(re.findall(r'[\u4e00-\u9fa5]', full_text))
                        # æ··åˆä¼°ç®—
                        completion_tokens = int((chinese_chars * 1.5) + ((total_chars - chinese_chars) * 0.3))
                        token_count = completion_tokens # æ›´æ–°ä¸ºæ›´å‡†ç¡®çš„ä¼°ç®—å€¼
                    else:
                        token_count = completion_tokens # ä½¿ç”¨çœŸå®å€¼

                    # å¤šæ ¸å¹¶è¡Œå¤„ç†èŠ‚ç‚¹
                    srcs = []
                    if response.source_nodes:
                        logger.log("INFO", f"æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(response.source_nodes)} ä¸ªç›¸å…³æ–‡æ¡£", stage="æŸ¥è¯¢å¯¹è¯", details={"kb_name": active_kb_name})
                        logger.data_summary("æ£€ç´¢ç»“æœ", {
                            "æŸ¥è¯¢": final_prompt[:50] + "..." if len(final_prompt) > 50 else final_prompt,
                            "ç›¸å…³æ–‡æ¡£": len(response.source_nodes),
                            "çŸ¥è¯†åº“": active_kb_name
                        })
                        
                        # å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†èŠ‚ç‚¹ï¼ˆçœŸæ­£åˆ©ç”¨å¤šæ ¸CPUï¼‰
                        max_workers = max(2, os.cpu_count() - 1)  # ä¿ç•™1æ ¸ç»™ç³»ç»Ÿ
                        
                        # æå–èŠ‚ç‚¹æ•°æ®ï¼ˆåºåˆ—åŒ–å‹å¥½ï¼‰
                        node_data = []
                        for node in response.source_nodes:
                            # å®‰å…¨æå–æ–‡æœ¬
                            text = ''
                            try:
                                if hasattr(node, 'get_text'):
                                    text = node.get_text()
                                elif hasattr(node, 'text'):
                                    text = node.text
                                elif hasattr(node, 'node') and hasattr(node.node, 'text'):
                                    text = node.node.text
                                else:
                                    text = str(node)[:150]
                            except:
                                text = str(node)[:150]
                            
                            node_data.append({
                                'metadata': getattr(node, 'metadata', {}),
                                'score': getattr(node, 'score', 0.0),
                                'text': text
                            })
                        
                        # ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œå™¨å¤„ç†èŠ‚ç‚¹ï¼ˆä¼˜åŒ–å¹¶è¡Œé˜ˆå€¼ï¼‰
                        executor = ParallelExecutor()
                        tasks = [(d, active_kb_name) for d in node_data]
                        # å¯ç”¨çœŸæ­£çš„å¹¶è¡Œå¤„ç†ï¼Œé™ä½é˜ˆå€¼åˆ°2ä¸ªèŠ‚ç‚¹
                        parallel_threshold = 2
                        srcs = [s for s in executor.execute(process_node_worker, tasks, threshold=parallel_threshold) if s]
                        
                        if len(node_data) >= parallel_threshold:
                            logger.info(f"âš¡ å¹¶è¡Œå¤„ç†: {len(srcs)} ä¸ªèŠ‚ç‚¹ (é˜ˆå€¼: {parallel_threshold})")
                        else:
                            logger.info(f"âš¡ å•èŠ‚ç‚¹å¤„ç†: {len(srcs)} ä¸ªèŠ‚ç‚¹")
                    
                    logger.log("SUCCESS", "å›ç­”ç”Ÿæˆå®Œæˆ", stage="æŸ¥è¯¢å¯¹è¯", details={"kb_name": active_kb_name, "model": llm_model, "tokens": token_count, "prompt_tokens": prompt_tokens, "completion_tokens": completion_tokens
                    })
                    
                    # è®¡ç®—æ€»è€—æ—¶
                    total_time = time.time() - start_time
                    logger.complete_operation(f"æŸ¥è¯¢å®Œæˆ (è€—æ—¶ {total_time:.2f}s)")
                    
                    # å‡†å¤‡ç»Ÿè®¡ä¿¡æ¯
                    tokens_per_sec = token_count / total_time if total_time > 0 else 0
                    stats = {
                        "time": total_time,
                        "tokens": token_count,
                        "tokens_per_sec": tokens_per_sec,
                        "prompt_tokens": prompt_tokens,
                        "completion_tokens": completion_tokens
                    }
                    
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": full_text, 
                        "sources": srcs,
                        "stats": stats
                    })
                    
                    # ç”Ÿæˆæ¨èé—®é¢˜ï¼ˆåœ¨spinnerå†…å®Œæˆï¼‰
                    existing_questions = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
                    existing_questions.extend(st.session_state.question_queue)
                    existing_questions.extend(st.session_state.suggestions_history)
                    
                    # è·å–LLMæ¨¡å‹
                    llm_model = None
                    if st.session_state.get('chat_engine'):
                        chat_engine = st.session_state.chat_engine
                        if hasattr(chat_engine, '_llm'):
                            llm_model = chat_engine._llm
                        elif hasattr(chat_engine, 'llm'):
                            llm_model = chat_engine.llm
                    
                    initial_sugs = generate_follow_up_questions(
                        full_text, 
                        num_questions=3,
                        existing_questions=existing_questions,
                        query_engine=st.session_state.chat_engine if st.session_state.get('chat_engine') else None,
                        llm_model=llm_model
                    )
                    
                    if initial_sugs:
                        st.session_state.suggestions_history = initial_sugs[:3]
                        logger.info(f"âœ¨ ç”Ÿæˆ {len(initial_sugs)} ä¸ªæ¨èé—®é¢˜")
                    
                    # å»¶è¿Ÿä¿å­˜ï¼šç¡®è®¤æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸåå†ä¿å­˜
                    if active_kb_name: HistoryManager.save(active_kb_name, state.get_messages())
                    
                    # é‡Šæ”¾å†…å­˜
                    cleanup_memory()
                    logger.info("ğŸ§¹ å¯¹è¯å®Œæˆï¼Œå†…å­˜å·²æ¸…ç†")
                    
                    st.session_state.is_processing = False  # å¤„ç†å®Œæˆ
                    
                    # æ•´ä½“å¤„ç†å®Œæˆåé¦ˆ
                    st.toast("âœ… å›ç­”ç”Ÿæˆå®Œæ¯•", icon="ğŸ‰")
                
                except Exception as e: 
                    print(f"âŒ æŸ¥è¯¢å‡ºé”™: {e}\n")
                    st.error(f"å‡ºé”™: {e}")
                    
                    # å‘ç”Ÿé”™è¯¯ï¼Œå›æ»šæœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯ assistant ç”Ÿæˆçš„ï¼‰
                    if st.session_state.messages and st.session_state.messages[-1]['role'] == 'assistant':
                        st.session_state.messages.pop()
                    
                    # é‡Šæ”¾å†…å­˜
                    cleanup_memory()
                    logger.info("ğŸ§¹ é”™è¯¯å¤„ç†å®Œæˆï¼Œå†…å­˜å·²æ¸…ç†")
                    st.session_state.is_processing = False
            
            # spinnerç»“æŸåæ˜¾ç¤ºæ‰€æœ‰å†…å®¹
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            if 'total_time' in locals() and 'token_count' in locals():
                stats_simple = f"â±ï¸ {total_time:.1f}ç§’ | ğŸ“ çº¦ {token_count} å­—ç¬¦"
                st.caption(stats_simple)
                
                # è¯¦ç»†ä¿¡æ¯ (æŠ˜å )
                with st.expander("ğŸ“Š è¯¦ç»†ç»Ÿè®¡", expanded=False):
                    st.caption(f"ğŸš€ é€Ÿåº¦: {tokens_per_sec:.1f} tokens/s")
                    if 'prompt_tokens' in locals() and prompt_tokens:
                        st.caption(f"ğŸ“¥ è¾“å…¥: {prompt_tokens} | ğŸ“¤ è¾“å‡º: {completion_tokens}")
                
                # æ˜¾ç¤ºå‚è€ƒæ¥æº
                if 'srcs' in locals() and srcs:
                    from src.ui.message_renderer import render_source_references
                    render_source_references(srcs, expanded=False)
            
            # è‡ªåŠ¨å¤„ç†é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªé—®é¢˜
            if st.session_state.question_queue:
                logger.info(f"ğŸ“ é˜Ÿåˆ—ä¸­è¿˜æœ‰ {len(st.session_state.question_queue)} ä¸ªé—®é¢˜ï¼Œè‡ªåŠ¨å¤„ç†ä¸‹ä¸€ä¸ª")
                st.rerun()  # è§¦å‘é‡æ–°è¿è¡Œï¼Œå¤„ç†ä¸‹ä¸€ä¸ªé—®é¢˜
            
            # åœ¨ chat_message å—å¤–æ˜¾ç¤ºæ¨èé—®é¢˜æŒ‰é’®
            if st.session_state.suggestions_history:
                st.divider()
                st.markdown("##### ğŸš€ è¿½é—®æ¨è")
                for idx, q in enumerate(st.session_state.suggestions_history):
                    if st.button(f"ğŸ‘‰ {q}", key=f"sug_btn_{int(time.time())}_{idx}", use_container_width=True):
                        click_btn(q)
                
                if st.button("âœ¨ ç»§ç»­æ¨è 3 ä¸ªè¿½é—®", key=f"gen_more_{int(time.time())}", type="secondary", use_container_width=True):
                    with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæ–°é—®é¢˜..."):
                        all_history_questions = [m['content'] for m in st.session_state.messages if m['role'] == 'user']
                        all_history_questions.extend(st.session_state.suggestions_history)
                        all_history_questions.extend(st.session_state.question_queue)
                        
                        # è·å–æœ€åä¸€æ¡å›ç­”ä½œä¸ºä¸Šä¸‹æ–‡
                        last_answer = ""
                        for msg in reversed(st.session_state.messages):
                            if msg['role'] == 'assistant':
                                last_answer = msg['content']
                                break
                        
                        # è·å–LLMæ¨¡å‹
                        llm_model = None
                        if st.session_state.get('chat_engine'):
                            chat_engine = st.session_state.chat_engine
                            if hasattr(chat_engine, '_llm'):
                                llm_model = chat_engine._llm
                            elif hasattr(chat_engine, 'llm'):
                                llm_model = chat_engine.llm
                        
                        new_sugs = generate_follow_up_questions(
                            context_text=last_answer, 
                            num_questions=3,
                            existing_questions=all_history_questions,
                            query_engine=st.session_state.chat_engine if st.session_state.get('chat_engine') else None,
                            llm_model=llm_model
                        )
                        
                        if new_sugs:
                            # æ›¿æ¢è€Œä¸æ˜¯ç´¯ç§¯ï¼šå§‹ç»ˆåªä¿æŒæœ€æ–°çš„3ä¸ªé—®é¢˜
                            st.session_state.suggestions_history = new_sugs[:3]
                            st.rerun()
                        else:
                            st.warning("æœªèƒ½ç”Ÿæˆæ›´å¤šè¿½é—®ï¼Œè¯·å°è¯•è¾“å…¥æ–°é—®é¢˜ã€‚")
