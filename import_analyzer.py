#!/usr/bin/env python3
"""
å¯¼å…¥ä¾èµ–åˆ†æå™¨ - æ£€æµ‹æœªä½¿ç”¨çš„å¯¼å…¥ã€é‡å¤å¯¼å…¥å’Œä¼˜åŒ–å»ºè®®
"""

import ast
import os
import re
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Set, Tuple

class ImportAnalyzer:
    def __init__(self, src_dir: str):
        self.src_dir = Path(src_dir)
        self.results = {
            'unused_imports': [],
            'duplicate_imports': [],
            'optimization_suggestions': [],
            'summary': {}
        }
    
    def analyze_file(self, file_path: Path) -> Dict:
        """åˆ†æå•ä¸ªPythonæ–‡ä»¶çš„å¯¼å…¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            # æ”¶é›†æ‰€æœ‰å¯¼å…¥
            imports = []
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append({
                            'type': 'import',
                            'module': alias.name,
                            'alias': alias.asname,
                            'line': node.lineno,
                            'full_line': content.split('\n')[node.lineno-1].strip()
                        })
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ''
                    for alias in node.names:
                        imports.append({
                            'type': 'from_import',
                            'module': module,
                            'name': alias.name,
                            'alias': alias.asname,
                            'line': node.lineno,
                            'full_line': content.split('\n')[node.lineno-1].strip()
                        })
            
            # æ£€æŸ¥ä½¿ç”¨æƒ…å†µ
            unused_imports = []
            for imp in imports:
                if not self._is_import_used(content, imp):
                    unused_imports.append(imp)
            
            # æ£€æŸ¥é‡å¤å¯¼å…¥
            duplicate_imports = self._find_duplicate_imports(imports)
            
            return {
                'file': str(file_path),
                'imports': imports,
                'unused_imports': unused_imports,
                'duplicate_imports': duplicate_imports
            }
            
        except Exception as e:
            return {
                'file': str(file_path),
                'error': str(e),
                'imports': [],
                'unused_imports': [],
                'duplicate_imports': []
            }
    
    def _is_import_used(self, content: str, imp: Dict) -> bool:
        """æ£€æŸ¥å¯¼å…¥æ˜¯å¦è¢«ä½¿ç”¨"""
        if imp['type'] == 'import':
            name = imp['alias'] or imp['module'].split('.')[-1]
        else:  # from_import
            name = imp['alias'] or imp['name']
        
        if name == '*':
            return True  # æ— æ³•å‡†ç¡®æ£€æµ‹ import *
        
        # ç§»é™¤å¯¼å…¥è¡Œæœ¬èº«
        lines = content.split('\n')
        content_without_imports = '\n'.join(
            line for i, line in enumerate(lines) 
            if i + 1 != imp['line']
        )
        
        # æ£€æŸ¥ä½¿ç”¨æ¨¡å¼
        patterns = [
            rf'\b{re.escape(name)}\b',  # ç›´æ¥ä½¿ç”¨
            rf'{re.escape(name)}\.',    # ä½œä¸ºæ¨¡å—ä½¿ç”¨
            rf'@{re.escape(name)}\b',   # è£…é¥°å™¨
            rf'isinstance\([^,]+,\s*{re.escape(name)}\)',  # isinstance
            rf'issubclass\([^,]+,\s*{re.escape(name)}\)',  # issubclass
        ]
        
        for pattern in patterns:
            if re.search(pattern, content_without_imports):
                return True
        
        return False
    
    def _find_duplicate_imports(self, imports: List[Dict]) -> List[Dict]:
        """æŸ¥æ‰¾é‡å¤å¯¼å…¥"""
        seen = {}
        duplicates = []
        
        for imp in imports:
            key = (imp['type'], imp['module'], imp.get('name', ''))
            if key in seen:
                duplicates.append({
                    'original': seen[key],
                    'duplicate': imp
                })
            else:
                seen[key] = imp
        
        return duplicates
    
    def analyze_all_files(self):
        """åˆ†ææ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = list(self.src_dir.rglob('*.py'))
        
        total_unused = 0
        total_duplicates = 0
        
        for file_path in python_files:
            if '__pycache__' in str(file_path):
                continue
                
            result = self.analyze_file(file_path)
            
            if result['unused_imports']:
                self.results['unused_imports'].append(result)
                total_unused += len(result['unused_imports'])
            
            if result['duplicate_imports']:
                self.results['duplicate_imports'].append(result)
                total_duplicates += len(result['duplicate_imports'])
        
        self.results['summary'] = {
            'total_files': len(python_files),
            'files_with_unused': len(self.results['unused_imports']),
            'files_with_duplicates': len(self.results['duplicate_imports']),
            'total_unused_imports': total_unused,
            'total_duplicate_imports': total_duplicates
        }
        
        self._generate_optimization_suggestions()
    
    def _generate_optimization_suggestions(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # ç»Ÿè®¡æœ€å¸¸è§çš„æœªä½¿ç”¨å¯¼å…¥
        unused_modules = defaultdict(int)
        for file_result in self.results['unused_imports']:
            for imp in file_result['unused_imports']:
                module = imp['module']
                unused_modules[module] += 1
        
        if unused_modules:
            top_unused = sorted(unused_modules.items(), key=lambda x: x[1], reverse=True)[:5]
            suggestions.append({
                'type': 'common_unused',
                'description': 'æœ€å¸¸è§çš„æœªä½¿ç”¨å¯¼å…¥æ¨¡å—',
                'data': top_unused
            })
        
        # æ£€æŸ¥å¯ä»¥åˆå¹¶çš„å¯¼å…¥
        merge_candidates = self._find_merge_candidates()
        if merge_candidates:
            suggestions.append({
                'type': 'merge_imports',
                'description': 'å¯ä»¥åˆå¹¶çš„å¯¼å…¥è¯­å¥',
                'data': merge_candidates
            })
        
        self.results['optimization_suggestions'] = suggestions
    
    def _find_merge_candidates(self) -> List[Dict]:
        """æŸ¥æ‰¾å¯ä»¥åˆå¹¶çš„å¯¼å…¥"""
        candidates = []
        
        for file_result in self.results['unused_imports'] + self.results['duplicate_imports']:
            file_imports = defaultdict(list)
            
            # æŒ‰æ¨¡å—åˆ†ç»„å¯¼å…¥
            for imp in file_result.get('imports', []):
                if imp['type'] == 'from_import':
                    file_imports[imp['module']].append(imp)
            
            # æŸ¥æ‰¾åŒä¸€æ¨¡å—çš„å¤šä¸ªå¯¼å…¥
            for module, imports in file_imports.items():
                if len(imports) > 1:
                    candidates.append({
                        'file': file_result['file'],
                        'module': module,
                        'imports': imports,
                        'suggestion': f"å¯ä»¥åˆå¹¶ä¸º: from {module} import {', '.join(imp['name'] for imp in imports)}"
                    })
        
        return candidates
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("RAG Pro Max - å¯¼å…¥ä¾èµ–åˆ†ææŠ¥å‘Š")
        report.append("=" * 80)
        
        # æ‘˜è¦
        summary = self.results['summary']
        report.append(f"\nğŸ“Š åˆ†ææ‘˜è¦:")
        report.append(f"  â€¢ æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        report.append(f"  â€¢ æœ‰æœªä½¿ç”¨å¯¼å…¥çš„æ–‡ä»¶: {summary['files_with_unused']}")
        report.append(f"  â€¢ æœ‰é‡å¤å¯¼å…¥çš„æ–‡ä»¶: {summary['files_with_duplicates']}")
        report.append(f"  â€¢ æœªä½¿ç”¨å¯¼å…¥æ€»æ•°: {summary['total_unused_imports']}")
        report.append(f"  â€¢ é‡å¤å¯¼å…¥æ€»æ•°: {summary['total_duplicate_imports']}")
        
        # æœªä½¿ç”¨å¯¼å…¥è¯¦æƒ…
        if self.results['unused_imports']:
            report.append(f"\nğŸš« æœªä½¿ç”¨çš„å¯¼å…¥ ({len(self.results['unused_imports'])} ä¸ªæ–‡ä»¶):")
            report.append("-" * 60)
            
            for file_result in self.results['unused_imports']:
                rel_path = os.path.relpath(file_result['file'], self.src_dir)
                report.append(f"\nğŸ“„ {rel_path}")
                
                for imp in file_result['unused_imports']:
                    report.append(f"  âŒ ç¬¬{imp['line']}è¡Œ: {imp['full_line']}")
        
        # é‡å¤å¯¼å…¥è¯¦æƒ…
        if self.results['duplicate_imports']:
            report.append(f"\nğŸ”„ é‡å¤å¯¼å…¥ ({len(self.results['duplicate_imports'])} ä¸ªæ–‡ä»¶):")
            report.append("-" * 60)
            
            for file_result in self.results['duplicate_imports']:
                rel_path = os.path.relpath(file_result['file'], self.src_dir)
                report.append(f"\nğŸ“„ {rel_path}")
                
                for dup in file_result['duplicate_imports']:
                    report.append(f"  ğŸ”„ é‡å¤å¯¼å…¥:")
                    report.append(f"     åŸå§‹: ç¬¬{dup['original']['line']}è¡Œ: {dup['original']['full_line']}")
                    report.append(f"     é‡å¤: ç¬¬{dup['duplicate']['line']}è¡Œ: {dup['duplicate']['full_line']}")
        
        # ä¼˜åŒ–å»ºè®®
        if self.results['optimization_suggestions']:
            report.append(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            report.append("-" * 60)
            
            for suggestion in self.results['optimization_suggestions']:
                report.append(f"\nğŸ”§ {suggestion['description']}:")
                
                if suggestion['type'] == 'common_unused':
                    for module, count in suggestion['data']:
                        report.append(f"  â€¢ {module}: {count} æ¬¡æœªä½¿ç”¨")
                
                elif suggestion['type'] == 'merge_imports':
                    for candidate in suggestion['data']:
                        rel_path = os.path.relpath(candidate['file'], self.src_dir)
                        report.append(f"  ğŸ“„ {rel_path}")
                        report.append(f"     {candidate['suggestion']}")
        
        # æ¸…ç†è„šæœ¬ç”Ÿæˆ
        report.append(f"\nğŸ§¹ è‡ªåŠ¨æ¸…ç†å»ºè®®:")
        report.append("-" * 60)
        report.append("# å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥:")
        report.append("# pip install autoflake")
        report.append("# autoflake --remove-all-unused-imports --in-place --recursive src/")
        
        return "\n".join(report)

def main():
    src_dir = "/Users/zhaosj/Documents/rag-pro-max/src"
    
    print("ğŸ” å¼€å§‹åˆ†æå¯¼å…¥ä¾èµ–...")
    analyzer = ImportAnalyzer(src_dir)
    analyzer.analyze_all_files()
    
    report = analyzer.generate_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = "/Users/zhaosj/Documents/rag-pro-max/import_analysis_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

if __name__ == "__main__":
    main()