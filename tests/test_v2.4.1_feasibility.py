#!/usr/bin/env python3
"""
RAG Pro Max v2.4.1 åŠŸèƒ½å¯è¡Œæ€§æµ‹è¯•
æµ‹è¯•æ™ºèƒ½çˆ¬å–ä¼˜åŒ–åŠŸèƒ½çš„å®Œæ•´æ€§å’Œå¯ç”¨æ€§
"""

import sys
import os
import traceback
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_crawl_optimizer():
    """æµ‹è¯•æ™ºèƒ½çˆ¬å–ä¼˜åŒ–å™¨"""
    try:
        from src.processors.crawl_optimizer import CrawlOptimizer
        
        optimizer = CrawlOptimizer()
        
        # æµ‹è¯•ç½‘ç«™åˆ†æ
        test_urls = [
            "https://docs.python.org/",
            "https://36kr.com/", 
            "https://apple.com/",
            "https://stackoverflow.com/"
        ]
        
        for url in test_urls:
            result = optimizer.analyze_website(url)
            
            # éªŒè¯è¿”å›ç»“æœ
            required_keys = ['site_type', 'recommended_depth', 'recommended_pages', 
                           'estimated_pages', 'confidence', 'description']
            
            for key in required_keys:
                if key not in result:
                    return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}"
            
            # éªŒè¯æ•°æ®ç±»å‹å’ŒèŒƒå›´
            if not isinstance(result['recommended_depth'], int) or result['recommended_depth'] < 1:
                return False, f"æ¨èæ·±åº¦æ— æ•ˆ: {result['recommended_depth']}"
            
            if not isinstance(result['recommended_pages'], int) or result['recommended_pages'] < 1:
                return False, f"æ¨èé¡µæ•°æ— æ•ˆ: {result['recommended_pages']}"
            
            if not isinstance(result['confidence'], (int, float)) or not 0 <= result['confidence'] <= 1:
                return False, f"ç½®ä¿¡åº¦æ— æ•ˆ: {result['confidence']}"
        
        return True, "æ™ºèƒ½çˆ¬å–ä¼˜åŒ–å™¨æµ‹è¯•é€šè¿‡"
        
    except Exception as e:
        return False, f"æ™ºèƒ½çˆ¬å–ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {str(e)}"



def test_website_type_recognition():
    """æµ‹è¯•ç½‘ç«™ç±»å‹è¯†åˆ«"""
    try:
        from src.processors.crawl_optimizer import CrawlOptimizer
        
        optimizer = CrawlOptimizer()
        
        # æµ‹è¯•ç”¨ä¾‹ï¼šURL -> æœŸæœ›ç±»å‹
        test_cases = [
            ("https://docs.python.org/", "documentation"),
            ("https://36kr.com/", "news"),
            ("https://stackoverflow.com/", "forum"),
            ("https://medium.com/", "blog"),
            ("https://apple.com/", "corporate"),
            ("https://wikipedia.org/", "wiki")
        ]
        
        correct_predictions = 0
        total_tests = len(test_cases)
        
        for url, expected_type in test_cases:
            result = optimizer.analyze_website(url)
            actual_type = result['site_type']
            
            if actual_type == expected_type:
                correct_predictions += 1
            else:
                print(f"  âš ï¸ ç±»å‹è¯†åˆ«åå·®: {url} -> æœŸæœ›:{expected_type}, å®é™…:{actual_type}")
        
        accuracy = correct_predictions / total_tests
        
        if accuracy >= 0.7:  # 70%å‡†ç¡®ç‡é˜ˆå€¼
            return True, f"ç½‘ç«™ç±»å‹è¯†åˆ«æµ‹è¯•é€šè¿‡ (å‡†ç¡®ç‡: {accuracy:.1%})"
        else:
            return False, f"ç½‘ç«™ç±»å‹è¯†åˆ«å‡†ç¡®ç‡è¿‡ä½: {accuracy:.1%}"
        
    except Exception as e:
        return False, f"ç½‘ç«™ç±»å‹è¯†åˆ«æµ‹è¯•å¤±è´¥: {str(e)}"

def test_realistic_estimation():
    """æµ‹è¯•ç°å®é¢„ä¼°ç®—æ³•"""
    try:
        from src.processors.crawl_optimizer import CrawlOptimizer
        
        optimizer = CrawlOptimizer()
        
        # æµ‹è¯•é¢„ä¼°åˆç†æ€§
        test_cases = [
            ("https://apple.com/", 100),      # ä¼ä¸šå®˜ç½‘åº”è¯¥é¢„ä¼°è¾ƒå°‘
            ("https://docs.python.org/", 500), # æ–‡æ¡£ç½‘ç«™åº”è¯¥é¢„ä¼°é€‚ä¸­
            ("https://stackoverflow.com/", 1000) # è®ºå›ç½‘ç«™å¯ä»¥é¢„ä¼°è¾ƒå¤š
        ]
        
        for url, max_reasonable in test_cases:
            result = optimizer.analyze_website(url)
            estimated = result['estimated_pages']
            
            if estimated > max_reasonable:
                return False, f"é¢„ä¼°è¿‡é«˜: {url} -> {estimated}é¡µ (ä¸Šé™:{max_reasonable})"
            
            if estimated < 10:
                return False, f"é¢„ä¼°è¿‡ä½: {url} -> {estimated}é¡µ (ä¸‹é™:10)"
        
        return True, "ç°å®é¢„ä¼°ç®—æ³•æµ‹è¯•é€šè¿‡"
        
    except Exception as e:
        return False, f"ç°å®é¢„ä¼°ç®—æ³•æµ‹è¯•å¤±è´¥: {str(e)}"

def test_ui_integration():
    """æµ‹è¯•UIé›†æˆ"""
    try:
        # æ£€æŸ¥ä¸»åº”ç”¨ä¸­æ˜¯å¦æ­£ç¡®é›†æˆäº†æ–°åŠŸèƒ½
        with open('src/apppro.py', 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥å…³é”®é›†æˆç‚¹
        integration_checks = [
            "from src.processors.crawl_optimizer import CrawlOptimizer",
            "æ™ºèƒ½åˆ†æ",
            "crawl_optimizer",
            "crawl_analysis"
        ]
        
        for check in integration_checks:
            if check not in content:
                return False, f"UIé›†æˆç¼ºå°‘: {check}"
        
        return True, "UIé›†æˆæµ‹è¯•é€šè¿‡"
        
    except Exception as e:
        return False, f"UIé›†æˆæµ‹è¯•å¤±è´¥: {str(e)}"

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰v2.4.1å¯è¡Œæ€§æµ‹è¯•"""
    
    print("=" * 60)
    print("  RAG Pro Max v2.4.1 åŠŸèƒ½å¯è¡Œæ€§æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    tests = [
        ("æ™ºèƒ½çˆ¬å–ä¼˜åŒ–å™¨", test_crawl_optimizer),

        ("ç½‘ç«™ç±»å‹è¯†åˆ«", test_website_type_recognition),
        ("ç°å®é¢„ä¼°ç®—æ³•", test_realistic_estimation),
        ("UIé›†æˆ", test_ui_integration)
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            print(f"ğŸ§ª æµ‹è¯•: {test_name}")
            success, message = test_func()
            
            if success:
                print(f"âœ… {message}")
                passed += 1
            else:
                print(f"âŒ {message}")
                failed += 1
                
        except Exception as e:
            print(f"ğŸ’¥ {test_name} æµ‹è¯•å¼‚å¸¸: {str(e)}")
            print(f"   {traceback.format_exc()}")
            failed += 1
        
        print()
    
    # æµ‹è¯•æ€»ç»“
    print("=" * 60)
    print("  æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    print(f"âœ… é€šè¿‡: {passed}/{passed + failed}")
    print(f"âŒ å¤±è´¥: {failed}/{passed + failed}")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰v2.4.1åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼æ™ºèƒ½çˆ¬å–ç³»ç»Ÿå¯ä»¥å‘å¸ƒã€‚")
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤åå†å‘å¸ƒã€‚")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
