#!/usr/bin/env python3
"""Re-ranking åŠŸèƒ½éªŒè¯è„šæœ¬"""

import os
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

print("ğŸ” æµ‹è¯• Re-ranking åŠŸèƒ½...")
print()

# 1. æµ‹è¯•å¯¼å…¥
try:
    from llama_index.core.postprocessor import SentenceTransformerRerank
    print("âœ… 1. SentenceTransformerRerank å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ 1. å¯¼å…¥å¤±è´¥: {e}")
    exit(1)

# 2. æµ‹è¯•æ¨¡å‹åŠ è½½
try:
    reranker = SentenceTransformerRerank(
        top_n=3,
        model="BAAI/bge-reranker-base",
        keep_retrieval_score=True,
    )
    print("âœ… 2. Re-ranking æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ 2. æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
    exit(1)

# 3. æµ‹è¯•åŸºæœ¬åŠŸèƒ½
try:
    from llama_index.core import Document, VectorStoreIndex, Settings
    from llama_index.embeddings.huggingface import HuggingFaceEmbedding
    
    # è®¾ç½®åµŒå…¥æ¨¡å‹
    Settings.embed_model = HuggingFaceEmbedding(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        cache_folder="./hf_cache"
    )
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    docs = [
        Document(text="Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€"),
        Document(text="Java æ˜¯ä¸€ç§é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€"),
        Document(text="JavaScript ç”¨äºç½‘é¡µå¼€å‘"),
    ]
    
    # åˆ›å»ºç´¢å¼•
    index = VectorStoreIndex.from_documents(docs, show_progress=False)
    
    # åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆå¸¦ Re-rankingï¼‰
    query_engine = index.as_query_engine(
        similarity_top_k=3,
        node_postprocessors=[reranker]
    )
    
    # æµ‹è¯•æŸ¥è¯¢
    response = query_engine.query("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ")
    
    if response and len(response.source_nodes) > 0:
        print("âœ… 3. Re-ranking æŸ¥è¯¢æµ‹è¯•æˆåŠŸ")
        print(f"   â””â”€ è¿”å› {len(response.source_nodes)} ä¸ªèŠ‚ç‚¹")
    else:
        print("âŒ 3. æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
        exit(1)
        
except Exception as e:
    print(f"âŒ 3. åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
    exit(1)

print()
print("âœ… Re-ranking åŠŸèƒ½éªŒè¯é€šè¿‡ï¼")
