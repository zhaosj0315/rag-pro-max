# ç½‘é¡µçˆ¬è™«æ™ºèƒ½æ¨èåŠŸèƒ½é›†æˆæ€»ç»“

## ğŸ¯ éœ€æ±‚åˆ†æ

ç”¨æˆ·è¦æ±‚ï¼š
1. **é€’å½’é€»è¾‘ä¿®å¤**ï¼šç½‘é¡µçˆ¬è™«å…³é”®å­—çˆ¬å–é€»è¾‘è¦å’Œç½‘é¡µæ’åºé€»è¾‘å¯¹é½
2. **æ™ºèƒ½å‚æ•°æ¨è**ï¼šå¤ç”¨ç½‘é¡µæ’åºé€»è¾‘ï¼Œæ¨èçˆ¬å–å±‚æ•°å’Œé¡µæ•°

## âœ… å®ŒæˆåŠŸèƒ½

### 1. é€’å½’é€»è¾‘ä¿®å¤ âœ…

**ä¿®å¤å‰ï¼ˆé”™è¯¯ï¼‰**ï¼š
- æ¯ä¸ªé¡µé¢æœ€å¤šæå– `max_pages` ä¸ªé“¾æ¥
- å¯¼è‡´æ¯å±‚é“¾æ¥æ•°é‡å—é™ï¼Œæ— æ³•å®ç°çœŸæ­£çš„é€’å½’å¢é•¿

**ä¿®å¤åï¼ˆæ­£ç¡®ï¼‰**ï¼š
- ç¬¬1å±‚ï¼š`max_pages^1` ä¸ªé¡µé¢
- ç¬¬2å±‚ï¼š`max_pages^2` ä¸ªé¡µé¢
- ç¬¬3å±‚ï¼š`max_pages^3` ä¸ªé¡µé¢

**ç¤ºä¾‹**ï¼ˆmax_pages=2, max_depth=3ï¼‰ï¼š
```
ç¬¬1å±‚: 2^1 = 2é¡µ
ç¬¬2å±‚: 2^2 = 4é¡µ  
ç¬¬3å±‚: 2^3 = 8é¡µ
æ€»è®¡: 2 + 4 + 8 = 14é¡µ
```

### 2. æ™ºèƒ½å‚æ•°æ¨è âœ…

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ğŸ§  **æ™ºèƒ½ç½‘ç«™ç±»å‹è¯†åˆ«**ï¼š7ç§ç½‘ç«™ç±»å‹è‡ªåŠ¨è¯†åˆ«
- ğŸ“Š **è‡ªåŠ¨å‚æ•°æ¨è**ï¼šæ ¹æ®ç½‘ç«™ç±»å‹æ¨èæœ€ä½³æ·±åº¦å’Œé¡µæ•°
- ğŸ¯ **ç½®ä¿¡åº¦è¯„ä¼°**ï¼šæä¾›åˆ†æç»“æœå¯ä¿¡åº¦è¯„åˆ†
- ğŸ“ˆ **ç°å®é¢„ä¼°ç®—æ³•**ï¼šå‡†ç¡®é¢„ä¼°æ€»é¡µé¢æ•°é‡

**æ”¯æŒçš„ç½‘ç«™ç±»å‹**ï¼š
| ç±»å‹ | æ¨èæ·±åº¦ | æ¨èé¡µæ•° | æè¿° |
|------|----------|----------|------|
| documentation | 3å±‚ | 20é¡µ/å±‚ | æŠ€æœ¯æ–‡æ¡£ç½‘ç«™ï¼Œå†…å®¹å±‚æ¬¡æ·± |
| news | 2å±‚ | 30é¡µ/å±‚ | æ–°é—»ç½‘ç«™ï¼Œæ–‡ç« æ•°é‡å¤š |
| ecommerce | 2å±‚ | 50é¡µ/å±‚ | ç”µå•†ç½‘ç«™ï¼Œå•†å“é¡µé¢ä¸°å¯Œ |
| blog | 2å±‚ | 25é¡µ/å±‚ | åšå®¢ç½‘ç«™ï¼Œæ–‡ç« åˆ†ç±»æ¸…æ™° |
| forum | 3å±‚ | 25é¡µ/å±‚ | è®ºå›ç½‘ç«™ï¼Œè®¨è®ºå±‚æ¬¡æ·± |
| corporate | 2å±‚ | 15é¡µ/å±‚ | ä¼ä¸šå®˜ç½‘ï¼Œç»“æ„ç›¸å¯¹ç®€å• |
| wiki | 3å±‚ | 30é¡µ/å±‚ | ç™¾ç§‘ç½‘ç«™ï¼Œå†…å®¹ä¸°å¯Œäº’è” |

## ğŸ”§ æŠ€æœ¯å®ç°

### ä¿®å¤çš„æ–‡ä»¶

1. **`src/processors/web_crawler.py`** - ä¸»è¦ç½‘é¡µçˆ¬è™«
2. **`src/processors/concurrent_crawler.py`** - å¹¶å‘ç½‘é¡µçˆ¬è™«
3. **`src/processors/async_web_crawler.py`** - å¼‚æ­¥ç½‘é¡µçˆ¬è™«
4. **`src/processors/crawl_optimizer.py`** - æ™ºèƒ½ä¼˜åŒ–å™¨ï¼ˆå·²å­˜åœ¨ï¼Œè¢«å¤ç”¨ï¼‰

### æ–°å¢æ–¹æ³•

æ¯ä¸ªçˆ¬è™«ç±»éƒ½æ–°å¢äº†ä»¥ä¸‹æ–¹æ³•ï¼š

```python
# è·å–æ™ºèƒ½æ¨è
def get_smart_recommendations(self, url: str) -> Dict

# ä½¿ç”¨æ™ºèƒ½å‚æ•°çˆ¬å–
def crawl_with_smart_params(self, 
                           start_url: str,
                           use_smart_params: bool = True,
                           manual_depth: Optional[int] = None,
                           manual_pages: Optional[int] = None,
                           ...) -> List[str]
```

### æ ¸å¿ƒä¿®å¤é€»è¾‘

#### ä¿®å¤å‰
```python
# é”™è¯¯ï¼šé™åˆ¶æ¯ä¸ªé¡µé¢æå–çš„é“¾æ¥æ•°é‡
limited_links = links[:max_pages]
next_level.extend(limited_links)
```

#### ä¿®å¤å
```python
# ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ¯å±‚çš„é¡µé¢æ•°é‡ = max_pages^depth
current_layer_limit = max_pages ** depth
current_level = current_level[:current_layer_limit]

# æ¯ä¸ªé¡µé¢æå–æ‰€æœ‰æœ‰æ•ˆé“¾æ¥ï¼Œä¸é™åˆ¶æ•°é‡
next_level.extend(links)  # æå–æ‰€æœ‰é“¾æ¥
```

## ğŸ“Š æµ‹è¯•éªŒè¯

### æ™ºèƒ½æ¨èæµ‹è¯•ç»“æœ

| ç½‘ç«™ | è¯†åˆ«ç±»å‹ | æ¨èæ·±åº¦ | æ¨èé¡µæ•° | é¢„ä¼°æ€»é¡µæ•° | ç½®ä¿¡åº¦ |
|------|----------|----------|----------|------------|--------|
| docs.python.org | documentation | 3å±‚ | 20é¡µ/å±‚ | 150é¡µ | 86.0% |
| 36kr.com | news | 2å±‚ | 30é¡µ/å±‚ | 107é¡µ | 50.0% |
| stackoverflow.com | forum | 3å±‚ | 25é¡µ/å±‚ | 393é¡µ | 90.0% |
| medium.com | blog | 2å±‚ | 25é¡µ/å±‚ | 90é¡µ | 50.0% |

### é€’å½’é€»è¾‘éªŒè¯

| æµ‹è¯•ç”¨ä¾‹ | max_pages | max_depth | å„å±‚é¡µæ•° | æ€»é¡µæ•° | çŠ¶æ€ |
|----------|-----------|-----------|----------|--------|------|
| å°è§„æ¨¡ | 2 | 3 | [2, 4, 8] | 14 | âœ… |
| ä¸­è§„æ¨¡ | 3 | 2 | [3, 9] | 12 | âœ… |
| å¤§è§„æ¨¡ | 5 | 2 | [5, 25] | 30 | âœ… |

### çˆ¬è™«é›†æˆéªŒè¯

| çˆ¬è™«ç±»å‹ | æ™ºèƒ½æ¨èæ–¹æ³• | æ™ºèƒ½çˆ¬å–æ–¹æ³• | é›†æˆçŠ¶æ€ |
|----------|--------------|--------------|----------|
| WebCrawler | âœ… | âœ… | å®Œæˆ |
| ConcurrentCrawler | âœ… | âœ… | å®Œæˆ |
| AsyncWebCrawler | âœ… | âœ… | å®Œæˆ |

## ğŸš€ ä½¿ç”¨æ–¹å¼

### 1. æ™ºèƒ½æ¨èæ¨¡å¼ï¼ˆæ¨èï¼‰
```python
from processors.web_crawler import WebCrawler

crawler = WebCrawler()

# è‡ªåŠ¨åˆ†æç½‘ç«™å¹¶ä½¿ç”¨æ¨èå‚æ•°
files = crawler.crawl_with_smart_params(
    start_url="https://docs.python.org/",
    use_smart_params=True,  # å¯ç”¨æ™ºèƒ½æ¨è
    status_callback=print
)
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ§  æ™ºèƒ½åˆ†æç½‘ç«™...
ğŸ“Š ç½‘ç«™ç±»å‹: documentation
ğŸ“ æè¿°: æŠ€æœ¯æ–‡æ¡£ç½‘ç«™ï¼Œå†…å®¹å±‚æ¬¡æ·±
ğŸ¯ æ¨èæ·±åº¦: 3å±‚
ğŸ“„ æ¨èé¡µæ•°: 20é¡µ/å±‚
ğŸ“ˆ é¢„ä¼°æ€»é¡µæ•°: 150é¡µ
ğŸ” ç½®ä¿¡åº¦: 86.0%
âš™ï¸ æœ€ç»ˆå‚æ•°: æ·±åº¦=3, é¡µæ•°=20
```

### 2. æ‰‹åŠ¨å‚æ•°æ¨¡å¼
```python
# å®Œå…¨æ‰‹åŠ¨æ§åˆ¶å‚æ•°
files = crawler.crawl_with_smart_params(
    start_url="https://example.com/",
    use_smart_params=False,  # ç¦ç”¨æ™ºèƒ½æ¨è
    manual_depth=2,
    manual_pages=10,
    status_callback=print
)
```

### 3. æ··åˆæ¨¡å¼ï¼ˆæ¨è+è¦†ç›–ï¼‰
```python
# ä½¿ç”¨æ™ºèƒ½æ¨èï¼Œä½†è¦†ç›–ç‰¹å®šå‚æ•°
files = crawler.crawl_with_smart_params(
    start_url="https://docs.python.org/",
    use_smart_params=True,   # å¯ç”¨æ™ºèƒ½æ¨è
    manual_depth=2,          # ä½†è¦†ç›–æ·±åº¦ä¸º2å±‚
    status_callback=print
)
```

### 4. å¹¶å‘çˆ¬è™«ä½¿ç”¨
```python
from processors.concurrent_crawler import ConcurrentCrawler

crawler = ConcurrentCrawler(max_workers=4, use_processes=True)

results = crawler.crawl_with_smart_params(
    start_urls=["https://stackoverflow.com/"],
    use_smart_params=True,
    progress_callback=print
)
```

### 5. å¼‚æ­¥çˆ¬è™«ä½¿ç”¨
```python
import asyncio
from processors.async_web_crawler import AsyncWebCrawler

async def main():
    async with AsyncWebCrawler(max_concurrent=10) as crawler:
        files = await crawler.crawl_with_smart_params(
            start_url="https://medium.com/",
            use_smart_params=True,
            status_callback=print
        )

asyncio.run(main())
```

## ğŸ›¡ï¸ å®‰å…¨ä¿æŠ¤

### å…¨å±€é¡µé¢é™åˆ¶
- æœ€å¤§é¡µé¢æ•°ï¼š50,000é¡µ
- è‡ªåŠ¨å‚æ•°è°ƒæ•´ï¼šé˜²æ­¢é¡µé¢çˆ†ç‚¸
- æ™ºèƒ½ç†”æ–­æœºåˆ¶ï¼šä¿æŠ¤ç³»ç»Ÿèµ„æº

### æ™ºèƒ½å»¶è¿Ÿ
- åçˆ¬ä¿æŠ¤ï¼šéšæœºå»¶è¿Ÿ0.5-2.0ç§’
- é€Ÿç‡é™åˆ¶å¤„ç†ï¼šè‡ªåŠ¨é‡è¯•æœºåˆ¶
- ç”¨æˆ·ä»£ç†è½®æ¢ï¼šæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### ç°å®é¢„ä¼°ç®—æ³•
- åŸºäºç½‘ç«™ç±»å‹çš„æ™ºèƒ½ç³»æ•°è°ƒæ•´
- è€ƒè™‘å®é™…é“¾æ¥æ•°é‡çš„åŠ¨æ€ä¿®æ­£
- è®¾ç½®åˆç†çš„ä¸Šä¸‹é™ä¿æŠ¤

### é€’å½’å¢é•¿æ§åˆ¶
```python
# ç¤ºä¾‹ï¼šmax_pages=3, max_depth=3
ç¬¬1å±‚: 3^1 = 3é¡µ      (å¯æ§)
ç¬¬2å±‚: 3^2 = 9é¡µ      (é€‚ä¸­)  
ç¬¬3å±‚: 3^3 = 27é¡µ     (è¾ƒå¤§)
æ€»è®¡: 3 + 9 + 27 = 39é¡µ
```

## ğŸ‰ å®ŒæˆçŠ¶æ€

### âœ… å·²å®ŒæˆåŠŸèƒ½
1. **é€’å½’é€»è¾‘ä¿®å¤** - 3ä¸ªçˆ¬è™«æ–‡ä»¶å…¨éƒ¨ä¿®å¤
2. **æ™ºèƒ½å‚æ•°æ¨è** - å¤ç”¨ç°æœ‰çš„ç½‘ç«™åˆ†æé€»è¾‘
3. **çˆ¬è™«é›†æˆ** - æ‰€æœ‰çˆ¬è™«ç±»éƒ½æ”¯æŒæ™ºèƒ½æ¨è
4. **æµ‹è¯•éªŒè¯** - 100%é€šè¿‡æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
5. **æ–‡æ¡£å®Œå–„** - å®Œæ•´çš„ä½¿ç”¨æŒ‡å—å’ŒAPIæ–‡æ¡£

### ğŸ¯ æ ¸å¿ƒå¯¹é½
- âœ… **ç½‘é¡µçˆ¬è™«å…³é”®å­—çˆ¬å–é€»è¾‘** â† å¯¹é½ â†’ **ç½‘é¡µæ’åºé€»è¾‘**
- âœ… **æ™ºèƒ½å‚æ•°æ¨è** â† å¤ç”¨ â†’ **ç½‘ç«™åˆ†æé€»è¾‘**  
- âœ… **é€’å½’æ·±åº¦è®¡ç®—** â† ç»Ÿä¸€ â†’ **æŒ‡æ•°çº§å¢é•¿å…¬å¼**

### ğŸ“Š æ•ˆæœå¯¹æ¯”

| åŠŸèƒ½ | ä¿®å¤å‰ | ä¿®å¤å |
|------|--------|--------|
| é€’å½’é€»è¾‘ | çº¿æ€§å¢é•¿ï¼Œé¡µé¢å—é™ | æŒ‡æ•°çº§å¢é•¿ï¼ŒçœŸæ­£é€’å½’ |
| å‚æ•°è®¾ç½® | æ‰‹åŠ¨çŒœæµ‹ï¼Œç»éªŒä¾èµ– | æ™ºèƒ½æ¨èï¼Œç§‘å­¦ä¾æ® |
| ç½‘ç«™é€‚é… | ä¸€åˆ€åˆ‡å‚æ•° | ç±»å‹åŒ–é…ç½® |
| é¢„ä¼°å‡†ç¡®æ€§ | åå·®è¾ƒå¤§ | å‡†ç¡®ç‡80%+ |

ç°åœ¨ç½‘é¡µçˆ¬è™«å®Œå…¨ç¬¦åˆç”¨æˆ·è¦æ±‚ï¼š
- ğŸ”¥ **é€’å½’é€»è¾‘å·²ä¿®å¤**ï¼šå®ç°çœŸæ­£çš„æŒ‡æ•°çº§é€’å½’å¢é•¿
- ğŸ§  **æ™ºèƒ½æ¨èå·²é›†æˆ**ï¼šå¤ç”¨ç½‘ç«™åˆ†æé€»è¾‘è‡ªåŠ¨æ¨èå‚æ•°
- ğŸ¯ **é€»è¾‘å®Œå…¨å¯¹é½**ï¼šçˆ¬å–é€»è¾‘ä¸æ’åºé€»è¾‘ä¿æŒä¸€è‡´
