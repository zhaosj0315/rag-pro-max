#!/usr/bin/env python3
"""
ä¿®å¤ç¦»çº¿æ¨¡å¼ - ç¦ç”¨æ‰€æœ‰ç½‘ç»œè¿æ¥
"""

def create_offline_config():
    """åˆ›å»ºç¦»çº¿é…ç½®"""
    
    config = '''
# ç¦»çº¿æ¨¡å¼é…ç½®
OFFLINE_MODE = True
DISABLE_QUERY_REWRITE = True
DISABLE_SUGGESTION_GENERATION = True
USE_LOCAL_LLM_ONLY = True

# æœ¬åœ°æ¨¡å‹é…ç½®
LOCAL_LLM_CONFIG = {
    "api_base": "http://localhost:11434",
    "model": "qwen2.5:7b",
    "temperature": 0.7
}

print("ğŸ”’ ç¦»çº¿æ¨¡å¼å·²å¯ç”¨")
'''
    
    with open('/Users/zhaosj/Documents/rag-pro-max/src/config/offline_config.py', 'w') as f:
        f.write(config)
    
    print("âœ… ç¦»çº¿é…ç½®å·²åˆ›å»º")

def patch_query_rewriter():
    """ç¦ç”¨æŸ¥è¯¢æ”¹å†™"""
    
    patch = '''
def disable_query_rewrite():
    """ç¦ç”¨æŸ¥è¯¢æ”¹å†™ï¼Œç›´æ¥è¿”å›åŸæŸ¥è¯¢"""
    return lambda query: query

# æ›¿æ¢æŸ¥è¯¢æ”¹å†™å‡½æ•°
query_rewrite = disable_query_rewrite()
'''
    
    with open('/Users/zhaosj/Documents/rag-pro-max/src/utils/offline_patch.py', 'w') as f:
        f.write(patch)
    
    print("âœ… æŸ¥è¯¢æ”¹å†™å·²ç¦ç”¨")

def create_local_llm_config():
    """åˆ›å»ºæœ¬åœ°LLMé…ç½®"""
    
    config = '''
# æœ¬åœ°LLMé…ç½®æ–‡ä»¶
import os

# å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹
os.environ["USE_LOCAL_LLM"] = "true"
os.environ["DISABLE_OPENAI"] = "true"

# Ollamaé…ç½®
OLLAMA_CONFIG = {
    "base_url": "http://localhost:11434",
    "model": "qwen2.5:7b",
    "timeout": 30
}

def get_local_llm():
    """è·å–æœ¬åœ°LLMå®ä¾‹"""
    try:
        from llama_index.llms.ollama import Ollama
        
        llm = Ollama(
            model=OLLAMA_CONFIG["model"],
            base_url=OLLAMA_CONFIG["base_url"],
            request_timeout=OLLAMA_CONFIG["timeout"]
        )
        
        print(f"âœ… æœ¬åœ°LLMå·²è¿æ¥: {OLLAMA_CONFIG['model']}")
        return llm
        
    except Exception as e:
        print(f"âŒ æœ¬åœ°LLMè¿æ¥å¤±è´¥: {e}")
        return None

# ç¦ç”¨ç½‘ç»œåŠŸèƒ½çš„é…ç½®
DISABLE_FEATURES = {
    "query_rewrite": True,
    "suggestion_generation": True,
    "openai_calls": True,
    "network_requests": True
}
'''
    
    with open('/Users/zhaosj/Documents/rag-pro-max/src/config/local_llm_config.py', 'w') as f:
        f.write(config)
    
    print("âœ… æœ¬åœ°LLMé…ç½®å·²åˆ›å»º")

def create_quick_fix_script():
    """åˆ›å»ºå¿«é€Ÿä¿®å¤è„šæœ¬"""
    
    script = '''#!/bin/bash
echo "ğŸ”’ å¯ç”¨ç¦»çº¿æ¨¡å¼..."

# è®¾ç½®ç¦»çº¿ç¯å¢ƒå˜é‡
export OFFLINE_MODE=true
export DISABLE_OPENAI=true
export USE_LOCAL_LLM=true
export DISABLE_QUERY_REWRITE=true
export DISABLE_SUGGESTIONS=true

# æ£€æŸ¥Ollamaæ˜¯å¦è¿è¡Œ
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âš ï¸  Ollamaæœªè¿è¡Œï¼Œå¯åŠ¨Ollama..."
    ollama serve &
    sleep 3
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if ! ollama list | grep -q "qwen2.5:7b"; then
        echo "ğŸ“¥ ä¸‹è½½æœ¬åœ°æ¨¡å‹..."
        ollama pull qwen2.5:7b
    fi
fi

echo "âœ… ç¦»çº¿æ¨¡å¼é…ç½®å®Œæˆ"
echo "ğŸš€ é‡å¯åº”ç”¨..."

# åœæ­¢å½“å‰åº”ç”¨
pkill -f "streamlit run"
sleep 2

# å¯åŠ¨ç¦»çº¿æ¨¡å¼åº”ç”¨
cd /Users/zhaosj/Documents/rag-pro-max
streamlit run src/apppro.py --server.headless=true &

echo "âœ… ç¦»çº¿åº”ç”¨å·²å¯åŠ¨"
'''
    
    with open('/Users/zhaosj/Documents/rag-pro-max/enable_offline_mode.sh', 'w') as f:
        f.write(script)
    
    import os
    os.chmod('/Users/zhaosj/Documents/rag-pro-max/enable_offline_mode.sh', 0o755)
    
    print("âœ… ç¦»çº¿æ¨¡å¼è„šæœ¬å·²åˆ›å»º")

def main():
    print("ğŸ”’ ç¦»çº¿æ¨¡å¼ä¿®å¤å·¥å…·")
    print("="*50)
    
    create_offline_config()
    patch_query_rewriter()
    create_local_llm_config()
    create_quick_fix_script()
    
    print("\nğŸ¯ ç«‹å³ä¿®å¤:")
    print("1. å¯ç”¨ç¦»çº¿æ¨¡å¼:")
    print("   ./enable_offline_mode.sh")
    print("\n2. æˆ–è€…æ‰‹åŠ¨è®¾ç½®:")
    print("   export OFFLINE_MODE=true")
    print("   export DISABLE_OPENAI=true")
    print("\n3. ç¡®ä¿Ollamaè¿è¡Œ:")
    print("   ollama serve")
    print("   ollama pull qwen2.5:7b")
    
    print("\nâœ… ä¿®å¤åå°†ç¦ç”¨:")
    print("   - OpenAI APIè°ƒç”¨")
    print("   - æŸ¥è¯¢æ”¹å†™åŠŸèƒ½") 
    print("   - åœ¨çº¿æ¨èé—®é¢˜ç”Ÿæˆ")
    print("   - æ‰€æœ‰ç½‘ç»œè¯·æ±‚")

if __name__ == "__main__":
    main()
