# éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç» RAG Pro Max çš„å„ç§éƒ¨ç½²æ–¹å¼ã€‚

## ğŸ“‹ ç›®å½•

- [æœ¬åœ°éƒ¨ç½²](#æœ¬åœ°éƒ¨ç½²)
- [Docker éƒ¨ç½²](#docker-éƒ¨ç½²)
- [macOS åº”ç”¨](#macos-åº”ç”¨)
- [äº‘ç«¯éƒ¨ç½²](#äº‘ç«¯éƒ¨ç½²)
- [ç”Ÿäº§ç¯å¢ƒ](#ç”Ÿäº§ç¯å¢ƒ)

---

## æœ¬åœ°éƒ¨ç½²

### ç³»ç»Ÿè¦æ±‚

| é¡¹ç›® | æœ€ä½é…ç½® | æ¨èé…ç½® |
|------|---------|---------|
| CPU | 4 æ ¸ | 8 æ ¸+ |
| å†…å­˜ | 8GB | 16GB+ |
| ç£ç›˜ | 20GB | 50GB+ |
| GPU | æ—  | æ”¯æŒ CUDA |
| Python | 3.8+ | 3.10/3.12 |

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/rag-pro-max.git
cd rag-pro-max

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. è¿è¡Œæµ‹è¯•
./scripts/test.sh

# 4. å¯åŠ¨åº”ç”¨
./scripts/start.sh
```

### é…ç½®ä¼˜åŒ–

#### 1. ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# LLM é…ç½®
OPENAI_API_KEY=sk-your-key-here
OPENAI_BASE_URL=https://api.openai.com/v1

# ç³»ç»Ÿé…ç½®
MAX_WORKERS=80
CHUNK_SIZE=500
TOP_K=5
```

#### 2. é…ç½®æ–‡ä»¶

ç¼–è¾‘ `app_config.json`:

```json
{
  "output_path": "./vector_db_storage",
  "llm_url_ollama": "http://127.0.0.1:11434",
  "embed_model_hf": "BAAI/bge-small-zh-v1.5"
}
```

#### 3. RAG å‚æ•°

ç¼–è¾‘ `rag_config.json`:

```json
{
  "chunk_size": 500,
  "chunk_overlap": 50,
  "top_k": 5,
  "similarity_threshold": 0.7
}
```

### æ€§èƒ½è°ƒä¼˜

#### CPU ä¼˜åŒ–

```python
# src/apppro.py ä¸­è°ƒæ•´çº¿ç¨‹æ•°
max_workers = min(80, os.cpu_count() * 4)
```

#### å†…å­˜ä¼˜åŒ–

```bash
# é™åˆ¶ Python å†…å­˜ä½¿ç”¨
export PYTHONMALLOC=malloc
ulimit -v 16000000  # é™åˆ¶ 16GB
```

#### GPU åŠ é€Ÿ

ç¡®ä¿ PyTorch æ”¯æŒ GPUï¼š

```python
import torch
print(torch.cuda.is_available())  # åº”è¿”å› True
```

---

## Docker éƒ¨ç½²

### å¿«é€Ÿéƒ¨ç½²

```bash
# 1. æ„å»ºé•œåƒ
./scripts/docker-build.sh

# 2. å¯åŠ¨æœåŠ¡
docker-compose up -d

# 3. æŸ¥çœ‹æ—¥å¿—
docker logs -f rag-pro-max

# 4. è®¿é—®åº”ç”¨
open http://localhost:8501
```

### Docker Compose é…ç½®

`docker-compose.yml`:

```yaml
version: '3.8'

services:
  rag-pro-max:
    build: .
    container_name: rag-pro-max
    ports:
      - "8501:8501"
    volumes:
      - ./vector_db_storage:/app/vector_db_storage
      - ./chat_histories:/app/chat_histories
      - ./hf_cache:/app/hf_cache
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    deploy:
      resources:
        limits:
          cpus: '12'
          memory: 48G
    restart: unless-stopped
```

### èµ„æºé™åˆ¶

æ ¹æ®æœåŠ¡å™¨é…ç½®è°ƒæ•´ï¼š

```yaml
deploy:
  resources:
    limits:
      cpus: '8'      # CPU æ ¸å¿ƒæ•°
      memory: 32G    # å†…å­˜é™åˆ¶
    reservations:
      cpus: '4'
      memory: 16G
```

### æ•°æ®æŒä¹…åŒ–

ç¡®ä¿æŒ‚è½½ä»¥ä¸‹ç›®å½•ï¼š

```yaml
volumes:
  - ./vector_db_storage:/app/vector_db_storage  # å‘é‡æ•°æ®åº“
  - ./chat_histories:/app/chat_histories        # å¯¹è¯å†å²
  - ./hf_cache:/app/hf_cache                    # æ¨¡å‹ç¼“å­˜
  - ./app_logs:/app/app_logs                    # åº”ç”¨æ—¥å¿—
```

### Docker ç®¡ç†

```bash
# å¯åŠ¨
docker-compose up -d

# åœæ­¢
docker-compose down

# é‡å¯
docker-compose restart

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# è¿›å…¥å®¹å™¨
docker exec -it rag-pro-max bash

# æ›´æ–°é•œåƒ
docker-compose pull
docker-compose up -d
```

---

## macOS åº”ç”¨

### æ‰“åŒ…åº”ç”¨

```bash
# 1. å®‰è£… PyInstaller
pip install pyinstaller

# 2. æ‰§è¡Œæ‰“åŒ…
./scripts/build_mac.sh

# 3. æµ‹è¯•åº”ç”¨
open dist/RAG_Pro_Max.app
```

### æ‰“åŒ…é…ç½®

`RAG_Pro_Max.spec`:

```python
# -*- mode: python ; coding: utf-8 -*-

a = Analysis(
    ['src/apppro.py'],
    pathex=[],
    binaries=[],
    datas=[
        ('hf_cache', 'hf_cache'),
        ('*.json', '.'),
    ],
    hiddenimports=[
        'streamlit',
        'llama_index',
        # ... å…¶ä»–ä¾èµ–
    ],
    hookspath=[],
    hooksconfig={},
    runtime_hooks=[],
    excludes=[],
    noarchive=False,
)
```

### ç­¾åå’Œå…¬è¯

```bash
# ä»£ç ç­¾å
codesign --force --deep --sign "Developer ID" dist/RAG_Pro_Max.app

# å…¬è¯
xcrun notarytool submit dist/RAG_Pro_Max.app.zip \
  --apple-id "your@email.com" \
  --password "app-specific-password" \
  --team-id "TEAM_ID"
```

### åˆ†å‘

```bash
# åˆ›å»º DMG
hdiutil create -volname "RAG Pro Max" \
  -srcfolder dist/RAG_Pro_Max.app \
  -ov -format UDZO \
  RAG_Pro_Max.dmg
```

---

## äº‘ç«¯éƒ¨ç½²

### AWS éƒ¨ç½²

#### EC2 å®ä¾‹

**æ¨èé…ç½®**:
- å®ä¾‹ç±»å‹: `t3.xlarge` (4 vCPU, 16GB RAM)
- å­˜å‚¨: 50GB EBS
- æ“ä½œç³»ç»Ÿ: Ubuntu 22.04 LTS

**éƒ¨ç½²æ­¥éª¤**:

```bash
# 1. è¿æ¥å®ä¾‹
ssh -i key.pem ubuntu@ec2-xx-xx-xx-xx.compute.amazonaws.com

# 2. å®‰è£…ä¾èµ–
sudo apt update
sudo apt install python3-pip git

# 3. å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/rag-pro-max.git
cd rag-pro-max

# 4. å®‰è£…ä¾èµ–
pip3 install -r requirements.txt

# 5. é…ç½®ç¯å¢ƒ
export OPENAI_API_KEY="your-key"

# 6. å¯åŠ¨æœåŠ¡
nohup streamlit run src/apppro.py --server.port 8501 &
```

#### ä½¿ç”¨ Docker

```bash
# 1. å®‰è£… Docker
sudo apt install docker.io docker-compose

# 2. æ„å»ºå’Œå¯åŠ¨
docker-compose up -d

# 3. é…ç½®å®‰å…¨ç»„
# å¼€æ”¾ç«¯å£ 8501
```

### Google Cloud Platform

#### Cloud Run éƒ¨ç½²

```bash
# 1. æ„å»ºé•œåƒ
gcloud builds submit --tag gcr.io/PROJECT_ID/rag-pro-max

# 2. éƒ¨ç½²æœåŠ¡
gcloud run deploy rag-pro-max \
  --image gcr.io/PROJECT_ID/rag-pro-max \
  --platform managed \
  --region us-central1 \
  --memory 16Gi \
  --cpu 4
```

### Azure éƒ¨ç½²

#### Container Instances

```bash
# 1. åˆ›å»ºèµ„æºç»„
az group create --name rag-pro-max-rg --location eastus

# 2. éƒ¨ç½²å®¹å™¨
az container create \
  --resource-group rag-pro-max-rg \
  --name rag-pro-max \
  --image your-registry/rag-pro-max:latest \
  --cpu 4 \
  --memory 16 \
  --ports 8501
```

---

## ç”Ÿäº§ç¯å¢ƒ

### åå‘ä»£ç†

#### Nginx é…ç½®

```nginx
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://localhost:8501;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

#### HTTPS é…ç½®

```bash
# ä½¿ç”¨ Let's Encrypt
sudo certbot --nginx -d your-domain.com
```

### è¿›ç¨‹ç®¡ç†

#### Systemd æœåŠ¡

åˆ›å»º `/etc/systemd/system/rag-pro-max.service`:

```ini
[Unit]
Description=RAG Pro Max
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/rag-pro-max
Environment="PATH=/home/ubuntu/.local/bin:/usr/bin"
Environment="PYTHONPATH=/home/ubuntu/rag-pro-max"
ExecStart=/usr/bin/streamlit run src/apppro.py --server.port 8501
Restart=always

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š

```bash
sudo systemctl enable rag-pro-max
sudo systemctl start rag-pro-max
sudo systemctl status rag-pro-max
```

### ç›‘æ§å’Œæ—¥å¿—

#### æ—¥å¿—ç®¡ç†

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f app_logs/log_$(date +%Y%m%d).jsonl

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
sudo journalctl -u rag-pro-max -f
```

#### ç›‘æ§æŒ‡æ ‡

ä½¿ç”¨ Prometheus + Grafanaï¼š

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'rag-pro-max'
    static_configs:
      - targets: ['localhost:8501']
```

### å¤‡ä»½ç­–ç•¥

#### è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/rag-pro-max"

# å¤‡ä»½å‘é‡æ•°æ®åº“
tar -czf $BACKUP_DIR/vector_db_$DATE.tar.gz vector_db_storage/

# å¤‡ä»½å¯¹è¯å†å²
tar -czf $BACKUP_DIR/chat_histories_$DATE.tar.gz chat_histories/

# å¤‡ä»½é…ç½®
cp app_config.json $BACKUP_DIR/app_config_$DATE.json

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™ 7 å¤©ï¼‰
find $BACKUP_DIR -name "*.tar.gz" -mtime +7 -delete
```

è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼š

```bash
# æ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½
0 2 * * * /path/to/backup.sh
```

### å®‰å…¨åŠ å›º

#### 1. é˜²ç«å¢™é…ç½®

```bash
# åªå¼€æ”¾å¿…è¦ç«¯å£
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS
sudo ufw enable
```

#### 2. ç¯å¢ƒå˜é‡ä¿æŠ¤

```bash
# ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡
export OPENAI_API_KEY=$(aws secretsmanager get-secret-value \
  --secret-id openai-key --query SecretString --output text)
```

#### 3. è®¿é—®æ§åˆ¶

åœ¨ Nginx ä¸­æ·»åŠ åŸºæœ¬è®¤è¯ï¼š

```nginx
location / {
    auth_basic "Restricted Access";
    auth_basic_user_file /etc/nginx/.htpasswd;
    proxy_pass http://localhost:8501;
}
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### ç«¯å£è¢«å ç”¨

```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
lsof -i :8501

# æ€æ­»è¿›ç¨‹
kill -9 PID
```

#### å†…å­˜ä¸è¶³

```bash
# å¢åŠ  swap
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

#### æƒé™é—®é¢˜

```bash
# ä¿®å¤æ–‡ä»¶æƒé™
sudo chown -R $USER:$USER .
chmod -R 755 .
```

---

## æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ

- **CPU**: 8 æ ¸
- **å†…å­˜**: 32GB
- **GPU**: æ— 
- **ç½‘ç»œ**: 1Gbps

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| å¹¶å‘ç”¨æˆ· | 10 |
| æŸ¥è¯¢å»¶è¿Ÿ | 2-3 ç§’ |
| æ–‡æ¡£å¤„ç† | ~3 é¡µ/ç§’ |
| å†…å­˜å ç”¨ | 10-15GB |
| CPU ä½¿ç”¨ | 30-40% |

---

**æœ€åæ›´æ–°**: 2025-12-07
