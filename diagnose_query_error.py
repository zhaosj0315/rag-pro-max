#!/usr/bin/env python3
"""
æŸ¥è¯¢é”™è¯¯è¯Šæ–­è„šæœ¬
åˆ†ææŸ¥è¯¢å¤„ç†ä¸­çš„é”™è¯¯åŸå› 
"""

import sys
import os
sys.path.append('src')

def diagnose_query_error():
    """è¯Šæ–­æŸ¥è¯¢é”™è¯¯"""
    print("ğŸ” è¯Šæ–­æŸ¥è¯¢å¤„ç†é”™è¯¯...")
    
    try:
        # 1. æ£€æŸ¥çŸ¥è¯†åº“åŠ è½½å™¨
        from src.kb.kb_loader import KnowledgeBaseLoader
        print("âœ… KnowledgeBaseLoader å¯¼å…¥æˆåŠŸ")
        
        # 2. æ£€æŸ¥åµŒå…¥æ¨¡å‹
        from src.utils.model_manager import get_embed
        print("âœ… get_embed å¯¼å…¥æˆåŠŸ")
        
        # 3. æ£€æŸ¥é…ç½®
        from src.config import ConfigLoader
        config = ConfigLoader.load()
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ: {len(config)} é¡¹")
        
        # 4. æµ‹è¯•çŸ¥è¯†åº“åŠ è½½
        kb_loader = KnowledgeBaseLoader("vector_db_storage")
        print("âœ… KnowledgeBaseLoader åˆå§‹åŒ–æˆåŠŸ")
        
        # 5. åˆ—å‡ºå¯ç”¨çŸ¥è¯†åº“
        from src.kb import KBManager
        kb_manager = KBManager()
        kb_manager.base_path = "vector_db_storage"
        kbs = kb_manager.list_all()
        print(f"âœ… å‘ç° {len(kbs)} ä¸ªçŸ¥è¯†åº“: {kbs[:3]}...")
        
        if kbs:
            # 6. å°è¯•åŠ è½½ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“
            test_kb = kbs[0]
            print(f"ğŸ§ª æµ‹è¯•åŠ è½½çŸ¥è¯†åº“: {test_kb}")
            
            try:
                chat_engine, error_msg, kb_index = kb_loader.load_knowledge_base(
                    test_kb, "ollama", "all-MiniLM-L6-v2", "", "http://localhost:11434"
                )
                
                if chat_engine:
                    print("âœ… çŸ¥è¯†åº“åŠ è½½æˆåŠŸ")
                    print(f"   chat_engine ç±»å‹: {type(chat_engine)}")
                    print(f"   æ˜¯å¦æœ‰ stream_chat: {hasattr(chat_engine, 'stream_chat')}")
                    print(f"   æ˜¯å¦æœ‰ query: {hasattr(chat_engine, 'query')}")
                    
                    # 7. æµ‹è¯•ç®€å•æŸ¥è¯¢
                    try:
                        test_query = "æµ‹è¯•æŸ¥è¯¢"
                        print(f"ğŸ§ª æµ‹è¯•æŸ¥è¯¢: {test_query}")
                        
                        if hasattr(chat_engine, 'query'):
                            result = chat_engine.query(test_query)
                            print(f"âœ… query æ–¹æ³•æ­£å¸¸: {type(result)}")
                        
                        if hasattr(chat_engine, 'stream_chat'):
                            result = chat_engine.stream_chat(test_query)
                            print(f"âœ… stream_chat æ–¹æ³•æ­£å¸¸: {type(result)}")
                            
                            # å°è¯•è·å–ç¬¬ä¸€ä¸ªtoken
                            try:
                                first_token = next(result.response_gen)
                                print(f"âœ… æµå¼å“åº”æ­£å¸¸: {first_token[:50]}...")
                            except Exception as e:
                                print(f"âŒ æµå¼å“åº”é”™è¯¯: {e}")
                        
                    except Exception as e:
                        print(f"âŒ æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        
                else:
                    print(f"âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {error_msg}")
                    
            except Exception as e:
                print(f"âŒ çŸ¥è¯†åº“åŠ è½½å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯Šæ–­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ RAG Pro Max æŸ¥è¯¢é”™è¯¯è¯Šæ–­")
    print("=" * 50)
    
    success = diagnose_query_error()
    
    if success:
        print("\nâœ… è¯Šæ–­å®Œæˆ")
    else:
        print("\nâŒ è¯Šæ–­å¤±è´¥")
