#!/usr/bin/env python3
"""
RAG Pro Max æ–‡æ¡£é€»è¾‘åŒæ­¥å·¥å…·
ç¡®ä¿æ‰€æœ‰æ–‡æ¡£çš„ç‰ˆæœ¬ã€åŠŸèƒ½æè¿°å’Œæ¶æ„ä¿¡æ¯ä¿æŒä¸€è‡´
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import logging

class DocumentSyncManager:
    """æ–‡æ¡£åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root or os.getcwd())
        self.setup_logging()
        self.version_pattern = r'v?(\d+\.\d+\.\d+)'
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = self.project_root / "sync_logs"
        log_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / f"doc_sync_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def extract_version_from_readme(self) -> Optional[str]:
        """ä»README.mdæå–ç‰ˆæœ¬å·"""
        readme_path = self.project_root / "README.md"
        if not readme_path.exists():
            return None
            
        with open(readme_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # æŸ¥æ‰¾ç‰ˆæœ¬æ ‡è¯†
        version_matches = re.findall(self.version_pattern, content)
        if version_matches:
            return version_matches[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ç‰ˆæœ¬å·
        return None
    
    def extract_features_from_readme(self) -> List[str]:
        """ä»README.mdæå–æ ¸å¿ƒåŠŸèƒ½åˆ—è¡¨"""
        readme_path = self.project_root / "README.md"
        if not readme_path.exists():
            return []
            
        with open(readme_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        features = []
        
        # æå–æ ¸å¿ƒåŠŸèƒ½éƒ¨åˆ†
        feature_section = re.search(r'## âœ¨ æ ¸å¿ƒåŠŸèƒ½(.*?)(?=##|\Z)', content, re.DOTALL)
        if feature_section:
            feature_text = feature_section.group(1)
            
            # æå–åŠŸèƒ½æ ‡é¢˜
            feature_titles = re.findall(r'### ğŸ¨ (.+)', feature_text)
            feature_titles.extend(re.findall(r'### ğŸ“„ (.+)', feature_text))
            feature_titles.extend(re.findall(r'### ğŸŒ (.+)', feature_text))
            feature_titles.extend(re.findall(r'### ğŸ” (.+)', feature_text))
            feature_titles.extend(re.findall(r'### ğŸ’¬ (.+)', feature_text))
            
            features.extend(feature_titles)
        
        return features
    
    def extract_architecture_from_readme(self) -> Dict[str, List[str]]:
        """ä»README.mdæå–æ¶æ„ä¿¡æ¯"""
        readme_path = self.project_root / "README.md"
        if not readme_path.exists():
            return {}
            
        with open(readme_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        architecture = {}
        
        # æå–å››å±‚æ¶æ„è®¾è®¡
        arch_section = re.search(r'### å››å±‚æ¶æ„è®¾è®¡(.*?)### æ ¸å¿ƒæ¨¡å—', content, re.DOTALL)
        if arch_section:
            arch_text = arch_section.group(1)
            
            # è§£ææ¶æ„å±‚
            layers = re.findall(r'(\w+å±‚) \((\w+ \w+)\)\s*- (.+)', arch_text)
            for layer_cn, layer_en, description in layers:
                architecture[layer_cn] = {
                    "english": layer_en,
                    "description": description.strip()
                }
        
        return architecture
    
    def analyze_code_structure(self) -> Dict[str, Dict]:
        """åˆ†æå®é™…ä»£ç ç»“æ„"""
        src_path = self.project_root / "src"
        if not src_path.exists():
            return {}
        
        structure = {
            "directories": {},
            "core_files": {},
            "total_files": 0,
            "total_lines": 0
        }
        
        # æ‰«æç›®å½•ç»“æ„
        for item in src_path.iterdir():
            if item.is_dir() and not item.name.startswith('__'):
                dir_info = self._analyze_directory(item)
                structure["directories"][item.name] = dir_info
                structure["total_files"] += dir_info["file_count"]
                structure["total_lines"] += dir_info["total_lines"]
        
        # åˆ†ææ ¸å¿ƒæ–‡ä»¶
        core_files = ["apppro.py", "file_processor.py", "rag_engine.py"]
        for core_file in core_files:
            file_path = src_path / core_file
            if file_path.exists():
                structure["core_files"][core_file] = self._analyze_file(file_path)
                structure["total_lines"] += structure["core_files"][core_file]["lines"]
        
        return structure
    
    def _analyze_directory(self, directory: Path) -> Dict:
        """åˆ†æç›®å½•"""
        info = {
            "file_count": 0,
            "total_lines": 0,
            "file_types": {},
            "files": []
        }
        
        for file_path in directory.rglob("*.py"):
            if not any(part.startswith('__') for part in file_path.parts):
                file_info = self._analyze_file(file_path)
                info["files"].append({
                    "name": file_path.name,
                    "path": str(file_path.relative_to(self.project_root)),
                    "lines": file_info["lines"]
                })
                info["file_count"] += 1
                info["total_lines"] += file_info["lines"]
                
                ext = file_path.suffix
                info["file_types"][ext] = info["file_types"].get(ext, 0) + 1
        
        return info
    
    def _analyze_file(self, file_path: Path) -> Dict:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            return {
                "lines": len(lines),
                "size": file_path.stat().st_size,
                "modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
            }
        except Exception as e:
            self.logger.warning(f"æ— æ³•åˆ†ææ–‡ä»¶ {file_path}: {e}")
            return {"lines": 0, "size": 0, "modified": ""}
    
    def check_version_consistency(self) -> Dict[str, str]:
        """æ£€æŸ¥ç‰ˆæœ¬ä¸€è‡´æ€§"""
        versions = {}
        
        # æ£€æŸ¥README.md
        readme_version = self.extract_version_from_readme()
        if readme_version:
            versions["README.md"] = readme_version
        
        # æ£€æŸ¥å…¶ä»–å¯èƒ½åŒ…å«ç‰ˆæœ¬çš„æ–‡ä»¶
        version_files = [
            "CHANGELOG.md",
            "src/apppro.py",
            "requirements.txt"
        ]
        
        for file_name in version_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                version = self._extract_version_from_file(file_path)
                if version:
                    versions[file_name] = version
        
        return versions
    
    def _extract_version_from_file(self, file_path: Path) -> Optional[str]:
        """ä»æ–‡ä»¶ä¸­æå–ç‰ˆæœ¬å·"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            version_matches = re.findall(self.version_pattern, content)
            if version_matches:
                return version_matches[0]
        except Exception as e:
            self.logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        
        return None
    
    def generate_architecture_summary(self) -> str:
        """ç”Ÿæˆæ¶æ„æ€»ç»“"""
        code_structure = self.analyze_code_structure()
        readme_architecture = self.extract_architecture_from_readme()
        
        summary = f"""
# RAG Pro Max æ¶æ„åˆ†ææŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}

## ä»£ç ç»“æ„ç»Ÿè®¡
- æ€»æ–‡ä»¶æ•°: {code_structure['total_files']}
- æ€»ä»£ç è¡Œæ•°: {code_structure['total_lines']:,}
- ç›®å½•æ•°é‡: {len(code_structure['directories'])}
- æ ¸å¿ƒæ–‡ä»¶æ•°: {len(code_structure['core_files'])}

## ç›®å½•ç»“æ„åˆ†æ
"""
        
        for dir_name, dir_info in code_structure["directories"].items():
            summary += f"\n### {dir_name}/\n"
            summary += f"- æ–‡ä»¶æ•°: {dir_info['file_count']}\n"
            summary += f"- ä»£ç è¡Œæ•°: {dir_info['total_lines']:,}\n"
            summary += f"- ä¸»è¦æ–‡ä»¶:\n"
            
            # æ˜¾ç¤ºå‰5ä¸ªæœ€å¤§çš„æ–‡ä»¶
            sorted_files = sorted(dir_info['files'], key=lambda x: x['lines'], reverse=True)[:5]
            for file_info in sorted_files:
                summary += f"  - {file_info['name']}: {file_info['lines']} è¡Œ\n"
        
        summary += "\n## æ ¸å¿ƒæ–‡ä»¶åˆ†æ\n"
        for file_name, file_info in code_structure["core_files"].items():
            summary += f"- {file_name}: {file_info['lines']:,} è¡Œ, {file_info['size']:,} bytes\n"
        
        return summary
    
    def sync_documentation(self) -> Dict:
        """åŒæ­¥æ–‡æ¡£é€»è¾‘"""
        self.logger.info("å¼€å§‹åŒæ­¥æ–‡æ¡£é€»è¾‘...")
        
        # 1. æ£€æŸ¥ç‰ˆæœ¬ä¸€è‡´æ€§
        versions = self.check_version_consistency()
        
        # 2. æå–READMEä¿¡æ¯
        current_version = self.extract_version_from_readme()
        features = self.extract_features_from_readme()
        architecture = self.extract_architecture_from_readme()
        
        # 3. åˆ†æä»£ç ç»“æ„
        code_structure = self.analyze_code_structure()
        
        # 4. ç”Ÿæˆæ¶æ„æ€»ç»“
        arch_summary = self.generate_architecture_summary()
        
        # 5. åˆ›å»ºåŒæ­¥æŠ¥å‘Š
        sync_report = {
            "timestamp": datetime.now().isoformat(),
            "current_version": current_version,
            "version_consistency": versions,
            "features_count": len(features),
            "architecture_layers": len(architecture),
            "code_statistics": {
                "total_files": code_structure["total_files"],
                "total_lines": code_structure["total_lines"],
                "directories": len(code_structure["directories"]),
                "core_files": len(code_structure["core_files"])
            },
            "features": features,
            "architecture": architecture
        }
        
        # 6. ä¿å­˜ç»“æœ
        sync_dir = self.project_root / "sync_results"
        sync_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        with open(sync_dir / f"doc_sync_report_{timestamp}.json", 'w', encoding='utf-8') as f:
            json.dump(sync_report, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ¶æ„æ€»ç»“
        with open(sync_dir / f"architecture_summary_{timestamp}.md", 'w', encoding='utf-8') as f:
            f.write(arch_summary)
        
        self.logger.info("æ–‡æ¡£åŒæ­¥å®Œæˆ!")
        return sync_report
    
    def validate_documentation(self) -> List[str]:
        """éªŒè¯æ–‡æ¡£å®Œæ•´æ€§"""
        issues = []
        
        # æ£€æŸ¥å¿…éœ€æ–‡æ¡£
        required_docs = [
            "README.md",
            "DEPLOYMENT.md", 
            "CHANGELOG.md",
            "API_DOCUMENTATION.md"
        ]
        
        for doc in required_docs:
            doc_path = self.project_root / doc
            if not doc_path.exists():
                issues.append(f"ç¼ºå¤±æ–‡æ¡£: {doc}")
            elif doc_path.stat().st_size == 0:
                issues.append(f"ç©ºæ–‡æ¡£: {doc}")
        
        # æ£€æŸ¥ç‰ˆæœ¬ä¸€è‡´æ€§
        versions = self.check_version_consistency()
        if len(set(versions.values())) > 1:
            issues.append(f"ç‰ˆæœ¬ä¸ä¸€è‡´: {versions}")
        
        # æ£€æŸ¥READMEç»“æ„
        readme_path = self.project_root / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            required_sections = [
                "æ ¸å¿ƒåŠŸèƒ½",
                "ç³»ç»Ÿæ¶æ„", 
                "å¿«é€Ÿå¼€å§‹",
                "æŠ€æœ¯æ ˆ"
            ]
            
            for section in required_sections:
                if section not in content:
                    issues.append(f"READMEç¼ºå¤±ç« èŠ‚: {section}")
        
        return issues

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“š RAG Pro Max æ–‡æ¡£é€»è¾‘åŒæ­¥å·¥å…·")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ–‡æ¡£åŒæ­¥ç®¡ç†å™¨
    doc_sync = DocumentSyncManager()
    
    try:
        # éªŒè¯æ–‡æ¡£
        issues = doc_sync.validate_documentation()
        if issues:
            print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªæ–‡æ¡£é—®é¢˜:")
            for issue in issues:
                print(f"  - {issue}")
        else:
            print("\nâœ… æ–‡æ¡£éªŒè¯é€šè¿‡!")
        
        # æ‰§è¡ŒåŒæ­¥
        result = doc_sync.sync_documentation()
        
        print(f"\nğŸ“Š åŒæ­¥ç»“æœ:")
        print(f"  - å½“å‰ç‰ˆæœ¬: {result['current_version']}")
        print(f"  - æ ¸å¿ƒåŠŸèƒ½: {result['features_count']} ä¸ª")
        print(f"  - æ¶æ„å±‚æ•°: {result['architecture_layers']} å±‚")
        print(f"  - ä»£ç æ–‡ä»¶: {result['code_statistics']['total_files']} ä¸ª")
        print(f"  - ä»£ç è¡Œæ•°: {result['code_statistics']['total_lines']:,} è¡Œ")
        
        print(f"\nğŸ“‹ æ ¸å¿ƒåŠŸèƒ½åˆ—è¡¨:")
        for i, feature in enumerate(result['features'][:5], 1):
            print(f"  {i}. {feature}")
        
        print(f"\nğŸ—ï¸  æ¶æ„å±‚çº§:")
        for layer, info in result['architecture'].items():
            print(f"  - {layer}: {info['description']}")
        
        print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜è‡³ sync_results/ ç›®å½•")
        
    except Exception as e:
        print(f"âŒ æ–‡æ¡£åŒæ­¥å¤±è´¥: {e}")
        logging.error(f"æ–‡æ¡£åŒæ­¥å¤±è´¥: {e}", exc_info=True)

if __name__ == "__main__":
    main()
