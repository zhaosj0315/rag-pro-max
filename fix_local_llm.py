#!/usr/bin/env python3
"""
å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°LLMï¼Œç¦ç”¨OpenAI
"""

def patch_llm_config():
    """ä¿®è¡¥LLMé…ç½®ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹"""
    
    # åˆ›å»ºæœ¬åœ°LLMé…ç½®
    local_config = '''
# å¼ºåˆ¶æœ¬åœ°LLMé…ç½®
import os
from llama_index.llms.ollama import Ollama

def get_local_llm():
    """è·å–æœ¬åœ°LLM"""
    try:
        # ä½¿ç”¨ä½ æœ¬åœ°çš„æ¨¡å‹
        llm = Ollama(
            model="gpt-oss:20b",  # ä½¿ç”¨ä½ æœ¬åœ°å·²æœ‰çš„æ¨¡å‹
            base_url="http://localhost:11434",
            request_timeout=30
        )
        print("âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹: gpt-oss:20b")
        return llm
    except:
        try:
            # å¤‡é€‰æ¨¡å‹
            llm = Ollama(
                model="qwen3:32b", 
                base_url="http://localhost:11434",
                request_timeout=30
            )
            print("âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹: qwen3:32b")
            return llm
        except:
            print("âŒ æœ¬åœ°æ¨¡å‹ä¸å¯ç”¨")
            return None

# å¼ºåˆ¶ç¦ç”¨OpenAI
os.environ["OPENAI_API_KEY"] = ""
os.environ["DISABLE_OPENAI"] = "true"

# å¯¼å‡ºæœ¬åœ°LLM
LOCAL_LLM = get_local_llm()
'''
    
    with open('/Users/zhaosj/Documents/rag-pro-max/src/config/force_local_llm.py', 'w') as f:
        f.write(local_config)
    
    print("âœ… æœ¬åœ°LLMé…ç½®å·²åˆ›å»º")

def increase_ocr_timeout():
    """å¢åŠ OCRè¶…æ—¶æ—¶é—´"""
    
    # ä¿®æ”¹æ‰¹é‡OCRå¤„ç†å™¨çš„è¶…æ—¶
    import fileinput
    import sys
    
    file_path = '/Users/zhaosj/Documents/rag-pro-max/src/utils/batch_ocr_processor.py'
    
    with open(file_path, 'r') as f:
        content = f.read()
    
    # å°†300ç§’æ”¹ä¸º1200ç§’ï¼ˆ20åˆ†é’Ÿï¼‰
    content = content.replace('timeout=300', 'timeout=1200')
    
    with open(file_path, 'w') as f:
        f.write(content)
    
    print("âœ… OCRè¶…æ—¶æ—¶é—´å·²å¢åŠ åˆ°20åˆ†é’Ÿ")

def main():
    print("ğŸ”§ ä¿®å¤æœ¬åœ°LLMå’ŒOCRè¶…æ—¶")
    print("="*40)
    
    patch_llm_config()
    increase_ocr_timeout()
    
    # é‡å¯åº”ç”¨
    import os
    os.system("pkill -f 'streamlit run'")
    os.system("sleep 2")
    
    # å¯åŠ¨æ—¶å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°é…ç½®
    cmd = '''cd /Users/zhaosj/Documents/rag-pro-max && \
OPENAI_API_KEY="" \
DISABLE_OPENAI=true \
USE_LOCAL_LLM=true \
streamlit run src/apppro.py --server.headless=true &'''
    
    os.system(cmd)
    
    print("âœ… åº”ç”¨å·²é‡å¯")
    print("ğŸ“‹ æœ¬åœ°å¯ç”¨æ¨¡å‹:")
    print("   - gpt-oss:20b")
    print("   - qwen3:32b") 
    print("   - qwen3-coder:latest")
    print("ğŸ’¡ åº”ç”¨ä¼šè‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„æœ¬åœ°æ¨¡å‹")

if __name__ == "__main__":
    main()
