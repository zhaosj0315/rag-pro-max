"""
æ”¹è¿›çš„å¯¹è¯å¤„ç†å·¥å…· - ç¨³å®šæ€§ä¼˜å…ˆ
- å®‰å…¨çš„æµå¼è¾“å‡º
- å¼•ç”¨æºéªŒè¯
- è¿½é—®ç”Ÿæˆå®¹é”™
- å¯¹è¯å†å²ä¿æŠ¤
"""

import os
import json
import shutil
import threading
import time
import re
from datetime import datetime
from pathlib import Path
from collections import Counter
from llama_index.core import Settings
import re

HISTORY_DIR = "chat_histories"
Path(HISTORY_DIR).mkdir(parents=True, exist_ok=True)


def load_chat_history_safe(kb_id, logger=None):
    """
    å®‰å…¨åŠ è½½å¯¹è¯å†å²
    - è‡ªåŠ¨æ¢å¤æŸåçš„æ–‡ä»¶
    - éªŒè¯æ•°æ®å®Œæ•´æ€§
    """
    path = os.path.join(HISTORY_DIR, f"{kb_id}.json")
    
    if not os.path.exists(path):
        return []
    
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            return data
        else:
            if logger:
                logger.log_error("å¯¹è¯åŠ è½½", "æ•°æ®æ ¼å¼é”™è¯¯", {"kb_id": kb_id})
            return []
    
    except json.JSONDecodeError:
        # å°è¯•ä»å¤‡ä»½æ¢å¤
        backup_path = path + ".bak"
        if os.path.exists(backup_path):
            try:
                with open(backup_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if logger:
                    logger.log("å¯¹è¯åŠ è½½", "warning", f"âš ï¸ ä»å¤‡ä»½æ¢å¤å¯¹è¯å†å²: {kb_id}", {"kb_id": kb_id})
                return data if isinstance(data, list) else []
            except:
                pass
        
        if logger:
            logger.log_error("å¯¹è¯åŠ è½½", "æ–‡ä»¶æŸåä¸”æ— å¤‡ä»½", {"kb_id": kb_id})
        return []
    
    except Exception as e:
        if logger:
            logger.log_error("å¯¹è¯åŠ è½½", str(e), {"kb_id": kb_id})
        return []


def _extract_keywords(text, max_keywords=5):
    """æå–æ–‡æœ¬å…³é”®è¯"""
    try:
        import jieba
        # ä½¿ç”¨ jieba åˆ†è¯
        words = jieba.lcut(text)
    except:
        # é™çº§ï¼šç®€å•åˆ†è¯
        text = re.sub(r'[^\w\s]', ' ', text)
        words = text.split()
    
    # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
    stop_words = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ç­‰', 'åŠ', 'ä»¥', 'ä¸º', 'è¿™', 'é‚£', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'ä¸ª', 'ä¸­', 'ä¹Ÿ', 'éƒ½', 'å°±', 'è€Œ', 'è¦', 'ä¼š', 'å¯ä»¥', 'èƒ½', 'è¯´', 'å¯¹', 'ä½†', 'ä¸', 'æ²¡æœ‰'}
    keywords = [w for w in words if len(w) > 1 and w not in stop_words]
    
    # ç»Ÿè®¡è¯é¢‘
    word_freq = Counter(keywords)
    # è¿”å›é«˜é¢‘è¯
    return [word for word, _ in word_freq.most_common(max_keywords)]


def _is_similar_question(q1, q2, threshold=0.7):
    """æ£€æµ‹ä¸¤ä¸ªé—®é¢˜æ˜¯å¦ç›¸ä¼¼"""
    if not q1 or not q2:
        return False
    
    # ç®€å•çš„ç›¸ä¼¼æ€§æ£€æµ‹
    q1_clean = re.sub(r'[^\w]', '', q1.lower())
    q2_clean = re.sub(r'[^\w]', '', q2.lower())
    
    # å®Œå…¨ç›¸åŒ
    if q1_clean == q2_clean:
        return True
    
    # åŒ…å«å…³ç³»
    if len(q1_clean) > 5 and len(q2_clean) > 5:
        if q1_clean in q2_clean or q2_clean in q1_clean:
            return True
    
    # å…³é”®è¯é‡å åº¦
    words1 = set(_extract_keywords(q1, max_keywords=5))
    words2 = set(_extract_keywords(q2, max_keywords=5))
    
    if words1 and words2:
        overlap = len(words1 & words2) / len(words1 | words2)
        return overlap > threshold
    
    return False


def generate_follow_up_questions_safe(context_text, num_questions=3, existing_questions=None, timeout=60, logger=None, query_engine=None, llm_model=None):
    """
    å®‰å…¨åœ°ç”Ÿæˆè¿½é—®ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶å’Œé”™è¯¯å¤„ç†ï¼‰
    
    Args:
        context_text: ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆå›ç­”å†…å®¹ï¼‰
        num_questions: éœ€è¦ç”Ÿæˆçš„é—®é¢˜æ•°é‡
        existing_questions: å·²å­˜åœ¨çš„é—®é¢˜åˆ—è¡¨ï¼ˆç”¨äºå»é‡ï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
        logger: æ—¥å¿—è®°å½•å™¨
        query_engine: æŸ¥è¯¢å¼•æ“ï¼ˆç”¨äºè·å–LLMï¼‰
        llm_model: ç›´æ¥ä¼ å…¥LLMæ¨¡å‹
        
    Returns:
        list: ç”Ÿæˆçš„é—®é¢˜åˆ—è¡¨
    """
    result = {"questions": []}
    
    # åŸºäºçŸ¥è¯†åº“å†…å®¹ç”Ÿæˆé’ˆå¯¹æ€§é™çº§é—®é¢˜
    def get_smart_fallback(text, query_engine=None):
        fallback = []
        
        # å¦‚æœæœ‰æŸ¥è¯¢å¼•æ“ï¼Œå°è¯•ä»çŸ¥è¯†åº“è·å–ç›¸å…³ä¸»é¢˜
        if query_engine:
            try:
                # æå–å…³é”®è¯å¹¶æŸ¥è¯¢çŸ¥è¯†åº“
                keywords = _extract_keywords(text, max_keywords=2)
                if keywords:
                    # æŸ¥è¯¢çŸ¥è¯†åº“ä¸­çš„ç›¸å…³å†…å®¹
                    kb_results = query_engine.query(f"å…³äº{keywords[0]}çš„å†…å®¹")
                    if hasattr(kb_results, 'source_nodes') and kb_results.source_nodes:
                        # åŸºäºçŸ¥è¯†åº“å®é™…å†…å®¹ç”Ÿæˆé—®é¢˜
                        for node in kb_results.source_nodes[:2]:
                            node_text = node.text if hasattr(node, 'text') else str(node)
                            if len(node_text) > 50:
                                # åŸºäºå®é™…æ–‡æ¡£å†…å®¹ç”Ÿæˆé—®é¢˜
                                if "æ–¹æ³•" in node_text or "æ­¥éª¤" in node_text:
                                    fallback.append(f"æ–‡æ¡£ä¸­æåˆ°çš„{keywords[0]}å…·ä½“æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ")
                                elif "åŸå› " in node_text or "å› ä¸º" in node_text:
                                    fallback.append(f"ä¸ºä»€ä¹ˆ{keywords[0]}ä¼šäº§ç”Ÿè¿™æ ·çš„ç»“æœï¼Ÿ")
                                elif "æ¡ˆä¾‹" in node_text or "ä¾‹å­" in node_text:
                                    fallback.append(f"æœ‰å“ªäº›å…³äº{keywords[0]}çš„å…·ä½“æ¡ˆä¾‹ï¼Ÿ")
                                else:
                                    fallback.append(f"æ–‡æ¡£ä¸­è¿˜æœ‰å“ªäº›å…³äº{keywords[0]}çš„ä¿¡æ¯ï¼Ÿ")
            except Exception as e:
                if logger:
                    logger.log_warning("æ¨èé—®é¢˜", f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {e}")
        
        # å¦‚æœçŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥æˆ–æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨åŸºäºå†…å®¹çš„é™çº§
        if not fallback:
            # åŸºäºå›ç­”å†…å®¹ç‰¹å¾ç”Ÿæˆé—®é¢˜
            if any(word in text for word in ["æ–¹æ¡ˆ", "è§£å†³", "å¤„ç†", "åº”å¯¹"]):
                fallback.extend([
                    "è¿™ä¸ªæ–¹æ¡ˆçš„å…·ä½“å®æ–½æ­¥éª¤æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "å¯èƒ½é‡åˆ°å“ªäº›å®é™…é—®é¢˜ï¼Ÿ",
                    "æœ‰æ²¡æœ‰å…¶ä»–æ›¿ä»£æ–¹æ¡ˆï¼Ÿ"
                ])
            elif any(word in text for word in ["åˆ†æ", "ç ”ç©¶", "è°ƒæŸ¥", "æ•°æ®"]):
                fallback.extend([
                    "è¿™ä¸ªåˆ†æçš„æ•°æ®æ¥æºæ˜¯ä»€ä¹ˆï¼Ÿ",
                    "ç»“è®ºçš„å¯é æ€§å¦‚ä½•ï¼Ÿ",
                    "è¿˜æœ‰å“ªäº›ç›¸å…³çš„ç ”ç©¶å‘ç°ï¼Ÿ"
                ])
            elif any(word in text for word in ["æŠ€æœ¯", "å·¥å…·", "ç³»ç»Ÿ", "å¹³å°"]):
                fallback.extend([
                    "è¿™ä¸ªæŠ€æœ¯çš„é€‚ç”¨èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "ä¸ç°æœ‰æ–¹æ¡ˆç›¸æ¯”æœ‰ä½•ä¼˜åŠ¿ï¼Ÿ",
                    "å®é™…åº”ç”¨ä¸­çš„æ•ˆæœå¦‚ä½•ï¼Ÿ"
                ])
            else:
                # åŸºäºå…³é”®è¯ç”ŸæˆçŸ¥è¯†åº“ç›¸å…³é—®é¢˜
                keywords = _extract_keywords(text, max_keywords=2)
                if keywords:
                    fallback.extend([
                        f"æ–‡æ¡£ä¸­è¿˜æœ‰å“ªäº›å…³äº{keywords[0]}çš„è¯¦ç»†ä¿¡æ¯ï¼Ÿ",
                        f"é™¤äº†{keywords[0]}ï¼Œè¿˜æ¶‰åŠå“ªäº›ç›¸å…³æ¦‚å¿µï¼Ÿ",
                        f"è¿™äº›å†…å®¹åœ¨å®é™…åº”ç”¨ä¸­å¦‚ä½•ä½“ç°ï¼Ÿ"
                    ])
                else:
                    fallback.extend([
                        "æ–‡æ¡£ä¸­è¿˜æœ‰å“ªäº›ç›¸å…³çš„é‡è¦ä¿¡æ¯ï¼Ÿ",
                        "è¿™äº›å†…å®¹å¦‚ä½•ä¸å…¶ä»–éƒ¨åˆ†å…³è”ï¼Ÿ",
                        "åœ¨å®é™…åº”ç”¨ä¸­éœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ"
                    ])
        
        return fallback[:num_questions]
        
        return fallback[:num_questions]

    def _generate():
        nonlocal result
        print(f"ğŸ” _generateå¼€å§‹ï¼Œresultåˆå§‹çŠ¶æ€: {result}")
        
        if result is None:
            result = {"questions": []}
            print(f"ğŸ” resultä¸ºNoneï¼Œé‡æ–°åˆå§‹åŒ–: {result}")
        
        # å°è¯•ä»å¤šä¸ªæ¥æºè·å–LLM
        llm = None
        
        # 1. ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„LLM
        if llm_model:
            llm = llm_model
            print(f"ğŸ” ä½¿ç”¨ä¼ å…¥çš„LLM: {type(llm_model)}")
        
        # 2. ä»Settingsè·å–
        elif hasattr(Settings, 'llm') and Settings.llm:
            llm = Settings.llm
            print(f"ğŸ” ä½¿ç”¨Settings.llm: {type(Settings.llm)}")
        
        # 3. ä»query_engineè·å–
        elif query_engine and hasattr(query_engine, '_llm'):
            llm = query_engine._llm
            print(f"ğŸ” ä½¿ç”¨query_engine._llm: {type(query_engine._llm)}")
        
        if not llm:
            print("âš ï¸ LLMæœªè®¾ç½®ï¼Œä½¿ç”¨çŸ¥è¯†åº“æ„ŸçŸ¥é™çº§ç­–ç•¥")
            result["questions"] = get_smart_fallback(context_text, query_engine)
            return
        
        print(f"ğŸ” LLMè·å–æˆåŠŸï¼Œå¼€å§‹ç”Ÿæˆæ¨èé—®é¢˜...")

        try:
            # ä¼˜åŒ–ä¸Šä¸‹æ–‡å¤„ç†
            short_context = context_text[-1500:] if len(context_text) > 1500 else context_text
            
            # æ’é™¤å·²é—®è¿‡çš„é—®é¢˜
            existing_str = "\n".join(existing_questions[-10:]) if existing_questions else ""  # åªçœ‹æœ€è¿‘10ä¸ª
            
            # ğŸ†• å¢å¼ºçŸ¥è¯†åº“ç›¸å…³æ€§
            kb_context = ""
            relevant_topics = []
            
            if query_engine:
                try:
                    # æ›´ç²¾å‡†çš„å…³é”®è¯æå–
                    keywords = _extract_keywords(short_context, max_keywords=5)
                    if keywords:
                        # å°è¯•å¤šä¸ªæŸ¥è¯¢ç­–ç•¥
                        for i in range(min(2, len(keywords))):
                            try:
                                kb_query = " ".join(keywords[i:i+2])  # 2ä¸ªå…³é”®è¯ç»„åˆ
                                
                                if hasattr(query_engine, 'query'):
                                    kb_response = query_engine.query(kb_query)
                                elif hasattr(query_engine, 'chat'):
                                    kb_response = query_engine.chat(kb_query)
                                else:
                                    continue
                                
                                if kb_response and hasattr(kb_response, 'source_nodes'):
                                    for node in kb_response.source_nodes[:3]:
                                        if hasattr(node, 'metadata'):
                                            if 'file_name' in node.metadata:
                                                topic = node.metadata['file_name'].replace('.pdf', '').replace('.txt', '')
                                                if topic not in relevant_topics:
                                                    relevant_topics.append(topic)
                                            # è·å–éƒ¨åˆ†å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡
                                            if hasattr(node, 'text') and len(node.text) > 50:
                                                kb_context += node.text[:200] + "...\n"
                                
                                if len(relevant_topics) >= 2:  # æ‰¾åˆ°è¶³å¤Ÿçš„ç›¸å…³ä¸»é¢˜å°±åœæ­¢
                                    break
                            except:
                                continue
                                
                except Exception as e:
                    pass  # é™é»˜å¤±è´¥
            
            # æ„å»ºæ›´æ™ºèƒ½çš„æç¤ºè¯ï¼Œå¼ºè°ƒåŸºäºçŸ¥è¯†åº“å†…å®¹
            topic_hint = f"\nç›¸å…³æ–‡æ¡£ï¼š{', '.join(relevant_topics[:3])}" if relevant_topics else ""
            kb_hint = f"\nçŸ¥è¯†åº“å†…å®¹å‚è€ƒï¼š\n{kb_context[:300]}" if kb_context else ""
            
            prompt = (
                f"åŸºäºä»¥ä¸‹å›ç­”å†…å®¹å’ŒçŸ¥è¯†åº“ä¿¡æ¯ï¼Œç”Ÿæˆ {num_questions * 2} ä¸ªé«˜è´¨é‡çš„è¿½é—®é—®é¢˜ã€‚\n\n"
                f"é‡è¦è¦æ±‚ï¼š\n"
                f"1. é—®é¢˜å¿…é¡»åŸºäºçŸ¥è¯†åº“å®é™…å†…å®¹ï¼Œç¡®ä¿çŸ¥è¯†åº“èƒ½å¤Ÿå›ç­”\n"
                f"2. é—®é¢˜ç®€æ´ï¼ˆ10-15å­—ï¼‰\n"
                f"3. å…·æœ‰å¯å‘æ€§å’Œå®ç”¨æ€§\n"
                f"4. é¿å…é‡å¤å·²æœ‰é—®é¢˜\n"
                f"5. æ¯è¡Œä¸€ä¸ªé—®é¢˜ï¼Œä¸è¦ç¼–å·\n"
                f"6. ä¼˜å…ˆç”ŸæˆçŸ¥è¯†åº“æœ‰æ˜ç¡®ç­”æ¡ˆçš„é—®é¢˜\n\n"
                f"å›ç­”å†…å®¹ï¼š{short_context}\n"
                f"{topic_hint}"
                f"{kb_hint}\n"
                f"{'å·²é—®è¿‡çš„é—®é¢˜ï¼ˆé¿å…é‡å¤ï¼‰ï¼š\n' + existing_str if existing_str else ''}"
            )
            
            print(f"ğŸ” å¼€å§‹è°ƒç”¨LLMç”Ÿæˆæ¨èé—®é¢˜...")
            print(f"ğŸ” æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            try:
                resp = llm.complete(prompt)
                text = resp.text.strip()
                print(f"ğŸ” LLMå“åº”: {text[:100]}...")
            except Exception as e:
                print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                result["questions"] = get_smart_fallback(context_text, query_engine)
                return
            
            # è§£æç”Ÿæˆçš„é—®é¢˜
            questions = []
            for line in text.split('\n'):
                line = line.strip()
                if line:
                    # æ¸…ç†é—®é¢˜æ ¼å¼
                    question = re.sub(r'^[\d\.\-\s\*\â€¢]+', '', line).strip()
                    if question and len(question) > 5:  # è¿‡æ»¤å¤ªçŸ­çš„é—®é¢˜
                        questions.append(question)
            
            print(f"ğŸ” è§£æå‡º {len(questions)} ä¸ªé—®é¢˜: {questions[:3]}")
            
            # ç›´æ¥è®¾ç½®resultï¼Œè·³è¿‡å¤æ‚çš„éªŒè¯é€»è¾‘
            if questions:
                result["questions"] = questions[:num_questions]
                print(f"ğŸ” å¼ºåˆ¶è®¾ç½®result: {result}")
                return
            
            # å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œä½¿ç”¨fallback
            result["questions"] = get_smart_fallback(context_text, query_engine)
            print(f"ğŸ” ä½¿ç”¨fallback: {result}")
            return
                
        except Exception as e:
            print(f"âŒ æ¨èé—®é¢˜ç”Ÿæˆå¼‚å¸¸: {e}")
            if logger:
                logger.log_error("è¿½é—®ç”Ÿæˆ", str(e))
            if result is not None:
                result["questions"] = get_smart_fallback(context_text, query_engine)
    
    # ä½¿ç”¨çº¿ç¨‹æ‰§è¡Œå¹¶è®¾ç½®è¶…æ—¶
    thread = threading.Thread(target=_generate, daemon=True)
    thread.start()
    thread.join(timeout=timeout)
    
    if thread.is_alive():
        print(f"â° æ¨èé—®é¢˜ç”Ÿæˆè¶…æ—¶ ({timeout}ç§’)ï¼Œç­‰å¾…åå°å®Œæˆ...")
        # ç»™æ›´å¤šæ—¶é—´è®©LLMå®Œæˆ
        thread.join(timeout=5)  # å†ç­‰5ç§’
        
        if thread.is_alive():
            print(f"â° æœ€ç»ˆè¶…æ—¶ï¼Œä½¿ç”¨fallback")
            if logger:
                logger.log_error("è¿½é—®ç”Ÿæˆ", "æœ€ç»ˆè¶…æ—¶")
            return get_smart_fallback(context_text, query_engine)
        else:
            print(f"âœ… åå°ç”Ÿæˆå®Œæˆ")
    
    print(f"ğŸ” çº¿ç¨‹æ‰§è¡Œå®Œæˆï¼Œresult: {result}")
    
    if result is None or "questions" not in result:
        print(f"ğŸ” resultä¸ºç©ºæˆ–æ— questionsï¼Œè¿”å›fallback")
        return get_smart_fallback(context_text, query_engine)
    
    print(f"ğŸ” å‡½æ•°æœ€ç»ˆè¿”å›: {result['questions']}")
    return result["questions"]
    