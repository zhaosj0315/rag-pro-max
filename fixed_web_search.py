#!/usr/bin/env python3
"""
ä¿®å¤è”ç½‘æœç´¢åŠŸèƒ½
è§£å†³å…³é”®è¯æå–å’Œæœç´¢æ•ˆæœé—®é¢˜
"""

import re
import time
from typing import List, Dict, Any

class FixedWebSearchEngine:
    """ä¿®å¤çš„è”ç½‘æœç´¢å¼•æ“"""
    
    def __init__(self):
        pass
        
    def extract_smart_keywords(self, query: str) -> List[str]:
        """æ™ºèƒ½æå–å…³é”®è¯"""
        print(f"ğŸ” åˆ†ææŸ¥è¯¢: {query}")
        
        # ç§»é™¤ç–‘é—®è¯å’ŒåŠ©è¯
        remove_words = [
            'ä»€ä¹ˆæ˜¯', 'å“ªäº›', 'å¦‚ä½•', 'æ€ä¹ˆ', 'æ€æ ·', 'ä¸ºä»€ä¹ˆ', 'æ˜¯ä»€ä¹ˆ', 'æœ‰å“ªäº›',
            'what is', 'how to', 'how do', 'which', 'what are', 'why'
        ]
        
        cleaned_query = query
        for word in remove_words:
            cleaned_query = cleaned_query.replace(word, ' ')
        
        # æå–æœ‰æ„ä¹‰çš„è¯æ±‡
        keywords = []
        
        # ä¸­æ–‡è¯æ±‡ (2-6ä¸ªå­—ç¬¦)
        chinese_words = re.findall(r'[\u4e00-\u9fff]{2,6}', cleaned_query)
        for word in chinese_words:
            if word not in ['å›½å®¶', 'ä½¿ç”¨', 'å‘å°„åœº', 'æ–‡ä»¶', 'ä½ç½®', 'å®šä½']:
                keywords.append(word)
        
        # è‹±æ–‡è¯æ±‡ (3ä¸ªå­—ç¬¦ä»¥ä¸Š)
        english_words = re.findall(r'[a-zA-Z]{3,}', cleaned_query)
        for word in english_words:
            if word.lower() not in ['the', 'and', 'for', 'are', 'how', 'what']:
                keywords.append(word)
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°å…³é”®è¯ï¼Œä½¿ç”¨åŸæŸ¥è¯¢çš„æ ¸å¿ƒéƒ¨åˆ†
        if not keywords:
            # å¯¹äº"å“ªäº›å›½å®¶ä½¿ç”¨è¯¥å‘å°„åœº"è¿™ç±»æŸ¥è¯¢
            if 'å‘å°„åœº' in query:
                keywords = ['å‘å°„åœº', 'èˆªå¤©å‘å°„', 'launch site', 'spaceport']
            elif 'æ–‡ä»¶ä½ç½®' in query:
                keywords = ['æ–‡ä»¶å®šä½', 'æŸ¥æ‰¾æ–‡ä»¶', 'find file', 'file location']
            elif 'æœºå™¨å­¦ä¹ ' in query:
                keywords = ['æœºå™¨å­¦ä¹ ', 'Python', 'machine learning', 'ML library']
            elif 'äººå·¥æ™ºèƒ½' in query:
                keywords = ['äººå·¥æ™ºèƒ½', 'AI', 'artificial intelligence']
            else:
                # åˆ†è¯å¤„ç†
                words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', query)
                keywords = [w for w in words if len(w) >= 2]
        
        print(f"ğŸ”‘ æå–å…³é”®è¯: {keywords}")
        return keywords[:4]  # æœ€å¤š4ä¸ªå…³é”®è¯
    
    def generate_search_queries(self, keywords: List[str], original_query: str) -> List[str]:
        """ç”Ÿæˆæœç´¢æŸ¥è¯¢"""
        queries = []
        
        if not keywords:
            return [original_query]
        
        # 1. ç›´æ¥å…³é”®è¯ç»„åˆ
        if len(keywords) >= 2:
            queries.append(' '.join(keywords[:2]))
        
        # 2. å•ä¸ªå…³é”®è¯
        for kw in keywords[:2]:
            queries.append(kw)
        
        # 3. è‹±æ–‡æŸ¥è¯¢
        english_kws = [kw for kw in keywords if re.match(r'^[a-zA-Z\s]+$', kw)]
        if english_kws:
            queries.append(' '.join(english_kws[:2]))
        
        # 4. ä¸­æ–‡æŸ¥è¯¢
        chinese_kws = [kw for kw in keywords if re.search(r'[\u4e00-\u9fff]', kw)]
        if chinese_kws:
            queries.append(' '.join(chinese_kws[:2]))
        
        # å»é‡
        unique_queries = []
        seen = set()
        for q in queries:
            if q and q not in seen:
                unique_queries.append(q)
                seen.add(q)
        
        print(f"ğŸ“ ç”ŸæˆæŸ¥è¯¢: {unique_queries}")
        return unique_queries[:3]  # æœ€å¤š3ä¸ªæŸ¥è¯¢
    
    def search_with_ddgs(self, query: str, max_results: int = 8) -> List[Dict]:
        """ä½¿ç”¨ddgsæœç´¢"""
        try:
            # å°è¯•æ–°çš„ddgsåŒ…
            try:
                from ddgs import DDGS
                print(f"  ä½¿ç”¨æ–°ç‰ˆddgsåŒ…æœç´¢...")
            except ImportError:
                # å›é€€åˆ°æ—§ç‰ˆæœ¬
                from duckduckgo_search import DDGS
                print(f"  ä½¿ç”¨æ—§ç‰ˆduckduckgo_searchåŒ…æœç´¢...")
            
            results = []
            
            # æœç´¢ç­–ç•¥ï¼šå…ˆä¸­æ–‡åŒºåŸŸï¼Œå†è‹±æ–‡åŒºåŸŸï¼Œæœ€åå…¨çƒ
            search_configs = [
                {'region': 'cn-zh', 'desc': 'ä¸­æ–‡åŒºåŸŸ'},
                {'region': 'us-en', 'desc': 'è‹±æ–‡åŒºåŸŸ'},
                {'region': None, 'desc': 'å…¨çƒæœç´¢'}
            ]
            
            with DDGS() as ddgs:
                for config in search_configs:
                    try:
                        print(f"    å°è¯•{config['desc']}æœç´¢...")
                        if config['region']:
                            search_results = list(ddgs.text(
                                query, 
                                max_results=max_results//2,
                                region=config['region']
                            ))
                        else:
                            search_results = list(ddgs.text(
                                query, 
                                max_results=max_results
                            ))
                        
                        if search_results:
                            results.extend(search_results)
                            print(f"    âœ… {config['desc']}: {len(search_results)} æ¡ç»“æœ")
                            break  # æ‰¾åˆ°ç»“æœå°±åœæ­¢
                        else:
                            print(f"    âŒ {config['desc']}: æ— ç»“æœ")
                            
                    except Exception as e:
                        print(f"    âŒ {config['desc']}æœç´¢å¤±è´¥: {e}")
                        continue
            
            return results[:max_results]
            
        except Exception as e:
            print(f"âŒ æœç´¢å¼•æ“é”™è¯¯: {e}")
            return []
    
    def enhanced_search(self, original_query: str) -> Dict[str, Any]:
        """å¢å¼ºæœç´¢ä¸»å‡½æ•°"""
        print(f"ğŸš€ å¯åŠ¨ä¿®å¤ç‰ˆè”ç½‘æœç´¢...")
        start_time = time.time()
        
        # 1. æ™ºèƒ½å…³é”®è¯æå–
        keywords = self.extract_smart_keywords(original_query)
        
        # 2. ç”Ÿæˆæœç´¢æŸ¥è¯¢
        search_queries = self.generate_search_queries(keywords, original_query)
        
        # 3. æ‰§è¡Œæœç´¢
        all_results = []
        
        for query in search_queries:
            print(f"ğŸ” æœç´¢æŸ¥è¯¢: {query}")
            results = self.search_with_ddgs(query)
            
            if results:
                for result in results:
                    result['search_query'] = query
                all_results.extend(results)
                print(f"  âœ… è·å¾— {len(results)} æ¡ç»“æœ")
                
                # å¦‚æœå·²ç»æœ‰è¶³å¤Ÿç»“æœï¼Œåœæ­¢æœç´¢
                if len(all_results) >= 10:
                    break
            else:
                print(f"  âŒ æ— ç»“æœ")
        
        # 4. å»é‡
        unique_results = []
        seen_urls = set()
        
        for result in all_results:
            url = result.get('href', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        # 5. ç®€å•è´¨é‡è¿‡æ»¤
        filtered_results = []
        for result in unique_results:
            title = result.get('title', '').lower()
            body = result.get('body', '').lower()
            
            # è¿‡æ»¤æ˜æ˜¾çš„åƒåœ¾å†…å®¹
            if not any(spam in title + body for spam in ['å¹¿å‘Š', 'æ¨å¹¿', 'ad', 'advertisement', 'ç‚¹å‡»', 'click here']):
                filtered_results.append(result)
        
        search_time = time.time() - start_time
        
        return {
            'original_query': original_query,
            'keywords': keywords,
            'search_queries': search_queries,
            'total_results': len(all_results),
            'unique_results': len(unique_results),
            'final_results': filtered_results[:8],  # æœ€å¤š8ä¸ªç»“æœ
            'search_time': round(search_time, 2),
            'success': len(filtered_results) > 0
        }

def test_fixed_search():
    """æµ‹è¯•ä¿®å¤çš„æœç´¢åŠŸèƒ½"""
    engine = FixedWebSearchEngine()
    
    test_queries = [
        "å“ªäº›å›½å®¶ä½¿ç”¨è¯¥å‘å°„åœºï¼Ÿ",
        "å¦‚ä½•å®šä½æ–‡ä»¶ä½ç½®",
        "Pythonæœºå™¨å­¦ä¹ åº“æœ‰å“ªäº›",
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
        print('='*60)
        
        result = engine.enhanced_search(query)
        
        print(f"\nğŸ“Š æœç´¢ç»“æœ:")
        print(f"  æœç´¢æˆåŠŸ: {result['success']}")
        print(f"  æœç´¢æ—¶é—´: {result['search_time']}ç§’")
        print(f"  æ€»ç»“æœæ•°: {result['total_results']}")
        print(f"  å»é‡ç»“æœ: {result['unique_results']}")
        print(f"  æœ€ç»ˆç»“æœ: {len(result['final_results'])}")
        
        if result['final_results']:
            print(f"\nğŸ¯ å‰3ä¸ªç»“æœ:")
            for i, res in enumerate(result['final_results'][:3], 1):
                print(f"  {i}. {res.get('title', 'No Title')}")
                print(f"     {res.get('href', 'No URL')}")
                print(f"     æ‘˜è¦: {res.get('body', 'No Body')[:100]}...")
                print()

if __name__ == "__main__":
    test_fixed_search()
