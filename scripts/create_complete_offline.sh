#!/bin/bash

echo "ðŸ“¦ RAG Pro Max å®Œå…¨ç¦»çº¿åŒ…æž„å»º (åŒ…å«æ‰€æœ‰æ¨¡åž‹)"
echo "===================================================="

# æ¸…ç†æ—§åŒ…
rm -rf rag-pro-max-complete-offline
rm -f rag-pro-max-complete-offline.tar.gz

# åˆ›å»ºç›®å½•
mkdir -p rag-pro-max-complete-offline/{offline_packages,hf_models,ollama_models,ollama_bin}

echo "ðŸ“‹ å¤åˆ¶åº”ç”¨ä»£ç ..."
cp -r src/ rag-pro-max-complete-offline/
cp requirements.txt rag-pro-max-complete-offline/
cp -r config/ rag-pro-max-complete-offline/ 2>/dev/null || true

echo "ðŸ“¦ ä¸‹è½½AMD64 Pythonä¾èµ–..."
pip download -r requirements.txt -d rag-pro-max-complete-offline/offline_packages/ --platform linux_x86_64 --only-binary=:all: --python-version 3.10

echo "ðŸ¤– ä¸‹è½½AMD64 OllamaäºŒè¿›åˆ¶..."
curl -L https://github.com/ollama/ollama/releases/latest/download/ollama-linux-amd64 -o rag-pro-max-complete-offline/ollama_bin/ollama
chmod +x rag-pro-max-complete-offline/ollama_bin/ollama

echo "ðŸ§  ä¸‹è½½HuggingFaceæ¨¡åž‹..."
python3 -c "
from sentence_transformers import SentenceTransformer
import shutil
import os
model = SentenceTransformer('BAAI/bge-small-zh-v1.5')
cache_dir = os.path.expanduser('~/.cache/huggingface/hub')
target_dir = 'rag-pro-max-complete-offline/hf_models'
if os.path.exists(cache_dir):
    shutil.copytree(cache_dir, target_dir, dirs_exist_ok=True)
print('âœ… HFæ¨¡åž‹å¤åˆ¶å®Œæˆ')
"

echo "ðŸŽ¯ ä¸‹è½½Ollamaæ¨¡åž‹ (gemma2:2b - çº¦1.6GB)..."
# å¯åŠ¨ä¸´æ—¶OllamaæœåŠ¡ä¸‹è½½æ¨¡åž‹
export OLLAMA_MODELS="$(pwd)/rag-pro-max-complete-offline/ollama_models"
mkdir -p "$OLLAMA_MODELS"

# ä½¿ç”¨æœ¬åœ°Ollamaä¸‹è½½æ¨¡åž‹
ollama serve &
OLLAMA_PID=$!
sleep 10

echo "ðŸ“¥ ä¸‹è½½gemma2:2bæ¨¡åž‹..."
ollama pull gemma2:2b

# åœæ­¢OllamaæœåŠ¡
kill $OLLAMA_PID 2>/dev/null || true

# å¤åˆ¶æ¨¡åž‹æ–‡ä»¶
cp -r ~/.ollama/models/* rag-pro-max-complete-offline/ollama_models/ 2>/dev/null || true

echo "ðŸ“ åˆ›å»ºå®Œå…¨ç¦»çº¿å®‰è£…è„šæœ¬..."
cat > rag-pro-max-complete-offline/install_complete_offline.sh << 'EOF'
#!/bin/bash
echo "ðŸš€ RAG Pro Max å®Œå…¨ç¦»çº¿å®‰è£… (åŒ…å«æ‰€æœ‰æ¨¡åž‹)"

# å®‰è£…Pythonä¾èµ–
echo "ðŸ“¦ å®‰è£…Pythonä¾èµ–..."
pip install --no-index --find-links offline_packages/ -r requirements.txt

# å®‰è£…Ollama
echo "ðŸ¤– å®‰è£…Ollama..."
sudo cp ollama_bin/ollama /usr/local/bin/
sudo chmod +x /usr/local/bin/ollama

# å¤åˆ¶HFæ¨¡åž‹
echo "ðŸ§  å¤åˆ¶HuggingFaceæ¨¡åž‹..."
mkdir -p ~/.cache/huggingface/
cp -r hf_models/* ~/.cache/huggingface/ 2>/dev/null || true

# å¤åˆ¶Ollamaæ¨¡åž‹
echo "ðŸŽ¯ å¤åˆ¶Ollamaæ¨¡åž‹..."
mkdir -p ~/.ollama/
cp -r ollama_models ~/.ollama/models 2>/dev/null || true

# åˆ›å»ºå¯åŠ¨è„šæœ¬
echo "ðŸ“ åˆ›å»ºå¯åŠ¨è„šæœ¬..."
cat > start_complete_offline.sh << 'STARTEOF'
#!/bin/bash
echo "ðŸš€ å¯åŠ¨RAG Pro Maxå®Œå…¨ç¦»çº¿ç‰ˆ..."
echo "âœ… æ‰€æœ‰æ¨¡åž‹å·²é¢„è£…ï¼Œæ— éœ€ç½‘ç»œè¿žæŽ¥"

export OLLAMA_HOST=0.0.0.0:11434
ollama serve &
sleep 5

echo "ðŸŽ¯ éªŒè¯æ¨¡åž‹..."
ollama list

echo "ðŸŒŸ å¯åŠ¨åº”ç”¨..."
streamlit run src/apppro.py --server.address=0.0.0.0 --server.port=8501
STARTEOF
chmod +x start_complete_offline.sh

echo "âœ… å®Œå…¨ç¦»çº¿å®‰è£…å®Œæˆï¼"
echo "ðŸš€ è¿è¡Œ ./start_complete_offline.sh å¯åŠ¨åº”ç”¨"
echo "ðŸŒ è®¿é—®: http://localhost:8501"
EOF

chmod +x rag-pro-max-complete-offline/install_complete_offline.sh

echo "ðŸ“„ åˆ›å»ºREADME..."
cat > rag-pro-max-complete-offline/README_COMPLETE_OFFLINE.md << 'EOF'
# RAG Pro Max å®Œå…¨ç¦»çº¿ç‰ˆ

## ç‰¹ç‚¹
- âœ… å®Œå…¨ç¦»çº¿ï¼Œæ— éœ€ä»»ä½•ç½‘ç»œè¿žæŽ¥
- âœ… åŒ…å«æ‰€æœ‰Pythonä¾èµ–åŒ…
- âœ… åŒ…å«HuggingFaceåµŒå…¥æ¨¡åž‹
- âœ… åŒ…å«Ollama + gemma2:2bå¤§è¯­è¨€æ¨¡åž‹
- âœ… ä¸€é”®å®‰è£…ï¼Œä¸€é”®å¯åŠ¨

## å®‰è£…æ­¥éª¤
1. è§£åŽ‹: `tar -xzf rag-pro-max-complete-offline.tar.gz`
2. å®‰è£…: `cd rag-pro-max-complete-offline && sudo bash install_complete_offline.sh`
3. å¯åŠ¨: `./start_complete_offline.sh`
4. è®¿é—®: http://localhost:8501

## ç³»ç»Ÿè¦æ±‚
- Linux AMD64 (x86_64)
- Python 3.8+
- 8GB+ å†…å­˜
- 25GB+ ç£ç›˜ç©ºé—´

## å®Œå…¨ç¦»çº¿
æ­¤ç‰ˆæœ¬åŒ…å«æ‰€æœ‰å¿…éœ€ç»„ä»¶ï¼Œéƒ¨ç½²åŽæ— éœ€ä»»ä½•ç½‘ç»œè¿žæŽ¥å³å¯æ­£å¸¸ä½¿ç”¨ã€‚
EOF

echo "ðŸ—œï¸ æ‰“åŒ…..."
tar -czf rag-pro-max-complete-offline.tar.gz rag-pro-max-complete-offline/

echo "âœ… å®Œå…¨ç¦»çº¿åŒ…æž„å»ºå®Œæˆ"
echo "ðŸ“¦ æ–‡ä»¶: rag-pro-max-complete-offline.tar.gz"
ls -lh rag-pro-max-complete-offline.tar.gz
echo ""
echo "ðŸŽ¯ è¿™æ˜¯çœŸæ­£çš„å®Œå…¨ç¦»çº¿ç‰ˆæœ¬ï¼ŒåŒ…å«:"
echo "  - æ‰€æœ‰Pythonä¾èµ–"
echo "  - HuggingFaceæ¨¡åž‹"
echo "  - Ollama + gemma2:2bæ¨¡åž‹"
echo "  - æ— éœ€ä»»ä½•ç½‘ç»œè¿žæŽ¥"
