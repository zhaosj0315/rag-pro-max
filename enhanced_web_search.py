#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„è”ç½‘æœç´¢åŠŸèƒ½
è§£å†³æœç´¢æ•ˆæœå·®çš„é—®é¢˜ï¼Œæå‡æœç´¢è´¨é‡å’Œå‡†ç¡®æ€§
"""

import re
import time
from typing import List, Dict, Any
from urllib.parse import urlparse

class EnhancedWebSearchEngine:
    """å¢å¼ºçš„è”ç½‘æœç´¢å¼•æ“"""
    
    def __init__(self):
        self.search_engines = {
            'duckduckgo': self._search_duckduckgo,
            'bing': self._search_bing,
            'google': self._search_google_fallback
        }
        
    def optimize_search_query(self, original_query: str) -> Dict[str, Any]:
        """ä¼˜åŒ–æœç´¢æŸ¥è¯¢"""
        print(f"ğŸ” åŸå§‹æŸ¥è¯¢: {original_query}")
        
        # 1. æŸ¥è¯¢æ„å›¾åˆ†æ
        intent = self._analyze_query_intent(original_query)
        
        # 2. å…³é”®è¯æå–å’Œä¼˜åŒ–
        keywords = self._extract_optimized_keywords(original_query, intent)
        
        # 3. å¤šè¯­è¨€æŸ¥è¯¢ç”Ÿæˆ
        queries = self._generate_multilingual_queries(keywords, intent)
        
        return {
            'intent': intent,
            'keywords': keywords,
            'queries': queries,
            'original': original_query
        }
    
    def _analyze_query_intent(self, query: str) -> str:
        """åˆ†ææŸ¥è¯¢æ„å›¾"""
        # æ„å›¾æ¨¡å¼åŒ¹é…
        intent_patterns = {
            'factual': ['ä»€ä¹ˆæ˜¯', 'è°æ˜¯', 'å“ªäº›', 'å¤šå°‘', 'ä½•æ—¶', 'what is', 'who is', 'when', 'how many'],
            'howto': ['å¦‚ä½•', 'æ€ä¹ˆ', 'æ€æ ·', 'how to', 'how do', 'how can'],
            'comparison': ['æ¯”è¾ƒ', 'å¯¹æ¯”', 'åŒºåˆ«', 'vs', 'versus', 'compare', 'difference'],
            'list': ['åˆ—å‡º', 'åå•', 'æ¸…å•', 'list', 'names of', 'æœ‰å“ªäº›'],
            'location': ['åœ¨å“ª', 'ä½ç½®', 'åœ°ç‚¹', 'where', 'location', 'place'],
            'definition': ['å®šä¹‰', 'å«ä¹‰', 'æ„æ€', 'definition', 'meaning', 'means']
        }
        
        query_lower = query.lower()
        for intent_type, patterns in intent_patterns.items():
            if any(pattern in query_lower for pattern in patterns):
                return intent_type
        
        return 'general'
    
    def _extract_optimized_keywords(self, query: str, intent: str) -> List[str]:
        """æå–ä¼˜åŒ–çš„å…³é”®è¯"""
        # ç§»é™¤åœç”¨è¯
        stop_words = {
            'zh': ['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†æ˜¯', 'ç„¶è€Œ', 'å› ä¸º', 'æ‰€ä»¥'],
            'en': ['the', 'is', 'are', 'was', 'were', 'and', 'or', 'but', 'because', 'so', 'that', 'this']
        }
        
        # æå–æ ¸å¿ƒåè¯å’ŒåŠ¨è¯
        keywords = []
        
        # ä¸­æ–‡å…³é”®è¯æå–
        chinese_chars = re.findall(r'[\u4e00-\u9fff]+', query)
        for word in chinese_chars:
            if len(word) >= 2 and word not in stop_words['zh']:
                keywords.append(word)
        
        # è‹±æ–‡å…³é”®è¯æå–
        english_words = re.findall(r'[a-zA-Z]+', query)
        for word in english_words:
            if len(word) >= 3 and word.lower() not in stop_words['en']:
                keywords.append(word)
        
        # æ ¹æ®æ„å›¾è°ƒæ•´å…³é”®è¯
        if intent == 'list':
            keywords = [kw for kw in keywords if kw not in ['åˆ—å‡º', 'list']]
        elif intent == 'location':
            keywords.extend(['ä½ç½®', 'location'])
        
        return keywords[:5]  # é™åˆ¶å…³é”®è¯æ•°é‡
    
    def _generate_multilingual_queries(self, keywords: List[str], intent: str) -> List[str]:
        """ç”Ÿæˆå¤šè¯­è¨€æŸ¥è¯¢"""
        queries = []
        
        # åŸºç¡€å…³é”®è¯ç»„åˆ
        if len(keywords) >= 2:
            queries.append(' '.join(keywords[:3]))
        
        # æ ¹æ®æ„å›¾ç”Ÿæˆç‰¹å®šæŸ¥è¯¢
        if intent == 'factual':
            if any('\u4e00' <= c <= '\u9fff' for c in ' '.join(keywords)):
                queries.append(f"{keywords[0]} æ˜¯ä»€ä¹ˆ")
                if len(keywords) > 1:
                    queries.append(f"{keywords[0]} {keywords[1]} ä»‹ç»")
            queries.append(f"what is {' '.join(keywords)}")
            
        elif intent == 'list':
            if any('\u4e00' <= c <= '\u9fff' for c in ' '.join(keywords)):
                queries.append(f"{keywords[0]} åå•")
                queries.append(f"{keywords[0]} æœ‰å“ªäº›")
            queries.append(f"list of {' '.join(keywords)}")
            
        elif intent == 'howto':
            if any('\u4e00' <= c <= '\u9fff' for c in ' '.join(keywords)):
                queries.append(f"å¦‚ä½• {keywords[0]}")
            queries.append(f"how to {' '.join(keywords)}")
            
        elif intent == 'location':
            if any('\u4e00' <= c <= '\u9fff' for c in ' '.join(keywords)):
                queries.append(f"{keywords[0]} ä½ç½®")
                queries.append(f"{keywords[0]} åœ¨å“ªé‡Œ")
            queries.append(f"{' '.join(keywords)} location")
            
        # æ·»åŠ è‹±æ–‡æŸ¥è¯¢å˜ä½“
        if keywords:
            queries.append(' '.join(keywords))
            if len(keywords) >= 2:
                queries.append(f'"{keywords[0]}" {keywords[1]}')
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_queries = []
        seen = set()
        for q in queries:
            if q not in seen and len(q.strip()) > 2:
                unique_queries.append(q)
                seen.add(q)
        
        return unique_queries[:4]  # æœ€å¤š4ä¸ªæŸ¥è¯¢
    
    def _search_duckduckgo(self, query: str, max_results: int = 10) -> List[Dict]:
        """DuckDuckGoæœç´¢"""
        try:
            from duckduckgo_search import DDGS
            
            results = []
            with DDGS() as ddgs:
                # å°è¯•ä¸­æ–‡åŒºåŸŸ
                if any('\u4e00' <= c <= '\u9fff' for c in query):
                    try:
                        cn_results = list(ddgs.text(query, max_results=max_results//2, region='cn-zh'))
                        results.extend(cn_results)
                    except:
                        pass
                
                # å°è¯•è‹±æ–‡åŒºåŸŸ
                try:
                    en_results = list(ddgs.text(query, max_results=max_results//2, region='us-en'))
                    results.extend(en_results)
                except:
                    pass
                
                # å¦‚æœç»“æœä¸å¤Ÿï¼Œå°è¯•å…¨çƒæœç´¢
                if len(results) < max_results // 2:
                    try:
                        global_results = list(ddgs.text(query, max_results=max_results))
                        results.extend(global_results)
                    except:
                        pass
            
            return results
            
        except Exception as e:
            print(f"âŒ DuckDuckGoæœç´¢å¤±è´¥: {e}")
            return []
    
    def _search_bing(self, query: str, max_results: int = 10) -> List[Dict]:
        """Bingæœç´¢ (å¤‡ç”¨)"""
        # è¿™é‡Œå¯ä»¥å®ç°Bing APIæœç´¢
        # ç›®å‰è¿”å›ç©ºåˆ—è¡¨ä½œä¸ºå ä½ç¬¦
        return []
    
    def _search_google_fallback(self, query: str, max_results: int = 10) -> List[Dict]:
        """Googleæœç´¢å¤‡ç”¨æ–¹æ¡ˆ"""
        # è¿™é‡Œå¯ä»¥å®ç°Google Custom Search API
        # ç›®å‰è¿”å›ç©ºåˆ—è¡¨ä½œä¸ºå ä½ç¬¦
        return []
    
    def enhanced_search(self, original_query: str, max_results: int = 20) -> Dict[str, Any]:
        """å¢å¼ºæœç´¢ä¸»å‡½æ•°"""
        print(f"ğŸš€ å¯åŠ¨å¢å¼ºè”ç½‘æœç´¢...")
        start_time = time.time()
        
        # 1. æŸ¥è¯¢ä¼˜åŒ–
        optimization = self.optimize_search_query(original_query)
        print(f"ğŸ¯ æŸ¥è¯¢æ„å›¾: {optimization['intent']}")
        print(f"ğŸ”‘ å…³é”®è¯: {optimization['keywords']}")
        print(f"ğŸ“ ç”ŸæˆæŸ¥è¯¢: {optimization['queries']}")
        
        # 2. å¤šå¼•æ“æœç´¢
        all_results = []
        
        for query in optimization['queries']:
            print(f"ğŸ” æœç´¢: {query}")
            
            # å°è¯•DuckDuckGo
            ddg_results = self._search_duckduckgo(query, max_results//len(optimization['queries']))
            if ddg_results:
                for result in ddg_results:
                    result['search_engine'] = 'duckduckgo'
                    result['search_query'] = query
                all_results.extend(ddg_results)
                print(f"  âœ… DuckDuckGo: {len(ddg_results)} æ¡ç»“æœ")
            else:
                print(f"  âŒ DuckDuckGo: æ— ç»“æœ")
        
        # 3. ç»“æœå»é‡å’Œè´¨é‡è¿‡æ»¤
        unique_results = self._deduplicate_results(all_results)
        filtered_results = self._filter_quality_results(unique_results, original_query)
        
        search_time = time.time() - start_time
        
        return {
            'query_optimization': optimization,
            'total_raw_results': len(all_results),
            'unique_results': len(unique_results),
            'final_results': filtered_results,
            'search_time': round(search_time, 2),
            'success': len(filtered_results) > 0
        }
    
    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:
        """å»é‡ç»“æœ"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            url = result.get('href', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        return unique_results
    
    def _filter_quality_results(self, results: List[Dict], original_query: str) -> List[Dict]:
        """è¿‡æ»¤é«˜è´¨é‡ç»“æœ"""
        if not results:
            return []
        
        # è´¨é‡è¯„åˆ†
        scored_results = []
        query_keywords = set(re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', original_query.lower()))
        
        for result in results:
            score = 0
            title = result.get('title', '').lower()
            body = result.get('body', '').lower()
            url = result.get('href', '').lower()
            
            # æ ‡é¢˜ç›¸å…³æ€§
            title_matches = sum(1 for kw in query_keywords if kw in title)
            score += title_matches * 3
            
            # å†…å®¹ç›¸å…³æ€§
            body_matches = sum(1 for kw in query_keywords if kw in body)
            score += body_matches * 1
            
            # URLè´¨é‡
            domain = urlparse(url).netloc
            if any(trusted in domain for trusted in ['wikipedia', 'baidu', 'zhihu', 'gov', 'edu']):
                score += 2
            
            # é¿å…åƒåœ¾å†…å®¹
            if any(spam in title + body for spam in ['å¹¿å‘Š', 'æ¨å¹¿', 'ad', 'advertisement']):
                score -= 5
            
            result['quality_score'] = score
            if score > 0:
                scored_results.append(result)
        
        # æŒ‰è´¨é‡æ’åº
        scored_results.sort(key=lambda x: x['quality_score'], reverse=True)
        
        return scored_results[:10]  # è¿”å›å‰10ä¸ªé«˜è´¨é‡ç»“æœ

def test_enhanced_search():
    """æµ‹è¯•å¢å¼ºæœç´¢åŠŸèƒ½"""
    engine = EnhancedWebSearchEngine()
    
    test_queries = [
        "å“ªäº›å›½å®¶ä½¿ç”¨è¯¥å‘å°„åœºï¼Ÿ",
        "å¦‚ä½•å®šä½æ–‡ä»¶ä½ç½®",
        "Pythonæœºå™¨å­¦ä¹ åº“æœ‰å“ªäº›",
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
    ]
    
    for query in test_queries:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯•æŸ¥è¯¢: {query}")
        print('='*50)
        
        result = engine.enhanced_search(query)
        
        print(f"æœç´¢æˆåŠŸ: {result['success']}")
        print(f"æœç´¢æ—¶é—´: {result['search_time']}ç§’")
        print(f"åŸå§‹ç»“æœ: {result['total_raw_results']} æ¡")
        print(f"å»é‡ç»“æœ: {result['unique_results']} æ¡")
        print(f"æœ€ç»ˆç»“æœ: {len(result['final_results'])} æ¡")
        
        if result['final_results']:
            print("\nå‰3ä¸ªç»“æœ:")
            for i, res in enumerate(result['final_results'][:3], 1):
                print(f"{i}. {res.get('title', 'No Title')}")
                print(f"   URL: {res.get('href', 'No URL')}")
                print(f"   è¯„åˆ†: {res.get('quality_score', 0)}")

if __name__ == "__main__":
    test_enhanced_search()
