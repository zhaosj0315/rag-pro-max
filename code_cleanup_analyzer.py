#!/usr/bin/env python3
"""
ä»£ç æ¸…ç†åˆ†æå™¨ - Phase 1
æ‰«æé¡¹ç›®ä¸­çš„åºŸå¼ƒä»£ç ã€æœªä½¿ç”¨å‡½æ•°ã€é‡å¤é€»è¾‘
"""

import os
import ast
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
import json

class CodeCleanupAnalyzer:
    """ä»£ç æ¸…ç†åˆ†æå™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.src_dir = self.project_root / "src"
        self.analysis_results = {
            'unused_functions': [],
            'unused_imports': [],
            'duplicate_functions': [],
            'commented_code': [],
            'large_functions': [],
            'summary': {}
        }
    
    def analyze_project(self):
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        print("ğŸ” å¼€å§‹ä»£ç æ¸…ç†åˆ†æ...")
        
        # 1. æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        python_files = list(self.src_dir.rglob("*.py"))
        print(f"ğŸ“ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
        
        # 2. åˆ†ææœªä½¿ç”¨çš„å‡½æ•°
        self._analyze_unused_functions(python_files)
        
        # 3. åˆ†ææœªä½¿ç”¨çš„å¯¼å…¥
        self._analyze_unused_imports(python_files)
        
        # 4. æ£€æµ‹é‡å¤å‡½æ•°
        self._detect_duplicate_functions(python_files)
        
        # 5. æ£€æµ‹æ³¨é‡Šä»£ç 
        self._detect_commented_code(python_files)
        
        # 6. æ£€æµ‹è¿‡å¤§å‡½æ•°
        self._detect_large_functions(python_files)
        
        # 7. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self._generate_report()
        
        print("âœ… ä»£ç æ¸…ç†åˆ†æå®Œæˆï¼")
    
    def _analyze_unused_functions(self, python_files: List[Path]):
        """åˆ†ææœªä½¿ç”¨çš„å‡½æ•°"""
        print("ğŸ” åˆ†ææœªä½¿ç”¨çš„å‡½æ•°...")
        
        # æ”¶é›†æ‰€æœ‰å‡½æ•°å®šä¹‰
        all_functions = {}
        function_calls = set()
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æAST
                tree = ast.parse(content)
                
                # æ”¶é›†å‡½æ•°å®šä¹‰
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        func_name = node.name
                        if not func_name.startswith('_'):  # è·³è¿‡ç§æœ‰å‡½æ•°
                            all_functions[func_name] = str(file_path)
                
                # æ”¶é›†å‡½æ•°è°ƒç”¨
                for match in re.finditer(r'(\w+)\s*\(', content):
                    function_calls.add(match.group(1))
                    
            except Exception as e:
                print(f"âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥: {file_path} - {e}")
        
        # æ‰¾å‡ºæœªä½¿ç”¨çš„å‡½æ•°
        unused_functions = []
        for func_name, file_path in all_functions.items():
            if func_name not in function_calls:
                unused_functions.append({
                    'function': func_name,
                    'file': file_path,
                    'type': 'unused_function'
                })
        
        self.analysis_results['unused_functions'] = unused_functions
        print(f"ğŸ“Š å‘ç° {len(unused_functions)} ä¸ªå¯èƒ½æœªä½¿ç”¨çš„å‡½æ•°")
    
    def _analyze_unused_imports(self, python_files: List[Path]):
        """åˆ†ææœªä½¿ç”¨çš„å¯¼å…¥"""
        print("ğŸ” åˆ†ææœªä½¿ç”¨çš„å¯¼å…¥...")
        
        unused_imports = []
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾importè¯­å¥
                import_lines = []
                for i, line in enumerate(content.split('\n')):
                    if re.match(r'^\s*(import|from)\s+', line):
                        import_lines.append((i+1, line.strip()))
                
                # æ£€æŸ¥æ¯ä¸ªå¯¼å…¥æ˜¯å¦è¢«ä½¿ç”¨
                for line_num, import_line in import_lines:
                    if 'import' in import_line:
                        # æå–å¯¼å…¥çš„æ¨¡å—å
                        if import_line.startswith('from'):
                            match = re.search(r'from\s+[\w.]+\s+import\s+([\w,\s]+)', import_line)
                            if match:
                                imports = [imp.strip() for imp in match.group(1).split(',')]
                        else:
                            match = re.search(r'import\s+([\w.]+)', import_line)
                            if match:
                                imports = [match.group(1).split('.')[-1]]
                        
                        # æ£€æŸ¥æ˜¯å¦åœ¨ä»£ç ä¸­ä½¿ç”¨
                        for imp in imports:
                            if imp not in content.replace(import_line, ''):
                                unused_imports.append({
                                    'import': imp,
                                    'line': line_num,
                                    'file': str(file_path),
                                    'full_line': import_line
                                })
                                
            except Exception as e:
                print(f"âš ï¸ åˆ†æå¯¼å…¥å¤±è´¥: {file_path} - {e}")
        
        self.analysis_results['unused_imports'] = unused_imports
        print(f"ğŸ“Š å‘ç° {len(unused_imports)} ä¸ªå¯èƒ½æœªä½¿ç”¨çš„å¯¼å…¥")
    
    def _detect_duplicate_functions(self, python_files: List[Path]):
        """æ£€æµ‹é‡å¤å‡½æ•°"""
        print("ğŸ” æ£€æµ‹é‡å¤å‡½æ•°...")
        
        function_signatures = {}
        duplicates = []
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾å‡½æ•°å®šä¹‰
                for match in re.finditer(r'def\s+(\w+)\s*\([^)]*\):', content):
                    func_name = match.group(1)
                    
                    if func_name in function_signatures:
                        duplicates.append({
                            'function': func_name,
                            'files': [function_signatures[func_name], str(file_path)],
                            'type': 'duplicate_function'
                        })
                    else:
                        function_signatures[func_name] = str(file_path)
                        
            except Exception as e:
                print(f"âš ï¸ æ£€æµ‹é‡å¤å¤±è´¥: {file_path} - {e}")
        
        self.analysis_results['duplicate_functions'] = duplicates
        print(f"ğŸ“Š å‘ç° {len(duplicates)} ä¸ªé‡å¤å‡½æ•°")
    
    def _detect_commented_code(self, python_files: List[Path]):
        """æ£€æµ‹æ³¨é‡Šä»£ç """
        print("ğŸ” æ£€æµ‹æ³¨é‡Šä»£ç ...")
        
        commented_code = []
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                for i, line in enumerate(lines):
                    # æ£€æµ‹æ³¨é‡Šæ‰çš„ä»£ç è¡Œ
                    if re.match(r'^\s*#\s*(def|class|import|if|for|while|try)', line):
                        commented_code.append({
                            'file': str(file_path),
                            'line': i+1,
                            'content': line.strip(),
                            'type': 'commented_code'
                        })
                        
            except Exception as e:
                print(f"âš ï¸ æ£€æµ‹æ³¨é‡Šä»£ç å¤±è´¥: {file_path} - {e}")
        
        self.analysis_results['commented_code'] = commented_code
        print(f"ğŸ“Š å‘ç° {len(commented_code)} è¡Œæ³¨é‡Šä»£ç ")
    
    def _detect_large_functions(self, python_files: List[Path]):
        """æ£€æµ‹è¿‡å¤§å‡½æ•°"""
        print("ğŸ” æ£€æµ‹è¿‡å¤§å‡½æ•°...")
        
        large_functions = []
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        # è®¡ç®—å‡½æ•°è¡Œæ•°
                        func_lines = node.end_lineno - node.lineno + 1
                        if func_lines > 50:  # è¶…è¿‡50è¡Œçš„å‡½æ•°
                            large_functions.append({
                                'function': node.name,
                                'file': str(file_path),
                                'lines': func_lines,
                                'start_line': node.lineno,
                                'type': 'large_function'
                            })
                            
            except Exception as e:
                print(f"âš ï¸ æ£€æµ‹å¤§å‡½æ•°å¤±è´¥: {file_path} - {e}")
        
        self.analysis_results['large_functions'] = large_functions
        print(f"ğŸ“Š å‘ç° {len(large_functions)} ä¸ªè¿‡å¤§å‡½æ•°")
    
    def _generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        # ç»Ÿè®¡ä¿¡æ¯
        summary = {
            'total_files': len(list(self.src_dir.rglob("*.py"))),
            'unused_functions_count': len(self.analysis_results['unused_functions']),
            'unused_imports_count': len(self.analysis_results['unused_imports']),
            'duplicate_functions_count': len(self.analysis_results['duplicate_functions']),
            'commented_code_count': len(self.analysis_results['commented_code']),
            'large_functions_count': len(self.analysis_results['large_functions'])
        }
        
        self.analysis_results['summary'] = summary
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        report_file = self.project_root / "code_cleanup_analysis.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆå¯è¯»æŠ¥å‘Š
        self._generate_readable_report()
        
        print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def _generate_readable_report(self):
        """ç”Ÿæˆå¯è¯»çš„åˆ†ææŠ¥å‘Š"""
        
        report_content = f"""# ä»£ç æ¸…ç†åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†ææ¦‚è§ˆ

- **æ€»æ–‡ä»¶æ•°**: {self.analysis_results['summary']['total_files']}
- **æœªä½¿ç”¨å‡½æ•°**: {self.analysis_results['summary']['unused_functions_count']} ä¸ª
- **æœªä½¿ç”¨å¯¼å…¥**: {self.analysis_results['summary']['unused_imports_count']} ä¸ª
- **é‡å¤å‡½æ•°**: {self.analysis_results['summary']['duplicate_functions_count']} ä¸ª
- **æ³¨é‡Šä»£ç **: {self.analysis_results['summary']['commented_code_count']} è¡Œ
- **è¿‡å¤§å‡½æ•°**: {self.analysis_results['summary']['large_functions_count']} ä¸ª

## ğŸ—‘ï¸ å»ºè®®æ¸…ç†é¡¹ç›®

### æœªä½¿ç”¨å‡½æ•°
"""
        
        for item in self.analysis_results['unused_functions'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            report_content += f"- `{item['function']}()` in {item['file']}\n"
        
        report_content += f"\n### æœªä½¿ç”¨å¯¼å…¥\n"
        for item in self.analysis_results['unused_imports'][:10]:
            report_content += f"- `{item['import']}` in {item['file']}:{item['line']}\n"
        
        report_content += f"\n### é‡å¤å‡½æ•°\n"
        for item in self.analysis_results['duplicate_functions'][:10]:
            report_content += f"- `{item['function']}()` in {', '.join(item['files'])}\n"
        
        # ä¿å­˜å¯è¯»æŠ¥å‘Š
        report_file = self.project_root / "CODE_CLEANUP_REPORT.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“„ å¯è¯»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = CodeCleanupAnalyzer()
    analyzer.analyze_project()
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. æŸ¥çœ‹ CODE_CLEANUP_REPORT.md äº†è§£è¯¦ç»†åˆ†æç»“æœ")
    print("2. æŸ¥çœ‹ code_cleanup_analysis.json è·å–å®Œæ•´æ•°æ®")
    print("3. å¼€å§‹Phase 2: å®‰å…¨æ¸…ç†é˜¶æ®µ")

if __name__ == "__main__":
    main()
