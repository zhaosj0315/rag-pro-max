#!/usr/bin/env python3
"""
æµ‹è¯•LLMè¿æ¥
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.utils.llm_manager import get_llm_manager

def test_llm_connection():
    """æµ‹è¯•LLMè¿æ¥"""
    print("ğŸ” æµ‹è¯•LLMè¿æ¥...")
    
    # è·å–LLMç®¡ç†å™¨
    llm_manager = get_llm_manager()
    
    # åˆ›å»ºOllama LLM
    llm = llm_manager.get_llm(
        provider="Ollama",
        model="gpt-oss:20b", 
        key="",
        url="http://localhost:11434"
    )
    
    if llm is None:
        print("âŒ LLMåˆ›å»ºå¤±è´¥")
        return False
    
    print("âœ… LLMåˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•ç®€å•è°ƒç”¨
    try:
        print("ğŸ”„ æµ‹è¯•LLMè°ƒç”¨...")
        response = llm.complete("Hello")
        print(f"âœ… LLMè°ƒç”¨æˆåŠŸ: {response.text[:50]}...")
        return True
    except Exception as e:
        print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    success = test_llm_connection()
    sys.exit(0 if success else 1)
